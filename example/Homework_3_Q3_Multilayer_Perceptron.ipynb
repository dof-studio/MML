{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Homework III\n",
    "\n",
    "### 3. Multilayer Perceptron (bh2821)\n",
    "\n",
    "* This document is open sourced under Apeche License Version 2.0\n",
    "* Author: Nathmath Huang (bh2821)\n",
    "* Date  : May 9, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Prior to Anything`:\n",
    "\n",
    "....* Even though I used torch, I just used its capability of computing on CUDA but `NEVER used its Autograd functionality`.\n",
    "\n",
    "....* In my implementation, the base class `nn_Parameter` is completely compatible for `numpy` and `torch` backend,\n",
    "\n",
    "....* so you can see I have manually programmed the gradient system and even a mimic scalable Autograd framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Dict, Tuple, Any, Optional, Union, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import lzma\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have cuda\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether using `numpy` as the backend or `torch`\n",
    "backend = \"torch\"; _backend = torch\n",
    "device = \"cuda\"    \n",
    "\n",
    "# Feel free to change those parameters since I have debugged and ensured all of them are useful.\n",
    "# Though, their result may NOT be completely the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Matrix Wrapper Library (self-implemented)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This object class is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "class Object:\n",
    "    \"\"\"\n",
    "    Base Type for all advanced n-dimensional data types.\n",
    "    \"\"\"\n",
    "   \n",
    "    __attr__ = \"MML.Object\"  \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "   \n",
    "    def __repr__(self):\n",
    "        return f\"Object (Abstract Data Type).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This matrix class is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "class Matrix(Object):\n",
    "    \"\"\"\n",
    "    A production-level Matrix class that provides a unified interface for common matrix operations used in machine learning.\n",
    "    The underlying data is stored as either a numpy.ndarray or a torch.Tensor depending on the chosen backend.\n",
    "    This class supports element-wise arithmetic, matrix multiplication, transpose, determinant, inverse, trace, and SVD.\n",
    "    Internal optimizations avoid repeated string comparisons by setting boolean flags during initialization.\n",
    "    \"\"\"\n",
    "    __attr__ = \"MML.Matrix\"    \n",
    "    \n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Returns natural exponent value as a single-value Matrix.\n",
    "        \n",
    "        Returns:\n",
    "            -------\n",
    "            Matrix with 0 shape. exp value.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Matrix(np.e, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "        else:\n",
    "            return Matrix(torch.e, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "    \n",
    "    def pi(self):\n",
    "        \"\"\"\n",
    "        Returns pi value as a single-value Matrix.\n",
    "        \n",
    "        Returns:\n",
    "            -------\n",
    "            Matrix with 0 shape. pi value.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Matrix(np.pi, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "        else:\n",
    "            return Matrix(torch.pi, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "    \n",
    "    def __init__(self, data, backend=\"numpy\", *, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Initializes a Matrix instance with the specified backend.\n",
    "        \n",
    "        Args:\n",
    "            data (array-like): Input data to be converted into a matrix.\n",
    "            backend (str): The backend to use (\"numpy\" or \"torch\").\n",
    "            dtype(str): The type of data to be stored in (any type or None).\n",
    "            device (str): Device where the data is stored on (\"cpu\" or \"cuda\", or None).\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If an unsupported backend is provided.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self._backend = backend.lower()\n",
    "        if self._backend not in (\"numpy\", \"torch\"):\n",
    "            raise ValueError(\"Unsupported backend. Please choose 'numpy' or 'torch'.\")\n",
    "        self._is_numpy = (self._backend == \"numpy\")\n",
    "        self._is_torch = (self._backend == \"torch\")\n",
    "        \n",
    "        # Convert input data to the appropriate type.\n",
    "        # By Nathmath Huang\n",
    "        if self._is_numpy:\n",
    "            self.data = np.array(data, dtype=dtype)\n",
    "        else:\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed but backend 'torch' was requested.\")\n",
    "            self.data = data.to(device, dtype=dtype) if isinstance(data, torch.Tensor) else torch.tensor(data, device=device, dtype=dtype)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the Matrix showing the backend, shape, and data.\n",
    "        \"\"\"\n",
    "        return f\"Matrix(backend={self._backend}, shape={self.shape}, data=\\n{self.data})\"\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "       \"\"\"\n",
    "       Allows subscription using a[i, j]. \n",
    "       If the result is an array, it returns a new Matrix; otherwise, the scalar value.\n",
    "       \"\"\"\n",
    "       result = self.data[key]\n",
    "       if (self._is_numpy and isinstance(result, np.ndarray)) or (self._is_torch and torch is not None and isinstance(result, torch.Tensor)):\n",
    "           return Matrix(result, backend=self._backend)\n",
    "       return result\n",
    "   \n",
    "    def __setitem__(self, key, value):\n",
    "        \"\"\"\n",
    "        Allows assignment using a[i, j] = value.\n",
    "        If the value is a Matrix instance, its underlying data is used.\n",
    "        \"\"\"\n",
    "        if isinstance(value, Matrix):\n",
    "            value = value.data\n",
    "        self.data[key] = value\n",
    "   \n",
    "    def submatrix(self, key):\n",
    "      \"\"\"\n",
    "      Retrieves a sub-array of the matrix using the given key while ensuring the result remains two-dimensional.\n",
    "      For example, using a[:, 1] will return a Matrix of shape (m, 1) rather than (m,).\n",
    "      \n",
    "      Args:\n",
    "          key: Indexing key (can be an int, slice, or tuple of such) for sub-array extraction.\n",
    "      \n",
    "      Returns:\n",
    "          Matrix: A new Matrix instance representing the sub-array with two dimensions.\n",
    "      \"\"\"\n",
    "      result = self.data[key]\n",
    "      # For numpy backend: if result is 1D but the original matrix is 2D, adjust the shape.\n",
    "      if self._is_numpy and isinstance(result, np.ndarray):\n",
    "          if result.ndim == 1 and len(self.data.shape) == 2:\n",
    "              if isinstance(key, tuple):\n",
    "                  if len(key) == 2:\n",
    "                      if isinstance(key[0], slice) and isinstance(key[1], int):\n",
    "                          # Selecting a column -> reshape to (m, 1)\n",
    "                          result = result[:, np.newaxis]\n",
    "                      elif isinstance(key[0], int) and isinstance(key[1], slice):\n",
    "                          # Selecting a row -> reshape to (1, n)\n",
    "                          result = result[np.newaxis, :]\n",
    "                      else:\n",
    "                          result = np.atleast_2d(result)\n",
    "                  else:\n",
    "                      result = np.atleast_2d(result)\n",
    "              else:\n",
    "                  # key is a single index (e.g., a[1]) -> treat as row selection.\n",
    "                  result = result[np.newaxis, :]\n",
    "      # For torch backend: similar adjustments using unsqueeze.\n",
    "      elif self._is_torch and torch is not None and isinstance(result, torch.Tensor):\n",
    "          if result.dim() == 1 and len(self.data.shape) == 2:\n",
    "              if isinstance(key, tuple):\n",
    "                  if len(key) == 2:\n",
    "                      if isinstance(key[0], slice) and isinstance(key[1], int):\n",
    "                          result = result.unsqueeze(1)  # Make column vector.\n",
    "                      elif isinstance(key[0], int) and isinstance(key[1], slice):\n",
    "                          result = result.unsqueeze(0)  # Make row vector.\n",
    "                      else:\n",
    "                          result = result.unsqueeze(0)\n",
    "                  else:\n",
    "                      result = result.unsqueeze(0)\n",
    "              else:\n",
    "                  result = result.unsqueeze(0)\n",
    "      return Matrix(result, backend=self._backend) \n",
    "   \n",
    "    @property\n",
    "    def shape(self):\n",
    "        \"\"\"\n",
    "        Returns the shape of the matrix.\n",
    "        \"\"\"\n",
    "        return self.data.shape\n",
    "    \n",
    "    @property\n",
    "    def dtype(self):\n",
    "        \"\"\"\n",
    "        Returns the data type of the matrix elements.\n",
    "        \"\"\"\n",
    "        return self.data.dtype\n",
    "    \n",
    "    @property\n",
    "    def device(self):\n",
    "        \"\"\"\n",
    "        Returns the data device of the matrix elements.\n",
    "        \"\"\"\n",
    "        if self._backend == \"numpy\":\n",
    "            return \"cpu\"\n",
    "        else:\n",
    "            return self.data.device.type\n",
    "\n",
    "    def reshape(self, shape):\n",
    "        \"\"\"\n",
    "        Converts the matrix into a new shape.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix object with the specified shape.\n",
    "        \"\"\"\n",
    "        return Matrix(self.data.reshape(shape), backend=self._backend)\n",
    "    \n",
    "    def astype(self, dtype):\n",
    "        \"\"\"\n",
    "        Converts the underlying data to the specified type.\n",
    "        \n",
    "        For the numpy backend, it uses np.ndarray.astype.\n",
    "        For the torch backend, it maps the input (which can be a torch.dtype, a string, or a numpy type)\n",
    "        to the corresponding torch dtype and uses tensor.to(dtype=...).\n",
    "        \n",
    "        Args:\n",
    "            dtype: The desired data type. For numpy, any valid numpy dtype is accepted.\n",
    "                   For torch, this can be a torch.dtype, a string (e.g., \"float32\", \"int64\"),\n",
    "                   or a numpy dtype.\n",
    "                   \n",
    "        Returns:\n",
    "            A new Matrix instance with the data converted to the specified type.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            new_data = self.data.astype(dtype)\n",
    "            return Matrix(new_data, backend=\"numpy\")\n",
    "        else:\n",
    "            # Map the input dtype to a torch dtype.\n",
    "            torch_dtype = None\n",
    "            if isinstance(dtype, torch.dtype):\n",
    "                torch_dtype = dtype\n",
    "            elif isinstance(dtype, str):\n",
    "                mapping = {\n",
    "                    \"float32\": torch.float32,\n",
    "                    \"float\": torch.float32,\n",
    "                    \"float64\": torch.float64,\n",
    "                    \"double\": torch.float64,\n",
    "                    \"int32\": torch.int32,\n",
    "                    \"int\": torch.int32,\n",
    "                    \"int64\": torch.int64,\n",
    "                    \"long\": torch.int64,\n",
    "                    \"bool\": torch.bool,\n",
    "                    \"complex64\": torch.complex64,\n",
    "                    \"complex128\": torch.complex128\n",
    "                }\n",
    "                if dtype in mapping:\n",
    "                    torch_dtype = mapping[dtype]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported dtype string: {dtype}\")\n",
    "            elif isinstance(dtype, (np.dtype, type)):\n",
    "                np_dtype = np.dtype(dtype)\n",
    "                mapping = {\n",
    "                    np.dtype(\"float32\"): torch.float32,\n",
    "                    np.dtype(\"float64\"): torch.float64,\n",
    "                    np.dtype(\"int32\"): torch.int32,\n",
    "                    np.dtype(\"int64\"): torch.int64,\n",
    "                    np.dtype(\"bool\"): torch.bool,\n",
    "                    np.dtype(\"complex64\"): torch.complex64,\n",
    "                    np.dtype(\"complex128\"): torch.complex128,\n",
    "                }\n",
    "                if np_dtype in mapping:\n",
    "                    torch_dtype = mapping[np_dtype]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported numpy dtype: {np_dtype}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported dtype argument: {dtype}\")\n",
    "            new_data = self.data.to(dtype=torch_dtype)\n",
    "            return Matrix(new_data, backend=\"torch\")\n",
    "\n",
    "    def to(self, backend, *, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Converts the matrix to the specified backend and optionally sets the device for torch tensors.\n",
    "        \n",
    "        Args:\n",
    "            backend (str): The target backend (\"numpy\" or \"torch\").\n",
    "            dtype (str, optional): The target type (any numpy or torch type nor None for auto inferenence).\n",
    "            device (str, optional): The target device for torch tensors (e.g., \"cpu\" or \"cuda\").\n",
    "                                    Ignored if converting to numpy.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix object with data in the target backend and on the specified device.\n",
    "        \"\"\"\n",
    "        target = backend.lower()\n",
    "        if target == self._backend:\n",
    "            # Already in the target backend: for torch, adjust device if specified.\n",
    "            if self._is_torch:\n",
    "                new_data = self.data.to(device = device, dtype = dtype)\n",
    "                return Matrix(new_data, backend=\"torch\")\n",
    "            return Matrix(self.data, backend=self._backend, device=device, dtype=dtype)\n",
    "        if target == \"numpy\":\n",
    "            # Converting from torch to numpy: always bring to CPU.\n",
    "            if self._is_torch:\n",
    "                return Matrix(self.data.cpu().to(dtype = dtype).numpy(), backend=\"numpy\")\n",
    "        elif target == \"torch\":\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed.\")\n",
    "            if self._is_numpy:\n",
    "                new_data = torch.tensor(self.data, device = device, dtype = dtype)\n",
    "                return Matrix(new_data, backend=\"torch\")\n",
    "        raise ValueError(\"Unsupported backend conversion.\")\n",
    "\n",
    "    def to_rational(self):\n",
    "        \"\"\"\n",
    "        Converts all values stored in the matrix to rational numbers (fractions.Fraction).\n",
    "        For the numpy backend, returns a new Matrix with a numpy array of Fraction objects (dtype=object).\n",
    "        For the torch backend, due to limitations of torch tensors with non-numeric types,\n",
    "        the conversion is performed via numpy and the underlying data becomes a numpy array of Fraction objects,\n",
    "        while the backend attribute is preserved as 'torch'.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            vec_func = np.vectorize(lambda x: float(x.real))\n",
    "            new_data = vec_func(self.data)\n",
    "            return Matrix(new_data, backend=\"numpy\")\n",
    "        else:\n",
    "            # Convert torch tensor to numpy, then to Fraction.\n",
    "            np_data = self.data.cpu().numpy()\n",
    "            vec_func = np.vectorize(lambda x: float(x.real))\n",
    "            new_data = vec_func(np_data)\n",
    "            # Although backend remains 'torch', data is now a numpy array.\n",
    "            return Matrix(new_data, backend=\"torch\")\n",
    "\n",
    "    def to_complex(self):\n",
    "        \"\"\"\n",
    "        Converts all values stored in the matrix to complex numbers.\n",
    "        For the numpy backend, returns a new Matrix with a numpy array of complex numbers.\n",
    "        For the torch backend, returns a new Matrix with data converted to a torch complex tensor.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            new_data = self.data.astype(complex)\n",
    "            return Matrix(new_data, backend=\"numpy\")\n",
    "        else:\n",
    "            if not torch.is_complex(self.data):\n",
    "                new_data = self.data.to(torch.complex64)\n",
    "                return Matrix(new_data, backend=\"torch\")\n",
    "            return Matrix(self.data, backend=\"torch\")\n",
    "        \n",
    "    def _apply_op(self, other, op):\n",
    "        \"\"\"\n",
    "        Internal helper to apply an element-wise binary operation.\n",
    "        \n",
    "        Args:\n",
    "            other (Matrix or scalar): The other operand.\n",
    "            op (callable): A function that applies the desired operation element-wise.\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: A new Matrix instance with the operation applied.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Matrix) else other\n",
    "        result = op(self.data, other_val)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def copy(self, *, backend=None, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a deep copy of the current matrix with the specified backend and data type.\n",
    "        \n",
    "        Args:\n",
    "            backend (str): The backend for the copied matrix. Default is None.\n",
    "            dtype: Desired data type for the result. Default is None.\n",
    "            device: Device to which the tensor should be moved if applicable. Default is None.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A deep copy of the current matrix with the specified parameters.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if backend is None:\n",
    "                return Matrix(self.data.copy(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Matrix(self.data.copy(), backend=backend, dtype=dtype, device=device)\n",
    "        else:\n",
    "            if backend is None:\n",
    "                return Matrix(self.data.clone().detach(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Matrix(self.data.clone().detach(), backend=backend, dtype=dtype, device=device)\n",
    "    \n",
    "    def append(self, to_append, axis=0):\n",
    "        \"\"\"\n",
    "        Append a scalar (broadcasted) or an array to the matrix along the specified axis.\n",
    "        \n",
    "        Args:\n",
    "            to_append: A scalar value or an array-like object (or Matrix) to append.\n",
    "            axis (int): Axis along which to append. For 2D matrices, use axis=0 (append row)\n",
    "                        or axis=1 (append column).\n",
    "                        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix instance with the appended data.\n",
    "        \"\"\"\n",
    "        orig_shape = self.data.shape\n",
    "    \n",
    "        # If to_append is an instance of self, extract its underlying data.\n",
    "        if isinstance(to_append, type(self)):\n",
    "            append_data = to_append.data\n",
    "        else:\n",
    "            # If to_append is a scalar, create an array of appropriate shape.\n",
    "            if np.isscalar(to_append):\n",
    "                if axis == 0:\n",
    "                    new_shape = (1, orig_shape[1])\n",
    "                elif axis == 1:\n",
    "                    new_shape = (orig_shape[0], 1)\n",
    "                else:\n",
    "                    raise ValueError(\"Axis out of bounds. Only axis=0 or axis=1 are supported.\")\n",
    "                if self._is_numpy:\n",
    "                    append_data = np.full(new_shape, to_append, dtype=self.data.dtype)\n",
    "                else:\n",
    "                    append_data = torch.full(new_shape, to_append, dtype=self.data.dtype, device=self.data.device.type)\n",
    "            # Not a scalar\n",
    "            else:\n",
    "                # If the input is a matrix.\n",
    "                if isinstance(to_append, Matrix):\n",
    "                    if self._is_numpy:\n",
    "                        append_data = np.array(to_append.data.copy(), dtype=self.data.dtype)\n",
    "                    else:\n",
    "                        append_data = torch.tensor(to_append.data.clone().detach(), dtype=self.data.dtype, device=self.data.device.type)\n",
    "                    \n",
    "                # Otherwise, assume to_append is array-like.\n",
    "                else:\n",
    "                    if self._is_numpy:\n",
    "                        append_data = np.array(to_append.copy(), dtype=self.data.dtype)\n",
    "                    else:\n",
    "                        append_data = torch.tensor(to_append.clone().detach(), dtype=self.data.dtype, device=self.data.device.type)\n",
    "                    \n",
    "                # Validate dimensions (assuming 2D matrices)\n",
    "                if len(append_data.shape) != len(orig_shape):\n",
    "                    raise ValueError(\"Dimension mismatch: appended data must match dimensions of the matrix.\")\n",
    "                if axis == 0:\n",
    "                    if append_data.shape[1:] != orig_shape[1:]:\n",
    "                        raise ValueError(\"Shape mismatch for axis 0: appended array must have the same number of columns.\")\n",
    "                elif axis == 1:\n",
    "                    if append_data.shape[0] != orig_shape[0]:\n",
    "                        raise ValueError(\"Shape mismatch for axis 1: appended array must have the same number of rows.\")\n",
    "                else:\n",
    "                    raise ValueError(\"Axis out of bounds. Only axis=0 or axis=1 are supported.\")\n",
    "        \n",
    "        # Concatenate along the specified axis using the appropriate backend.\n",
    "        if self._is_numpy:\n",
    "            new_data = np.concatenate((self.data, append_data), axis=axis)\n",
    "        else:\n",
    "            new_data = torch.cat((self.data, append_data), dim=axis)\n",
    "        \n",
    "        return Matrix(new_data, backend=self._backend)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Element-wise addition.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Matrix(self.data + other_val, backend=self._backend)\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        \"\"\"\n",
    "        Right-hand element-wise addition.\n",
    "        \"\"\"\n",
    "        return self.__add__(other)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        \"\"\"\n",
    "        Element-wise subtraction.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Matrix(self.data - other_val, backend=self._backend)\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        \"\"\"\n",
    "        Right-hand element-wise subtraction.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Matrix(other_val - self.data, backend=self._backend)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"\n",
    "        Element-wise multiplication.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Matrix(self.data * other_val, backend=self._backend)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        \"\"\"\n",
    "        Right-hand element-wise multiplication.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Matrix(other_val * self.data, backend=self._backend)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        \"\"\"\n",
    "        Element-wise true division.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Matrix(self.data / other_val, backend=self._backend)\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        \"\"\"\n",
    "        Right-hand element-wise true division.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Matrix(other_val / self.data, backend=self._backend)\n",
    "    \n",
    "    def __matmul__(self, other):\n",
    "        \"\"\"\n",
    "        Matrix multiplication using the @ operator.\n",
    "        \n",
    "        Args:\n",
    "            other (Matrix or array-like): The matrix to multiply with.\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: The result of the matrix multiplication.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        result = self.data @ other_val\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Equals operator. \"\"\"\n",
    "        if isinstance(other, Object):\n",
    "            if np.prod(self.data.shape) == 1 and np.prod(other.data.shape) == 1:\n",
    "                # Scalar to scalar, output a scalar\n",
    "                return bool(self.flatten().data == other.flatten().data)\n",
    "            else:\n",
    "                return Matrix(self.data == other.data, backend=self._backend)\n",
    "                \n",
    "        elif np.prod(self.data.shape) == 1 and hasattr(other, \"__len__\") == False:\n",
    "            # Scalar to scalar, output a scalar\n",
    "            return bool(self.data == other)\n",
    "        else:\n",
    "            return Matrix(self.data == other, backend=self._backend)\n",
    "    \n",
    "    def __pow__(self, to_power):\n",
    "        \"\"\"Element-wise power.\"\"\"\n",
    "        return self._apply_op(to_power, lambda a, b: a ** b)\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        \"\"\"Right-hand element-wise power.\"\"\"\n",
    "        return self.__pow__(other)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"\n",
    "        Returns the negation of the matrix.\n",
    "        \"\"\"\n",
    "        return Matrix(-self.data, backend=self._backend) \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the matrix.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def unique(self):\n",
    "        \"\"\"\n",
    "        Returns the unique values of the elements that are non-zero.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The unique value matrix.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.unique(self.data)\n",
    "        else:\n",
    "            result = torch.unique(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def nonzero(self):\n",
    "        \"\"\"\n",
    "        Returns the indices of the elements that are non-zero.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The indices matrix.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = self.data.nonzero()\n",
    "        else:\n",
    "            result = self.data.nonzero()\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def any(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the element-wise logical OR along a specified axis.\n",
    "        \n",
    "        Args: \n",
    "            axis (int or None): Axis along which to apply the `any` operation. If not provided,\n",
    "                                it applies over all elements of the matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the result of the logical OR operation along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.any(self.data, axis=axis)\n",
    "        else:\n",
    "            result = self.data.any(dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def all(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the element-wise logical AND along a specified axis.\n",
    "    \n",
    "        Args: \n",
    "            axis (int or None): Axis along which to apply the `all` operation. If not provided,\n",
    "                                it applies over all elements of the matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the result of the logical AND operation along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.all(self.data, axis=axis)\n",
    "        else:\n",
    "            result = self.data.all(dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def round(self, digits = 0):\n",
    "        \"\"\"\n",
    "        Rounds the data to a specified number of decimal places.\n",
    "    \n",
    "        Args:\n",
    "            digits (int): The number of decimal places to round the data. Default is 0.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the rounded values of the original data.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.round(self.data, decimals = digits)\n",
    "        else:\n",
    "            result = torch.round(self.data, decimals = digits)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def mean(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the mean of the matrix along a specified axis.\n",
    "    \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the mean. If None, computes the mean across all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed mean values.\n",
    "    \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.mean(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.mean(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def median(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the median along a given axis.\n",
    "    \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the median. Default is None, which computes over all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the computed medians.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.median(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.median(self.data)\n",
    "            else:\n",
    "                result, _ = torch.median(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def std(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the standard deviation of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the standard deviation. If None, computes across all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed standard deviation values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.std(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.std(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def var(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the variance of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the variance. If None, computes across all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed variance values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.var(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.var(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def min(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the minimum of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the minimum. If None, computes across all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed minimum values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if axis is None:\n",
    "                result = np.min(self.data)\n",
    "            else:\n",
    "                result = np.min(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.min(self.data)\n",
    "            else:\n",
    "                result, indices = torch.min(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def max(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the maximum of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the maximum. If None, computes across all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed maximum values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if axis is None:\n",
    "                result = np.max(self.data)\n",
    "            else:\n",
    "                result = np.max(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.max(self.data)\n",
    "            else:\n",
    "                result, indices = torch.max(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def clip(self, a_min=None, a_max=None):\n",
    "        \"\"\"\n",
    "        Clips the values of the matrix to a specified range.\n",
    "    \n",
    "        Args: \n",
    "            a_min (float or None): Minimum value for clipping. If None, no minimum is applied.\n",
    "            a_max (float or None): Maximum value for clipping. If None, no maximum is applied.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the clipped values of the original data within the specified range.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.clip(self.data, a_min=a_min, a_max=a_max)\n",
    "        else:\n",
    "            result = torch.clip(self.data, min=a_min, max=a_max)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def sum(self, axis = None, keepdims = False):\n",
    "        \"\"\"\n",
    "        Computes the sum of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the sum. If None, computes across all dimensions.\n",
    "            keepdims (bool): If keeps the dimension or not.\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed sum values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sum(self.data, axis=axis, keepdims=keepdims)\n",
    "        else:\n",
    "            result = torch.sum(self.data, dim=axis, keepdim=keepdims)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def cumsum(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the cumulative sum of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the cumulative sum. If None, computes across all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed cumulative sum values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cumsum(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.cumsum(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def prod(self, axis = None, keepdims = False):\n",
    "        \"\"\"\n",
    "        Computes the product of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the product. If None, computes across all dimensions.\n",
    "            keepdims (bool): If keeps the dimension or not.\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed product values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.prod(self.data, axis=axis, keepdims=keepdims)\n",
    "        else:\n",
    "            result = torch.prod(self.data, dim=axis, keepdim=keepdims)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def cumprod(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the cumulative product of the matrix along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the cumulative product. If None, computes across all dimensions.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix: A new instance containing the computed cumulative product values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cumprod(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.cumprod(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise exponential.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: New matrix with exponential applied.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.exp(self.data)\n",
    "        else:\n",
    "            result = torch.exp(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def sin(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise sine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the sine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sin(self.data)\n",
    "        else:\n",
    "            result = torch.sin(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def cos(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise cosine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the cosine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cos(self.data)\n",
    "        else:\n",
    "            result = torch.cos(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def tan(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise tangent.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the tangent values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.tan(self.data)\n",
    "        else:\n",
    "            result = torch.tan(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def sinh(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise hyperbolic sine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the hyperbolic sine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sinh(self.data)\n",
    "        else:\n",
    "            result = torch.sinh(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def cosh(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise hyperbolic cosine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the hyperbolic cosine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cosh(self.data)\n",
    "        else:\n",
    "            result = torch.cosh(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def tanh(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise hyperbolic tangent.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the hyperbolic tangent values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.tanh(self.data)\n",
    "        else:\n",
    "            result = torch.tanh(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def abs(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise absolute values.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: New matrix with absolute values applied.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.abs(self.data)\n",
    "        else:\n",
    "            result = torch.abs(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def log(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise natural logarithm.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: New matrix with logarithm applied.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.log(self.data)\n",
    "        else:\n",
    "            result = torch.log(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def gamma(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise Gamma function.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the Gamma function values for each element in the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = sp.special.gamma(self.data)\n",
    "        else:\n",
    "            def torch_gamma(x):\n",
    "                pos = torch.exp(torch.lgamma(x))\n",
    "                neg = torch.pi / (torch.sin(torch.pi * x) * torch.exp(torch.lgamma(1 - x)))\n",
    "                return torch.where(x > 0, pos, neg)\n",
    "            result = torch_gamma(self.data)\n",
    "        return Matrix(result, backend=self._backend) \n",
    "    \n",
    "    def loggamma(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise natural logarithm of the Gamma function.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the natural logarithm of the Gamma function values for each element in the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = sp.special.gammaln(self.data)\n",
    "        else:\n",
    "            result = torch.special.gammaln(self.data)\n",
    "        return Matrix(result, backend=self._backend) \n",
    "    \n",
    "    def sigmoid(self):\n",
    "        \"\"\"\n",
    "        Applies the standard sigmoid function element-wise on the input Matrix.\n",
    "        \n",
    "        f(x) = L / (1 + exp(-1*x))\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix with the sigmoid function applied element-wise.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = 1.0 / (1.0 + np.exp(-1.0 * self.data ))\n",
    "        else:\n",
    "            result = torch.sigmoid(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def logistic(self, L=1.0, k=1.0, x0=0.0):\n",
    "        \"\"\"\n",
    "        Applies the logistic (sigmoid) function element-wise on the input Matrix.\n",
    "        \n",
    "        f(x) = L / (1 + exp(-k*(x - x0)))\n",
    "        \n",
    "        Args:\n",
    "            L (float): The curve's maximum value.\n",
    "            k (float): The steepness of the curve.\n",
    "            x0 (float): The x-value of the sigmoid's midpoint.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix with the logistic function applied element-wise.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = L / (1.0 + np.exp(-k * (self.data - x0)))\n",
    "        else:\n",
    "            result = L / (1.0 + torch.exp(-k * (self.data - x0)))\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def logistic_inv(self, L=1.0, k=1.0, x0=0.0):\n",
    "        \"\"\"\n",
    "        Applies the inverse of the logistic (sigmoid) function element-wise on the input Matrix.\n",
    "        \n",
    "        f(y) = x0 - (1/k)*ln((L - y)/y)\n",
    "        \n",
    "        Args:\n",
    "            L (float): The curve's maximum value used in the logistic function.\n",
    "            k (float): The steepness of the curve used in the logistic function.\n",
    "            x0 (float): The sigmoid's midpoint used in the logistic function.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix with the inverse logistic function applied element-wise.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = x0 - (1/k) * np.log((L - self.data) / self.data)\n",
    "        else:\n",
    "            result = x0 - (1/k) * torch.log((L - self.data) / self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def cholesky(self, upper = False):\n",
    "        \"\"\"\n",
    "        Computes the Cholesky decomposition of a symmetric positive-definite matrix.\n",
    "        L @ U = self.data\n",
    "        returns L if upper = False else U\n",
    "        \n",
    "        Args:\n",
    "            upper (bool): If True, compute the upper triangular factor. Default is False.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the lower triangular factor of the original data if `upper` is False,\n",
    "                    or its transpose if `upper` is True.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.linalg.cholesky(self.data)\n",
    "            if upper == True:\n",
    "                result = result.T\n",
    "        else:\n",
    "            result = torch.cholesky(self.data, upper = upper)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def softmax(self, axis = 1, keepdims:bool | None = True):\n",
    "        \"\"\"\n",
    "        Applies the softmax function along a specified axis.\n",
    "    \n",
    "        Args:\n",
    "            axis (int): Axis along which to apply the softmax. Default is 1.\n",
    "            keepdims (bool or None): Whether to keep the reduced dimensions as axes with size one. \n",
    "                                    If `True`, the shape of the result will be the same as input; otherwise, it will not have these dimensions.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the softmax values along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if keepdims is not None and axis is not None:\n",
    "                e_x = np.exp(self.data - np.max(self.data, axis=axis, keepdims=keepdims))\n",
    "                result = e_x / e_x.sum(axis=axis, keepdims=keepdims)\n",
    "            else:\n",
    "                e_x = np.exp(self.data - np.max(self.data, axis=axis))\n",
    "                result = e_x / e_x.sum(axis=axis)\n",
    "        else:\n",
    "            result = torch.nn.functional.softmax(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "\n",
    "    def argmax(self, axis = 1):\n",
    "        \"\"\"\n",
    "         Computes the indices of the maximum values along a specified axis.\n",
    "         Reminder -> Shapre will be shrinked by 1 so that you may need to reshape() it.\n",
    "        \n",
    "         Args:\n",
    "             axis (int | None): Axis along which to compute the argmax. Default is 1.\n",
    "         \n",
    "         Returns:\n",
    "             Matrix: A new matrix containing the indices of the maximum values along the specified axis.\n",
    "         \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.argmax(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.argmax(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def argmin(self, axis = 1):\n",
    "        \"\"\"\n",
    "        Computes the indices of the minimum values along a specified axis.\n",
    "        Reminder -> Shapre will be shrinked by 1 so that you may need to reshape() it.\n",
    "    \n",
    "        Args:\n",
    "            axis (int | None): Axis along which to compute the argmin. Default is 1.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the indices of the minimum values along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.argmin(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.argmin(self.data, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)    \n",
    "    \n",
    "    def flatten(self, major = \"row\"):\n",
    "        \"\"\"\n",
    "        Returns the flattened matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The flattened matrix.\n",
    "        \"\"\"\n",
    "        if major == \"col\":\n",
    "            x = self.transpose()\n",
    "            return Matrix(x.data.flatten(), backend=self._backend)\n",
    "        elif major == \"row\":\n",
    "            return Matrix(self.data.flatten(), backend=self._backend)\n",
    "        else:\n",
    "            raise ValueError(\"major must be either 'row' or 'column'!\")\n",
    "            \n",
    "    def reverse(self, axis = 0):\n",
    "        \"\"\"\n",
    "        Reverse the flattened matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The reversed matrix.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Matrix(np.flip(self.data, axis=axis), backend=self._backend)\n",
    "        else:\n",
    "            return Matrix(torch.flip(self.data, axis=axis), backend=self._backend)\n",
    "            \n",
    "    def vstack(self, *wargs):\n",
    "        \"\"\"\n",
    "        Stack data in sequence vertically (row wise).\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The vstacked matrix.\n",
    "        \"\"\"\n",
    "        data_list = [self.data]\n",
    "        for arg in wargs:\n",
    "            data_list.append(arg.data)\n",
    "        if self._is_numpy:\n",
    "            result = np.vstack(data_list)\n",
    "        else:\n",
    "            result = torch.vstack(data_list)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def hstack(self, *wargs):\n",
    "        \"\"\"\n",
    "        Stack data in sequence horizontally (col wise).\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The hstacked matrix.\n",
    "        \"\"\"\n",
    "        data_list = [self.data]\n",
    "        for arg in wargs:\n",
    "            data_list.append(arg.data)\n",
    "        if self._is_numpy:\n",
    "            result = np.hstack(data_list)\n",
    "        else:\n",
    "            result = torch.hstack(data_list)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def sign(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise sign of the data. Returns with the same type.\n",
    "    \n",
    "        Args: \n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the sign values (1 for positive, -1 for negative, 0 for zero) of each element in the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sign(self.data)\n",
    "        else:\n",
    "            result = torch.sign(self.data)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def repeat(self, repeats, axis=None):\n",
    "        \"\"\"\n",
    "        Repeats the matrix elements along a specified axis.\n",
    "    \n",
    "        Args:\n",
    "            repeats (int or tuple[int]): The number of times to repeat each element.\n",
    "            axis (int): Axis along which to repeat the elements. If `None`, repeats over all dimensions.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix: A new matrix with repeated elements.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = self.data.repeat(repeats, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.repeat_interleave(self.data, repeats)\n",
    "            else:\n",
    "                result = torch.repeat_interleave(self.data, repeats, dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def bincount(self, *, weights = None, inttype: type = int):\n",
    "        \"\"\"\n",
    "        Counts the number of occurrences of each value in `data` and optionally returns a weighted count.\n",
    "    \n",
    "        Args:\n",
    "            weights (array_like | Matrix): An array-like object containing weights corresponding to each element in `data`. Default is None.\n",
    "            inttype (type): A type that the data is going to be casted to.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix with the bin counts or weighted bin counts.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.bincount(self.astype(inttype).data, weights = weights)\n",
    "        else:\n",
    "            result = torch.bincount(self.astype(inttype).data, weights = weights)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def transpose(self, *axes):\n",
    "        \"\"\"\n",
    "        Returns the transpose of the matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The transposed matrix.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = self.data.transpose(axes) if axes else self.data.T\n",
    "        else:\n",
    "            result = self.data.permute(*axes) if axes else self.data.permute(*reversed(range(self.data.dim())))\n",
    "        if len(self.shape) > 1:\n",
    "            return Matrix(result, backend=self._backend)\n",
    "        else:\n",
    "            # From a row vector to a column vector\n",
    "            return Matrix(result.reshape([self.shape[0], 1]), backend=self._backend)\n",
    "        \n",
    "    def quantile(self, q: float, axis = None, keepdims = False):\n",
    "        \"\"\"\n",
    "        Computes the specified quantiles along a given axis.\n",
    "    \n",
    "        Args:\n",
    "            q (float): The quantile to compute. Should be between 0 and 1.\n",
    "            axis (Optional[int]): Axis along which to compute the quantile. Default is None, which computes over all dimensions.\n",
    "            keepdims (bool): Whether to keep the reduced axes in the result as singleton dimensions. Default is False.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing the computed quantiles.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.quantile(self.data, q, axis = axis, keepdims = keepdims)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.quantile(self.data, q, keepdims = keepdims)\n",
    "            else:\n",
    "                result = torch.quantile(self.data, q, dim = axis, keepdims = keepdims)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "        \n",
    "    def sort(self, axis: int | None = None):\n",
    "        \"\"\"\n",
    "        Sorts the matrix elements along (the first column of) a specified axis.\n",
    "        If you intend to sort on only one array, use `sort_along` instead,\n",
    "        or if you want to sort along each column of each base dimension, use `sort_along_each_column` instead.\n",
    "        \n",
    "        Args:\n",
    "            axis (int or None): Axis to sort along. If `None`, sorts the entire matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix with sorted elements.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sort(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result, idx = self.data.sort()\n",
    "            else:\n",
    "                result, idx = self.data.sort(dim=axis)\n",
    "        return Matrix(result, backend=self._backend)\n",
    "    \n",
    "    def sort_along(self, axis: tuple = (None, 0)):\n",
    "        \"\"\"\n",
    "        Sort the N-dimensional data along the 1d values on `axis`.\n",
    "        If you intend to sort on the first column of axis `axis`, use `sort` to speed up,\n",
    "        or if you want to sort along each column of each base dimension, use `sort_along_each_column` instead.\n",
    "       \n",
    "        Detail:\n",
    "        Sort the input array x. The axis parameter is a tuple of t\n",
    "        he same length as x.ndim, where each position can be None or an integer. \n",
    "        It is required that exactly one position d in axis_vec is not None,\n",
    "        and the reference position of this dimension d is fixed = axis_vec[d], \n",
    "        but when taking this reference, the index 0 is selected for each dimension \n",
    "        in the global uniform way (i.e., only x[(0,)*d + (fixed,)] is used as the \n",
    "        reference). \n",
    "        The 1D sorting permutation is calculated (using argsort, in ascending order), \n",
    "        and then the global permutation is applied to dimension d+1 \n",
    "        (the subsequent dimension) of x, acting on all data without sorting each\n",
    "        preceding block separately.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            axis : tuple\n",
    "                The indicator indicating sort which data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Matrix, sorted copy.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(self.data.shape) != len(axis):\n",
    "            raise ValueError(\"The length of axis must be equal to the number of dimensions of the input array.\")\n",
    "        non_none = [(d, val) for d, val in enumerate(axis) if val is not None]\n",
    "        if len(non_none) != 1:\n",
    "            raise ValueError(\"There must be exactly one non-None element in axis\")\n",
    "        d, fixed = non_none[0]\n",
    "        if d > len(self.data.shape) - 1:\n",
    "            raise ValueError(\"The non-None dimension cannot be greater than dimension.\")\n",
    "        if fixed < 0 or fixed >= self.data.shape[d]:\n",
    "            raise IndexError(f\"Fixed index {fixed} is out of range for dimension {d} (0 to {self.data.shape[d]-1})\")\n",
    "        \n",
    "        # Last dim sort\n",
    "        if d == len(self.data.shape) - 1 and len(self.data.shape) == 2:\n",
    "            # Transpose, and sort the row\n",
    "            return self.transpose().sort_along(axis=(axis[1], axis[0])).transpose()\n",
    "        elif d == len(self.data.shape) - 1 and len(self.data.shape) > 2:\n",
    "            # Transpose the inner two dimensions\n",
    "            tr_axe = list(range(len(self.data.shape))); tmp = tr_axe[-1]; tr_axe[-1] = tr_axe[-2]; tr_axe[-2] = tmp;\n",
    "            axis_new = list(np.repeat(None, len(self.data.shape))); axis_new[-2] = fixed\n",
    "            return self.transpose(*tr_axe).sort_along(axis=axis_new).transpose(*tr_axe)\n",
    "        \n",
    "        # Extract global reference: fixed on dimension d, but all dimensions before d are indexed as 0.\n",
    "        # Construct index tuple: fixed to 0 for dimensions < d, fixed to the dth dimension, and use slice(None) to eliminate the remaining axes.\n",
    "        idx = (0,) * d + (fixed,)\n",
    "        \n",
    "        if self._is_numpy:\n",
    "            # Extract the reference key, which is expected to be 1D and have a length equal to self.data.shape[d+1]\n",
    "            key = np.asarray(self.data[idx])\n",
    "            if key.ndim != 1 or key.shape[0] != self.data.shape[d+1]:\n",
    "                raise ValueError(\"The reference key must be one-dimensional and its length must be the same as the length of the sorting axis.\")\n",
    "            order = np.argsort(key)\n",
    "           \n",
    "            # Construct a global index array for np.take_along_axis: needs to have the same shape as x,\n",
    "            # but order along sorting axis d+1, other dimensions are copied via broadcasting.\n",
    "            order_shape = [1] * len(self.data.shape)\n",
    "            order_shape[d+1] = self.data.shape[d+1]\n",
    "            order_global = order.reshape(order_shape)\n",
    "            order_global = np.broadcast_to(order_global, self.data.shape)\n",
    "            sorted_ = np.take_along_axis(self.data, order_global, axis=d+1)\n",
    "            return Matrix(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        else:\n",
    "            key = self.data[idx]\n",
    "            # key should be 1D, and its length should be equal to self.data.shape[d+1]\n",
    "            if key.dim() != 1 or key.size(0) != self.data.shape[d+1]:\n",
    "                raise ValueError(\"The reference key must be one-dimensional and its length must be the same as the length of the sorting axis.\")\n",
    "            # Calculate the sort order (ascending)\n",
    "            order = torch.argsort(key, dim=0)\n",
    "            \n",
    "            # Construct a global index tensor with the same shape as self.data, but with order on the sorting axis d+1\n",
    "            order_shape = [1] * len(self.data.shape)\n",
    "            order_shape[d+1] = self.data.shape[d+1]\n",
    "            order_global = order.view(*order_shape).expand(self.data.shape)\n",
    "            \n",
    "            # Use torch.gather to rearrange self.data according to the global index tensor on dim=d+1\n",
    "            sorted_ = torch.gather(self.data, dim=d+1, index=order_global)\n",
    "            return Matrix(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "    def sort_along_each_column(self, axis: int = 1, on_col: int = 0):\n",
    "        \"\"\"\n",
    "        Sort the N-dimensional data along values on column `on_col` of the axis `axis`.\n",
    "        Note, it will sort EACH `on_col` of the exterior axises.\n",
    "        If you intend to sort on the first column of axis `axis`, use `sort` to speed up.\n",
    "       \n",
    "        Detail:\n",
    "        Instead of sorting itself in d dimensions, use the reference sequence obtained by taking index=i on the d axis of x, and apply the same rearrangement to the d+1 axis (next axis) of x.\n",
    "\n",
    "        For example, for a 2D array, when d=0, i=1,\n",
    "        take the reference sequence = x[1, :], calculate its argsort to get the sorted arrangement, and then rearrange the columns of each row of the entire array according to this arrangement;\n",
    "        For a 3D array, when d=1, i=0,\n",
    "        for each subarray with fixed axis=0, take the reference sequence = subarray[0, :] (that is, the row of axis=1 index 0),\n",
    "        calculate argsort (sort the elements in the reference sequence), and then rearrange all rows in the subarray (all slices of axis=1) on axis=2 according to this arrangement.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            axis : int\n",
    "                The axis of the column is on. The default is 1.\n",
    "            on_col : int\n",
    "                The index of the column is on. The default is 0.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Matrix, sorted copy.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(self.data.shape) < 2:\n",
    "            raise ValueError(\"The input data must at least have 2 dimensions. Use `sort` if it is a 1d array.\")\n",
    "        if axis < 0 or axis > len(self.data.shape) - 1:\n",
    "            raise ValueError(\"The parameter d must be positive and smaller than ndim.\")\n",
    "        if axis == len(self.data.shape) - 1 and len(self.data.shape) == 2:\n",
    "            # Transpose, and sort the row\n",
    "            return self.transpose().sort_along_each_column(axis=0, on_col=on_col).transpose()\n",
    "        elif axis == len(self.data.shape) - 1 and len(self.data.shape) > 2:\n",
    "            # Transpose the inner two dimensions\n",
    "            tr_axe = list(range(len(self.data.shape))); tmp = tr_axe[-1]; tr_axe[-1] = tr_axe[-2]; tr_axe[-2] = tmp;\n",
    "            return self.transpose(*tr_axe).sort_along_each_column(axis=axis-1, on_col=on_col).transpose(*tr_axe)\n",
    "            \n",
    "        sorted_axis = axis + 1\n",
    "\n",
    "        if self._is_numpy:\n",
    "            key = np.take(self.data, indices=on_col, axis=axis)\n",
    "            order = np.argsort(key, axis=axis)\n",
    "            order_expanded = np.expand_dims(order, axis=axis)\n",
    "            sorted_ = np.take_along_axis(self.data, order_expanded, axis=sorted_axis)\n",
    "            return Matrix(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        else:\n",
    "            key = self.data.select(dim=axis, index=on_col)\n",
    "            order = torch.argsort(key, dim=axis)\n",
    "            order_expanded = order.unsqueeze(dim=axis)\n",
    "            expand_shape = list(self.data.shape)\n",
    "            index = order_expanded.expand(*expand_shape)\n",
    "            sorted_ = torch.gather(self.data, dim=sorted_axis, index=index)\n",
    "            return Matrix(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)        \n",
    "    \n",
    "    def _eigen_kernel(self):\n",
    "        \"\"\"\n",
    "        Calculates eigenvalues and eigenvectors using internal libraries (numpy or torch).\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: eigen_values, eigen_vectors: The computed eigenvalues and eigenvectors.\n",
    "        \"\"\"\n",
    "        if self.shape[0] != self.shape[1]:\n",
    "            raise ValueError(\"Eigen decomposition requires a square matrix.\")\n",
    "        if self._is_numpy:\n",
    "            eigen_values, eigen_vectors = np.linalg.eig(self.data)\n",
    "        else:\n",
    "            # Using torch.linalg.eig (available in newer versions of PyTorch)\n",
    "            eigen_values, eigen_vectors = torch.linalg.eig(self.data)\n",
    "        return Matrix(eigen_values, backend=self._backend), Matrix(eigen_vectors, backend=self._backend)\n",
    "\n",
    "    def _jacobi_eigen(self, tol=1e-10, max_iterations=1000):\n",
    "        \"\"\"\n",
    "        Eigen decomposition using the Jacobi rotation method for symmetric matrices.\n",
    "        \n",
    "        Returns:\n",
    "            eigen_values, eigen_vectors: Sorted in descending order.\n",
    "        \"\"\"\n",
    "        A = self.data.astype(float).copy()\n",
    "        n = A.shape[0]\n",
    "        V = np.eye(n)\n",
    "        for iteration in range(max_iterations):\n",
    "            p, q = 0, 1\n",
    "            max_val = 0\n",
    "            for i in range(n):\n",
    "                for j in range(i+1, n):\n",
    "                    if abs(A[i, j]) > max_val:\n",
    "                        max_val = abs(A[i, j])\n",
    "                        p, q = i, j\n",
    "            if max_val < tol:\n",
    "                break\n",
    "            if abs(A[p, p] - A[q, q]) < tol:\n",
    "                theta = np.pi / 4\n",
    "            else:\n",
    "                theta = 0.5 * np.arctan2(2 * A[p, q], A[q, q] - A[p, p])\n",
    "            c = np.cos(theta)\n",
    "            s = np.sin(theta)\n",
    "            app, aqq, apq = A[p, p], A[q, q], A[p, q]\n",
    "            A[p, p] = c**2 * app - 2 * s * c * apq + s**2 * aqq\n",
    "            A[q, q] = s**2 * app + 2 * s * c * apq + c**2 * aqq\n",
    "            A[p, q] = 0.0\n",
    "            A[q, p] = 0.0\n",
    "            for i in range(n):\n",
    "                if i != p and i != q:\n",
    "                    aip, aiq = A[i, p], A[i, q]\n",
    "                    A[i, p] = c * aip - s * aiq\n",
    "                    A[p, i] = A[i, p]\n",
    "                    A[i, q] = s * aip + c * aiq\n",
    "                    A[q, i] = A[i, q]\n",
    "            for i in range(n):\n",
    "                vip, viq = V[i, p], V[i, q]\n",
    "                V[i, p] = c * vip - s * viq\n",
    "                V[i, q] = s * vip + c * viq\n",
    "        eigen_values = np.diag(A)\n",
    "        idx = np.argsort(eigen_values)[::-1]\n",
    "        eigen_values = eigen_values[idx]\n",
    "        eigen_vectors = V[:, idx]\n",
    "        return Matrix(eigen_values, backend=self._backend), Matrix(eigen_vectors, backend=self._backend)\n",
    "\n",
    "    def _qr_eigen_nonsymmetric(self, tol=1e-10, max_iterations=1000):\n",
    "        \"\"\"\n",
    "        Eigen decomposition for non-symmetric matrices using a basic QR algorithm\n",
    "        for eigenvalues and SVD-based extraction for eigenvectors.\n",
    "        \n",
    "        Returns:\n",
    "            eigen_values, eigen_vectors: Sorted in descending order by modulus.\n",
    "        \"\"\"\n",
    "        # Work in complex to capture possible complex eigenvalues.\n",
    "        A_orig = np.array(self.data, dtype=complex)\n",
    "        n = A_orig.shape[0]\n",
    "        A = A_orig.copy()\n",
    "        for _ in range(max_iterations):\n",
    "            Q, R = np.linalg.qr(A)\n",
    "            A = R @ Q\n",
    "            off_diag = A - np.diag(np.diag(A))\n",
    "            if np.linalg.norm(off_diag) < tol:\n",
    "                break\n",
    "        eigen_values = np.diag(A)\n",
    "        # Compute eigenvectors by solving (A_orig - lambda I)v = 0 via SVD.\n",
    "        eigen_vectors = np.empty((n, n), dtype=complex)\n",
    "        for j, lam in enumerate(eigen_values):\n",
    "            B = A_orig - lam * np.eye(n, dtype=complex)\n",
    "            U, S, Vh = np.linalg.svd(B)\n",
    "            v = Vh.conj().T[:, -1]\n",
    "            v = v / np.linalg.norm(v)\n",
    "            eigen_vectors[:, j] = v\n",
    "        # Sort eigenpairs by descending modulus of eigenvalues.\n",
    "        idx = np.argsort(np.abs(eigen_values))[::-1]\n",
    "        eigen_values = eigen_values[idx]\n",
    "        eigen_vectors = eigen_vectors[:, idx]\n",
    "        return Matrix(eigen_values, backend = self._backend), Matrix(eigen_vectors, backend = self._backend)\n",
    "\n",
    "    def eigen(self, method=\"kernel\", symmetric=None, tol=1e-10, max_iterations=1000):\n",
    "        \"\"\"\n",
    "        Unified eigen decomposition method.\n",
    "        \n",
    "        Args:\n",
    "            method (str): \"kernel\" to use internal libraries; \"selfimpl\" to use the self-implemented solver.\n",
    "            symmetric (bool, optional): If known symmetric; if None, determined automatically.\n",
    "            tol (float): Tolerance for convergence (used in self-implementation).\n",
    "            max_iterations (int): Maximum iterations (used in self-implementation).\n",
    "        \n",
    "        Returns:\n",
    "            eigen_values, eigen_vectors: eigenvalues and eigenvectors.\n",
    "        \"\"\"\n",
    "        if self.shape[0] != self.shape[1]:\n",
    "            raise ValueError(\"Eigen decomposition requires a square matrix.\")\n",
    "        # Determine symmetry if not explicitly provided.\n",
    "        if symmetric is None:\n",
    "            if self._is_numpy:\n",
    "                symmetric = np.allclose(self.data, self.data.T, atol=tol)\n",
    "            else:\n",
    "                symmetric = torch.allclose(self.data, self.data.T)\n",
    "                \n",
    "        if method == \"kernel\":\n",
    "            return self._eigen_kernel()\n",
    "        \n",
    "        elif method == \"selfimpl\":\n",
    "            if self._is_numpy:\n",
    "                if symmetric:\n",
    "                    return self._jacobi_eigen(tol, max_iterations)\n",
    "                else:\n",
    "                    return self._qr_eigen_nonsymmetric(tol, max_iterations)\n",
    "            else:\n",
    "                # Use kernel instead\n",
    "                return self._eigen_kernel()\n",
    "        else:\n",
    "            raise ValueError(\"Unknown eigen method. Use 'kernel' or 'selfimpl'.\")\n",
    "\n",
    "    def _check_square(self):\n",
    "        \"\"\"\n",
    "        Internal helper to ensure the matrix is square (required for determinant, inverse, and trace).\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If the matrix is not square.\n",
    "        \"\"\"\n",
    "        if len(self.shape) != 2 or self.shape[0] != self.shape[1]:\n",
    "            raise ValueError(\"This operation requires a square matrix.\")\n",
    "    \n",
    "    def determinant(self):\n",
    "        \"\"\"\n",
    "        Computes the determinant of a square matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Scalar: The determinant value.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the matrix is not square.\n",
    "        \"\"\"\n",
    "        self._check_square()\n",
    "        if self._is_numpy:\n",
    "            return np.linalg.det(self.data)\n",
    "        else:\n",
    "            return torch.det(self.data)\n",
    "    \n",
    "    def inverse(self):\n",
    "        \"\"\"\n",
    "        Computes the inverse of a square matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The inverse matrix.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the matrix is not square.\n",
    "        \"\"\"\n",
    "        self._check_square()\n",
    "        if self._is_numpy:\n",
    "            inv_data = np.linalg.inv(self.data)\n",
    "        else:\n",
    "            inv_data = torch.inverse(self.data)\n",
    "        return Matrix(inv_data, backend=self._backend)\n",
    "    \n",
    "    def trace(self):\n",
    "        \"\"\"\n",
    "        Computes the trace of a square matrix (sum of diagonal elements).\n",
    "        \n",
    "        Returns:\n",
    "            Scalar: The trace value.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the matrix is not square.\n",
    "        \"\"\"\n",
    "        self._check_square()\n",
    "        if self._is_numpy:\n",
    "            return np.trace(self.data)\n",
    "        else:\n",
    "            return torch.trace(self.data)\n",
    "    \n",
    "    def diag(self):\n",
    "        \"\"\"\n",
    "        Computes the diagonal vector of a square matrix.\n",
    "        Or create a diagonal matrix if 1D matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The diagonal vector.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the matrix is not square.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Matrix(np.diag(self.data), backend=self._backend)\n",
    "        else:\n",
    "            return Matrix(torch.diag(self.data), backend=self._backend)\n",
    "    \n",
    "    def dot(self, other):\n",
    "        \"\"\"\n",
    "        Computes the dot product of this matrix with another Matrix.\n",
    "        \n",
    "        Args:\n",
    "            other (Matrix): The other matrix to multiply.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix instance with the result of the dot product.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Matrix(np.dot(self.data, other.data), backend=\"numpy\")\n",
    "        else:\n",
    "            return Matrix(torch.matmul(self.data, other.data), backend=\"torch\")\n",
    "    \n",
    "    def inner(self, other):\n",
    "        \"\"\"\n",
    "        Computes the inner product of this matrix with another Matrix.\n",
    "        \n",
    "        Args:\n",
    "            other (Matrix): The other matrix to multiply.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix instance with the result of the inner product.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Matrix(np.inner(self.data, other.data), backend=\"numpy\")\n",
    "        else:\n",
    "            return Matrix(torch.inner(self.data, other.data), backend=\"torch\")\n",
    "    \n",
    "    def outer(self, other):\n",
    "        \"\"\"\n",
    "        Computes the outer product of this matrix with another Matrix.\n",
    "        \n",
    "        Args:\n",
    "            other (Matrix): The other matrix to multiply.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix instance with the result of the outer product.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Matrix(np.outer(self.data, other.data), backend=\"numpy\")\n",
    "        else:\n",
    "            return Matrix(torch.outer(self.data, other.data), backend=\"torch\")\n",
    "    \n",
    "    def svd(self, full_matrices=True):\n",
    "        \"\"\"\n",
    "        Computes the Singular Value Decomposition (SVD) of the matrix.\n",
    "        \n",
    "        Args:\n",
    "            full_matrices (bool): If True, compute the full SVD; otherwise, compute the reduced SVD.\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[Matrix, Matrix, Matrix]: A tuple containing U, S, and V^T as Matrix objects.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            U, S, Vh = np.linalg.svd(self.data, full_matrices=full_matrices)\n",
    "            return Matrix(U, backend=\"numpy\"), Matrix(S, backend=\"numpy\"), Matrix(Vh, backend=\"numpy\")\n",
    "        else:\n",
    "            if hasattr(torch.linalg, 'svd'):\n",
    "                U, S, Vh = torch.linalg.svd(self.data, full_matrices=full_matrices)\n",
    "            else:\n",
    "                U, S, V = torch.svd(self.data, some=not full_matrices)\n",
    "                Vh = V.t()\n",
    "            return Matrix(U, backend=\"torch\"), Matrix(S, backend=\"torch\"), Matrix(Vh, backend=\"torch\")\n",
    "          \n",
    "    def to_zeros(self):\n",
    "        \"\"\"\n",
    "        Converts the Matrix data into a same shape Matrix with 0s.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: a same shape Matrix with 0s.\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.copy()\n",
    "        x[...] = 0\n",
    "        return x\n",
    "    \n",
    "    def to_ones(self):\n",
    "        \"\"\"\n",
    "        Converts the Matrix data into a same shape Matrix with 1s.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: a same shape Matrix with 1s.\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.copy()\n",
    "        x[...] = 1\n",
    "        return x\n",
    "    \n",
    "    def to_ks(self, k: float | int = 0):\n",
    "        \"\"\"\n",
    "        Converts the Matrix data into a same shape Matrix with ks.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: a same shape Matrix with 0s.\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.copy()\n",
    "        x[...] = k\n",
    "        return x        \n",
    "\n",
    "    def to_rands(self):\n",
    "        \"\"\"\n",
    "        Converts the Matrix data into a same shape Matrix with uniform random numbers.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: a same shape Matrix with uniform random numbers.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.rand(self.shape, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "    def to_list(self):\n",
    "        \"\"\"\n",
    "        Converts the matrix data into a Python list.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            list: A Python list containing the same elements as `self.data`.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return self.data.tolist()\n",
    "        else:\n",
    "            return self.data.cpu().tolist()\n",
    "        \n",
    "    def to_numpy_array(self):\n",
    "        \"\"\"\n",
    "        Converts the matrix data into a NumPy array.\n",
    "        \n",
    "        Returns: \n",
    "            np.ndarray: The underlying NumPy array of the matrix.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return self.data\n",
    "        else:\n",
    "            return self.data.detach().cpu().numpy()\n",
    "        \n",
    "    def to_torch_tensor(self, *, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Converts the matrix data into a PyTorch tensor.\n",
    "        \n",
    "        Args: \n",
    "            dtype (torch.dtype or None): The desired data type for the resulting tensor. If not provided,\n",
    "                                         uses the current data type of `self.data`.\n",
    "            device (torch.device or None): The target device to which the tensor should be moved.\n",
    "                                           If not provided, it will use the default device.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: A PyTorch tensor containing the same data as `self.data`.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return torch.tensor(self.data, dtype=dtype, device=device)\n",
    "        else:\n",
    "            return self.data\n",
    "        \n",
    "    @staticmethod\n",
    "    def equal(x, other, *, equal_nan=False):\n",
    "        \"\"\"\n",
    "        Compare if two Matrix objects have the same shape and elements.\n",
    "        \n",
    "        Args:\n",
    "            x (Matrix): The one matrix to compare.\n",
    "            other (Matrix): The other matrix to compare.\n",
    "        \n",
    "        Returns:\n",
    "           ``True`` if two matrices have the same size and elements, \n",
    "           ``False`` otherwise.\n",
    "        \"\"\"\n",
    "        if x._is_numpy == True and other._is_numpy == True:\n",
    "            return np.array_equal(x, other, equal_nan=equal_nan)\n",
    "        elif  x._is_numpy == False and other._is_numpy == False:\n",
    "            return torch.equal(x, other)\n",
    "        else:\n",
    "            raise ValueError(\"Input `x` and `other` for comparison must have to have the same backend!\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def gather_along(data, axis, index):\n",
    "        \"\"\"\n",
    "        Gather values on an axis with specified index.\n",
    "        \n",
    "        Parameters:\n",
    "            axis: int, the axis number to gather values on.\n",
    "            index: list | array | Matrix, the indices for each row/column/.. to gather values on.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: gathered elements.\n",
    "        \"\"\"\n",
    "        if data._is_numpy:\n",
    "            result = np.take_along_axis(data.data, indices=index, axis=axis)\n",
    "        else:\n",
    "            result = torch.gather(data.data, dim=axis, index=index.data)\n",
    "        return Matrix(result, backend=data._backend, dtype=data.dtype, device=data.device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def where(condition, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Returns elements depending on `condition`.\n",
    "        \n",
    "        Parameters:\n",
    "            condition : Internal Type (array_like); bool Where True\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: chosen elements.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            result = np.where(condition)\n",
    "        else:\n",
    "            result = torch.where(condition)         \n",
    "            if isinstance(result, tuple):\n",
    "                result = result[0]\n",
    "        return Matrix(result, backend=backend, dtype=dtype, device=device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def where_as(condition, then, other, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Returns elements depending on `condition`.\n",
    "        \n",
    "        Parameters:\n",
    "            condition : Internal Type (array_like); bool Where True\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: if true then applied then to true elements; other to fales elements.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            result = np.where(condition, then, other)\n",
    "        else:\n",
    "            result = torch.where(condition, then, other)         \n",
    "            if isinstance(result, tuple):\n",
    "                result = result[0]\n",
    "        return Matrix(result, backend=backend, dtype=dtype, device=device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeros(shape, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a matrix filled with zeros.\n",
    "        \n",
    "        Args:\n",
    "            shape (tuple): The shape of the matrix.\n",
    "            backend (str): The backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: A new matrix of zeros.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.zeros(shape, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.zeros(shape, dtype=dtype, device=device) if dtype else torch.zeros(shape, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Matrix(data, backend=backend)\n",
    "    \n",
    "    @staticmethod\n",
    "    def ones(shape, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a matrix filled with ones.\n",
    "        \n",
    "        Args:\n",
    "            shape (tuple): The shape of the matrix.\n",
    "            backend (str): The backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: A new matrix of ones.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.ones(shape, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.ones(shape, dtype=dtype, device=device) if dtype else torch.ones(shape, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Matrix(data, backend=backend)\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeros_like(x, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a matrix of zeros with the same shape and data type as another matrix.\n",
    "        \n",
    "        Args:\n",
    "            x (Matrix): The input matrix.\n",
    "            backend (str): The backend for computation (\"numpy\" or \"torch\"). Default is \"numpy\".\n",
    "            dtype: Desired data type for the result. If not specified, uses the data type from `x`.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing zeros with the same shape and type as `x`.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If an unsupported backend is provided.\n",
    "        \n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.zeros_like(x.data, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.zeros_like(x.data, dtype=dtype, device=device) if dtype else torch.zeros_like(x.data, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Matrix(data, backend=backend)\n",
    "    \n",
    "    @staticmethod\n",
    "    def ones_like(x, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a matrix of ones with the same shape and data type as another matrix.\n",
    "        \n",
    "        Args:\n",
    "            x (Matrix): The input matrix.\n",
    "            backend (str): The backend for computation (\"numpy\" or \"torch\"). Default is \"numpy\".\n",
    "            dtype: Desired data type for the result. If not specified, uses the data type from `x`.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new matrix containing ones with the same shape and type as `x`.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If an unsupported backend is provided.\n",
    "        \n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.ones_like(x.data, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.ones_like(x.data, dtype=dtype, device=device) if dtype else torch.ones_like(x.data, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Matrix(data, backend=backend)\n",
    "    \n",
    "    @staticmethod\n",
    "    def identity(n, backend=\"numpy\", dtype=None):\n",
    "        \"\"\"\n",
    "        Creates an identity matrix of size n x n.\n",
    "        \n",
    "        Args:\n",
    "            n (int): The number of rows and columns.\n",
    "            backend (str): The backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: An identity matrix.\n",
    "        \"\"\"\n",
    "        bk = backend.lower()\n",
    "        if bk == \"numpy\":\n",
    "            data = np.eye(n, dtype=dtype)\n",
    "        elif bk == \"torch\":\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed.\")\n",
    "            data = torch.eye(n, dtype=dtype)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Matrix(data, backend=bk)\n",
    "    \n",
    "    @staticmethod\n",
    "    def rand(shape, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a matrix with random values uniformly distributed in [0, 1).\n",
    "        \n",
    "        Args:\n",
    "            shape (tuple): The shape of the matrix.\n",
    "            backend (str): The backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: A new matrix with random values.\n",
    "        \"\"\"\n",
    "        bk = backend.lower()\n",
    "        if bk == \"numpy\":\n",
    "            data = np.random.rand(*shape)\n",
    "            if dtype:\n",
    "                data = data.astype(dtype)\n",
    "        elif bk == \"torch\":\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed.\")\n",
    "            data = torch.rand(shape, dtype=dtype, device=device) if dtype else torch.rand(shape, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Matrix(data, backend=bk)\n",
    "\n",
    "    @staticmethod\n",
    "    def least_square(X, Y, backend=\"numpy\", dtype=None):\n",
    "        \"\"\"\n",
    "        Solves the linear system bX = Y using the normal equation approach.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix): The matrix of features or independent variables.\n",
    "            Y (Matrix): The matrix of observations or dependent variables.\n",
    "            backend (str): The backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type for the result.\n",
    "            \n",
    "        Returns:\n",
    "            Matrix: The least-squares solution b satisfying bX = Y\n",
    "        \"\"\"    \n",
    "        # Check if the matrix Y is with one column or not\n",
    "        if len(Y.shape) == 1:\n",
    "            Y = Y.reshape([Y.shape[0], 1])\n",
    "        if Y.shape[1] != 1:\n",
    "            raise ValueError(\"The input matrix Y must be of 1 column!\")\n",
    "        \n",
    "        # Compute the least-squares solution (X^T@X)^-1@X^T@Y\n",
    "        X_transpose = X.transpose()\n",
    "        b = (X_transpose @ X).inverse() @ X_transpose @ Y\n",
    "        if dtype:\n",
    "            b = b.astype(dtype)\n",
    "            \n",
    "        return b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Tensor Wrapper Library (self-implemented)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tensor class is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "class Tensor(Object):\n",
    "    \"\"\"\n",
    "    A production-level Tensor class providing a unified interface for common machine learning operations.\n",
    "    This class supports either a numpy.ndarray or a torch.Tensor as its underlying backend. To optimize performance,\n",
    "    the backend string is processed once at initialization, and boolean flags (_is_numpy and _is_torch) are used to \n",
    "    avoid repeated string comparisons.\n",
    "    \n",
    "    The implemented operations include element-wise arithmetic, matrix multiplication, reshaping, reductions (sum, mean, \n",
    "    max, min), and element-wise exponential and logarithmic functions.\n",
    "    \n",
    "    Attributes:\n",
    "        data (np.ndarray or torch.Tensor): Underlying storage for tensor data.\n",
    "        _backend (str): Lowercase string for the backend (\"numpy\" or \"torch\").\n",
    "        _is_numpy (bool): True if using numpy as the backend.\n",
    "        _is_torch (bool): True if using torch as the backend.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.Tensor\"    \n",
    "    \n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Returns natural exponent value as a single-value Matrix.\n",
    "        \n",
    "        Returns:\n",
    "            -------\n",
    "            Tensor with 0 shape. exp value.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Tensor(np.e, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "        else:\n",
    "            return Tensor(torch.e, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "    \n",
    "    def pi(self):\n",
    "        \"\"\"\n",
    "        Returns pi value as a single-value Matrix.\n",
    "        \n",
    "        Returns:\n",
    "            -------\n",
    "            Tensor with 0 shape. pi value.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Tensor(np.pi, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "        else:\n",
    "            return Tensor(torch.pi, backend = self._backend, dtype = self.dtype, device = self.device)\n",
    "    \n",
    "    def __init__(self, data, backend=\"numpy\", *, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Initializes a Tensor instance with the specified backend.\n",
    "        \n",
    "        Args:\n",
    "            data (array-like): Input data to be converted into a tensor.\n",
    "            backend (str): Backend to use (\"numpy\" or \"torch\").\n",
    "            dtype(str): The type of data to be stored in (any type or None).\n",
    "            device (str): Device where the data is stored on (\"cpu\" or \"cuda\", or None).\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If an unsupported backend is specified.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self._backend = backend.lower()\n",
    "        if self._backend not in (\"numpy\", \"torch\"):\n",
    "            raise ValueError(\"Unsupported backend. Please choose 'numpy' or 'torch'.\")\n",
    "        self._is_numpy = (self._backend == \"numpy\")\n",
    "        self._is_torch = (self._backend == \"torch\")\n",
    "        \n",
    "        # Convert input data to the appropriate tensor type.\n",
    "        if self._is_numpy:\n",
    "            self.data = np.array(data, dtype=dtype)\n",
    "        else:\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed but backend 'torch' was requested.\")\n",
    "            self.data = data.to(device, dtype=dtype) if isinstance(data, torch.Tensor) else torch.tensor(data, device=device, dtype=dtype)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation showing backend, shape, and data.\n",
    "        \"\"\"\n",
    "        return f\"Tensor(backend={self._backend}, shape={self.shape}, data=\\n{self.data})\"\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "       \"\"\"\n",
    "       Allows subscription using a[i, j]. \n",
    "       If the result is an array, it returns a new Tensor; otherwise, the scalar value.\n",
    "       \"\"\"\n",
    "       result = self.data[key]\n",
    "       if (self._is_numpy and isinstance(result, np.ndarray)) or (self._is_torch and torch is not None and isinstance(result, torch.Tensor)):\n",
    "           return Tensor(result, backend=self._backend)\n",
    "       return result\n",
    "   \n",
    "    def __setitem__(self, key, value):\n",
    "        \"\"\"\n",
    "        Allows assignment using a[i, j] = value.\n",
    "        If the value is a Tensor instance, its underlying data is used.\n",
    "        \"\"\"\n",
    "        if isinstance(value, Tensor):\n",
    "            value = value.data\n",
    "        self.data[key] = value\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        \"\"\"\n",
    "        Retrieves the shape of the tensor.\n",
    "        \"\"\"\n",
    "        return self.data.shape\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        \"\"\"\n",
    "        Retrieves the data type of the tensor elements.\n",
    "        \"\"\"\n",
    "        return self.data.dtype\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        \"\"\"\n",
    "        Returns the data device of the tensor elements.\n",
    "        \"\"\"\n",
    "        if self._backend == \"numpy\":\n",
    "            return \"cpu\"\n",
    "        else:\n",
    "            return self.data.device.type\n",
    "        \n",
    "    @property\n",
    "    def requires_grad(self):\n",
    "        \"\"\"\n",
    "        Retrieve whether it requires gradients or not\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            raise NotImplementedError(\"Autograd is not implemented in numpy backend.\")\n",
    "        else:\n",
    "            return self.data.requires_grad\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Clear the Pytorch Gradient if any.\n",
    "        \"\"\"\n",
    "        if self._is_numpy == False:\n",
    "            if self.data.grad is not None:\n",
    "                self.data.grad.zero_()\n",
    "        return self\n",
    "    \n",
    "    def reshape(self, shape):\n",
    "        \"\"\"\n",
    "        Converts the tensor into a new shape.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor object with the specified shape.\n",
    "        \"\"\"\n",
    "        return Tensor(self.data.reshape(shape), backend=self._backend)\n",
    "    \n",
    "    def astype(self, dtype):\n",
    "        \"\"\"\n",
    "        Converts the underlying data to the specified type.\n",
    "        \n",
    "        For the numpy backend, it uses np.ndarray.astype.\n",
    "        For the torch backend, it maps the input (which can be a torch.dtype, a string, or a numpy type)\n",
    "        to the corresponding torch dtype and uses tensor.to(dtype=...).\n",
    "        \n",
    "        Args:\n",
    "            dtype: The desired data type. For numpy, any valid numpy dtype is accepted.\n",
    "                   For torch, this can be a torch.dtype, a string (e.g., \"float32\", \"int64\"),\n",
    "                   or a numpy dtype.\n",
    "                   \n",
    "        Returns:\n",
    "            A new Matrix instance with the data converted to the specified type.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            new_data = self.data.astype(dtype)\n",
    "            return Tensor(new_data, backend=\"numpy\")\n",
    "        else:\n",
    "            # Map the input dtype to a torch dtype.\n",
    "            torch_dtype = None\n",
    "            if isinstance(dtype, torch.dtype):\n",
    "                torch_dtype = dtype\n",
    "            elif isinstance(dtype, str):\n",
    "                mapping = {\n",
    "                    \"float32\": torch.float32,\n",
    "                    \"float\": torch.float32,\n",
    "                    \"float64\": torch.float64,\n",
    "                    \"double\": torch.float64,\n",
    "                    \"int32\": torch.int32,\n",
    "                    \"int\": torch.int32,\n",
    "                    \"int64\": torch.int64,\n",
    "                    \"long\": torch.int64,\n",
    "                    \"bool\": torch.bool,\n",
    "                    \"complex64\": torch.complex64,\n",
    "                    \"complex128\": torch.complex128\n",
    "                }\n",
    "                if dtype in mapping:\n",
    "                    torch_dtype = mapping[dtype]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported dtype string: {dtype}\")\n",
    "            elif isinstance(dtype, (np.dtype, type)):\n",
    "                np_dtype = np.dtype(dtype)\n",
    "                mapping = {\n",
    "                    np.dtype(\"float32\"): torch.float32,\n",
    "                    np.dtype(\"float64\"): torch.float64,\n",
    "                    np.dtype(\"int32\"): torch.int32,\n",
    "                    np.dtype(\"int64\"): torch.int64,\n",
    "                    np.dtype(\"bool\"): torch.bool,\n",
    "                    np.dtype(\"complex64\"): torch.complex64,\n",
    "                    np.dtype(\"complex128\"): torch.complex128,\n",
    "                }\n",
    "                if np_dtype in mapping:\n",
    "                    torch_dtype = mapping[np_dtype]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported numpy dtype: {np_dtype}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported dtype argument: {dtype}\")\n",
    "            new_data = self.data.to(dtype=torch_dtype)\n",
    "            return Tensor(new_data, backend=\"torch\")\n",
    "    \n",
    "    def to(self, backend, *, dtype = None, device=None):\n",
    "        \"\"\"\n",
    "        Converts the tensor to the specified backend and moves it to the specified device.\n",
    "        \n",
    "        Args:\n",
    "            backend (str): The target backend (\"numpy\" or \"torch\").\n",
    "            dtype (str, optional): The target type (any numpy or torch type nor None for auto inferenence).\n",
    "            device (str, optional): The target device (\"cpu\" or \"cuda\"). This parameter is only applicable when the target or source is torch.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: A new Tensor object with data in the target backend and on the specified device.\n",
    "        \"\"\"\n",
    "        target = backend.lower()\n",
    "        # If the target backend is the same as the current one.\n",
    "        if target == self._backend:\n",
    "            if self._is_torch:\n",
    "                # If already torch tensor, just move it to the desired device.\n",
    "                return Tensor(self.data.to(device, dtype = dtype), backend=\"torch\")\n",
    "            return Tensor(self.data, backend=self._backend, device=device, dtype=dtype)\n",
    "        \n",
    "        # Convert to numpy if requested.\n",
    "        if target == \"numpy\":\n",
    "            if self._is_torch:\n",
    "                # Move to CPU first (numpy only works on CPU) then convert to numpy.\n",
    "                return Tensor(self.data.cpu().to(dtype = dtype).numpy(), backend=\"numpy\")\n",
    "        \n",
    "        # Convert to torch if requested.\n",
    "        elif target == \"torch\":\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed.\")\n",
    "            if self._is_numpy:\n",
    "                # Create a torch tensor from numpy array.\n",
    "                tensor = torch.tensor(self.data, dtype = dtype, device = device)\n",
    "            else:\n",
    "                tensor = self.data\n",
    "            return Tensor(tensor, backend=\"torch\")\n",
    "        \n",
    "        raise ValueError(\"Unsupported backend conversion.\")\n",
    "\n",
    "    def _apply_op(self, other, op):\n",
    "        \"\"\"\n",
    "        Helper method to apply an element-wise binary operation.\n",
    "        \n",
    "        Args:\n",
    "            other (Tensor or scalar): Other operand.\n",
    "            op (callable): Function applying the desired operation element-wise.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: New Tensor resulting from the operation.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Tensor) else other\n",
    "        result = op(self.data, other_val)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def copy(self, *, backend=None, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a deep copy of the current tensor with the specified backend and data type.\n",
    "        \n",
    "        Args:\n",
    "            backend (str): The backend for the copied matrix. Default is None.\n",
    "            dtype: Desired data type for the result. Default is None.\n",
    "            device: Device to which the tensor should be moved if applicable. Default is None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A deep copy of the current matrix with the specified parameters.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if backend is None:\n",
    "                return Tensor(self.data.copy(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Tensor(self.data.copy(), backend=backend, dtype=dtype, device=device)\n",
    "        else:\n",
    "            if backend is None:\n",
    "                return Tensor(self.data.clone().detach(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Tensor(self.data.clone().detach(), backend=backend, dtype=dtype, device=device)\n",
    "    \n",
    "    def clone(self, *, backend=None, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a deep copy of the current tensor with the specified backend and data type without detach.\n",
    "        \n",
    "        Args:\n",
    "            backend (str): The backend for the copied matrix. Default is None.\n",
    "            dtype: Desired data type for the result. Default is None.\n",
    "            device: Device to which the tensor should be moved if applicable. Default is None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A deep copy of the current matrix with the specified parameters.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if backend is None:\n",
    "                return Tensor(self.data.copy(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Tensor(self.data.copy(), backend=backend, dtype=dtype, device=device)\n",
    "        else:\n",
    "            if backend is None:\n",
    "                return Tensor(self.data.clone(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Tensor(self.data.clone(), backend=backend, dtype=dtype, device=device)\n",
    "            \n",
    "    def clone_detach(self, *, backend=None, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a deep copy of the current tensor with the specified backend and data type with detach.\n",
    "        \n",
    "        Args:\n",
    "            backend (str): The backend for the copied matrix. Default is None.\n",
    "            dtype: Desired data type for the result. Default is None.\n",
    "            device: Device to which the tensor should be moved if applicable. Default is None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A deep copy of the current matrix with the specified parameters.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if backend is None:\n",
    "                return Tensor(self.data.copy(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Tensor(self.data.copy(), backend=backend, dtype=dtype, device=device)\n",
    "        else:\n",
    "            if backend is None:\n",
    "                return Tensor(self.data.clone().detach(), backend=self._backend, dtype=dtype, device=device)\n",
    "            else:\n",
    "                return Tensor(self.data.clone().detach(), backend=backend, dtype=dtype, device=device)\n",
    "    \n",
    "    def append(self, to_append, axis=0):\n",
    "        \"\"\"\n",
    "        Append a scalar (broadcasted) or an array to the matrix along the specified axis.\n",
    "        The tensor is a general n-dimensional tensor, so the appended data must have the same \n",
    "        shape as the original tensor on all axes except the specified axis.\n",
    "    \n",
    "        Args:\n",
    "            to_append: A scalar or an array-like object (or Tensor instance) to append.\n",
    "            axis (int): Axis along which to append. Negative values are supported.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new Tensor instance with the appended data.\n",
    "        \"\"\"\n",
    "        # Get number of dimensions and normalize the axis.\n",
    "        n_dim = len(self.data.shape)\n",
    "        if axis < 0:\n",
    "            axis = axis % n_dim\n",
    "        if axis >= n_dim:\n",
    "            raise ValueError(f\"Axis {axis} out of bounds for array with {n_dim} dimensions.\")\n",
    "    \n",
    "        orig_shape = self.data.shape\n",
    "    \n",
    "        # If to_append is a Tensor instance, extract its data.\n",
    "        if isinstance(to_append, type(self)):\n",
    "            appended_data = to_append.data\n",
    "        else:\n",
    "            # If to_append is a scalar, create an array/tensor with shape matching the original\n",
    "            # on every axis except the specified axis (which will be 1).\n",
    "            if np.isscalar(to_append):\n",
    "                new_shape = tuple(1 if i == axis else orig_shape[i] for i in range(n_dim))\n",
    "                if self._is_numpy:\n",
    "                    appended_data = np.full(new_shape, to_append, dtype=self.data.dtype)\n",
    "                else:\n",
    "                    appended_data = torch.full(new_shape, to_append, dtype=self.data.dtype, device=self.data.device)\n",
    "            elif isinstance(to_append, Tensor):\n",
    "                # Convert to array/tensor using the appropriate backend.\n",
    "                if self._is_numpy:\n",
    "                    appended_data = np.array(to_append.data.copy(), dtype=self.data.dtype)\n",
    "                else:\n",
    "                    appended_data = torch.tensor(to_append.data.clone().detach(), dtype=self.data.dtype, device=self.data.device)\n",
    "            else:\n",
    "                # Convert to array/tensor using the appropriate backend.\n",
    "                if self._is_numpy:\n",
    "                    appended_data = np.array(to_append.copy(), dtype=self.data.dtype)\n",
    "                else:\n",
    "                    appended_data = torch.tensor(to_append.clone().detach(), dtype=self.data.dtype, device=self.data.device)\n",
    "        \n",
    "        # If appended_data has one less dimension, expand it along the specified axis.\n",
    "        if len(appended_data.shape) == n_dim - 1:\n",
    "            if self._is_numpy:\n",
    "                appended_data = np.expand_dims(appended_data, axis=axis)\n",
    "            else:\n",
    "                appended_data = torch.unsqueeze(appended_data, dim=axis)\n",
    "        elif len(appended_data.shape) != n_dim:\n",
    "            raise ValueError(\"Appended data must have either the same number of dimensions as the original Tensor or one less.\")\n",
    "        \n",
    "        # Validate shape compatibility: for all dimensions except the specified axis, sizes must match.\n",
    "        for i in range(n_dim):\n",
    "            if i != axis and appended_data.shape[i] != orig_shape[i]:\n",
    "                raise ValueError(f\"Shape mismatch at dimension {i}: expected {orig_shape[i]}, got {appended_data.shape[i]}.\")\n",
    "        \n",
    "        # Concatenate along the specified axis.\n",
    "        if self._is_numpy:\n",
    "            new_data = np.concatenate((self.data, appended_data), axis=axis)\n",
    "        else:\n",
    "            new_data = torch.cat((self.data, appended_data), dim=axis)\n",
    "        \n",
    "            # Return a new Matrix instance with the updated data.\n",
    "        return Tensor(new_data, backend=self._backend)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Equals operator. \"\"\"\n",
    "        if isinstance(other, Object):\n",
    "            if np.prod(self.data.shape) == 1 and np.prod(other.data.shape) == 1:\n",
    "                # Scalar to scalar, output a scalar\n",
    "                return bool(self.flatten().data == other.flatten().data)\n",
    "            else:\n",
    "                return Tensor(self.data == other.data, backend=self._backend)\n",
    "                \n",
    "        elif np.prod(self.data.shape) == 1 and hasattr(other, \"__len__\") == False:\n",
    "            # Scalar to scalar, output a scalar\n",
    "            return bool(self.data == other)\n",
    "        else:\n",
    "            return Tensor(self.data == other, backend=self._backend)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"Element-wise addition.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(self.data + other_val, backend=self._backend)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        \"\"\"Right-hand element-wise addition.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(other_val + self.data, backend=self._backend)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \"\"\"Element-wise subtraction.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(self.data - other_val, backend=self._backend)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        \"\"\"Right-hand element-wise subtraction.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(other_val - self.data, backend=self._backend)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        \"\"\"Element-wise multiplication.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(self.data * other_val, backend=self._backend)\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        \"\"\"Right-hand element-wise multiplication.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(other_val * self.data, backend=self._backend)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        \"\"\"Element-wise true division.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(self.data / other_val, backend=self._backend)\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        \"\"\"Right-hand element-wise true division.\"\"\"\n",
    "        other_val = other.data if isinstance(other, Object) else other\n",
    "        return Tensor(other_val / self.data, backend=self._backend)\n",
    "    \n",
    "    def __pow__(self, to_power):\n",
    "        \"\"\"Element-wise power.\"\"\"\n",
    "        return self._apply_op(to_power, lambda a, b: a ** b)\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        \"\"\"Right-hand element-wise power.\"\"\"\n",
    "        return self.__pow__(other)\n",
    "\n",
    "    def __matmul__(self, other):\n",
    "        \"\"\"\n",
    "        Matrix multiplication using the @ operator.\n",
    "        \n",
    "        Uses the backend's built-in matmul operator.\n",
    "        \"\"\"\n",
    "        other_val = other.data if isinstance(other, Tensor) else other\n",
    "        result = self.data @ other_val\n",
    "        return Tensor(result, backend=self._backend)\n",
    "\n",
    "    def __neg__(self):\n",
    "        \"\"\"Negates the tensor element-wise.\"\"\"\n",
    "        return Tensor(-self.data, backend=self._backend)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the tensor.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def requires_grad_(self, requires_grad: bool = False):\n",
    "        \"\"\"\n",
    "        Require gradients to be computed or not. Only support torch.tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A revised self tensor with gradients opt-in or opt-out.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            raise NotImplementedError(\"Autograd is not implemented by numpy backend\")\n",
    "        else:\n",
    "            self.data = self.data.requires_grad_(requires_grad)\n",
    "        return self\n",
    "    \n",
    "    def unique(self):\n",
    "        \"\"\"\n",
    "        Returns the unique values of the elements that are non-zero.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The unique value tensor.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.unique(self.data)\n",
    "        else:\n",
    "            result = torch.unique(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def nonzero(self):\n",
    "        \"\"\"\n",
    "        Returns the indices of the elements that are non-zero.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The indices tensor.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = self.data.nonzero()\n",
    "        else:\n",
    "            result = self.data.nonzero()\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def any(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the element-wise logical OR along a specified axis.\n",
    "        \n",
    "        Args: \n",
    "            axis (int or None): Axis along which to apply the `any` operation. If not provided,\n",
    "                                it applies over all elements of the matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the result of the logical OR operation along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.any(self.data, axis=axis)\n",
    "        else:\n",
    "            result = self.data.any(dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def all(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the element-wise logical AND along a specified axis.\n",
    "    \n",
    "        Args: \n",
    "            axis (int or None): Axis along which to apply the `all` operation. If not provided,\n",
    "                                it applies over all elements of the matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the result of the logical AND operation along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.all(self.data, axis=axis)\n",
    "        else:\n",
    "            result = self.data.all(dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def round(self, digits = 0):\n",
    "        \"\"\"\n",
    "        Rounds the data to a specified number of decimal places.\n",
    "    \n",
    "        Args:\n",
    "            digits (int): The number of decimal places to round the data. Default is 0.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the rounded values of the original data.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.round(self.data, decimals = digits)\n",
    "        else:\n",
    "            result = torch.round(self.data, decimals = digits)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def mean(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the mean of the Tensor along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the mean. If None, computes the mean over all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed mean values.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.mean(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.mean(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def median(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the median along a given axis.\n",
    "    \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the median. Default is None, which computes over all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the computed medians.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.median(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.median(self.data)\n",
    "            else:\n",
    "                result, _ = torch.median(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def std(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the standard deviation of the Tensor along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the standard deviation. If None, computes the mean over all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed standard deviation values.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.std(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.std(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def var(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the variance of the Tensor along a specified axis.\n",
    "    \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the variance. If None, computes the mean over all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed variance values.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.var(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.var(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def min(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the minimum of the Tensor along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the minimum. If None, computes the mean over all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed minimum values.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if axis is None:\n",
    "                result = np.min(self.data)\n",
    "            else:\n",
    "                result = np.min(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.min(self.data)\n",
    "            else:\n",
    "                result, indices = torch.min(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def max(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the maximum of the Tensor along a specified axis.\n",
    "    \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the maximum. If None, computes the maximum over all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed maximum values.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if axis is None:\n",
    "                result = np.max(self.data)\n",
    "            else:\n",
    "                result = np.max(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.max(self.data)\n",
    "            else:\n",
    "                result, indices = torch.max(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def clip(self, a_min=None, a_max=None):\n",
    "        \"\"\"\n",
    "        Clips the values of the matrix to a specified range.\n",
    "    \n",
    "        Args: \n",
    "            a_min (float or None): Minimum value for clipping. If None, no minimum is applied.\n",
    "            a_max (float or None): Maximum value for clipping. If None, no maximum is applied.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the clipped values of the original data within the specified range.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.clip(self.data, a_min=a_min, a_max=a_max)\n",
    "        else:\n",
    "            result = torch.clip(self.data, min=a_min, max=a_max)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "\n",
    "    def sum(self, axis = None, keepdims = False):\n",
    "        \"\"\"\n",
    "        Computes the sum of the Tensor along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the sum. If None, computes across all dimensions.\n",
    "            keepdims (bool): If keeps the dimension or not.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed sum values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sum(self.data, axis=axis, keepdims=keepdims)\n",
    "        else:\n",
    "            result = torch.sum(self.data, dim=axis, keepdim=keepdims)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def cumsum(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the cumulative sum of the Tensor along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the cumulative sum. If None, computes across all dimensions.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed cumulative sum values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cumsum(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.cumsum(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def prod(self, axis = None, keepdims = False):\n",
    "        \"\"\"\n",
    "        Computes the product of the Tensor along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the product. If None, computes across all dimensions.\n",
    "            keepdims (bool): If keeps the dimension or not.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed product values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.prod(self.data, axis=axis, keepdims=keepdims)\n",
    "        else:\n",
    "            result = torch.prod(self.data, dim=axis, keepdim=keepdims)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def cumprod(self, axis = None):\n",
    "        \"\"\"\n",
    "        Computes the cumulative product of the Tensor along a specified axis.\n",
    "        \n",
    "        Args:\n",
    "            axis (Optional[int]): Axis along which to compute the cumulative product. If None, computes across all dimensions.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new instance containing the computed cumulative product values.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If no data attribute exists in the instance.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cumprod(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.cumprod(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def gamma(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise Gamma function.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the Gamma function values for each element in the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = sp.special.gamma(self.data)\n",
    "        else:\n",
    "            def torch_gamma(x):\n",
    "                pos = torch.exp(torch.lgamma(x))\n",
    "                neg = torch.pi / (torch.sin(torch.pi * x) * torch.exp(torch.lgamma(1 - x)))\n",
    "                return torch.where(x > 0, pos, neg)\n",
    "            result = torch_gamma(self.data)\n",
    "        return Tensor(result, backend=self._backend) \n",
    "    \n",
    "    def loggamma(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise natural logarithm of the Gamma function.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the natural logarithm of the Gamma function values for each element in the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = sp.special.gammaln(self.data)\n",
    "        else:\n",
    "            result = torch.special.gammaln(self.data)\n",
    "        return Tensor(result, backend=self._backend) \n",
    "    \n",
    "    def sigmoid(self):\n",
    "        \"\"\"\n",
    "        Applies the standard sigmoid function element-wise on the input Matrix.\n",
    "        \n",
    "        f(x) = L / (1 + exp(-1*x))\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor with the sigmoid function applied element-wise.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = 1.0 / (1.0 + np.exp(-1.0 * self.data ))\n",
    "        else:\n",
    "            result = torch.sigmoid(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def logistic(self, L=1.0, k=1.0, x0=0.0):\n",
    "        \"\"\"\n",
    "        Applies the logistic (sigmoid) function element-wise on the input Tensor.\n",
    "        \n",
    "        f(x) = L / (1 + exp(-k*(x - x0)))\n",
    "        \n",
    "        Args:\n",
    "            L (float): The curve's maximum value.\n",
    "            k (float): The steepness of the curve.\n",
    "            x0 (float): The x-value of the sigmoid's midpoint.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor with the logistic function applied element-wise.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = L / (1.0 + np.exp(-k * (self.data - x0)))\n",
    "        else:\n",
    "            result = L / (1.0 + torch.exp(-k * (self.data - x0)))\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def logistic_inv(self, L=1.0, k=1.0, x0=0.0):\n",
    "        \"\"\"\n",
    "        Applies the inverse of the logistic (sigmoid) function element-wise on the input Tensor.\n",
    "        \n",
    "        f(y) = x0 - (1/k)*ln((L - y)/y)\n",
    "        \n",
    "        Args:\n",
    "            L (float): The curve's maximum value used in the logistic function.\n",
    "            k (float): The steepness of the curve used in the logistic function.\n",
    "            x0 (float): The sigmoid's midpoint used in the logistic function.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor with the inverse logistic function applied element-wise.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = x0 - (1/k) * np.log((L - self.data) / self.data)\n",
    "        else:\n",
    "            result = x0 - (1/k) * torch.log((L - self.data) / self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def cholesky(self, upper = False):\n",
    "        \"\"\"\n",
    "        Computes the Cholesky decomposition of a symmetric positive-definite matrix.\n",
    "        L @ U = self.data\n",
    "        returns L if upper = False else U\n",
    "        \n",
    "        Args:\n",
    "            upper (bool): If True, compute the upper triangular factor. Default is False.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the lower triangular factor of the original data if `upper` is False,\n",
    "                    or its transpose if `upper` is True.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.linalg.cholesky(self.data)\n",
    "            if upper == True:\n",
    "                result = result.T\n",
    "        else:\n",
    "            result = torch.cholesky(self.data, upper = upper)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise exponential.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: New tensor with exponential applied.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.exp(self.data)\n",
    "        else:\n",
    "            result = torch.exp(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def sin(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise sine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Tensor containing the sine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sin(self.data)\n",
    "        else:\n",
    "            result = torch.sin(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def cos(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise cosine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Tensor containing the cosine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cos(self.data)\n",
    "        else:\n",
    "            result = torch.cos(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def tan(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise tangent.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Tensor containing the tangent values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.tan(self.data)\n",
    "        else:\n",
    "            result = torch.tan(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def sinh(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise hyperbolic sine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Tensor containing the hyperbolic sine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sinh(self.data)\n",
    "        else:\n",
    "            result = torch.sinh(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def cosh(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise hyperbolic cosine.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Tensor containing the hyperbolic cosine values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.cosh(self.data)\n",
    "        else:\n",
    "            result = torch.cosh(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def tanh(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise hyperbolic tangent.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Tensor containing the hyperbolic tangent values of the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.tanh(self.data)\n",
    "        else:\n",
    "            result = torch.tanh(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def abs(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise absolute values.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: New tensor with absolute values applied.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.abs(self.data)\n",
    "        else:\n",
    "            result = torch.abs(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def log(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise natural logarithm.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: New tensor with logarithm applied.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.log(self.data)\n",
    "        else:\n",
    "            result = torch.log(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def softmax(self, axis = 1, keepdims:bool | None = True):\n",
    "        \"\"\"\n",
    "        Applies the softmax function along a specified axis.\n",
    "        Reminder -> Shapre will be shrinked by 1 so that you may need to reshape() it.\n",
    "        \n",
    "        Args:\n",
    "            axis (int): Axis along which to apply the softmax. Default is 1.\n",
    "            keepdims (bool or None): Whether to keep the reduced dimensions as axes with size one. \n",
    "                                    If `True`, the shape of the result will be the same as input; otherwise, it will not have these dimensions.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the softmax values along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            if keepdims is not None and axis is not None:\n",
    "                e_x = np.exp(self.data - np.max(self.data, axis=axis, keepdims=keepdims))\n",
    "                result = e_x / e_x.sum(axis=axis, keepdims=keepdims)\n",
    "            else:\n",
    "                e_x = np.exp(self.data - np.max(self.data, axis=axis))\n",
    "                result = e_x / e_x.sum(axis=axis)\n",
    "        else:\n",
    "            result = torch.nn.functional.softmax(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "\n",
    "    def argmax(self, axis = 1):\n",
    "        \"\"\"\n",
    "         Computes the indices of the maximum values along a specified axis.\n",
    "         Reminder -> Shapre will be shrinked by 1 so that you may need to reshape() it.\n",
    "        \n",
    "         Args:\n",
    "             axis (int | None): Axis along which to compute the argmax. Default is 1.\n",
    "         \n",
    "         Returns:\n",
    "             Tensor: A new Tensor containing the indices of the maximum values along the specified axis.\n",
    "         \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.argmax(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.argmax(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def argmin(self, axis = 1):\n",
    "        \"\"\"\n",
    "        Computes the indices of the minimum values along a specified axis.\n",
    "    \n",
    "        Args:\n",
    "            axis (int | None): Axis along which to compute the argmin. Default is 1.\n",
    "        \n",
    "        Returns:\n",
    "           Tensor: A new Tensor containing the indices of the minimum values along the specified axis.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.argmin(self.data, axis=axis)\n",
    "        else:\n",
    "            result = torch.argmin(self.data, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)    \n",
    "    \n",
    "    def flatten(self):\n",
    "        \"\"\"\n",
    "        Returns the flattened tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: The flattened tensor.\n",
    "        \"\"\"\n",
    "        return Tensor(self.data.flatten(), backend=self._backend)\n",
    "    \n",
    "    def diag(self):\n",
    "        \"\"\"\n",
    "        Computes the diagonal vector of a square matrix.\n",
    "        Or create a diagonal matrix if 1D matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The diagonal vector.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the Tensor is not square.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Tensor(np.diag(self.data), backend=self._backend)\n",
    "        else:\n",
    "            return Tensor(torch.diag(self.data), backend=self._backend)\n",
    "    \n",
    "    def reverse(self, axis = 0):\n",
    "        \"\"\"\n",
    "        Reverse the flattened tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The reversed tensor.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Tensor(np.flip(self.data, axis=axis), backend=self._backend)\n",
    "        else:\n",
    "            return Tensor(torch.flip(self.data, axis=axis), backend=self._backend)\n",
    "\n",
    "    def vstack(self, *wargs):\n",
    "        \"\"\"\n",
    "        Stack data in sequence vertically (row wise).\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The vstacked tensor.\n",
    "        \"\"\"\n",
    "        data_list = [self.data]\n",
    "        for arg in wargs:\n",
    "            data_list.append(arg.data)\n",
    "        if self._is_numpy:\n",
    "            result = np.vstack(data_list)\n",
    "        else:\n",
    "            result = torch.vstack(data_list)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def hstack(self, *wargs):\n",
    "        \"\"\"\n",
    "        Stack data in sequence horizontally (col wise).\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The hstacked tensor.\n",
    "        \"\"\"\n",
    "        data_list = [self.data]\n",
    "        for arg in wargs:\n",
    "            data_list.append(arg.data)\n",
    "        if self._is_numpy:\n",
    "            result = np.hstack(data_list)\n",
    "        else:\n",
    "            result = torch.hstack(data_list)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "\n",
    "    def sign(self):\n",
    "        \"\"\"\n",
    "        Computes the element-wise sign of the data. Returns with the same type.\n",
    "    \n",
    "        Args: \n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the sign values (1 for positive, -1 for negative, 0 for zero) of each element in the original data.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sign(self.data)\n",
    "        else:\n",
    "            result = torch.sign(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "\n",
    "    def repeat(self, repeats, axis=None):\n",
    "        \"\"\"\n",
    "        Repeats the Tensor elements along a specified axis.\n",
    "    \n",
    "        Args:\n",
    "            repeats (int or tuple[int]): The number of times to repeat each element.\n",
    "            axis (int): Axis along which to repeat the elements. If `None`, repeats over all dimensions.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new Tensor with repeated elements.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = self.data.repeat(repeats, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.repeat_interleave(self.data, repeats)\n",
    "            else:\n",
    "                result = torch.repeat_interleave(self.data, repeats, dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def bincount(self, *, weights = None, inttype: type = int):\n",
    "        \"\"\"\n",
    "        Counts the number of occurrences of each value in `data` and optionally returns a weighted count.\n",
    "        Values will be forcefully casted to `inttype`\n",
    "    \n",
    "        Args:\n",
    "            weights (array_like | Tensor): An array-like object containing weights corresponding to each element in `data`. Default is None.\n",
    "            inttype (type): A type that the data is going to be casted to.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor with the bin counts or weighted bin counts.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.bincount(self.astype(inttype).data, weights = weights)\n",
    "        else:\n",
    "            result = torch.bincount(self.astype(inttype).data, weights = weights)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def transpose(self, *axes):\n",
    "        \"\"\"\n",
    "        Transposes the tensor dimensions. If axes are provided, permutes accordingly; otherwise, reverses dimensions.\n",
    "        \n",
    "        Args:\n",
    "            *axes: Optional permutation of dimensions.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: New transposed tensor.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = self.data.transpose(axes) if axes else self.data.T\n",
    "        else:\n",
    "            result = self.data.permute(*axes) if axes else self.data.permute(*reversed(range(self.data.dim())))\n",
    "        if len(self.shape) > 1:\n",
    "            return Tensor(result, backend=self._backend)\n",
    "        else:\n",
    "            # From a row vector to a column vector\n",
    "            return Tensor(result.reshape([self.shape[0], 1]), backend=self._backend)\n",
    "    \n",
    "    def quantile(self, q: float, axis = None, keepdims = False):\n",
    "        \"\"\"\n",
    "        Computes the specified quantiles along a given axis.\n",
    "    \n",
    "        Args:\n",
    "            q (float): The quantile to compute. Should be between 0 and 1.\n",
    "            axis (Optional[int]): Axis along which to compute the quantile. Default is None, which computes over all dimensions.\n",
    "            keepdims (bool): Whether to keep the reduced axes in the result as singleton dimensions. Default is False.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing the computed quantiles.\n",
    "    \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.quantile(self.data, q, axis = axis, keepdims = keepdims)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result = torch.quantile(self.data, q, keepdims = keepdims)\n",
    "            else:\n",
    "                result = torch.quantile(self.data, q, dim = axis, keepdims = keepdims)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def sort(self, axis: int | None = None):\n",
    "        \"\"\"\n",
    "        Sorts the tensor elements along (the first column of) a specified axis.\n",
    "        If you intend to sort on only one array, use `sort_along` instead,\n",
    "        or if you want to sort along each column of each base dimension, use `sort_along_each_column` instead.\n",
    "        \n",
    "        Args:\n",
    "            axis (int or None): Axis to sort along. If `None`, sorts the entire matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor with sorted elements.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.sort(self.data, axis=axis)\n",
    "        else:\n",
    "            if axis is None:\n",
    "                result, idx = self.data.sort()\n",
    "            else:\n",
    "                result, idx = self.data.sort(dim=axis)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "    \n",
    "    def sort_along(self, axis: tuple = (None, 0)):\n",
    "        \"\"\"\n",
    "        Sort the N-dimensional data along the 1d values on `axis`.\n",
    "        If you intend to sort on the first column of axis `axis`, use `sort` to speed up,\n",
    "        or if you want to sort along each column of each base dimension, use `sort_along_each_column` instead.\n",
    "       \n",
    "        Detail:\n",
    "        Sort the input array x. The axis parameter is a tuple of t\n",
    "        he same length as x.ndim, where each position can be None or an integer. \n",
    "        It is required that exactly one position d in axis_vec is not None,\n",
    "        and the reference position of this dimension d is fixed = axis_vec[d], \n",
    "        but when taking this reference, the index 0 is selected for each dimension \n",
    "        in the global uniform way (i.e., only x[(0,)*d + (fixed,)] is used as the \n",
    "        reference). \n",
    "        The 1D sorting permutation is calculated (using argsort, in ascending order), \n",
    "        and then the global permutation is applied to dimension d+1 \n",
    "        (the subsequent dimension) of x, acting on all data without sorting each\n",
    "        preceding block separately.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            axis : tuple\n",
    "                The indicator indicating sort which data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tensor, sorted copy.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(self.data.shape) != len(axis):\n",
    "            raise ValueError(\"The length of axis must be equal to the number of dimensions of the input array.\")\n",
    "        non_none = [(d, val) for d, val in enumerate(axis) if val is not None]\n",
    "        if len(non_none) != 1:\n",
    "            raise ValueError(\"There must be exactly one non-None element in axis\")\n",
    "        d, fixed = non_none[0]\n",
    "        if d > len(self.data.shape) - 1:\n",
    "            raise ValueError(\"The non-None dimension cannot be greater than dimension.\")\n",
    "        if fixed < 0 or fixed >= self.data.shape[d]:\n",
    "            raise IndexError(f\"Fixed index {fixed} is out of range for dimension {d} (0 to {self.data.shape[d]-1})\")\n",
    "        \n",
    "        # Last dim sort\n",
    "        if d == len(self.data.shape) - 1 and len(self.data.shape) == 2:\n",
    "            # Transpose, and sort the row\n",
    "            return self.transpose().sort_along(axis=(axis[1], axis[0])).transpose()\n",
    "        elif d == len(self.data.shape) - 1 and len(self.data.shape) > 2:\n",
    "            # Transpose the inner two dimensions\n",
    "            tr_axe = list(range(len(self.data.shape))); tmp = tr_axe[-1]; tr_axe[-1] = tr_axe[-2]; tr_axe[-2] = tmp;\n",
    "            axis_new = list(np.repeat(None, len(self.data.shape))); axis_new[-2] = fixed\n",
    "            return self.transpose(*tr_axe).sort_along(axis=axis_new).transpose(*tr_axe)\n",
    "        \n",
    "        # Extract global reference: fixed on dimension d, but all dimensions before d are indexed as 0.\n",
    "        # Construct index tuple: fixed to 0 for dimensions < d, fixed to the dth dimension, and use slice(None) to eliminate the remaining axes.\n",
    "        idx = (0,) * d + (fixed,)\n",
    "        \n",
    "        if self._is_numpy:\n",
    "            # Extract the reference key, which is expected to be 1D and have a length equal to self.data.shape[d+1]\n",
    "            key = np.asarray(self.data[idx])\n",
    "            if key.ndim != 1 or key.shape[0] != self.data.shape[d+1]:\n",
    "                raise ValueError(\"The reference key must be one-dimensional and its length must be the same as the length of the sorting axis.\")\n",
    "            order = np.argsort(key)\n",
    "           \n",
    "            # Construct a global index array for np.take_along_axis: needs to have the same shape as x,\n",
    "            # but order along sorting axis d+1, other dimensions are copied via broadcasting.\n",
    "            order_shape = [1] * len(self.data.shape)\n",
    "            order_shape[d+1] = self.data.shape[d+1]\n",
    "            order_global = order.reshape(order_shape)\n",
    "            order_global = np.broadcast_to(order_global, self.data.shape)\n",
    "            sorted_ = np.take_along_axis(self.data, order_global, axis=d+1)\n",
    "            return Tensor(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        else:\n",
    "            key = self.data[idx]\n",
    "            # key should be 1D, and its length should be equal to self.data.shape[d+1]\n",
    "            if key.dim() != 1 or key.size(0) != self.data.shape[d+1]:\n",
    "                raise ValueError(\"The reference key must be one-dimensional and its length must be the same as the length of the sorting axis.\")\n",
    "            # Calculate the sort order (ascending)\n",
    "            order = torch.argsort(key, dim=0)\n",
    "            \n",
    "            # Construct a global index tensor with the same shape as self.data, but with order on the sorting axis d+1\n",
    "            order_shape = [1] * len(self.data.shape)\n",
    "            order_shape[d+1] = self.data.shape[d+1]\n",
    "            order_global = order.view(*order_shape).expand(self.data.shape)\n",
    "            \n",
    "            # Use torch.gather to rearrange self.data according to the global index tensor on dim=d+1\n",
    "            sorted_ = torch.gather(self.data, dim=d+1, index=order_global)\n",
    "            return Tensor(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "    def sort_along_each_column(self, axis: int = 1, on_col: int = 0):\n",
    "        \"\"\"\n",
    "        Sort the N-dimensional data along values on column `on_col` of the axis `axis`.\n",
    "        Note, it will sort EACH `on_col` of the exterior axises.\n",
    "        If you intend to sort on the first column of axis `axis`, use `sort` to speed up.\n",
    "       \n",
    "        Detail:\n",
    "        Instead of sorting itself in d dimensions, use the reference sequence obtained by taking index=i on the d axis of x, and apply the same rearrangement to the d+1 axis (next axis) of x.\n",
    "\n",
    "        For example, for a 2D array, when d=0, i=1,\n",
    "        take the reference sequence = x[1, :], calculate its argsort to get the sorted arrangement, and then rearrange the columns of each row of the entire array according to this arrangement;\n",
    "        For a 3D array, when d=1, i=0,\n",
    "        for each subarray with fixed axis=0, take the reference sequence = subarray[0, :] (that is, the row of axis=1 index 0),\n",
    "        calculate argsort (sort the elements in the reference sequence), and then rearrange all rows in the subarray (all slices of axis=1) on axis=2 according to this arrangement.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            axis : int\n",
    "                The axis of the column is on. The default is 1.\n",
    "            on_col : int\n",
    "                The index of the column is on. The default is 0.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tensor, sorted copy.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(self.data.shape) < 2:\n",
    "            raise ValueError(\"The input data must at least have 2 dimensions. Use `sort` if it is a 1d array.\")\n",
    "        if axis < 0 or axis > len(self.data.shape) - 1:\n",
    "            raise ValueError(\"The parameter d must be positive and smaller than ndim.\")\n",
    "        if axis == len(self.data.shape) - 1 and len(self.data.shape) == 2:\n",
    "            # Transpose, and sort the row\n",
    "            return self.transpose().sort_along_each_column(axis=0, on_col=on_col).transpose()\n",
    "        elif axis == len(self.data.shape) - 1 and len(self.data.shape) > 2:\n",
    "            # Transpose the inner two dimensions\n",
    "            tr_axe = list(range(len(self.data.shape))); tmp = tr_axe[-1]; tr_axe[-1] = tr_axe[-2]; tr_axe[-2] = tmp;\n",
    "            return self.transpose(*tr_axe).sort_along_each_column(axis=axis-1, on_col=on_col).transpose(*tr_axe)\n",
    "            \n",
    "        sorted_axis = axis + 1\n",
    "\n",
    "        if self._is_numpy:\n",
    "            key = np.take(self.data, indices=on_col, axis=axis)\n",
    "            order = np.argsort(key, axis=axis)\n",
    "            order_expanded = np.expand_dims(order, axis=axis)\n",
    "            sorted_ = np.take_along_axis(self.data, order_expanded, axis=sorted_axis)\n",
    "            return Tensor(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        else:\n",
    "            key = self.data.select(dim=axis, index=on_col)\n",
    "            order = torch.argsort(key, dim=axis)\n",
    "            order_expanded = order.unsqueeze(dim=axis)\n",
    "            expand_shape = list(self.data.shape)\n",
    "            index = order_expanded.expand(*expand_shape)\n",
    "            sorted_ = torch.gather(self.data, dim=sorted_axis, index=index)\n",
    "            return Tensor(sorted_, backend=self._backend, dtype=self.dtype, device=self.device)        \n",
    "    \n",
    "    def determinant(self):\n",
    "        \"\"\"\n",
    "        Computes the determinant if the tensor is a matrix.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: New tensor of determinant.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return np.linalg.det(self.data)\n",
    "        else:\n",
    "            if hasattr(torch, 'linalg') and hasattr(torch.linalg, 'det'):\n",
    "                return torch.linalg.det(self.data)\n",
    "            else:\n",
    "                return torch.det(self.data)\n",
    "            \n",
    "    def inverse(self):\n",
    "        \"\"\"\n",
    "        Computes the inverse of a tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: New tensor with its inversed stored.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            result = np.linalg.inv(self.data)\n",
    "        else:\n",
    "            if hasattr(torch, 'linalg') and hasattr(torch.linalg, 'inv'):\n",
    "                result = torch.linalg.inv(self.data)\n",
    "            else:\n",
    "                result = torch.inverse(self.data)\n",
    "        return Tensor(result, backend=self._backend)\n",
    "\n",
    "    def trace(self):\n",
    "        \"\"\"\n",
    "        Computes the trace of a tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: New tensor with trace stored.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return np.trace(self.data)\n",
    "        else:\n",
    "            return torch.trace(self.data)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def dot(self, other):\n",
    "        \"\"\"\n",
    "        Computes the dot product of this matrix with another Matrix.\n",
    "        \n",
    "        Args:\n",
    "            other (Matrix): The other matrix to multiply.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A new Matrix instance with the result of the dot product.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Tensor(np.dot(self.data, other.data), backend=\"numpy\")\n",
    "        else:\n",
    "            return Tensor(torch.matmul(self.data, other.data), backend=\"torch\")\n",
    "        \n",
    "    def inner(self, other):\n",
    "        \"\"\"\n",
    "        Computes the inner product of this Tensor with another Tensor.\n",
    "        \n",
    "        Args:\n",
    "            other (Tensor): The other Tensor to multiply.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor instance with the result of the inner product.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Tensor(np.inner(self.data, other.data), backend=\"numpy\")\n",
    "        else:\n",
    "            return Tensor(torch.inner(self.data, other.data), backend=\"torch\")\n",
    "    \n",
    "    def outer(self, other):\n",
    "        \"\"\"\n",
    "        Computes the outer product of this Tensor with another Tensor.\n",
    "        \n",
    "        Args:\n",
    "            other (Tensor): The other Tensor to multiply.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor instance with the result of the outer product.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return Tensor(np.outer(self.data, other.data), backend=\"numpy\")\n",
    "        else:\n",
    "            return Tensor(torch.outer(self.data, other.data), backend=\"torch\")\n",
    "\n",
    "    def svd(self, full_matrices=True):\n",
    "        \"\"\"\n",
    "        Computes the singular value decomposition for a general tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensors: New s,v,d tensors in a tuple.\n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            U, s, Vh = np.linalg.svd(self.data, full_matrices=full_matrices)\n",
    "            return Tensor(U, backend=\"numpy\"), Tensor(s, backend=\"numpy\"), Tensor(Vh, backend=\"numpy\")\n",
    "        else:\n",
    "            if hasattr(torch, 'linalg') and hasattr(torch.linalg, 'svd'):\n",
    "                U, s, Vh = torch.linalg.svd(self.data, full_matrices=full_matrices)\n",
    "            else:\n",
    "                U, s, V = torch.svd(self.data, some=not full_matrices)\n",
    "                Vh = V.t()\n",
    "            return Tensor(U, backend=\"torch\"), Tensor(s, backend=\"torch\"), Tensor(Vh, backend=\"torch\")\n",
    " \n",
    "    def to_zeros(self):\n",
    "        \"\"\"\n",
    "        Converts the Tensor data into a same shape Tensor with 0s.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: a same shape Tensor with 0s.\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.copy()\n",
    "        x[...] = 0\n",
    "        return x\n",
    "    \n",
    "    def to_ones(self):\n",
    "        \"\"\"\n",
    "        Converts the Tensor data into a same shape Tensor with 1s.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: a same shape Tensor with 0s.\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.copy()\n",
    "        x[...] = 1\n",
    "        return x\n",
    "    \n",
    "    def to_ks(self, k: float | int = 0):\n",
    "        \"\"\"\n",
    "        Converts the Tensor data into a same shape Tensor with ks.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: a same shape Tensor with 1s.\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.copy()\n",
    "        x[...] = k\n",
    "        return x\n",
    "    \n",
    "    def to_rands(self):\n",
    "        \"\"\"\n",
    "        Converts the Tensor data into a same shape Tensor with uniform random numbers.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: a same shape Tensor with uniform random numbers.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.rand(self.shape, backend=self._backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "    def to_list(self):\n",
    "        \"\"\"\n",
    "        Converts the Tensor data into a Python list.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            list: A Python list containing the same elements as `self.data`.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return self.data.tolist()\n",
    "        else:\n",
    "            return self.data.cpu().tolist()\n",
    "        \n",
    "    def to_numpy_array(self):\n",
    "        \"\"\"\n",
    "        Converts the Tensor data into a NumPy array.\n",
    "        \n",
    "        Returns: \n",
    "            np.ndarray: The underlying NumPy array of the matrix.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return self.data\n",
    "        else:\n",
    "            return self.data.detach().cpu().numpy()\n",
    "        \n",
    "    def to_torch_tensor(self, *, dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Converts the Tensor data into a PyTorch tensor.\n",
    "        \n",
    "        Args: \n",
    "            dtype (torch.dtype or None): The desired data type for the resulting tensor. If not provided,\n",
    "                                         uses the current data type of `self.data`.\n",
    "            device (torch.device or None): The target device to which the tensor should be moved.\n",
    "                                           If not provided, it will use the default device.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: A PyTorch tensor containing the same data as `self.data`.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self._is_numpy:\n",
    "            return torch.tensor(self.data, dtype=dtype, device=device)\n",
    "        else:\n",
    "            return self.data\n",
    "        \n",
    "    @staticmethod\n",
    "    def equal(x, other, *, equal_nan=False):\n",
    "        \"\"\"\n",
    "        Compare if two Tensor objects have the same shape and elements.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): The one tensor to compare.\n",
    "            other (Tensor): The other tensor to compare.\n",
    "        \n",
    "        Returns:\n",
    "           ``True`` if two tensors have the same size and elements, \n",
    "           ``False`` otherwise.\n",
    "        \"\"\"\n",
    "        if x._is_numpy == True and other._is_numpy == True:\n",
    "            return np.array_equal(x, other, equal_nan=equal_nan)\n",
    "        elif  x._is_numpy == False and other._is_numpy == False:\n",
    "            return torch.equal(x, other)\n",
    "        else:\n",
    "            raise ValueError(\"Input `x` and `other` for comparison must have to have the same backend!\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def gather_along(data, axis, index):\n",
    "        \"\"\"\n",
    "        Gather values on an axis with specified index.\n",
    "        \n",
    "        Parameters:\n",
    "            axis: int, the axis number to gather values on.\n",
    "            index: list | array | Matrix, the indices for each row/column/.. to gather values on.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: gathered elements.\n",
    "        \"\"\"\n",
    "        if data._is_numpy:\n",
    "            result = np.take_along_axis(data.data, indices=index, axis=axis)\n",
    "        else:\n",
    "            result = torch.gather(data.data, dim=axis, index=index.data)\n",
    "        return Tensor(result, backend=data._backend, dtype=data.dtype, device=data.device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def where(condition, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Returns elements depending on `condition`.\n",
    "        \n",
    "        Parameters:\n",
    "            condition : Internal Type (array_like); bool Where True\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: chosen elements.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            result = np.where(condition)\n",
    "        else:\n",
    "            result, = torch.where(condition)\n",
    "            if isinstance(result, tuple):\n",
    "                result = result[0]\n",
    "        return Tensor(result, backend=backend, dtype=dtype, device=device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def where_as(condition, then, other, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Returns elements depending on `condition`.\n",
    "        \n",
    "        Parameters:\n",
    "            condition : Internal Type (array_like); bool Where True\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: if true then applied then to true elements; other to fales elements.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            result = np.where(condition, then, other)\n",
    "        else:\n",
    "            result = torch.where(condition, then, other)         \n",
    "            if isinstance(result, tuple):\n",
    "                result = result[0]\n",
    "        return Tensor(result, backend=backend, dtype=dtype, device=device)\n",
    "        \n",
    "    @staticmethod\n",
    "    def zeros(shape, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a tensor filled with zeros.\n",
    "        \n",
    "        Args:\n",
    "            shape (tuple): Desired shape.\n",
    "            backend (str): Backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: New tensor of zeros.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.zeros(shape, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.zeros(shape, dtype=dtype, device=device) if dtype else torch.zeros(shape, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Tensor(data, backend=backend)\n",
    "\n",
    "    @staticmethod\n",
    "    def ones(shape, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a tensor filled with ones.\n",
    "        \n",
    "        Args:\n",
    "            shape (tuple): Desired shape.\n",
    "            backend (str): Backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: New tensor of ones.\n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.ones(shape, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.ones(shape, dtype=dtype, device=device) if dtype else torch.ones(shape, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Tensor(data, backend=backend)\n",
    "    \n",
    "    @staticmethod\n",
    "    def zeros_like(x, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a matrix of zeros with the same shape and data type as another matrix.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): The input matrix.\n",
    "            backend (str): The backend for computation (\"numpy\" or \"torch\"). Default is \"numpy\".\n",
    "            dtype: Desired data type for the result. If not specified, uses the data type from `x`.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing zeros with the same shape and type as `x`.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If an unsupported backend is provided.\n",
    "        \n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.zeros_like(x.data, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.zeros_like(x.data, dtype=dtype, device=device) if dtype else torch.zeros_like(x.data, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Tensor(data, backend=backend)\n",
    "    \n",
    "    @staticmethod\n",
    "    def ones_like(x, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a matrix of ones with the same shape and data type as another matrix.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): The input matrix.\n",
    "            backend (str): The backend for computation (\"numpy\" or \"torch\"). Default is \"numpy\".\n",
    "            dtype: Desired data type for the result. If not specified, uses the data type from `x`.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: A new Tensor containing ones with the same shape and type as `x`.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If an unsupported backend is provided.\n",
    "        \n",
    "        \"\"\"\n",
    "        if backend == \"numpy\":\n",
    "            data = np.ones_like(x.data, dtype=dtype)\n",
    "        elif backend == \"torch\":\n",
    "            data = torch.ones_like(x.data, dtype=dtype, device=device) if dtype else torch.ones_like(x.data, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Tensor(data, backend=backend)\n",
    "    \n",
    "    @staticmethod\n",
    "    def rand(shape, backend=\"numpy\", dtype=None, device=None):\n",
    "        \"\"\"\n",
    "        Creates a tensor with random values uniformly distributed in [0, 1).\n",
    "        \n",
    "        Args:\n",
    "            shape (tuple): Desired shape.\n",
    "            backend (str): Backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            device: Data device, \"cpu\" or \"cuda\".\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: New tensor with random values.\n",
    "        \"\"\"\n",
    "        bk = backend.lower()\n",
    "        if bk == \"numpy\":\n",
    "            data = np.random.rand(*shape)\n",
    "            if dtype:\n",
    "                data = data.astype(dtype)\n",
    "        elif bk == \"torch\":\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed.\")\n",
    "            data = torch.rand(shape, dtype=dtype, device=device) if dtype else torch.rand(shape, device=device)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Tensor(data, backend=bk)\n",
    "    \n",
    "    @staticmethod\n",
    "    def identity(n, backend=\"numpy\", dtype=None):\n",
    "        \"\"\"\n",
    "        Creates a tensor with identity property.\n",
    "        \n",
    "        Args:\n",
    "            backend (str): Backend (\"numpy\" or \"torch\").\n",
    "            dtype: Desired data type.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: New identity tensor.\n",
    "        \"\"\"\n",
    "        bk = backend.lower()\n",
    "        if bk == \"numpy\":\n",
    "            data = np.eye(n, dtype=dtype)\n",
    "        elif bk == \"torch\":\n",
    "            if torch is None:\n",
    "                raise ImportError(\"PyTorch is not installed.\")\n",
    "            data = torch.eye(n, dtype=dtype)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backend. Choose 'numpy' or 'torch'.\")\n",
    "        return Tensor(data, backend=bk)\n",
    "\n",
    "    def reshape_(self, *shape):\n",
    "        \"\"\"\n",
    "        In-place reshape of the tensor.\n",
    "        \n",
    "        Args:\n",
    "            *shape: New shape dimensions.\n",
    "            \n",
    "        Returns:\n",
    "            self: The reshaped tensor.\n",
    "        \"\"\"\n",
    "        self.data = self.data.reshape(*shape)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Metrics for Binary and Multi-Class Classification Implementation (self-implemented)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These metrics classes are self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Metrics Base Class\n",
    "class BaseMetrics:\n",
    "    \n",
    "    __attr__ = \"MML.BaseMetrics\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        Compute the specified metric for the predictions given true data.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Compute is NOT implemented in the base class.\")\n",
    "        \n",
    "    def deriv_1(self):\n",
    "        \"\"\"\n",
    "        Compute the sample-wise 1st order derivatives of metric for the predictions given true data.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Deriv_1 is NOT implemented in the base class.\")\n",
    "        \n",
    "    def deriv_2(self):\n",
    "        \"\"\"\n",
    "        Compute the sample-wise 2nd order derivatives of metric for the predictions given true data.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Deriv_2 is NOT implemented in the base class.\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"BaseMetrics(Abstract Class).\"\n",
    "\n",
    "\n",
    "# Metrics for regression\n",
    "class RegressionMetrics(BaseMetrics):\n",
    "    \"\"\"\n",
    "    A class to compute common regression metrics between predicted results and target values.\n",
    "    \n",
    "    Supported metrics:\n",
    "        - MSE (Mean Squared Error)\n",
    "        - RMSE (Root Mean Squared Error) \n",
    "        - MAE (Mean Absolute Error)\n",
    "        - MAPE (Mean Absolute Percentage Error)\n",
    "        - Huber Loss\n",
    "        - Quantile Loss\n",
    "        - WMSE (Weighted Mean Squared Error)\n",
    "        - WRMSE (Weighted Root Mean Squared Error)\n",
    "        - R^2 (R Square)\n",
    "        - Adjusted R^2 (Adjusted R Square)\n",
    "        \n",
    "    Special metrics:\n",
    "        - Negative R^2 (R Square)\n",
    "        - Negative Adjusted R^2 (Adjusted R Square)\n",
    "        \n",
    "    The computations are performed using the underlying tensor operations, maintaining\n",
    "    compatibility with both numpy and torch backends.\n",
    "    \n",
    "    Attributes:\n",
    "        result: Predicted results tensor\n",
    "        target: Target values tensor\n",
    "        metric_type: String specifying which metric to compute ('mse', 'rmse', 'mae', 'mape', 'r2', 'adjusted r2')\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.RegressionMetrics\"\n",
    "    \n",
    "    def __init__(self, result: Tensor | Matrix, target: Tensor | Matrix, metric_type: str, k: int | None = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the RegressionMetrics instance with result and target tensors.\n",
    "        \n",
    "        Args:\n",
    "            result (Tensor | Matrix): Predicted results tensor\n",
    "            target (Tensor | Matrix): Target values tensor\n",
    "            metric_type (str): Metric type to compute ('mse', 'rmse', 'mae', 'mape', 'huber_loss', 'quantile_loss', \n",
    "                              'wmse', 'wrmse', 'r2', 'adjusted r2', 'nr2', 'nadjusted r2')\n",
    "            k (int): Number of predictors (parameters) in the model, only used in Adjusted R2.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Different instances or different backends.\n",
    "        if isinstance(result,  Object) == False or isinstance(target, Object) == False:\n",
    "            raise ValueError(\"Predicted `result` and real `target` should be either `Matrix` or `Tensor` type!\")\n",
    "        if type(result) != type(target):\n",
    "            raise ValueError(\"Predicted `result` and real `target` should have the same type, either Tensor or Matrix!\")\n",
    "        if result._backend != target._backend:\n",
    "            raise ValueError(\"Predicted `result` and real `target` should have the same backend, either numpy or torch!\")\n",
    "        \n",
    "        # Member variables.\n",
    "        self.k = k\n",
    "        self.result = result\n",
    "        self.target = target\n",
    "        self.typeclass = type(result)\n",
    "        self.metric_type = metric_type.lower()\n",
    "        \n",
    "        if not self.result.shape == self.target.shape:\n",
    "            raise ValueError(\"Result and target tensors must have the same shape.\")\n",
    "            \n",
    "    def compute(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the specified regression metric between result and target.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: The computed metric value as a tensor\n",
    "        \"\"\"\n",
    "        if self.metric_type == 'mse':\n",
    "            return self._compute_mse(**kwargs)\n",
    "        elif self.metric_type == 'rmse':\n",
    "            return self._compute_rmse(**kwargs)\n",
    "        elif self.metric_type == 'mae':\n",
    "            return self._compute_mae(**kwargs)\n",
    "        elif self.metric_type == 'mape':\n",
    "            return self._compute_mape(**kwargs)\n",
    "        elif self.metric_type == 'huber_loss':\n",
    "            return self._compute_huber_loss(**kwargs)\n",
    "        elif self.metric_type == 'quantile_loss':\n",
    "            return self._compute_quantile_loss(**kwargs)\n",
    "        elif self.metric_type == 'wmse':\n",
    "            return self._compute_wmse(**kwargs)\n",
    "        elif self.metric_type == 'wrmse':\n",
    "            return self._compute_wrmse(**kwargs)\n",
    "        elif self.metric_type == 'r2':\n",
    "            return self._compute_r2(**kwargs)\n",
    "        elif self.metric_type == 'adjusted r2':\n",
    "            return self._compute_adjusted_r2(**kwargs)\n",
    "        # Special Metrics\n",
    "        elif self.metric_type == 'nr2':\n",
    "            return - self._compute_r2(**kwargs)\n",
    "        elif self.metric_type == 'nadjusted r2':\n",
    "            return - self._compute_adjusted_r2(**kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "    \n",
    "    def deriv_1(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the sample-wise 1st order derivative of the specified regression metric between result and target.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: The computed gradient vector as a matrix or a tensor\n",
    "        \"\"\"\n",
    "        if self.metric_type == 'mse':\n",
    "            return self._deriv_1_mse(**kwargs)\n",
    "        elif self.metric_type == 'rmse':\n",
    "            return self._deriv_1_rmse(**kwargs)\n",
    "        elif self.metric_type == 'mae':\n",
    "            return self._deriv_1_mae(**kwargs)\n",
    "        elif self.metric_type == 'mape':\n",
    "            return self._deriv_1_mape(**kwargs)\n",
    "        elif self.metric_type == 'huber_loss':\n",
    "            return self._deriv_1_huber_loss(**kwargs)\n",
    "        elif self.metric_type == 'quantile_loss':\n",
    "            return self._deriv_1_quantile_loss(**kwargs)\n",
    "        elif self.metric_type == 'wmse':\n",
    "            return self._deriv_1_wmse(**kwargs)\n",
    "        elif self.metric_type == 'wrmse':\n",
    "            return self._deriv_1_wrmse(**kwargs)\n",
    "        elif self.metric_type == 'r2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'adjusted r2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # Special Metrics\n",
    "        elif self.metric_type == 'nr2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'nadjusted r2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        else:\n",
    "            raise  ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "    \n",
    "    def deriv_2(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the sample-wise 2nd order derivative of the specified regression metric between result and target.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: The computed hessian matrix (without cross terms) as a matrix or a tensor\n",
    "        \"\"\"\n",
    "        if self.metric_type == 'mse':\n",
    "            return self._deriv_2_mse(**kwargs)\n",
    "        elif self.metric_type == 'rmse':\n",
    "            return self._deriv_2_rmse(**kwargs)\n",
    "        elif self.metric_type == 'mae':\n",
    "            return self._deriv_2_mae(**kwargs)\n",
    "        elif self.metric_type == 'mape':\n",
    "            return self._deriv_2_mape(**kwargs)\n",
    "        elif self.metric_type == 'huber_loss':\n",
    "            return self._deriv_2_huber_loss(**kwargs)\n",
    "        elif self.metric_type == 'quantile_loss':\n",
    "            return self._deriv_2_quantile_loss(**kwargs)\n",
    "        elif self.metric_type == 'wmse':\n",
    "            return self._deriv_2_wmse(**kwargs)\n",
    "        elif self.metric_type == 'wrmse':\n",
    "            return self._deriv_2_wrmse(**kwargs)\n",
    "        elif self.metric_type == 'r2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'adjusted r2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # Special Metrics\n",
    "        elif self.metric_type == 'nr2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'nadjusted r2':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        else:\n",
    "            raise  ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "        \n",
    "    def _compute_mse(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: MSE tensor or matrix\n",
    "        \"\"\"\n",
    "        error = (self.result - self.target)\n",
    "        squared_error = error ** 2\n",
    "        if axis is None:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / np.array(squared_error.shape).prod()\n",
    "        else:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / squared_error.shape[axis]\n",
    "        return mean_squared_error\n",
    "    \n",
    "    def _deriv_1_mse(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of MSE tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        grad = 2 * error / error.shape[0]\n",
    "        if axis is None:\n",
    "            grad = 2 * error / np.array(error.shape).prod()\n",
    "        else:\n",
    "            grad = 2 * error / error.shape[axis]\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_mse(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative (Hessian diagonal) of the Mean Squared Error between result and target.\n",
    "    \n",
    "        Args:\n",
    "            only_diag: bool, if True, only calculate the diagonal vector and return,\n",
    "                             else, return the full hessian matrix.\n",
    "    \n",
    "        Returns:\n",
    "            Tensor | Matrix: Constant Hessian of MSE (2/N) with the same shape as result.\n",
    "        \"\"\"\n",
    "        ones = self.result.copy(); ones[...] = 1;\n",
    "        if axis is None:\n",
    "            return ones * (2.0 / np.array(self.result.shape).prod())\n",
    "        else:\n",
    "            return ones * (2.0 / self.result.shape[axis])\n",
    "    \n",
    "    def _compute_rmse(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Root Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "                \n",
    "        Returns:\n",
    "            Tensor | Matrix: RMSE tensor or matrix\n",
    "        \"\"\"\n",
    "        error = (self.result - self.target)\n",
    "        squared_error = error ** 2\n",
    "        if axis is None:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / np.array(squared_error.shape).prod()\n",
    "        else:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / squared_error.shape[axis]\n",
    "        rmse = mean_squared_error ** 0.5\n",
    "        return rmse\n",
    "    \n",
    "    def _deriv_1_rmse(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Root Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of RMSE tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        squared_error = error ** 2\n",
    "        if axis is None:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / np.array(squared_error.shape).prod()\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            grad = error / (np.array(squared_error.shape).prod() * rmse)\n",
    "        else:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / squared_error.shape[axis]\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            grad = error / (error.shape[axis] * rmse)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_rmse(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative of the Root Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Second-order derivative (Hessian diagonal) of RMSE with respect to result.\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        squared_error = error ** 2\n",
    "        if axis is None:\n",
    "            sum_squared = squared_error.sum(axis = axis)\n",
    "            mean_squared_error = sum_squared / np.array(squared_error.shape).prod()\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            hessian = (sum_squared - squared_error) / ((np.array(squared_error.shape).prod() ** 2) * (rmse ** 3))\n",
    "        else:\n",
    "            sum_squared = squared_error.sum(axis = axis)\n",
    "            mean_squared_error = sum_squared / squared_error.shape[axis]\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            hessian = (sum_squared - squared_error) / ((error.shape[axis] ** 2) * (rmse ** 3))\n",
    "        \n",
    "        return hessian\n",
    "    \n",
    "    def _compute_mae(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Mean Absolute Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: MAE tensor or matrix\n",
    "        \"\"\"\n",
    "        error = (self.result - self.target)\n",
    "        absolute_error = error.abs()\n",
    "        if axis is None:\n",
    "            mean_absolute_error = absolute_error.sum(axis = axis) / np.array(absolute_error.shape).prod()\n",
    "        else:\n",
    "            mean_absolute_error = absolute_error.sum(axis = axis) / absolute_error.shape[axis]\n",
    "        return mean_absolute_error\n",
    "\n",
    "    def _deriv_1_mae(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Mean Absolute Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of MAE tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        grad = error.sign() / error.shape[0]\n",
    "        if axis is None:\n",
    "            grad = error.sign() / np.array(error.shape).prod()\n",
    "        else:\n",
    "            grad = error.sign() / error.shape[axis]\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_mae(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative of per-output MAE between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "                \n",
    "        Returns:\n",
    "            Tensor | Matrix: Hessian diagonal of MAE (zero), shape (N, D).\n",
    "        \"\"\"\n",
    "        zeros = self.result.copy(); zeros[...] = 0;\n",
    "        return zeros\n",
    "    \n",
    "    def _compute_mape(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Mean Absolute Percentage Error between result and target.\n",
    "        \n",
    "        Note: Division by zero occurs if target contains zeros. This is handled\n",
    "        gracefully by the underlying tensor operations, but users should ensure \n",
    "        target values are non-zero when using MAPE.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: MAPE tensor or matrix\n",
    "        \"\"\"\n",
    "        error = (self.result - self.target) / self.target\n",
    "        absolute_percentage_error = error.abs()\n",
    "        if axis is None:\n",
    "            mean_absolute_percentage_error = absolute_percentage_error.sum(axis = axis) / np.array(absolute_percentage_error.shape).prod()\n",
    "        else:\n",
    "            mean_absolute_percentage_error = absolute_percentage_error.sum(axis = axis) / absolute_percentage_error.shape[axis]\n",
    "        return mean_absolute_percentage_error\n",
    "\n",
    "    def _deriv_1_mape(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Mean Absolute Percentage Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of MAPE tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        # Derivative: sign(ratio) * (1/target) / N\n",
    "        ratio = (self.result - self.target) / self.target\n",
    "        if axis is None:\n",
    "            grad = ratio.sign() / (self.target * np.array(ratio.shape).prod())\n",
    "        else:\n",
    "            grad = ratio.sign() / (self.target * ratio.shape[axis])\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_mape(self, axis: int | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative of per-output MAPE between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "                \n",
    "        Returns:\n",
    "            Tensor | Matrix: Hessian diagonal of MAPE (zero), shape (N, D).\n",
    "        \"\"\"\n",
    "        zeros = self.result.copy(); zeros[...] = 0;\n",
    "        return zeros\n",
    "    \n",
    "    def _compute_huber_loss(self, axis: int | None = None, delta: float = 1.0, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Huber Loss between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Huber Loss tensor or matrix\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        abs_error = error.abs()\n",
    "        # The mask is in an INTERNAL format (np/torch)\n",
    "        small_mask = abs_error.data <= delta\n",
    "        \n",
    "        # The squared region: 0.5 * e^2\n",
    "        sq_loss = 0.5 * (error ** 2)\n",
    "        # The linear region: delta * (|e| - 0.5 * delta)\n",
    "        lin_loss = delta * (abs_error - 0.5 * delta)\n",
    "        \n",
    "        # Huber loss is a combinition of mse and mae\n",
    "        if self.result._is_numpy:\n",
    "            huber = np.where(small_mask, sq_loss.data, lin_loss.data)\n",
    "        else:\n",
    "            huber = torch.where(small_mask, sq_loss.data, lin_loss.data)\n",
    "        \n",
    "        if axis is None:\n",
    "            return type(self.result)(huber, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device).sum(axis = axis) / np.array(error.shape).prod()\n",
    "        else:\n",
    "            return type(self.result)(huber, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device).sum(axis = axis) / error.shape[axis]\n",
    "    \n",
    "    def _deriv_1_huber_loss(self, axis: int | None = None, delta: float = 1.0, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Huber Loss between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "            delta: float, the Huber threshold parameter.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of Huber Loss tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        abs_error = error.abs()\n",
    "        # The mask is in an INTERNAL format (np/torch)\n",
    "        small_mask = abs_error.data <= delta\n",
    "        \n",
    "        if self.result._is_numpy:\n",
    "            grad_elt = np.where(small_mask, error.data, delta * error.sign().data)\n",
    "        else:\n",
    "            grad_elt = torch.where(small_mask, error.data, delta * error.sign().data)\n",
    "        \n",
    "        if axis is None:\n",
    "            return type(self.result)(grad_elt, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / np.array(error.shape).prod()\n",
    "        else:\n",
    "            return type(self.result)(grad_elt, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / error.shape[axis]\n",
    "\n",
    "    def _deriv_2_huber_loss(self, axis: int | None = None, delta: float = 1.0, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative (Hessian diagonal) of the Huber Loss between result and target.\n",
    "\n",
    "        Args:\n",
    "            axis: None or int, if you intend to get per-output metrics/derivs, set axis = 0. Else None.\n",
    "            delta: float, the Huber threshold parameter.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor | Matrix: Second-order derivative of Huber Loss wrt result, shape like result.\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        abs_error = error.abs()\n",
    "        # The mask is in an INTERNAL format (np/torch)\n",
    "        small_mask = abs_error.data <= delta\n",
    "\n",
    "        if self.result._is_numpy:\n",
    "            hess_elt = small_mask.astype(float)\n",
    "        else:\n",
    "            # torch.where on a boolean mask: 1.0 where small, else 0.0\n",
    "            one = error.ones(error.shape, backend=self.result._backend).to(backend=self.result._backend, dtype=self.result.dtype, device=self.result.device)\n",
    "            zero = error.zeros(error.shape, backend=self.result._backend).to(backend=self.result._backend, dtype=self.result.dtype, device=self.result.device)\n",
    "            hess_elt = torch.where(small_mask, one.data, zero.data)\n",
    "\n",
    "        if axis is None:\n",
    "            return type(self.result)(hess_elt, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / np.array(error.shape).prod()\n",
    "        else:\n",
    "            return type(self.result)(hess_elt, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / error.shape[axis]\n",
    "\n",
    "    def _compute_quantile_loss(self, axis: int | None = None, q: float = 0.5, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Quantile Loss between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Quantile Loss tensor or matrix\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        if self.result._is_numpy:\n",
    "            loss = np.where(error.data >= 0, q * error.data, (q - 1) * error.data)\n",
    "        else:\n",
    "            loss = torch.where(error.data >= 0, q * error.data, (q - 1) * error.data)\n",
    "        \n",
    "        if axis is None:\n",
    "            return type(self.result)(loss, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device).sum(axis = axis) / np.array(error.shape).prod()\n",
    "        else:\n",
    "            return type(self.result)(loss, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device).sum(axis = axis) / error.shape[axis]\n",
    "\n",
    "    def _deriv_1_quantile_loss(self, axis: int | None = None, q: float = 0.5, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Quantile Loss between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get per-output metrics/derivs, set axis = 0. Else None.\n",
    "            q: float in (0,1), the quantile level.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of Quantile Loss tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        if self.result._is_numpy:\n",
    "            grad_elt = np.where(error.data >= 0, q, q - 1)\n",
    "        else:\n",
    "            grad_elt = torch.where(error.data >= 0, q, q - 1)\n",
    "\n",
    "        if axis is None:\n",
    "            return type(self.result)(grad_elt, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / np.array(error.shape).prod()\n",
    "        else:\n",
    "            return type(self.result)(grad_elt, backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / error.shape[axis]\n",
    "\n",
    "    def _deriv_2_quantile_loss(self, axis: int | None = None, q: float = 0.5, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative (Hessian diagonal) of the Quantile Loss between result and target.\n",
    "\n",
    "        Args:\n",
    "            axis: None or int, if you intend to get per-output metrics/derivs, set axis = 0. Else None.\n",
    "            q: float in (0,1), the quantile level.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor | Matrix: Second-order derivative of Quantile Loss wrt result, shape like result (all zeros).\n",
    "        \"\"\"\n",
    "        error = self.result - self.target\n",
    "        \n",
    "        if axis is None:\n",
    "            return error.zeros_like(error).to(backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / np.array(error.shape).prod()\n",
    "        else:\n",
    "            return error.zeros_like(error).to(backend=self.result._backend, dtype=self.result.dtype, device=self.result.device) / error.shape[axis]\n",
    "\n",
    "    def _compute_wmse(self, axis: int | None = None, weights: Matrix | Tensor | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Weighted Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "            weights: Matrix or Tensor or None, if None, fail to normal mse.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: MSE tensor or matrix\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            return self._compute_mse(axis = axis, **kwargs)\n",
    "        \n",
    "        error = (self.result - self.target)\n",
    "        squared_error = error ** 2\n",
    "        if axis is None:\n",
    "            mean_squared_error = (weights * squared_error).sum(axis = axis) / np.array(squared_error.shape).prod()\n",
    "        else:\n",
    "            mean_squared_error = (weights * squared_error).sum(axis = axis) / squared_error.shape[axis]\n",
    "        return mean_squared_error\n",
    "    \n",
    "    def _deriv_1_wmse(self, axis: int | None = None, weights: Matrix | Tensor | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Weighted Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "            weights: Matrix or Tensor or None, if None, fail to normal mse.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of MSE tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            return self._deriv_1_mse(axis = axis, **kwargs)\n",
    "        \n",
    "        error = self.result - self.target\n",
    "        grad = 2 * error / error.shape[0]\n",
    "        if axis is None:\n",
    "            grad = 2 * weights * error / np.array(error.shape).prod()\n",
    "        else:\n",
    "            grad = 2 * weights * error / error.shape[axis]\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_wmse(self, axis: int | None = None, weights: Matrix | Tensor | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative (Hessian diagonal) of the Weighted Mean Squared Error between result and target.\n",
    "    \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "            weights: Matrix or Tensor or None, if None, fail to normal mse.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor | Matrix: Constant Hessian of MSE (2/N) with the same shape as result.\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            return self._deriv_2_mse(axis = axis, **kwargs)\n",
    "        \n",
    "        ones = self.result.copy(); ones[...] = 1;\n",
    "        if axis is None:\n",
    "            return ones * (2.0 * weights / np.array(self.result.shape).prod())\n",
    "        else:\n",
    "            return ones * (2.0 * weights / self.result.shape[axis])\n",
    "    \n",
    "    def _compute_wrmse(self, axis: int | None = None, weights: Matrix | Tensor | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the Weighted Root Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "            weights: Matrix or Tensor or None, if None, fail to normal rmse.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor | Matrix: RMSE tensor or matrix\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            return self._compute_rmse(axis = axis, **kwargs)\n",
    "        \n",
    "        error = (self.result - self.target)\n",
    "        squared_error = weights * error ** 2\n",
    "        if axis is None:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / np.array(squared_error.shape).prod()\n",
    "        else:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / squared_error.shape[axis]\n",
    "        rmse = mean_squared_error ** 0.5\n",
    "        return rmse\n",
    "    \n",
    "    def _deriv_1_wrmse(self, axis: int | None = None, weights: Matrix | Tensor | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the Weighted Root Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "            weights: Matrix or Tensor or None, if None, fail to normal rmse.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor | Matrix: Derivative of RMSE tensor or matrix with respect to result.\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            return self._deriv_1_rmse(axis = axis, **kwargs)\n",
    "        \n",
    "        error = self.result - self.target\n",
    "        squared_error = weights * error ** 2\n",
    "        if axis is None:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / np.array(squared_error.shape).prod()\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            grad = weights * error / (np.array(squared_error.shape).prod() * rmse)\n",
    "        else:\n",
    "            mean_squared_error = squared_error.sum(axis = axis) / squared_error.shape[axis]\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            grad = weights * error / (error.shape[axis] * rmse)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_wrmse(self, axis: int | None = None, weights: Matrix | Tensor | None = None, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative of the Weighted Root Mean Squared Error between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "            weights: Matrix or Tensor or None, if None, fail to normal rmse.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor | Matrix: Second-order derivative (Hessian diagonal) of RMSE with respect to result.\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            return self._deriv_2_rmse(axis = axis, **kwargs)\n",
    "        \n",
    "        error = self.result - self.target\n",
    "        squared_error = weights * error ** 2\n",
    "        if axis is None:\n",
    "            sum_squared = squared_error.sum(axis = axis)\n",
    "            mean_squared_error = sum_squared / np.array(squared_error.shape).prod()\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            N = np.array(squared_error.shape).prod()\n",
    "            hessian = weights / (N * rmse) - (weights **2 * error ** 2) / ((N ** 2) * (rmse ** 3))\n",
    "        else:\n",
    "            sum_squared = squared_error.sum(axis = axis)\n",
    "            mean_squared_error = sum_squared / squared_error.shape[axis]\n",
    "            rmse = mean_squared_error ** 0.5\n",
    "            N = error.shape[axis] \n",
    "            hessian = weights / (N * rmse) - (weights **2 * error ** 2) / ((N ** 2) * (rmse ** 3))\n",
    "        \n",
    "        return hessian\n",
    "    \n",
    "    def _compute_r2(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the coefficient of determination R^2 between result and target.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: R^2 value.\n",
    "        \"\"\"\n",
    "        # Compute the residual sum of squares (SS_res)\n",
    "        error = self.result - self.target\n",
    "        ss_res = (error ** 2.0).sum()\n",
    "        \n",
    "        # Compute the total sum of squares (SS_tot)\n",
    "        target_mean = self.target.sum() / self.target.shape[0]\n",
    "        total_error = self.target - target_mean\n",
    "        ss_tot = (total_error ** 2.0).sum()\n",
    "        \n",
    "        # Calculate R^2 = 1 - (SS_res / SS_tot)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        return r2\n",
    "    \n",
    "    def _compute_adjusted_r2(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the adjusted R^2 value.\n",
    "        \n",
    "        Args:\n",
    "            axis: None or int, if you intend to get the per-output metrics/derivs, set axis = 0. Else None.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: Adjusted R^2 value.\n",
    "        \"\"\"\n",
    "        # If self.k is None, badly initialized.\n",
    "        if self.k is None or isinstance(self.k, int) == False:\n",
    "            raise ValueError(\"You must specify a valid `k` as the number of parameters in the model before calculating Adjusted R^2.\")\n",
    "        \n",
    "        # Compute R^2 using the previously defined method.\n",
    "        r2 = self._compute_r2()\n",
    "        \n",
    "        # Determine the number of observations (be the size along the first dimension)\n",
    "        n = self.target.shape[0]\n",
    "        \n",
    "        # Calculate adjusted R^2 using: 1 - (1-R^2)*((n-1)/(n-p-1))\n",
    "        adjusted_r2 = 1 - ((1 - r2) * ((n - 1) /  (n - self.k - 1)))\n",
    "        return adjusted_r2\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        String representation of the RegressionMetrics instance.\n",
    "        \"\"\"\n",
    "        return f\"RegressionMetrics(metric_type={self.metric_type}, shape={self.result.shape})\"\n",
    "\n",
    "\n",
    "# Metrics for classfication (base)\n",
    "class ClassificationMetrics(BaseMetrics):\n",
    "\n",
    "    __attr__ = \"MML.ClassificationMetrics\"    \n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"ClassificationMetrics(Abstract Class).\"\n",
    "\n",
    "\n",
    "# Metrics for binary classification\n",
    "class BinaryClassificationMetrics(ClassificationMetrics):\n",
    "    \"\"\"\n",
    "    A class to compute common binary classification metrics between predicted results and target values.\n",
    "    \n",
    "    Supported metrics include:\n",
    "        - accuracy\n",
    "        - precision\n",
    "        - recall (sensitivity) [TPR]\n",
    "        - f1 score\n",
    "        - specificity [TNR]\n",
    "        - auc_roc\n",
    "        - confusion_matrix\n",
    "        - tpr (True Positive Rate)\n",
    "        - tnr (True Negative Rate)\n",
    "        - fpr (False Positive Rate)\n",
    "        - fnr (False Negative Rate)\n",
    "        - logloss (continuous)\n",
    "    \n",
    "    The computations are performed using the underlying tensor operations. It is assumed that both \n",
    "    the result and target are of the same type (Tensor or Matrix) and support similar operations.\n",
    "    \n",
    "    Attributes:\n",
    "        result: Predicted results tensor or matrix (can be continuous scores or binary labels).\n",
    "        target: Target binary values tensor or matrix.\n",
    "        metric_type: A string specifying which metric to compute ('accuracy', 'precision', 'recall',\n",
    "                     'f1', 'specificity', 'auc_roc', 'confusion_matrix').\n",
    "        threshold: A float value used to convert continuous scores into binary predictions (default 0.5).\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.BinaryClassificationMetrics\"   \n",
    "    \n",
    "    def __init__(self, result: Tensor | Matrix, target: Tensor | Matrix, metric_type: str = \"accuracy\", threshold: float = 0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the BinaryClassificationMetrics instance with result and target tensors.\n",
    "        \n",
    "        Args:\n",
    "            result (Tensor | Matrix): Predicted results tensor\n",
    "            target (Tensor | Matrix): Target values tensor\n",
    "            metric_type (str): Metric type to compute ('accuracy', 'precision', 'recall', 'f1', 'specificity',\n",
    "                               'auc_roc', 'confusion_matrix', 'tpr', 'tnr', 'fpr', 'fnr', 'logloss')\n",
    "            threshold (float): a threshold for considering which one to be the positive samples and negative samples.\n",
    "                               In normal tasks, it is recommended to be 0.5. But adjusting this may change the metrics.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Different instances or different backends.\n",
    "        if isinstance(result, Object) == False or isinstance(target, Object) == False:\n",
    "            raise ValueError(\"Predicted `result` and real `target` should be either `Matrix` or `Tensor` type!\")\n",
    "        if type(result) != type(target):\n",
    "            raise ValueError(\"Predicted `result` and real `target` should have the same type, either Tensor or Matrix!\")\n",
    "        if result._backend != target._backend:\n",
    "            raise ValueError(\"Predicted `result` and real `target` should have the same backend, either numpy or torch!\")\n",
    "        \n",
    "        # Data Members.\n",
    "        self.result = result\n",
    "        self.target = target\n",
    "        self.metric_type = metric_type.lower()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Use the type of result as the typeclass.\n",
    "        self.typeclass = type(result)\n",
    "        \n",
    "        if not self.result.shape == self.target.shape:\n",
    "            raise ValueError(\"Result and target tensors must have the same shape.\")\n",
    "\n",
    "    def compute(self, **kwargs) -> Matrix | Tensor:\n",
    "        \"\"\"\n",
    "        Computes the specified metric for a given model or data.\n",
    "    \n",
    "        Args:\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "            \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed metric value. The result is always returned as a Matrix or Tensor object,\n",
    "                                      even if the computation yields a scalar.                            \n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If an unsupported metric type is provided.\n",
    "            \n",
    "        \"\"\"\n",
    "        # Note, all results are stored in a Matrix | Tensor even it is a scalar.\n",
    "        if self.metric_type == 'accuracy':\n",
    "            return self._compute_accuracy(**kwargs)\n",
    "        elif self.metric_type == 'precision':\n",
    "            return self._compute_precision(**kwargs)\n",
    "        elif self.metric_type in ('recall', 'sensitivity', 'tpr'):\n",
    "            return self._compute_recall(**kwargs)\n",
    "        elif self.metric_type in ('f1', 'f1 score'):\n",
    "            return self._compute_f1(**kwargs)\n",
    "        elif self.metric_type in ('specificity', 'tnr'):\n",
    "            return self._compute_specificity(**kwargs)\n",
    "        elif self.metric_type == 'fpr':\n",
    "            return self._compute_fpr(**kwargs)\n",
    "        elif self.metric_type == 'fnr':\n",
    "            return self._compute_fnr(**kwargs)\n",
    "        elif self.metric_type == 'auc_roc':\n",
    "            return self._compute_auc_roc(**kwargs)\n",
    "        elif self.metric_type == 'confusion_matrix':\n",
    "            return self._compute_confusion_matrix(**kwargs)\n",
    "        elif self.metric_type in ('logloss', 'log-loss', 'entropy', 'cross-entropy'):\n",
    "            return self._compute_logloss(**kwargs)\n",
    "        # Implemented by Nathmath Huang.\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "    \n",
    "    def deriv_1(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the sample-wise 1st order derivative for a given model or data.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: The computed metric value as a tensor\n",
    "        \"\"\"\n",
    "        # Note, all results are stored in a Matrix | Tensor even it is a scalar.\n",
    "        if self.metric_type in ('logloss', 'log-loss', 'entropy', 'cross-entropy'):\n",
    "            return self._deriv_1_logloss(**kwargs)\n",
    "        elif self.metric_type == 'accuracy':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'precision':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type in ('recall', 'sensitivity', 'tpr'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type in ('f1', 'f1 score'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type in ('specificity', 'tnr'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'fpr':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'fnr':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'auc_roc':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'confusion_matrix':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "    \n",
    "    def deriv_2(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the sample-wise 2nd order derivative for a given model or data.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: The computed metric value as a tensor\n",
    "        \"\"\"\n",
    "        # Note, all results are stored in a Matrix | Tensor even it is a scalar.\n",
    "        if self.metric_type in ('logloss', 'log-loss', 'entropy', 'cross-entropy'):\n",
    "            return self._deriv_2_logloss(**kwargs)\n",
    "        elif self.metric_type == 'accuracy':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'precision':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type in ('recall', 'sensitivity', 'tpr'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type in ('f1', 'f1 score'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type in ('specificity', 'tnr'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'fpr':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'fnr':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'auc_roc':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        elif self.metric_type == 'confusion_matrix':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "            \n",
    "    def _binarize(self, y_real_or_pred: Matrix | Tensor) -> Matrix | Tensor:\n",
    "        \"\"\"\n",
    "        Binarizes continuous prediction scores by applying a threshold.\n",
    "    \n",
    "        Args:\n",
    "            y_real_or_pred (Matrix | Tensor): the y values to be binarized.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: A matrix or tensor containing binary predictions (True/False values).\n",
    "    \n",
    "        \"\"\"\n",
    "        # Return the results in a Matrix or Tensor of Booleans\n",
    "        return self.typeclass(y_real_or_pred.data >= self.threshold, backend = y_real_or_pred._backend, device = y_real_or_pred.device)\n",
    "    \n",
    "    def _compute_confusion_counts(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the counts of true positives (TP), true negatives (TN), \n",
    "                     false positives (FP) and false negatives (FN) using binarized predictions.\n",
    "    \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            tuple: A tuple containing four elements, each representing TP, TN, FP, and FN respectively.\n",
    "                  Each element is a matrix or tensor of the same type as self.target.\n",
    "    \n",
    "        \"\"\"\n",
    "        pred = self._binarize(self.result)  # Full of Booleans.\n",
    "        real = self._binarize(self.target)  # Full of Booleans.\n",
    "\n",
    "        TP = ((pred.data == True) & (real.data == True)).sum()\n",
    "        TN = ((pred.data == False) & (real.data == False)).sum()\n",
    "        FP = ((pred.data == True) & (real.data == False)).sum()\n",
    "        FN = ((pred.data == False) & (real.data == True)).sum()\n",
    "        return (self.typeclass(TP, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device), \n",
    "                self.typeclass(TN, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device),\n",
    "                self.typeclass(FP, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device),\n",
    "                self.typeclass(FN, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "                )\n",
    "\n",
    "    def _compute_accuracy(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes accuracy = (TP + TN) / total.\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed accuracy value.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        TP, TN, FP, FN = self._compute_confusion_counts()\n",
    "        total = TP + TN + FP + FN\n",
    "        return (TP + TN) / total\n",
    "\n",
    "    def _compute_precision(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes precision = TP / (TP + FP).\n",
    "    \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed precision value.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        TP, _, FP, _ = self._compute_confusion_counts()\n",
    "        denom = TP + FP\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return TP / denom\n",
    "\n",
    "    def _compute_recall(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes recall (sensitivity) = TP / (TP + FN).\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed recall value.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        TP, _, _, FN = self._compute_confusion_counts()\n",
    "        denom = TP + FN\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return TP / denom\n",
    "\n",
    "    def _compute_f1(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the F1 score as the harmonic mean of precision and recall.\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed f1 score value.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        TP, TN, FP, FN = self._compute_confusion_counts()\n",
    "        denom = 2 * TP + FP + FN\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return 2 * TP / denom\n",
    "\n",
    "    def _compute_specificity(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes specificity = TN / (TN + FP).\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed specificity value.\n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        _, TN, FP, _ = self._compute_confusion_counts()\n",
    "        denom = TN + FP\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return TN / denom\n",
    "\n",
    "    def _compute_tpr(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes recall (TPR) = TP / (TP + FN).\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed TPR value.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        TP, _, _, FN = self._compute_confusion_counts()\n",
    "        denom = TP + FN\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return TP / denom\n",
    "\n",
    "    def _compute_tnr(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes specificity (TNR) = TN / (TN + FP).\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed TNR value.\n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        _, TN, FP, _ = self._compute_confusion_counts()\n",
    "        denom = TN + FP\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return TN / denom\n",
    "\n",
    "    def _compute_fpr(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes FPR = FP / (FP + TN).\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed TPR value.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        _, TN, FP, _ = self._compute_confusion_counts()\n",
    "        denom = FP + TN\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return FP / denom\n",
    "\n",
    "    def _compute_fnr(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes FNR = FN / (TP + FN).\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed FNR value.\n",
    "        \n",
    "        \"\"\"\n",
    "        TP, _, _, FN = self._compute_confusion_counts()\n",
    "        denom = TP + FN\n",
    "        if bool(denom.data == 0) == True:\n",
    "            return self.typeclass(0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "        return FN / denom\n",
    "\n",
    "    def _compute_auc_roc(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the area under the ROC curve (AUC-ROC) using the trapezoidal rule.\n",
    "        This method assumes that self.result contains continuous prediction scores.\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed auc_roc area.\n",
    "        \"\"\"\n",
    "        # Always return a Matrix | Tensor as the class input.\n",
    "        scores = self.result.data\n",
    "        labels = self.target.data\n",
    "        \n",
    "        # Sort indices based on scores in descending order.\n",
    "        sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "        sorted_labels = [labels[i] for i in sorted_indices]\n",
    "        P = sum(labels)\n",
    "        N = len(labels) - P\n",
    "        if P == 0 or N == 0:\n",
    "            return self.typeclass(0.0, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "\n",
    "        tpr, fpr = [], []\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for label in sorted_labels:\n",
    "            if label == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "            tpr.append(tp / P)\n",
    "            fpr.append(fp / N)\n",
    "        \n",
    "        auc = 0.0\n",
    "        prev_fpr = 0.0\n",
    "        prev_tpr = 0.0\n",
    "        for current_fpr, current_tpr in zip(fpr, tpr):\n",
    "            auc += (current_fpr - prev_fpr) * (current_tpr + prev_tpr) / 2.0\n",
    "            prev_fpr = current_fpr\n",
    "            prev_tpr = current_tpr\n",
    "        return self.typeclass(auc, backend=self.target._backend, dtype=self.target.dtype, device=self.target.device)\n",
    "\n",
    "    def _compute_logloss(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the binary classification log loss between predicted and actual values.\n",
    "    \n",
    "        Args: \n",
    "            None\n",
    "            \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed logloss using this formula:\n",
    "                logloss = - (y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))\n",
    "        \"\"\"\n",
    "        epsilon = 1e-15\n",
    "        preds = self.result.to(self.result._backend, dtype=float)\n",
    "        labels = self.target.to(self.result._backend, dtype=float)\n",
    "        clipped_preds = preds.clip(epsilon, 1 - epsilon)\n",
    "        losses = -(labels * clipped_preds.log() + (1 - labels) * (1 - clipped_preds).log())\n",
    "        return losses.mean()\n",
    "\n",
    "    def _deriv_1_logloss(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the binary classification log loss between predicted and actual values.\n",
    "\n",
    "        Args: \n",
    "            None\n",
    "            \n",
    "        Returns:\n",
    "            Matrix | Tensor: Derivative of logloss with respect to the predictions.\n",
    "        \"\"\"\n",
    "        epsilon = 1e-15\n",
    "        preds = self.result.to(self.result._backend, dtype=float)\n",
    "        labels = self.target.to(self.result._backend, dtype=float)\n",
    "        clipped = preds.clip(epsilon, 1 - epsilon)\n",
    "        grad = ((1 - labels) / (1 - clipped) - labels / clipped) / clipped.shape[0]\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_logloss(self, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative of the binary classification log loss between predicted and actual values.\n",
    "\n",
    "        Args: \n",
    "            None\n",
    "            \n",
    "        Returns:\n",
    "            Matrix | Tensor: Second-order derivative (Hessian diagonal) of logloss with respect to the predictions.\n",
    "        \"\"\"\n",
    "        epsilon = 1e-15\n",
    "        preds = self.result.to(self.result._backend, dtype=float)\n",
    "        labels = self.target.to(self.result._backend, dtype=float)\n",
    "        clipped = preds.clip(epsilon, 1 - epsilon)\n",
    "        hess = ((1 - labels) / (1 - clipped) ** 2 + labels / clipped ** 2) / clipped.shape[0]\n",
    "        return hess\n",
    "\n",
    "    def _compute_confusion_matrix(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the confusion matrix as a 2x2 tensor or matrix with the format:\n",
    "          [[TP, FP],\n",
    "           [FN, TN]]\n",
    "            \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed confusion matrix, with shape 2,2.\n",
    "        \"\"\"\n",
    "        TP, TN, FP, FN = self._compute_confusion_counts()\n",
    "        return self.typeclass(\n",
    "            [TP.data, FP.data,\n",
    "             FN.data, TN.data], \n",
    "            backend=self.target._backend, dtype=self.target.dtype, device=self.target.device).reshape([2,2])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BinaryClassificationMetrics(metric_type={self.metric_type}, shape={self.result.shape})\"\n",
    "\n",
    "\n",
    "# Metrics for multi-class classification\n",
    "class MultiClassificationMetrics(ClassificationMetrics):\n",
    "    \"\"\"\n",
    "    A class to compute common multi-class classification metrics between predicted results and target values.\n",
    "    \n",
    "    Supported metrics include:\n",
    "        - accuracy\n",
    "        - precision        (macro-average computed either in one-vs-rest (OVR) or one-vs-one (OVO) mode)\n",
    "        - recall           (macro-average computed either in OVR or OVO mode)\n",
    "        - f1 score         (macro-average computed either in OVR or OVO mode)\n",
    "        - logloss          (cross-entropy loss, continuous)\n",
    "        - confusion_matrix (of shape [n_classes, n_classes])\n",
    "        \n",
    "    The class is designed to support two scenarios:\n",
    "        1. Multi-target: where predictions are provided as a 1D vector of labels\n",
    "           (e.g. 0, 1, 2, 3, ...) and the target is also a vector.\n",
    "        2. One-hot: where the target (and optionally predictions) are provided as a\n",
    "           one-hot encoded matrix of shape [n_samples, n_classes].\n",
    "    \n",
    "    When computing precision, recall, and f1-score, the user can specify\n",
    "    whether the aggregation should be based on one-vs-rest (default) or one-vs-one.\n",
    "    \n",
    "    Attributes:\n",
    "        result (Tensor | Matrix): Predicted results. Can be either a 1D vector (labels) \n",
    "                                   or a 2D matrix (probabilities / one-hot scores). \n",
    "        target (Tensor | Matrix): True labels. Must be in a format compatible with result\n",
    "                                   (either both 1D or both 2D, or convertible between them).\n",
    "        metric_type (str): Which metric to compute (\"accuracy\", \"precision\", \"recall\",\n",
    "                           \"f1\", \"logloss\", \"confusion_matrix\").\n",
    "        mode (str): For metrics that require binary decomposition (\"precision\",\n",
    "                    \"recall\", \"f1\"), the aggregation mode: either \"ovr\" (one-vs-rest) or \"ovo\" (one-vs-one).\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.MultiClassificationMetrics\"   \n",
    "    \n",
    "    def __init__(self, result: Tensor | Matrix, target: Tensor | Matrix, metric_type: str = \"accuracy\", n_classes: int = None, mode: str = \"ovr\", **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the MultiClassificationMetrics instance with result and target tensors.\n",
    "        \n",
    "        Args:\n",
    "            result (Tensor | Matrix): Predicted results tensor\n",
    "            target (Tensor | Matrix): Target values tensor\n",
    "            metric_type (str): Metric type to compute ('accuracy', 'precision', 'recall', 'f1', 'confusion_matrix', 'logloss')\n",
    "            n_classes (int): Number of Classes\n",
    "            mode (str): `ovr` or `ovo`, one versus remaining or one versus one.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Check type compatibility\n",
    "        if isinstance(result, Object) == False or isinstance(target,  Object) == False:\n",
    "            raise ValueError(\"Predicted `result` and real `target` should be either `Matrix` or `Tensor` type!\")\n",
    "        if type(result) != type(target):\n",
    "            raise ValueError(\"Predicted `result` and real `target` should have the same type, either Tensor or Matrix!\")\n",
    "        if result._backend != target._backend:\n",
    "            raise ValueError(\"Predicted `result` and real `target` should have the same backend, either numpy or torch!\")\n",
    "\n",
    "        # Data Members.        \n",
    "        self.result = result\n",
    "        self.target = target\n",
    "        self.metric_type = metric_type.lower()\n",
    "        self.mode = mode.lower()\n",
    "        self.typeclass = type(result)\n",
    "        \n",
    "        # Determine classification format and number of classes.\n",
    "        # If given, then okay, or infer.\n",
    "        # If one of the inputs is two-dimensional, we assume the second dimension is the number of classes.\n",
    "        if n_classes is not None:\n",
    "            self.n_classes = n_classes\n",
    "        else:\n",
    "            if len(result.shape) == 2:\n",
    "                if result.shape[1] == 1:\n",
    "                    # Check if it is indeed a binary problem\n",
    "                    if len(result.flatten().bincount().unique()) == 2:\n",
    "                        self.n_classes = 2\n",
    "                    else:\n",
    "                        self.n_classes = len(result.flatten().bincount().unique())\n",
    "                        # Not safe, but okay.\n",
    "                else:\n",
    "                    self.n_classes = result.shape[1]\n",
    "            elif len(target.shape) == 2:\n",
    "                if target.shape[1] == 1:\n",
    "                    # Check if it is indeed a binary problem\n",
    "                    if len(target.flatten().unique()) == 2:\n",
    "                        self.n_classes = 2\n",
    "                    else:\n",
    "                        self.n_classes = len(target.flatten().unique())\n",
    "                        # Not safe, but okay.\n",
    "                else:\n",
    "                    self.n_classes = target.shape[1]\n",
    "            else:\n",
    "                # Error. The result dimension is not 2?!!\n",
    "                raise ValueError(\"The input `result` and `target` do not have a 2-dimension shape. Make sure it is a multi-classification problem. Set n_classes or resize the Matrix | Tensor if you only have one row.\")\n",
    "        \n",
    "    def compute(self, eps: float = 1e-15, floattype: type = float, **kwargs) -> Matrix | Tensor:\n",
    "        \"\"\"\n",
    "        Computes the specified multi-class metric.\n",
    "        \n",
    "        Supported metric_type values (case insensitive):\n",
    "            - 'accuracy'\n",
    "            - 'precision'\n",
    "            - 'recall'\n",
    "            - 'f1'\n",
    "            - 'logloss'\n",
    "            - 'confusion_matrix'\n",
    "        \n",
    "        For precision, recall and f1, the results are computed according to the specified mode (ovr or ovo).\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed metric value. The result is always returned as a Matrix or Tensor object,\n",
    "                                      even if the computation yields a scalar.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If an unsupported metric type or mode type is provided.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Note, all results are stored in a Matrix | Tensor even it is a scalar.\n",
    "        # Accuracy\n",
    "        if self.metric_type == 'accuracy':\n",
    "            return self._compute_accuracy(floattype=floattype, **kwargs)\n",
    "        # Precision\n",
    "        elif self.metric_type == 'precision':\n",
    "            if self.mode == 'ovr':\n",
    "                return self._compute_precision_ovr(eps=eps, floattype=floattype, **kwargs)\n",
    "            elif self.mode == 'ovo':\n",
    "                return self._compute_precision_ovo(eps=eps, floattype=floattype, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported mode for precision: {self.mode}. Use `ovo` or `ovr`.\")\n",
    "        # Recall\n",
    "        elif self.metric_type in ('recall', 'sensitivity', 'tpr'):\n",
    "            if self.mode == 'ovr':\n",
    "                return self._compute_recall_ovr(eps=eps, floattype=floattype, **kwargs)\n",
    "            elif self.mode == 'ovo':\n",
    "                return self._compute_recall_ovo(eps=eps, floattype=floattype, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported mode for recall: {self.mode}. Use `ovo` or `ovr`.\")\n",
    "        # F1 Score\n",
    "        elif self.metric_type in ('f1', 'f1 score'):\n",
    "            if self.mode == 'ovr':\n",
    "                return self._compute_f1_ovr(eps=eps, floattype=floattype, **kwargs)\n",
    "            elif self.mode == 'ovo':\n",
    "                return self._compute_f1_ovo(eps=eps, floattype=floattype, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported mode for f1: {self.mode}. Use `ovo` or `ovr`.\")\n",
    "        # Cross entropy/logloss\n",
    "        elif self.metric_type in ('logloss', 'log-loss', 'entropy', 'cross-entropy'):\n",
    "            return self._compute_logloss(eps=eps, floattype=floattype, **kwargs)\n",
    "        # Confusion matrix\n",
    "        elif self.metric_type == 'confusion_matrix':\n",
    "            return self._compute_confusion_matrix(**kwargs)\n",
    "        # Implemented by Nathmath Huang.\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "    \n",
    "    def deriv_1(self, eps: float = 1e-15, floattype: type = float, **kwargs) -> Matrix | Tensor:\n",
    "        \"\"\"\n",
    "        Computes the specified multi-class element-wise 1st order derivative.\n",
    "        \n",
    "        Supported metric_type values (case insensitive):\n",
    "            - 'logloss'\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "            **kwargs: Other arguments supported by metrics.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed metric value. The result is always returned as a Matrix or Tensor object,\n",
    "                                      even if the computation yields a scalar.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If an unsupported metric type or mode type is provided.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Note, only \"logloss\" supports derivatives.\n",
    "        # Cross entropy/logloss\n",
    "        if self.metric_type in ('logloss', 'log-loss', 'entropy', 'cross-entropy'):\n",
    "            return self._deriv_1_logloss(eps=eps, floattype=floattype, **kwargs)\n",
    "        # Accuracy\n",
    "        elif self.metric_type == 'accuracy':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # Precision\n",
    "        elif self.metric_type == 'precision':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # Recall\n",
    "        elif self.metric_type in ('recall', 'sensitivity', 'tpr'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # F1 Score\n",
    "        elif self.metric_type in ('f1', 'f1 score'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "\n",
    "        # Confusion matrix\n",
    "        elif self.metric_type == 'confusion_matrix':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        \n",
    "        # Implemented by Nathmath Huang.\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "    \n",
    "    def deriv_2(self, eps: float = 1e-15, floattype: type = float, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the sample-wise 2nd order derivative for a given model or data.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor | Matrix: The computed metric value as a tensor\n",
    "        \"\"\"\n",
    "        # Note, only \"logloss\" supports derivatives.\n",
    "        # Cross entropy/logloss\n",
    "        if self.metric_type in ('logloss', 'log-loss', 'entropy', 'cross-entropy'):\n",
    "            return self._deriv_2_logloss(eps=eps, floattype=floattype, **kwargs)\n",
    "        # Accuracy\n",
    "        elif self.metric_type == 'accuracy':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # Precision\n",
    "        elif self.metric_type == 'precision':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # Recall\n",
    "        elif self.metric_type in ('recall', 'sensitivity', 'tpr'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        # F1 Score\n",
    "        elif self.metric_type in ('f1', 'f1 score'):\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "\n",
    "        # Confusion matrix\n",
    "        elif self.metric_type == 'confusion_matrix':\n",
    "            raise  ValueError(f\"Metric type: {self.metric_type} cannot compute derivatives.\")\n",
    "        \n",
    "        # Implemented by Nathmath Huang.\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric type: {self.metric_type}\")\n",
    "            \n",
    "    def _to_labels(self, x: Tensor | Matrix, *, apply_softmax:bool = False) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Converts predictions or targets into label vectors.\n",
    "        \n",
    "        If x has more than one column (i.e. one-hot or probability matrix), it returns\n",
    "        the index of the maximum value along axis 1. Otherwise, x is assumed already to be a vector.\n",
    "             \n",
    "        Args:\n",
    "            x: Matrix | Tensor: The one-hot or probability matrix.\n",
    "            apply_softmax: bool, whether to apply softmax before calculating argmax or not.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The converted Tensor or Matrix in (n_samples, 1) shape.\n",
    "        \"\"\"\n",
    "        # Wide-table: prob or one-hot\n",
    "        if len(x.shape) > 1 and x.shape[1] > 1:\n",
    "            # Always keep the dim.\n",
    "            return x.argmax(axis=1).reshape([-1, 1]) if apply_softmax == False else x.softmax(axis=1).argmax(axis=1).reshape([-1, 1])\n",
    "        # Narrow table\n",
    "        else:    \n",
    "            return x\n",
    "\n",
    "    def _to_onehot(self, x: Tensor | Matrix, *, binarize = False) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Converts a label vector into a one-hot encoded matrix of shape [n_samples, n_classes].\n",
    "        If x is already a matrix with the correct number of columns, it is returned unaltered.\n",
    "        If x is binary probability input and binarize is False, then will return the probablistic one-hot.\n",
    "                     \n",
    "        Args:\n",
    "            x: Matrix | Tensor: The label-encoded matrix.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The converted one-hot Tensor or Matrix in (n_samples, n_classes) shape.\n",
    "        \"\"\"\n",
    "        if len(x.shape) == 2 and x.shape[1] == self.n_classes:\n",
    "            return x\n",
    "        \n",
    "        # If binary case, then create a probabilistic one-hot to reduce information loss\n",
    "        if self.n_classes == 2 and binarize == False:\n",
    "            onehot_data = type(x).zeros([x.shape[0], 2], backend=x._backend)\n",
    "            onehot_data[:, 1] = x.flatten()\n",
    "            onehot_data[:, 0] = 1.0 - onehot_data[:, 1]\n",
    "            return onehot_data.to(backend=x._backend, device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        # Else, do the round\n",
    "        else:\n",
    "            # Create one-hot by comparing each element with a range vector.\n",
    "            range_vec = self.typeclass(np.arange(self.n_classes), backend=x._backend, device=x.device)\n",
    "            # Reshape x to [n_samples, 1] if necessary\n",
    "            x_reshaped = x.reshape([x.shape[0], 1])\n",
    "        \n",
    "            # Broadcast the comparison: each entry becomes True if equal to the class index.\n",
    "            onehot_data = x_reshaped.astype(self.result.dtype).round() == range_vec\n",
    "            # The above one produces a boolean array -> like True, False, True, ...\n",
    "            #                                                False, True, False, ...\n",
    "            return onehot_data.to(backend=x._backend, device=x.device, dtype=float)\n",
    "\n",
    "    def _compute_accuracy(self, *, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes accuracy = (# correct predictions) / (# total samples).\n",
    "                             \n",
    "        Args:\n",
    "            floattype: type, the internal precision of calculation\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed accuracy value.\n",
    "        \"\"\"\n",
    "        pred_labels = self._to_labels(self.result)\n",
    "        true_labels = self._to_labels(self.target)\n",
    "        correct = pred_labels == true_labels\n",
    "        total = true_labels.shape[0]\n",
    "        return correct.sum().to(correct._backend, dtype=floattype, device=correct.device) / total\n",
    "    \n",
    "    def _compute_confusion_matrix(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the multi-class confusion matrix of shape [n_classes, n_classes],\n",
    "        where rows correspond to true labels and columns to predicted labels.\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed confusion matrix with shape [n_classes, n_classes].\n",
    "        \"\"\"\n",
    "        # Convert both predictions and targets to label vectors\n",
    "        pred_labels = self._to_labels(self.result)\n",
    "        true_labels = self._to_labels(self.target)\n",
    "        \n",
    "        # Convert them into one-hot matrices of shape [n_samples, n_classes]\n",
    "        pred_onehot = self._to_onehot(pred_labels)\n",
    "        true_onehot = self._to_onehot(true_labels)\n",
    "        \n",
    "        # Compute the confusion matrix as: (true_onehot)^T dot (pred_onehot)\n",
    "        conf_matrix = true_onehot.transpose().dot(pred_onehot)\n",
    "        return conf_matrix\n",
    "\n",
    "    def _compute_logloss(self, *, eps: float = 1e-15, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the cross-entropy loss (logloss) for multi-class classification.\n",
    "        \n",
    "        Assumes that `result` is a probability matrix of shape [n_samples, n_classes].\n",
    "        The loss is computed as:\n",
    "            logloss = - 1/N * sum_over_samples [ sum_over_classes (y_true * log(y_pred)) ]\n",
    "            \n",
    "        Args:\n",
    "            eps: float, clip value to ensure predictions are not going to be log(0)\n",
    "            floattype: type, the internal precision of calculation\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed log loss value.\n",
    "        \"\"\"\n",
    "        if len(self.result.shape) != 2:\n",
    "            raise ValueError(\"Logloss metric requires probability predictions with shape [n_samples, n_classes].\")\n",
    "        \n",
    "        # Ensure predictions are floating point and clip values to avoid log(0)\n",
    "        preds = self.result.to(self.result._backend, dtype=floattype, device=self.result.device).clip(eps, 1 - eps)\n",
    "\n",
    "        # Compute elementwise: y_true * log(y_pred), then sum over classes (axis=1) then average over samples.\n",
    "        true_onehot = self._to_onehot(self._to_labels(self.target))\n",
    "        losses = -(true_onehot * preds.log()).sum(axis=1)\n",
    "        return losses.mean()\n",
    "    \n",
    "    def _deriv_1_logloss(self, *, eps: float = 1e-15, floattype: type = float, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the first-order derivative of the cross-entropy loss (logloss) for multi-class classification.\n",
    "        \n",
    "        Assumes that `result` is a probability matrix of shape [n_samples, n_classes].\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure predictions are not going to be log(0)\n",
    "            floattype: type, the internal precision of calculation\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: Derivative of the logloss with respect to the predictions.\n",
    "        \"\"\"\n",
    "        if len(self.result.shape) != 2:\n",
    "            raise ValueError(\"Logloss metric requires probability predictions with shape [n_samples, n_classes].\")\n",
    "        \n",
    "        # Ensure predictions are floating point and clip values to avoid log(0)\n",
    "        preds = self.result.to(self.result._backend, dtype=floattype, device=self.result.device).clip(eps, 1 - eps)\n",
    "\n",
    "        # Convert to one-hot labels\n",
    "        true_onehot = self._to_onehot(self._to_labels(self.target))\n",
    "\n",
    "        # L/p = -y/p \n",
    "        grad = -(true_onehot / preds) / preds.shape[0]\n",
    "        return grad\n",
    "    \n",
    "    def _deriv_2_logloss(self, *, eps: float = 1e-15, floattype: type = float, **kwargs) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Computes the second-order derivative of the cross-entropy loss (logloss) for multi-class classification.\n",
    "        \n",
    "        Assumes that `result` is a probability matrix of shape [n_samples, n_classes].\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure predictions are not going to be log(0)\n",
    "            floattype: type, the internal precision of calculation\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: Second-order derivative (Hessian diagonal) of the logloss with respect to the predictions.\n",
    "        \"\"\"\n",
    "        if len(self.result.shape) != 2:\n",
    "            raise ValueError(\"Logloss metric requires probability predictions with shape [n_samples, n_classes].\")\n",
    "        \n",
    "        # Ensure predictions are floating point and clip values to avoid log(0)\n",
    "        preds = self.result.to(self.result._backend, dtype=floattype, device=self.result.device).clip(eps, 1 - eps)\n",
    "\n",
    "        # Convert to one-hot labels\n",
    "        true_onehot = self._to_onehot(self._to_labels(self.target))\n",
    "        \n",
    "        hess = (true_onehot / preds ** 2) / preds.shape[0]\n",
    "        return hess\n",
    "\n",
    "    # OVR (One-Vs-Remaining) implementations for precision, recall and f1\n",
    "\n",
    "    def _compute_precision_ovr(self, *, eps: float = 1e-15, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes macro-average precision using a one-vs-rest approach.\n",
    "        \n",
    "        For each class c:\n",
    "            precision[c] = TP[c] / (TP[c] + FP[c])\n",
    "        and the final metric is the mean over classes.\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed precision value.\n",
    "        \"\"\"\n",
    "        pred_labels = self._to_labels(self.result)\n",
    "        true_labels = self._to_labels(self.target)\n",
    "        pred_onehot = self._to_onehot(pred_labels.astype(self.result.dtype))\n",
    "        true_onehot = self._to_onehot(true_labels.astype(self.target.dtype))\n",
    "        \n",
    "        # True positives: elementwise multiplication then sum over samples (axis=0)\n",
    "        TP = (true_onehot * pred_onehot).sum(axis=0)\n",
    "       \n",
    "        # False positives: predicted positive but not truly positive.\n",
    "        FP = ((self.typeclass.ones_like(true_onehot, backend=true_onehot._backend) - true_onehot) * pred_onehot).sum(axis=0)\n",
    "        precision_per_class = TP / (TP + FP + floattype(eps))\n",
    "        return precision_per_class.mean()\n",
    "\n",
    "    def _compute_recall_ovr(self, *, eps: float = 1e-15, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes macro-average recall (sensitivity) using a one-vs-rest approach.\n",
    "        \n",
    "        For each class c:\n",
    "            recall[c] = TP[c] / (TP[c] + FN[c])\n",
    "        and the final metric is the mean over classes.\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed recall value.\n",
    "        \"\"\"\n",
    "        pred_labels = self._to_labels(self.result)\n",
    "        true_labels = self._to_labels(self.target)\n",
    "        pred_onehot = self._to_onehot(pred_labels.astype(self.result.dtype))\n",
    "        true_onehot = self._to_onehot(true_labels.astype(self.target.dtype))\n",
    "        \n",
    "        # True positives: elementwise multiplication then sum over samples (axis=0)\n",
    "        TP = (true_onehot * pred_onehot).sum(axis=0)\n",
    "        \n",
    "        # False negatives: predicted negative but not trully negative.\n",
    "        FN = (true_onehot * (self.typeclass.ones_like(pred_onehot, backend=pred_onehot._backend) - pred_onehot)).sum(axis=0)\n",
    "        recall_per_class = TP / (TP + FN + floattype(eps))\n",
    "        return recall_per_class.mean()\n",
    "\n",
    "    def _compute_f1_ovr(self, *, eps: float = 1e-15, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes macro-average F1-score in one-vs-rest mode.\n",
    "        F1 per class is computed as:\n",
    "            F1[c] = 2 * precision[c] * recall[c] / (precision[c] + recall[c])\n",
    "        The final score is the average over classes.\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed recall value.\n",
    "        \"\"\"\n",
    "        # Compute per-class precision and recall in OVR mode.\n",
    "        pred_labels = self._to_labels(self.result)\n",
    "        true_labels = self._to_labels(self.target)\n",
    "        pred_onehot = self._to_onehot(pred_labels.astype(self.result.dtype))\n",
    "        true_onehot = self._to_onehot(true_labels.astype(self.target.dtype))\n",
    "        \n",
    "        TP = (true_onehot * pred_onehot).sum(axis=0)\n",
    "        FP = ((self.typeclass.ones_like(true_onehot, backend=true_onehot._backend) - true_onehot) * pred_onehot).sum(axis=0)\n",
    "        FN = (true_onehot * (self.typeclass.ones_like(pred_onehot, backend=pred_onehot._backend) - pred_onehot)).sum(axis=0)\n",
    "        \n",
    "        precision_per_class = TP / (TP + FP + floattype(eps))\n",
    "        recall_per_class = TP / (TP + FN + floattype(eps))\n",
    "        f1_per_class = (2 * precision_per_class * recall_per_class) / (precision_per_class + recall_per_class + floattype(eps))\n",
    "        return f1_per_class.mean()\n",
    "\n",
    "    # OVO (One-Vs-One) implementations for precision, recall and f1\n",
    "    #\n",
    "    # These computations use the full confusion matrix. For every pair of different classes\n",
    "    # (i, j), we define binary precision and recall:\n",
    "    #   For class i in pair (i,j):\n",
    "    #       precision_i = M[i,i] / (M[i,i] + M[j,i] + eps)\n",
    "    #       recall_i = M[i,i] / (M[i,i] + M[i,j] + eps)\n",
    "    #   Similarly for class j.\n",
    "    # The final OVO metric is computed as the average over all the binary evaluations.\n",
    "    \n",
    "    def _compute_precision_ovo(self, *, eps: float = 1e-15, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes macro-average precision using a ovo approach.\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed precision value.\n",
    "        \"\"\"\n",
    "        conf_matrix = self._compute_confusion_matrix()  # shape: [n_classes, n_classes]\n",
    "        \n",
    "        # Create index matrices using broadcasting.\n",
    "        idx = self.typeclass(np.arange(self.n_classes), backend=conf_matrix._backend, device=conf_matrix.device)\n",
    "        I = idx.reshape([self.n_classes, 1]).repeat(self.n_classes, axis=1)\n",
    "        J = idx.reshape([1, self.n_classes]).repeat(self.n_classes, axis=0)\n",
    "        mask = I.data < J.data  # boolean mask selecting one instance per unordered pair\n",
    "                                # Internal type\n",
    "        \n",
    "        # Extract diagonal elements as a vector.\n",
    "        diag = conf_matrix.diag()  # shape [n_classes]\n",
    "        \n",
    "        # Expand diagonals for broadcasting.\n",
    "        diag_i = diag.reshape([self.n_classes, 1]).repeat(self.n_classes, axis=1)  # each row: diag[i]\n",
    "        diag_j = diag.reshape([1, self.n_classes]).repeat(self.n_classes, axis=0)  # each column: diag[j]\n",
    "        \n",
    "        # For a given pair (i, j):\n",
    "        # precision for class i:\n",
    "        p_i_matrix = diag_i / (diag_i + conf_matrix.transpose())  \n",
    "        \n",
    "        # We need M[j, i] for p_i. In our matrix, conf_matrix[j,i] is given by\n",
    "        # conf_matrix.transpose()[i,j]. Thus, we use:\n",
    "        p_i_matrix = diag_i / (diag_i + conf_matrix.transpose() + floattype(eps))\n",
    "        \n",
    "        # And precision for class j:\n",
    "        p_j_matrix = diag_j / (diag_j + conf_matrix + floattype(eps))\n",
    "        \n",
    "        # Now select only entries for pairs where I < J.\n",
    "        p_i_vals = p_i_matrix[mask]\n",
    "        p_j_vals = p_j_matrix[mask]\n",
    "        \n",
    "        # Concatenate and compute the mean.\n",
    "        all_precisions = p_i_vals.append(p_j_vals, axis=0)\n",
    "        return all_precisions.mean()\n",
    "\n",
    "    def _compute_recall_ovo(self, *, eps: float = 1e-15, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes macro-average recall using a ovo approach.\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed recall value.\n",
    "        \"\"\"\n",
    "        conf_matrix = self._compute_confusion_matrix()  # shape: [n_classes, n_classes]\n",
    "        \n",
    "        # Create index matrices using broadcasting.\n",
    "        idx = self.typeclass(np.arange(self.n_classes), backend=conf_matrix._backend, device=conf_matrix.device)\n",
    "        I = idx.reshape([self.n_classes, 1]).repeat(self.n_classes, axis=1)\n",
    "        J = idx.reshape([1, self.n_classes]).repeat(self.n_classes, axis=0)\n",
    "        mask = I.data < J.data  # boolean mask selecting one instance per unordered pair\n",
    "                                # Internal type\n",
    "        \n",
    "        # Extract diagonal elements as a vector.\n",
    "        diag = conf_matrix.diag()\n",
    "        diag_i = diag.reshape([self.n_classes, 1]).repeat(self.n_classes, axis=1)\n",
    "        diag_j = diag.reshape([1, self.n_classes]).repeat(self.n_classes, axis=0)\n",
    "\n",
    "        # For recall in a pair (i, j):\n",
    "        # recall for class i:\n",
    "        r_i_matrix = diag_i / (diag_i + conf_matrix +  floattype(eps))\n",
    "        # and recall for class j:\n",
    "        r_j_matrix = diag_j / (diag_j + conf_matrix.transpose() + floattype(eps))\n",
    "        \n",
    "        # Now select only entries for pairs where I < J.\n",
    "        r_i_vals = r_i_matrix[mask]\n",
    "        r_j_vals = r_j_matrix[mask]\n",
    "        \n",
    "        # Concatenate and compute the mean.\n",
    "        all_recalls = r_i_vals.append(r_j_vals, axis=0)\n",
    "        return all_recalls.mean()\n",
    "\n",
    "    def _compute_f1_ovo(self, *, eps: float = 1e-15, floattype: type = float, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes macro-average f1-score using a ovo approach.\n",
    "        \n",
    "        Args:\n",
    "            eps: float, clip value to ensure 0/0 cases.\n",
    "            floattype: type, the internal precision of calculation.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The computed f1-score.\n",
    "        \"\"\"\n",
    "        \n",
    "        # First compute the binary precisions and recalls from OVO.\n",
    "        precision_ovo = self._compute_precision_ovo(eps=eps, floattype=floattype)\n",
    "        recall_ovo = self._compute_recall_ovo(eps=eps, floattype=floattype)\n",
    "        f1_ovo = (2 * precision_ovo * recall_ovo) / (precision_ovo + recall_ovo + floattype(eps))\n",
    "        return f1_ovo\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"MultiClassificationMetrics(metric_type={self.metric_type}, mode={self.mode}, \"\n",
    "                f\"n_classes={self.n_classes}, result_shape={self.result.shape})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. BaseML Classes for all algorithms (self-implemented)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These base classes are self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Machine Learning Algorithm Base Class\n",
    "class MLBase:\n",
    "    \"\"\"\n",
    "    Base class that provides common traits for machine learning tasks,\n",
    "    including data splitting methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.MLBase\"\n",
    "    \n",
    "    def _random_state_next(self, attr: str = \"random_state\") -> int | None:\n",
    "        \"\"\"\n",
    "        Advances the random state for a given attribute and returns it.\n",
    "        If assigned as None, then return None without doing anything.\n",
    "        \n",
    "        Args:\n",
    "            attr (str): The name of the attribute to retrieve and advance. Default is 'random_state'.\n",
    "        \n",
    "        Returns:\n",
    "            int | None: The next value of the random state or None if no such state exists.\n",
    "        \n",
    "        Raises:\n",
    "            AttributeError: If the specified attribute does not exist in the object.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Retrieve the random state atrribute\n",
    "        if getattr(self, attr) is None:\n",
    "            return None  # Nonetype cannot be advanced\n",
    "        else:\n",
    "            random_state = getattr(self, attr)\n",
    "        \n",
    "        # If existing random_state_count, retrieve the count, else create it\n",
    "        try:\n",
    "            if getattr(self, attr + \"_count\") is None:\n",
    "                setattr(self, attr + \"_count\", 0)\n",
    "        except AttributeError as e:\n",
    "            setattr(self, attr + \"_count\", 0)\n",
    "        \n",
    "        # If existing random_state_offset, retrieve the offset, else create it\n",
    "        try:\n",
    "            if getattr(self, attr + \"_offset\") is None:\n",
    "                setattr(self, attr + \"_offset\", 57119)\n",
    "        except AttributeError as e:\n",
    "            setattr(self, attr + \"_offset\", 57119)\n",
    "        random_state_offset = getattr(self, attr + \"_offset\")\n",
    "        \n",
    "        # Next the random state and return it\n",
    "        random_state += random_state_offset\n",
    "        setattr(self, attr + \"_count\", getattr(self, attr + \"_count\") + 1)\n",
    "        \n",
    "        return random_state\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_test_split(X: Matrix | Tensor, y: Matrix | Tensor, test_size=0.2, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the input data into training and testing sets.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix.\n",
    "            y (Matrix | Tensor): The target vector.\n",
    "            test_size (float): Proportion of samples to include in the test split.\n",
    "            random_state (int or None): Seed for reproducible random number generation. Default is None.\n",
    "        \n",
    "        Returns:\n",
    "            tuple[Matrix | Tensor, Matrix | Tensor]: A tuple containing four elements: \n",
    "                - X_train: Training feature matrix.\n",
    "                - X_test: Testing feature matrix.\n",
    "                - y_train: Training target vector.\n",
    "                - y_test: Testing target vector.\n",
    "        \n",
    "        Raises:\n",
    "            TypeError: If 'X' and 'y' are not of the same type (Matrix or Tensor).\n",
    "        \n",
    "        \"\"\"\n",
    "        if X.__attr__ != y.__attr__:\n",
    "            raise TypeError(\"Input 'X' and 'y' should have the same type Matrix or Tensor!\")\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        test_count = int(round(n_samples * test_size))\n",
    "        train_idx = indices[test_count:]\n",
    "        test_idx = indices[:test_count]\n",
    "        return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def train_test_split_for_timeseries(X: Matrix | Tensor, y: Matrix | Tensor, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Splits time series data into training and testing sets.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix of the time series.\n",
    "            y (Matrix | Tensor): The target vector or dependent variable of the time series.\n",
    "            test_size (float): Proportion of the dataset to include in the test split. Default is 0.2.\n",
    "        \n",
    "        Returns:\n",
    "            tuple[Matrix, Matrix]: A tuple containing two matrices: \n",
    "                                   - X_train: Training feature matrix\n",
    "                                   - X_test: Testing feature matrix\n",
    "                                   - y_train: Training target vector\n",
    "                                   - y_test: Testing target vector\n",
    "        \n",
    "        Raises:\n",
    "            TypeError: If 'X' and 'y' are not of the same type (Matrix or Tensor).\n",
    "        \n",
    "        \"\"\"\n",
    "        if X.__attr__ != y.__attr__:\n",
    "            raise TypeError(\"Input 'X' and 'y' should have the same type Matrix or Tensor!\")\n",
    "        n_samples = X.shape[0]\n",
    "        test_count = int(round(n_samples * test_size))\n",
    "        # For time series the split is sequential: training data comes first.\n",
    "        train_idx = slice(0, n_samples - test_count)\n",
    "        test_idx = slice(n_samples - test_count, n_samples)\n",
    "        return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def train_test_split_binarydata_siid(X: Matrix | Tensor, y: Matrix | Tensor, test_size=0.2, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the input data into training and testing sets ensuring that the percentage of \n",
    "        positives and negatives in the target vector y are similar in both sets, as if they\n",
    "        are similar to iid distributed in the train and the test set.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix.\n",
    "            y (Matrix | Tensor): The binary target vector.\n",
    "            test_size (float): Proportion of samples to include in the test split.\n",
    "            random_state (int or None): Seed for reproducible random number generation. Default is None.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: A tuple containing four elements:\n",
    "                - X_train: Training feature matrix.\n",
    "                - X_test: Testing feature matrix.\n",
    "                - y_train: Training target vector.\n",
    "                - y_test: Testing target vector.\n",
    "        \n",
    "        Raises:\n",
    "            TypeError: If 'X' and 'y' are not of the same type (Matrix or Tensor).\n",
    "            ValueError: If y does not contain binary labels (0 and 1).\n",
    "        \"\"\"\n",
    "        # Ensure both X and y are of the same type.\n",
    "        if X.__attr__ != y.__attr__:\n",
    "            raise TypeError(\"Input 'X' and 'y' should have the same type Matrix or Tensor!\")\n",
    "        \n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        \n",
    "        # Verify y is binary.\n",
    "        unique_labels = y.unique().to(\"numpy\")\n",
    "        if len(unique_labels.data) != 2:\n",
    "            raise ValueError(f\"Target vector y must be binary (contain 2 kinds of labels) while it contains {len(unique_labels)} kinds.\")\n",
    "        \n",
    "        # Get indices for each class.\n",
    "        idx0 = np.where(y.flatten().to(\"numpy\").data == unique_labels.data[0])[0]\n",
    "        idx1 = np.where(y.flatten().to(\"numpy\").data == unique_labels.data[1])[0]\n",
    "        \n",
    "        # Shuffle indices for each class.\n",
    "        idx0 = np.random.permutation(idx0)\n",
    "        idx1 = np.random.permutation(idx1)\n",
    "        \n",
    "        # Determine the number of test samples per class.\n",
    "        n_test_0 = int(round(len(idx0) * test_size))\n",
    "        n_test_1 = int(round(len(idx1) * test_size))\n",
    "        \n",
    "        # Split indices for each class.\n",
    "        test_idx = np.concatenate((idx0[:n_test_0], idx1[:n_test_1]))\n",
    "        train_idx = np.concatenate((idx0[n_test_0:], idx1[n_test_1:]))\n",
    "        \n",
    "        # Shuffle the final indices.\n",
    "        train_idx = np.random.permutation(train_idx)\n",
    "        test_idx = np.random.permutation(test_idx)\n",
    "        \n",
    "        return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def k_fold(X: Matrix | Tensor, y: Matrix | Tensor, n_splits=5, random_state=None) -> List:\n",
    "        \"\"\"\n",
    "        Splits the data into `n_splits` folds for cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix.\n",
    "            y (Matrix | Tensor): The target vector.\n",
    "            n_splits (int): Number of splits to make. Default is 5.\n",
    "            random_state (Optional[int]): Seed value for reproducible randomness. Default is None.\n",
    "        \n",
    "        Returns:\n",
    "            List: A list where each element contains a tuple with the training and test indices for `X` and `y`.\n",
    "                  List[ (X[train_idx], X[test_idx], y[train_idx], y[test_idx]) ]\n",
    "        \n",
    "        Raises:\n",
    "            TypeError: If 'X' and 'y' are not of the same type, either Matrix or Tensor.\n",
    "        \n",
    "        \"\"\"        \n",
    "        if X.__attr__ != y.__attr__:\n",
    "            raise TypeError(\"Input 'X' and 'y' should have the same type Matrix or Tensor!\")\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        fold_size = n_samples // n_splits\n",
    "        folds = []\n",
    "        for i in range(n_splits):\n",
    "            start = i * fold_size\n",
    "            # Make sure the last fold takes all remaining samples\n",
    "            end = (i + 1) * fold_size if i < n_splits - 1 else n_samples\n",
    "            test_idx = indices[start:end]\n",
    "            train_idx = np.concatenate((indices[:start], indices[end:]))\n",
    "            folds.append((X[train_idx], X[test_idx], y[train_idx], y[test_idx]))\n",
    "        return folds\n",
    "\n",
    "    @staticmethod\n",
    "    def save(instance, filepath:str):\n",
    "        \"\"\"\n",
    "        Save the model object into a file to your disk.\n",
    "        \n",
    "        Args:\n",
    "            instance: a MLBase derived object\n",
    "            filepath: str, the destination file path to save.\n",
    "        \"\"\"\n",
    "        save({\"__attr__\" : instance.__attr__, \"data\": instance}, filepath, kompress=lzma, protocol=5)\n",
    "        \n",
    "    def load(self, filepath:str):\n",
    "        \"\"\"\n",
    "        Load the model object from a file from your disk.\n",
    "        Return the loaded model instead of evaluating to self.\n",
    "        \n",
    "        Args:\n",
    "            filepath: str, the destination file path to load.\n",
    "        \"\"\"\n",
    "        rawobj = load(filepath, kompress=lzma)\n",
    "        if isinstance(rawobj, dict) == False:\n",
    "            raise ValueError(f\"The file input is NOT a valid {self.__attr__} model.\")\n",
    "        if rawobj.get(\"__attr__\", \"\") != self.__attr__:\n",
    "            raise ValueError(f\"The file input is NOT a valid {self.__attr__} model.\")\n",
    "        return rawobj[\"data\"]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"MLBase(Machine Learning Abstract Base Class).\"\n",
    "\n",
    "\n",
    "# Base Class for Regression Models\n",
    "class Regression(MLBase):\n",
    "    \"\"\"\n",
    "    Base regression model that provides common traits for regression tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.Regression\"\n",
    "    \n",
    "    def fit(self, X: Matrix | Tensor, y: Matrix | Tensor):\n",
    "        \"\"\"\n",
    "        Fits a regression model to the given data.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix.\n",
    "            y (Matrix | Tensor): The target vector.\n",
    "        \n",
    "        Raises:\n",
    "            TypeError: If 'X' and 'y' are not of the same type, either Matrix or Tensor.\n",
    "            NotImplementedError: If the specific regression model does not implement a fit method.\n",
    "        \n",
    "        \"\"\"\n",
    "        if X.__attr__ != y.__attr__:\n",
    "            raise TypeError(\"Input 'X' and 'y' should have the same type Matrix or Tensor!\")\n",
    "        raise NotImplementedError(\"Regression model must implement fit method.\")\n",
    "\n",
    "    def predict(self, X: Matrix | Tensor):\n",
    "        \"\"\"\n",
    "        Predicts target values for the given feature matrix `X`.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix.\n",
    "        \n",
    "        Raises:\n",
    "            NotImplementedError: If the specific regression model does not implement a predict method.\n",
    "        \n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Regression model must implement predict method.\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Regression(Regression Abstract Base Class).\"\n",
    "\n",
    "\n",
    "# Base Class for Classification Models\n",
    "class Classification(MLBase):\n",
    "    \"\"\"\n",
    "    Base classification model that provides common traits for classification tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.Classification\"\n",
    "    \n",
    "    def fit(self, X: Matrix | Tensor, y: Matrix | Tensor):\n",
    "        \"\"\"\n",
    "        Fits a classification model to the provided feature matrix `X` and target vector `y`.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix.\n",
    "            y (Matrix | Tensor): The target vector.\n",
    "        \n",
    "        Raises:\n",
    "            TypeError: If 'X' and 'y' are not of the same type, either Matrix or Tensor.\n",
    "            NotImplementedError: If a derived class has not implemented the `fit` method for classification models.\n",
    "        \n",
    "        \"\"\"\n",
    "        if X.__attr__ != y.__attr__:\n",
    "            raise TypeError(\"Input 'X' and 'y' should have the same type Matrix or Tensor!\")\n",
    "        raise NotImplementedError(\"Classification model must implement fit method.\")\n",
    "\n",
    "    def predict(self, X: Matrix | Tensor):\n",
    "        \"\"\"\n",
    "        Predicts the target values for a given set of features.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The feature matrix or tensor to make predictions on.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix: A matrix containing the predicted target values.\n",
    "        \n",
    "        Raises:\n",
    "            NotImplementedError: This method should be implemented by subclasses as it is abstract in the current model class.\n",
    "        \n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Classification model must implement predict method.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_binary_prob(x: Tensor | Matrix) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Converts one-hot predictions or targets into binary probability.\n",
    "        \n",
    "        If x has more than one column (two, must be), it returns\n",
    "        probabilities of entries to be 1.\n",
    "             \n",
    "        Args:\n",
    "            x: Matrix | Tensor: The one-hot or probability matrix.\n",
    "\n",
    "        Returns:\n",
    "            Matrix | Tensor: The converted Tensor or Matrix in (n_samples, 1) shape.\n",
    "        \"\"\"\n",
    "        # Wide-table: prob or one-hot\n",
    "        if len(x.shape) > 1 and x.shape[1] == 2:\n",
    "            # Always keep the dim.\n",
    "            return x[:,1].reshape([-1, 1])\n",
    "        # Already only one column\n",
    "        elif len(x.shape) > 1 and x.shape[1] == 1:\n",
    "            return x\n",
    "        # Unknown cases\n",
    "        else:\n",
    "            raise ValueError(\"When converting to binary_probability from one-hot probabilities, the input dimension must be (n_samples, 2) or aleady been (n_samples, 1)\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_labels(x: Tensor | Matrix, *, apply_softmax:bool = False) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Converts predictions or targets into label vectors.\n",
    "        \n",
    "        If x has more than one column (i.e. one-hot or probability matrix), it returns\n",
    "        the index of the maximum value along axis 1. Otherwise, x is assumed already to be a vector.\n",
    "             \n",
    "        Args:\n",
    "            x: Matrix | Tensor: The one-hot or probability matrix.\n",
    "            apply_softmax: bool, whether to apply softmax before calculating argmax or not.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The converted Tensor or Matrix in (n_samples, 1) shape.\n",
    "        \"\"\"\n",
    "        # Wide-table: prob or one-hot\n",
    "        if len(x.shape) > 1 and x.shape[1] > 1:\n",
    "            # Always keep the dim.\n",
    "            return x.argmax(axis=1).reshape([-1, 1]) if apply_softmax == False else x.softmax(axis=1).argmax(axis=1).reshape([-1, 1])\n",
    "        # Narrow table\n",
    "        else:    \n",
    "            return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_onehot(x: Tensor | Matrix, n_classes: int, *, binarize = False) -> Tensor | Matrix:\n",
    "        \"\"\"\n",
    "        Converts a label vector into a one-hot encoded matrix of shape [n_samples, n_classes].\n",
    "        If x is already a matrix with the correct number of columns, it is returned unaltered.\n",
    "        If x is binary probability input and binarize is False, then will return the probablistic one-hot.\n",
    "                     \n",
    "        Args:\n",
    "            x: Matrix | Tensor: The label-encoded matrix.\n",
    "    \n",
    "        Returns:\n",
    "            Matrix | Tensor: The converted one-hot Tensor or Matrix in (n_samples, n_classes) shape.\n",
    "        \"\"\"\n",
    "        if len(x.shape) == 2 and x.shape[1] == n_classes:\n",
    "            return x\n",
    "        \n",
    "        # If binary case, then create a probabilistic one-hot to reduce information loss\n",
    "        if n_classes == 2 and binarize == False:\n",
    "            onehot_data = type(x).zeros([x.shape[0], 2], backend=x._backend)\n",
    "            onehot_data[:, 1] = x.flatten()\n",
    "            onehot_data[:, 0] = 1.0 - onehot_data[:, 1]\n",
    "            return onehot_data.to(backend=x._backend, device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        # Else, do the round\n",
    "        else:\n",
    "            # Create one-hot by comparing each element with a range vector.\n",
    "            range_vec = type(x)(np.arange(n_classes), backend=x._backend, device=x.device)\n",
    "            # Reshape x to [n_samples, 1] if necessary\n",
    "            x_reshaped = x.reshape([x.shape[0], 1])\n",
    "            \n",
    "            # Broadcast the comparison: each entry becomes True if equal to the class index.\n",
    "            onehot_data = x_reshaped.astype(float).round() == range_vec\n",
    "            # The above one produces a boolean array -> like True, False, True, ...\n",
    "            #                                                False, True, False, ...\n",
    "            return onehot_data.to(backend=x._backend, device=x.device, dtype=float)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Classification(Regression Abstract Base Class).\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Data Scaler (self-implemented)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scaling class is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Implementation of Data Scaler\n",
    "class Scaling:\n",
    "    \"\"\"\n",
    "    Scale class that fits on a Matrix and can perform either centralization (subtracting the mean)\n",
    "    or min-max scaling (scaling features to the [0, 1] range), with the ability to reverse the operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.Scaling\"\n",
    "    \n",
    "    def __init__(self, method=\"centralize\", *, robust_p = 0.25):\n",
    "        '''\n",
    "        Args:\n",
    "            `method` can be:\n",
    "                \"centralize\": only subtract the mean\n",
    "                \"normalize\": subtract the mean and standardize the variance to 1\n",
    "                \"minmax\": keep the data with in the range of [0, 1]\n",
    "                \"robust\": compute median and interquartile range to reduce the effect of outliers.\n",
    "            `robust_p` the lower percentile [0,1] of the percentile estimate. 0.25 means 25% and 75%\n",
    "        '''\n",
    "        self.method = method\n",
    "        self.params = {}\n",
    "        \n",
    "        # Method specific parameters\n",
    "        self.robust_p = robust_p if robust_p < 0.5 else 1 - robust_p\n",
    "\n",
    "    def fit(self, X: Matrix | Tensor, axis = 0):\n",
    "        \"\"\"\n",
    "        Fits the scaling parameters to the data.\n",
    "    \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The input matrix or tensor for fitting.\n",
    "            axis (int): Axis along which to compute the mean and standard deviation. Default is 0.\n",
    "    \n",
    "        Returns:\n",
    "            self: The fitted instance of the class, allowing method chaining.\n",
    "    \n",
    "        Raises:\n",
    "            ValueError: If an unsupported scaling method is provided.\n",
    "    \n",
    "        \"\"\"\n",
    "        type_X = type(X)\n",
    "        if self.method == \"centralize\":\n",
    "            # Just demean the data to 0 mean\n",
    "            if X._is_numpy:\n",
    "                mean_val = np.mean(X.data, axis=axis)\n",
    "            else:\n",
    "                mean_val = torch.mean(X.data, dim=axis)\n",
    "            self.params['mean'] = type_X(mean_val, backend=X._backend, device=X.device, dtype=X.dtype)\n",
    "        \n",
    "        elif self.method == \"normalize\":\n",
    "            # Normalize the data with 0 mean and std of 1\n",
    "            if X._is_numpy:\n",
    "                mean_val = np.mean(X.data, axis=axis)\n",
    "                stdev_val = np.std(X.data, axis=axis)\n",
    "            else:\n",
    "                mean_val = torch.mean(X.data, dim=axis)\n",
    "                stdev_val = torch.std(X.data, dim=axis)\n",
    "            self.params['mean'] = type_X(mean_val, backend=X._backend, device=X.device, dtype=X.dtype)\n",
    "            self.params['std'] = type_X(stdev_val, backend=X._backend, device=X.device, dtype=X.dtype)\n",
    "        \n",
    "        elif self.method == \"minmax\":\n",
    "            # Minmax to make data in a range of [0,1]\n",
    "            if X._is_numpy:\n",
    "                min_val = np.min(X.data, axis=axis)\n",
    "                max_val = np.max(X.data, axis=axis)\n",
    "            else:\n",
    "                min_val = torch.min(X.data, dim=axis).values\n",
    "                max_val = torch.max(X.data, dim=axis).values\n",
    "            self.params['min'] = type_X(min_val, backend=X._backend, device=X.device, dtype=X.dtype)\n",
    "            self.params['max'] = type_X(max_val, backend=X._backend, device=X.device, dtype=X.dtype)\n",
    "        \n",
    "        elif self.method == \"robust\":\n",
    "            # Compute median and interquartile range to reduce the effect of outliers.\n",
    "            if X._is_numpy:\n",
    "                median_val = np.median(X.data, axis=axis)\n",
    "                q1 = np.percentile(X.data, int(self.robust_p * 100), axis=axis)\n",
    "                q3 = np.percentile(X.data, 100 - int(self.robust_p * 100), axis=axis)\n",
    "                iqr_val = q3 - q1\n",
    "            else:\n",
    "                median_val = torch.median(X.data, dim=axis).values\n",
    "                q1 = torch.quantile(X.data, self.robust_p, dim=axis)\n",
    "                q3 = torch.quantile(X.data, 1 - self.robust_p, dim=axis)\n",
    "                iqr_val = q3 - q1\n",
    "            self.params['p'] = self.robust_p\n",
    "            self.params['median'] = type_X(median_val, backend=X._backend, device=X.device, dtype=X.dtype)\n",
    "            self.params['iqr'] = type_X(iqr_val, backend=X._backend, device=X.device, dtype=X.dtype)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported scaling method. Choose 'centralize', 'normalize', 'minmax', or 'robust'.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: Matrix | Tensor):\n",
    "        \"\"\"\n",
    "        Transforms the input matrix using the fitted parameters.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The input matrix for transformation.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix | Tensor: The transformed matrix or tensor.\n",
    "        \n",
    "        Raises:\n",
    "            InterruptedError: If no scaling parameters have been fitted yet.\n",
    "            ValueError: If an unsupported scaling method is provided.\n",
    "        \n",
    "        \"\"\"\n",
    "        if len(self.params) == 0:\n",
    "            raise InterruptedError(\"You should call `fit` before doing any transformation\")\n",
    "        if self.method == \"centralize\":\n",
    "            return (X - self.params['mean'])\n",
    "        elif self.method == \"normalize\":\n",
    "            return (X - self.params['mean']) / self.params['std']\n",
    "        elif self.method == \"minmax\":\n",
    "            range_matrix = self.params['max'] - self.params['min']\n",
    "            return (X - self.params['min']) / range_matrix\n",
    "        elif self.method == \"robust\":\n",
    "            return (X - self.params['median']) / self.params['iqr']\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported scaling method. Choose 'centralize', 'normalize', 'minmax', or 'robust'.\")\n",
    "\n",
    "    def inverse_transform(self, X: Matrix | Tensor):\n",
    "        \"\"\"\n",
    "        Inverses the transformation applied during fitting.\n",
    "        \n",
    "        Args:\n",
    "            X (Matrix | Tensor): The transformed matrix for inversion.\n",
    "        \n",
    "        Returns:\n",
    "            Matrix | Tensor: The original matrix or tensor before scaling.\n",
    "        \n",
    "        Raises:\n",
    "            InterruptedError: If no scaling parameters have been fitted yet.\n",
    "            ValueError: If an unsupported scaling method is provided. \n",
    "        \n",
    "        \"\"\"\n",
    "        if len(self.params) == 0:\n",
    "            raise InterruptedError(\"You should call `fit` before doing any transformation\")\n",
    "        if self.method == \"centralize\":\n",
    "            # Inverse centralization: add the mean back.\n",
    "            return X + self.params['mean']\n",
    "        if self.method == \"normalize\":\n",
    "            # Inverse centralization: multiply the std and add the mean back.\n",
    "            return X * self.params['std'] + self.params['mean']\n",
    "        elif self.method == \"minmax\":\n",
    "            # Inverse minmax scaling: X*(max - min) + min\n",
    "            range_matrix = self.params['max'] - self.params['min']\n",
    "            return X * range_matrix + self.params['min']\n",
    "        elif self.method == \"robust\":\n",
    "            # Inverse robust scaling: X*(iqr) + median\n",
    "            return X * self.params['iqr'] + self.params['median']\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported scaling method. Choose 'centralize', 'normalize', 'minmax', or 'robust'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Threadpool and Mutex Wrapper (self-implemented, for future purpose, what if one day GIL is deprecated)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These threading interface is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "import concurrent.futures\n",
    "import uuid\n",
    "import threading\n",
    "from typing import Any\n",
    "\n",
    "# A threadpool worker class\n",
    "class ThreadPool:\n",
    "    \"\"\"\n",
    "    A simple thread pool for executing functions in separate threads.\n",
    "    Each submitted task returns a unique id, and you can wait until a task finishes or stop all tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_workers=4):\n",
    "        \"\"\"\n",
    "        Initialize the thread pool.\n",
    "        \n",
    "        Parameters:\n",
    "            max_workers (int): Maximum number of worker threads (default: system default).\n",
    "        \"\"\"\n",
    "        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)\n",
    "        self.tasks = {}  # Mapping from task id to Future\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    # Execute something with an assigned task number returned\n",
    "    def execute(self, func, *args, **kwargs) -> Any:\n",
    "        \"\"\"\n",
    "        Submit a function to be executed in a separate thread.\n",
    "        \n",
    "        Parameters:\n",
    "            func (callable): The function to execute.\n",
    "            *args: Positional arguments for the function.\n",
    "            **kwargs: Keyword arguments for the function.\n",
    "            \n",
    "        Returns:\n",
    "            str: A unique task id representing the submitted task.\n",
    "        \"\"\"\n",
    "        task_id = str(uuid.uuid4())\n",
    "        future = self.executor.submit(func, *args, **kwargs)\n",
    "        with self.lock:\n",
    "            self.tasks[task_id] = future\n",
    "        return task_id\n",
    "\n",
    "    # Coresively stop all tasks\n",
    "    def stopall(self):\n",
    "        \"\"\"\n",
    "        Attempt to cancel all tasks that haven't started.\n",
    "        Note that tasks already running may not be cancelled.\n",
    "        Clears the internal task registry.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            for task_id, future in list(self.tasks.items()):\n",
    "                future.cancel()\n",
    "            self.tasks.clear()\n",
    "            \n",
    "    # Wait for a certain task\n",
    "    def waituntil(self, task_id: Any):\n",
    "        \"\"\"\n",
    "        Block until the task corresponding to the given id has finished.\n",
    "        \n",
    "        Parameters:\n",
    "            task_id (str): The unique id of the task.\n",
    "        \n",
    "        Returns:\n",
    "            The result of the task, if it completed successfully.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If the task id is not found.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            future = self.tasks.get(task_id)\n",
    "        if future is None:\n",
    "            raise ValueError(f\"Task with id {task_id} not found.\")\n",
    "        return future.result()  # Blocks until the task completes\n",
    "    \n",
    "    # Normally shut down\n",
    "    def shutdown(self, wait=True):\n",
    "        \"\"\"\n",
    "        Shutdown the thread pool.\n",
    "        \n",
    "        Parameters:\n",
    "            wait (bool): If True, block until all running tasks are finished.\n",
    "        \"\"\"\n",
    "        self.executor.shutdown(wait=wait)\n",
    "\n",
    "# A Pythonic/STL mutex comptible wrapper\n",
    "class Mutex:\n",
    "    \"\"\"\n",
    "    A thin wrapper around :class:`threading.Lock` that mimics the interface\n",
    "    of C++`std::mutex` while feeling Pythonic.\n",
    "\n",
    "    It supports the three canonical methods``lock``, ``try_lock``, and\n",
    "    ``unlock``plus contextmanager helpers so you can use the ``with``statement\n",
    "    for automatic acquisition / release.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> m = Mutex()\n",
    "    >>> m.lock()          # block until the mutex is free\n",
    "    >>> m.unlock()        # release it again\n",
    "    >>> m.try_lock()      # returns True or False\n",
    "    >>> with m:           # RAII style\n",
    "    ...     critical()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Create an unlocked mutex.\n",
    "        \"\"\"\n",
    "        self._lock: threading.Lock = threading.Lock()\n",
    "\n",
    "    # C++ std::mutex::lock()\n",
    "    def lock(self) -> None:\n",
    "        \"\"\"\n",
    "        Block the calling thread until the mutex is acquired.\n",
    "        \"\"\"\n",
    "        self._lock.acquire()\n",
    "\n",
    "    # C++ std::mutex::try_lock()\n",
    "    def try_lock(self) -> bool:\n",
    "        \"\"\"\n",
    "        Attempt to acquire the mutex without blocking.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            ``True`` if the lock was acquired, ``False`` otherwise.\n",
    "        \"\"\"\n",
    "        return self._lock.acquire(blocking=False)\n",
    "\n",
    "    # C++ std::mutex::unlock()\n",
    "    def unlock(self) -> None:\n",
    "        \"\"\"\n",
    "        Release the mutex.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Only the thread that currently owns the lock may call this.\n",
    "        \"\"\"\n",
    "        self._lock.release()\n",
    "\n",
    "    def __enter__(self) -> \"Mutex\":\n",
    "        \"\"\"\n",
    "        Enter a ``with``block by locking the mutex.\n",
    "        \"\"\"\n",
    "        self.lock()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type: Any, exc: Any, tb: Any) -> None:\n",
    "        \"\"\"\n",
    "        Exit a ``with``block by unlocking the mutexeven if an exception\n",
    "        was raised inside the block.\n",
    "        \"\"\"\n",
    "        self.unlock()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Save and Load Interface for Saving a Model (self-implemented, using pickle and lzma)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These save/load interface is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "import pickle\n",
    "from typing import Any\n",
    "\n",
    "# Kompress can be:\n",
    "#  gzip\n",
    "#  lzma\n",
    "\n",
    "def save(obj: Any, filename: str, *, kompress: Any = None, protocol: int | None = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Save a Python object to a file using pickle.\n",
    "    Directly save without wrapping.\n",
    "    \"\"\"\n",
    "    # Uncompress\n",
    "    if kompress is None:\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(obj, f, protocol = protocol)\n",
    "    # Compress\n",
    "    else:\n",
    "        with kompress.open(filename, 'wb', **kwargs) as f:\n",
    "            pickle.dump(obj, f, protocol = protocol)\n",
    "\n",
    "def load(filename: str, *, kompress: Any = None) -> Any:\n",
    "    \"\"\"\n",
    "    Load a Python object from a pickle file.\n",
    "    Generally loading. Try to unwrap if possible\n",
    "    \n",
    "    Exception:\n",
    "        Throw a ValueError when in the dumping mode and failed to\n",
    "        pass the hash test.\n",
    "    \"\"\"\n",
    "    # Uncompress\n",
    "    if kompress is None:\n",
    "        with open(filename, 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "    else:\n",
    "        with kompress.open(filename, 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "    \n",
    "    # No need to unwrap\n",
    "    if isinstance(obj, dict) == False:\n",
    "        return obj\n",
    "    elif isinstance(obj, dict) == True and obj.get(\"~attr~\", None) is None:\n",
    "        return obj\n",
    "    \n",
    "    # Need to unwrap\n",
    "    if isinstance(obj, dict) == True and obj.get(\"~attr~\", None) == \"~dump~\":\n",
    "        if obj.get(\"~hash~\", None) is None:\n",
    "            raise ValueError(\"Corrupted dumpped file. Hash attribute has Nonetype.\")\n",
    "        elif isinstance(obj.get(\"~hash~\", None), str) == False:\n",
    "            raise ValueError(\"Corrupted dumpped file. Hash attribute has Non-string type.\")\n",
    "        if obj.get(\"data\", None) is None:\n",
    "            raise ValueError(\"Corrupted dumpped file. Data attribute is Nonetype.\")\n",
    "        if obj.get(\"~hash~\", None) != str(hash(obj.get(\"data\"))):\n",
    "            raise ValueError(\"Corrupted dumpped file. Data hash mismatched.\")\n",
    "        return obj[\"data\"] \n",
    "    \n",
    "    else:\n",
    "        return obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P. Basic Neural Network Components (self-implemented)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These basic Neural Network Components are self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Deep Neural Network Abstract Module Base Class\n",
    "class nn_Base(Regression, Classification):\n",
    "    \n",
    "    __attr__ = \"MML.nn_Base\"    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Set all gradients of all parameters to zero.\n",
    "        It will clear the gradients accumulated and restore when a new batch starts.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"zero_grad() is not implemented in nn_Base\")\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Set module to training mode.\n",
    "        It will affect dropouts and enable gradients calculation.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"train() is not implemented in nn_Base\")\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"\n",
    "        Set module to evaluation mode.\n",
    "        It will disable dropouts and disable gradients calculation.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"eval() is not implemented in nn_Base\")\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        Return an iterator of all Parameters in this module (includes children)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"parameters() is not implemented in nn_Base\")\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Perform a forward propagation to calculate the loss.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"forward() is not implemented in nn_Base\")\n",
    "        \n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Perform a backward propagation to compute gradients for updating weights.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"backward() is not implemented in nn_Base\")\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"nn_Base(Deep Neural Network Abstract Module Base Class).\"\n",
    "\n",
    "\n",
    "# A Deep Neural Network Trainable Parameter Class\n",
    "class nn_Parameter(MLBase):\n",
    "    \"\"\"\n",
    "    A trainable parameter base data structure with gradient storage.\n",
    "    Contains data and manually implemented gradients, while you can use pytorch autograd techniques.\n",
    "    Optionally, you may set `autograd` = True to enable torch Autograd functionality instead of manual grads computation.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Parameter\"    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 data: Tensor, \n",
    "                 requires_grad: bool = True, \n",
    "                 *, \n",
    "                 device: str | None = None, \n",
    "                 dtype: str | None = None, \n",
    "                 autograd: bool = False, \n",
    "                 **kwargs): \n",
    "        \"\"\"\n",
    "        Create a wrapped Neural Network Parameter Container, including gradients.\n",
    "        \n",
    "        Parameters:\n",
    "            --------\n",
    "            data: Tensor, The initial value for the parameter as a Tensor object.\n",
    "            requires_grad: bool, A flag indicating whether gradients should be tracked for this parameter. Defaults to True.\n",
    "            Optional:\n",
    "                device: str | None, The device where the tensor should reside (e.g., \"cpu\", \"cuda\"). If None, uses the default device. Defaults to None.\n",
    "                dtype: str | None, The data type of the tensor (e.g., \"float32\", \"float64\", or type like torch.float32). If None, uses the data type of the input `data`. Defaults to None.\n",
    "                autograd: bool, A flag indicating whether to use PyTorch's autograd functionality for gradient computation.  If True, manual gradient tracking is disabled. Defaults to None.\n",
    "        \n",
    "        Raises:\n",
    "            --------\n",
    "            ValueError: If the input `data` is not a Tensor object.\n",
    "    \n",
    "        Attributes:\n",
    "            --------\n",
    "            self.autograd: bool, Indicates whether PyTorch's autograd is enabled.\n",
    "            self.requires_grad: bool, A flag indicating whether gradients are tracked for this parameter.\n",
    "            self.data: Tensor, The parameter data as a Tensor object, cloned and potentially moved to the specified device/dtype.\n",
    "            self.grad: Tensor | None, The manually accumulated gradient (reserved for future evaluation); set to None initially.\n",
    "        \"\"\"\n",
    "        \n",
    "        # MLBase is for save/load purposes.\n",
    "        super().__init__()\n",
    "        \n",
    "        # Record if it uses pytorch's autograd\n",
    "        self.autograd = autograd\n",
    "        \n",
    "        # Record if it uses gradients (either autograd or manually calculated)\n",
    "        self.requires_grad = requires_grad\n",
    "        \n",
    "        # Initialize the parameter with a tensor (ensure float dtype and device placement)\n",
    "        if not isinstance(data, Tensor):\n",
    "            raise ValueError(\"Input data MUST be a MML.Tensor! Please convert by calling Tensor(data, backend='torch')\")\n",
    "        # Parameter Data - a Tensor Object\n",
    "        self.data = data if dtype is None and device is None else data.to(backend=data._backend, dtype=dtype, device=device)\n",
    "        # Gradient manually accumulated during backprop\n",
    "        # If uses autograd, then self.data.grad will record it\n",
    "        self.grad = self.data.to_zeros() if requires_grad == True and autograd == False else None \n",
    "        \n",
    "        # If uses pytorch autograd, then enable if requires grad\n",
    "        if autograd == True and requires_grad == True:\n",
    "            self.data.requires_grad_(True)\n",
    "       \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Reset the gradient to zero.\n",
    "        \n",
    "        Returns:\n",
    "            -------\n",
    "            self\n",
    "        \"\"\"\n",
    "        if self.requires_grad == True:\n",
    "            # Use pytorch's autograd, then directly set to 0\n",
    "            if self.autograd == True:\n",
    "                self.data.data.grad.zero_()\n",
    "            # Use manually calculated grads, then manually set to 0\n",
    "            else:\n",
    "                if self.grad is not None:\n",
    "                    self.grad[...] = 0\n",
    "                else:\n",
    "                    self.grad = self.data.to_zeros()\n",
    "        return self\n",
    "\n",
    "    def requires_grad_(self, requires_grad: bool = True):\n",
    "        \"\"\"\n",
    "        Set the attributes of `requires_grid` and enable/disable autograd if used.\n",
    "        \n",
    "        Returns:\n",
    "            -------\n",
    "            self\n",
    "        \"\"\"\n",
    "        \n",
    "        # If status conflicts, then create/disable grad\n",
    "        if self.requires_grad != requires_grad:\n",
    "            \n",
    "            # Set the attribute of requiring grads or not\n",
    "            self.requires_grad = requires_grad\n",
    "            \n",
    "            # If uses pytorch autograd, then enable if requires grad\n",
    "            if self.autograd == True:\n",
    "                self.data.requires_grad_(requires_grad)\n",
    "            else:\n",
    "                if requires_grad == True:\n",
    "                    self.zero_grad()\n",
    "                else:\n",
    "                    self.grad = None\n",
    "\n",
    "    def to(self, device: str | None = None):\n",
    "        \"\"\"\n",
    "        Move the parameters and gradients to the specified device.\n",
    "        \n",
    "        Parameters:\n",
    "            --------\n",
    "            device: str | None, The device where the tensor should reside (e.g., \"cpu\", \"cuda\"). If None, do nothing.\n",
    "        \"\"\"\n",
    "        if device is not None:\n",
    "            self.data = self.data.to(backend = self.data._backend, device = device)\n",
    "            if self.grad is not None:\n",
    "                self.grad = self.grad.to(backend = self.grad._backend, device = device)\n",
    "        return self\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Create a deepcopy of the parameters and gradiets.\n",
    "        \"\"\"\n",
    "        return deepcopy(self)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"nn_Parameter(Deep Neural Network Trainable Parameter Class).\" + \"\\nData: \" + self.data.__repr__() + \"\\nGrad: \" + (self.grad.__repr__() if self.grad is not None else \"\")\n",
    "\n",
    "\n",
    "# A Deep Neural Network Interface Module Base Class\n",
    "class nn_BaseModule(nn_Base):\n",
    "    \"\"\"\n",
    "    A even base class for Neural Network Modules.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_BaseModule\"    \n",
    "    \n",
    "    def __setattr__(self, name: str, value: Any):\n",
    "        \"\"\"\n",
    "        Override setattr to register Parameters and Modules.\n",
    "        \n",
    "        Registers parameters (nn_Parameter) and modules (nn_Module) under the `._parameters` and `._modules` dictionaries \n",
    "        when appropriate. Delegates attribute assignment to the base class's `__setattr__` method for standard attributes.\n",
    "        \n",
    "        Args:\n",
    "            name: str, The name of the attribute being set.\n",
    "            value: Any, The value to assign to the attribute.\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Register a parameter if is nn_Parameter\n",
    "        if isinstance(value, nn_Parameter):\n",
    "            self._parameters[name] = value\n",
    "            \n",
    "        # Register a submodule if nn_Module\n",
    "        elif isinstance(value, nn_BaseModule):\n",
    "            self._modules[name] = value\n",
    "            \n",
    "        # Copy if it is a Object based variable\n",
    "        elif isinstance(value, Object):\n",
    "            object.__setattr__(self, name, value)\n",
    "        \n",
    "        # In all cases, set the attribute normally as an attribute\n",
    "        object.__setattr__(self, name, value)\n",
    "    \n",
    "    def __call__(self, *inputs):\n",
    "        \"\"\"\n",
    "        Delegates to the forward method to perform the forward pass of the module.\n",
    "        \n",
    "        This method allows a Module instance to be called like a function, passing inputs to the forward() method.\n",
    "        It delegates attribute assignment and functionality to the base class's `__setattr__` and `forward()` methods.\n",
    "        \n",
    "        Args:\n",
    "            *inputs: list, Variable number of input tensors or values to pass to the forward method.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The output tensor resulting from the forward pass.\n",
    "        \n",
    "        Raises:\n",
    "            NotImplementedError: If the forward() method is not implemented in the subclass.\n",
    "        \"\"\"\n",
    "        # Allows Module instance to be called like a function to perform forward pass\n",
    "        return self.forward(*inputs)\n",
    "    \n",
    "    def __init__(self, module_name: str = \"Default_Module_Container\"):\n",
    "        \"\"\"\n",
    "        Initializes a base neural network module with basic structural components.\n",
    "\n",
    "        This constructor sets up essential properties for a module, including its name,\n",
    "        training mode flag, and containers for parameters and submodules. It follows a\n",
    "        convention similar to PyTorch modules, where modules are organized hierarchically\n",
    "        with parameter tracking and submodule management.\n",
    "\n",
    "        Parameters:\n",
    "            --------\n",
    "            module_name: str, The name of the module instance. Defaults to \"Default_Module_Container\".\n",
    "\n",
    "        Attributes:\n",
    "            self.name: The name of the module instance, set dynamically via __setattr__.\n",
    "            self.training: A flag indicating whether the module is in training mode. Defaults to True.\n",
    "            self._parameter: A dictionary container for all parameters of this module.\n",
    "            self._modules: A dictionary container for all submodule instances nested within this module.\n",
    "        \"\"\"\n",
    "        \n",
    "        # A default module at least contains:\n",
    "        # 1. self.name, str, the name of this module instance\n",
    "        # 2. self.training, bool, whether the module is in training or evaluation mode\n",
    "        # 3. self.accumulate, bool, whether the module is accumulating gradients\n",
    "        # 4. self._parameters, container, all parameters of THIS module\n",
    "        # 5. self._modules, container, all instances of SUB modules\n",
    "        \n",
    "        # Module name, indicating the name of the module, a string\n",
    "        self.__setattr__(\"name\", module_name)\n",
    "        \n",
    "        # Training flag, indicating the model is training or not\n",
    "        self.__setattr__(\"training\", False)\n",
    "        \n",
    "        # Accumulating flag, indicating the model is accumulating gradients or not\n",
    "        self.__setattr__(\"accumulate\", False)\n",
    "        # You can only set this to True by calling accumulate_grad before doing forward\n",
    "        # to accumulate gradients when training.\n",
    "        \n",
    "        # Initialize internal containers for parameters\n",
    "        self.__setattr__(\"_parameters\", {})\n",
    "        self.__setattr__(\"_modules\", {})\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        \"\"\"\n",
    "        Override this method in subclasses to define forward pass.\n",
    "        A forward pass is the way that the neural network passes the inputs\n",
    "        through parameters and generates the output.\n",
    "        \n",
    "        Raises:\n",
    "            NotImplementedError: You should implement your own forward pass. Calling the base will raise this error.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"forward() is not implemented in the base module. You should define the architecture of your neural network manually.\")\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        Returns an iterator (or list) of all Parameters in this module, including those from child modules.\n",
    "\n",
    "        This method recursively collects all `Parameter` instances from the current module and its submodules,\n",
    "        following a pattern similar to PyTorch's `parameters()` method. It aggregates parameters from both direct\n",
    "        parameters (`self._parameters`) and nested modules (`self._modules`).\n",
    "\n",
    "        Returns:\n",
    "            list: An iterator of all `Parameter` objects in this module and its submodules.\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        \n",
    "        # Own parameters\n",
    "        for param in self._parameters.values():\n",
    "            params.append(param)\n",
    "            \n",
    "        # Parameters of submodules\n",
    "        for module in self._modules.values():\n",
    "            params.extend(module.parameters())\n",
    "        return params\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Resets the gradients of all parameters in this module and its submodules to zero.\n",
    "\n",
    "        This method iterates through all `Parameter` objects in the module (including those from child modules)\n",
    "        and calls `zero_grad()` on each, effectively clearing the gradient buffers. It follows the same pattern\n",
    "        as PyTorch's `zero_grad()` method for efficiency and consistency with standard neural network training workflows.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.zero_grad()\n",
    "\n",
    "    def accumulate_grad(self):\n",
    "        \"\"\"\n",
    "        Set module to gradient accumulate mode. \n",
    "\n",
    "        This method sets the `accumulate` flag to True, ensures gradients are accumulated in backward passing instead of being set to 0.\n",
    "        You should first call `train` to turn the module into training model. Otherwise it will raise a RuntimeError.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: if calling accumulate_grad in non-training mode.\n",
    "        \"\"\"\n",
    "        # If called in non-training mode, raise RuntimeError\n",
    "        if self.training == False:\n",
    "            raise RuntimeError(f\"Calling accumulate_grad() on Module {self.name} to accumulate gradients, but without turning training mode on. Please call .train() first.\")\n",
    "        \n",
    "        # Set the status to accumulating\n",
    "        self.accumulate = True\n",
    "        \n",
    "        # For other modules, set to accumulate mode\n",
    "        for module in self._modules.values():\n",
    "            module.accumulate_grad()\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Set module to training mode (affects dropout, and enables gradients).\n",
    "\n",
    "        This method sets the `training` flag to True, ensures all direct parameters require gradients, and recursively applies \n",
    "        the training mode to all submodules. It is typically used at the beginning of a training loop to activate behaviors \n",
    "        specific to training, such as dropout or batch normalization.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Set the status to training\n",
    "        self.training = True\n",
    "        \n",
    "        # For this module, set all parameters to requires_grad = True\n",
    "        for param in self._parameters.values():\n",
    "            param.requires_grad_(True)\n",
    "        \n",
    "        # For other modules, set to train modes\n",
    "        for module in self._modules.values():\n",
    "            module.train()\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"\n",
    "        Set module to evaluation mode (disable dropout and gradients).\n",
    "        \n",
    "        This method sets the `training` flag to False, which disables behaviors specific to training (e.g., dropout). \n",
    "        It also explicitly sets all direct parameters to require gradients (`requires_grad=True`) and recursively applies \n",
    "        evaluation mode to all submodules.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Set the status to evalutating\n",
    "        self.training = False\n",
    "        \n",
    "        # For this module, set all parameters to requires_grad = False\n",
    "        for param in self._parameters.values():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        # For other modules, set to evaluation mode\n",
    "        for module in self._modules.values():\n",
    "            module.eval()\n",
    "\n",
    "    def to(self, device: str | None = None):\n",
    "        \"\"\"\n",
    "        Moves all parameters and submodules to the specified device.\n",
    "\n",
    "        This method relocates the module's parameters and nested submodules to the given device (e.g., 'cpu', 'cuda'). \n",
    "        If `device` is None, it uses the default device. This is essential for moving models between devices during training or inference.\n",
    "\n",
    "        Args:\n",
    "            device (str | None): The target device (e.g., \"cpu\", \"cuda\"). If None, the default device is used.\n",
    "\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # Set device directly\n",
    "        if device == self.device:\n",
    "            return self\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        # For this module, set every parameters to device\n",
    "        for param in self._parameters.values():\n",
    "            param.to(device)\n",
    "       \n",
    "        # For other modules, set every parameters to device\n",
    "        for module in self._modules.values():\n",
    "            module.to(device)\n",
    "        return self\n",
    "\n",
    "    def backward(self, grad_output: Tensor | None):\n",
    "        \"\"\"\n",
    "        Backpropagate through the module. \n",
    "\n",
    "        This method performs gradient propagation through the module's submodules in reverse order of their addition.\n",
    "        ** By default, if the module contains submodules, propagate grad through them in reverse order.\n",
    "        ** Leaf modules (layers) should override this to implement their own backward logic.\n",
    "        ** Leaf modules (layers) should also be compatible to pytorch's autograd and manual calculation.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): The gradient tensor resulting from the output of the module, used as input for backpropagation..\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The propagated gradient after processing through all submodules.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Note. This will be override by Layers to implement the actual logic of \n",
    "        #       gradient calculation and backpropagation.\n",
    "        # For a normal non-leaf module, we assume it is a container containing NO\n",
    "        #       parameter and just sub-modules. So we invoke backward of submodules.\n",
    "        \n",
    "        # If autograd, then the true backward is performed by LOSS function\n",
    "        # Although it gets soemthing here into the module, it just for compatibility.\n",
    "        # We don't need to processs it anymore.\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, it must be a Tensor object if non-autograd mode\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"Output gradient must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "            \n",
    "        # Propagate gradient through submodules in `reverse` order of addition\n",
    "        for module in reversed(list(self._modules.values())):\n",
    "            grad_output = module.backward(grad_output)\n",
    "            \n",
    "        return grad_output\n",
    "    \n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Create a deepcopy of the parameters and gradiets.\n",
    "        \"\"\"\n",
    "        return deepcopy(self)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"nn_BaseModule(Deep Neural Network Base Module Class \\nConstruct Your Own Network by Creating Children of this Module.).\"\n",
    "\n",
    "\n",
    "# A Deep Neural Network Interface Module Class\n",
    "# Construct Your Own Network by Creating Children of this Module\n",
    "class nn_Module(nn_BaseModule):\n",
    "    \n",
    "    \"\"\"\n",
    "    Base interface for all neural network modules, with standard keyword arguments.\n",
    "    \n",
    "    All neural network modules implemented by users should inherit this class\n",
    "    and utilize the forward() to define the architecture of their networks.\n",
    "    By interacting with an optimizer and loss function, you can update\n",
    "    the weights stored in Parameters and train your neural network.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Module\"    \n",
    "\n",
    "    def __init__(self, \n",
    "                 *,\n",
    "                 module_name: str = \"Default_Module_Container\",\n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes a neural network module interface with basic structural components.\n",
    "\n",
    "        This constructor sets up essential properties for a module, including its name,\n",
    "        training mode flag, and containers for parameters and submodules. It follows a\n",
    "        convention similar to PyTorch modules, where modules are organized hierarchically\n",
    "        with parameter tracking and submodule management.\n",
    "\n",
    "        Parameters:\n",
    "            --------\n",
    "            module_name: str, The name of the module instance. Defaults to \"Default_Module_Container\".\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.name: The name of the module instance, set dynamically via __setattr__.\n",
    "            self.training: A flag indicating whether the module is in training mode. Defaults to True.\n",
    "            self._parameter: A dictionary container for all parameters of this module.\n",
    "            self._modules: A dictionary container for all submodule instances nested within this module.\n",
    "            self.backend: Literal[\"torch\", \"numpy\"], The computational backend used by the layer.\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # A default module at least contains:\n",
    "        # 1. self.name, str, the name of this module instance\n",
    "        # 2. self.training, bool, whether the module is in training or evaluation mode\n",
    "        # 3. self.accumulate, bool, whether the module is accumulating gradients\n",
    "        # 4. self._parameters, container, all parameters of THIS module\n",
    "        # 5. self._modules, container, all instances of SUB modules\n",
    "        # 6. self.backend, str, saying which backend Tensor will by default use\n",
    "        # 7. self.dtype, type, saying the type the data will be stored\n",
    "        # 8. self.device, str, saying the device where the data is stored on\n",
    "        # 9. self.autograd, bool, whether the modules use pytorch autograd or not\n",
    "        \n",
    "        # Module name, internal containers, calling base init to initialize\n",
    "        super().__init__(module_name = module_name)\n",
    "        \n",
    "        # Process the default types\n",
    "        if backend not in (\"numpy\", \"torch\"):\n",
    "            raise ValueError(f\"In creating a module {module_name}, an unsupported backend is passed in. Use 'numpy' or 'torch' only.\")\n",
    "        if backend == \"numpy\":\n",
    "            dtype = np.float32 if dtype is None else dtype\n",
    "            device = \"cpu\" if device is None else device\n",
    "        elif backend == \"torch\":\n",
    "            dtype = torch.float32 if dtype is None else dtype\n",
    "            device = \"cpu\" if device is None else device\n",
    "        \n",
    "        # Record the backend, dtype, device, autograd traits\n",
    "        self.__setattr__(\"backend\", backend)\n",
    "        self.__setattr__(\"dtype\", dtype)\n",
    "        self.__setattr__(\"device\", device)\n",
    "        self.__setattr__(\"autograd\", autograd)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"nn_Module(name = {self.name}).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Module\n",
    "Module = nn_Module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. Implementation of key Components (self-implemented)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Dense layer is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Implementation of Dense Layer (Fully Connected Layer)\n",
    "class nn_Layer_Dense(nn_Module):\n",
    "    \"\"\"\n",
    "    Dense Layer (Fully-Connected Layer) Implementation\n",
    "    \n",
    "    This class serves as the foundation for implementing fully connected (dense)\n",
    "    neural network layers. It contains weight and bias in nn_Parameter containers\n",
    "    and ready to perform forward() and backward() pass to perform MLP tasks.    \n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Layer_Dense\"    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_features: int = 1, \n",
    "                 out_features: int = 1, \n",
    "                 has_bias: str = True,\n",
    "                 init_scale: float = 0.01,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Layer_Dense\", \n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A fully connected layer: y = x @ W + b.\n",
    "        \n",
    "        This class implements a dense (fully connected) neural network layer, which performs a linear transformation\n",
    "        on input data followed by an optional bias addition. It is designed to be compatible with both PyTorch and NumPy backends,\n",
    "        supporting automatic gradient computation via autograd or manual gradient tracking.\n",
    "\n",
    "        Parameters:\n",
    "            in_features: int, The number of input features for this layer. Defaults to 1.\n",
    "            out_features: int, The number of output features for this layer. Defaults to 1.\n",
    "            has_bias: str, A flag indicating whether to include a bias term. Valid values are \"True\" or \"False\".\n",
    "                    If set to \"True\", the layer includes an additive bias term (b). Defaults to \"True\".\n",
    "            module_name: str, The name of the module instance. Defaults to \"nn_Layer_Dense\".\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.in_features: int, The number of input features for this layer.\n",
    "            self.out_features: int, The number of output features for this layer.\n",
    "            self.has_bias: str, A flag indicating whether a bias term is included (\"True\" or \"False\").\n",
    "            self.init_scale: float, A floatting number indicating the maximum value of initial random weights.\n",
    "            self.backend: Literal[\"torch\", \"numpy\"], The computational backend used by the layer.\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(module_name = module_name, backend = backend, dtype = dtype, device = device, autograd = autograd)\n",
    "        \n",
    "        # Shape Notation\n",
    "        # Input: (in_features)\n",
    "        # Output: (out_features)\n",
    "        # self._parameters[\"weight\"]: (in_features, out_features)\n",
    "        # self._parameters[\"bias\"]: (out_features)\n",
    "        \n",
    "        # Record shapes etc\n",
    "        self.__setattr__(\"in_features\", in_features)\n",
    "        self.__setattr__(\"out_features\", out_features)\n",
    "        self.__setattr__(\"has_bias\", has_bias)\n",
    "        self.__setattr__(\"init_scale\", init_scale)\n",
    "        \n",
    "        # Initialize weight and bias parameters\n",
    "        self.__setattr__(\"weight\", nn_Parameter(\n",
    "            Tensor.rand([in_features, out_features], backend=backend, dtype=dtype, device=device) * init_scale,\n",
    "            requires_grad = True,\n",
    "            dtype = None,\n",
    "            device = None,\n",
    "            autograd = autograd)\n",
    "            )\n",
    "        \n",
    "        if has_bias == True:\n",
    "            # If uses bias, then set the bias\n",
    "            self.__setattr__(\"bias\", nn_Parameter(\n",
    "                Tensor.zeros([out_features], backend=backend, dtype=dtype, device=device),\n",
    "                requires_grad = True,\n",
    "                dtype = None,\n",
    "                device = None,\n",
    "                autograd = autograd)\n",
    "                )\n",
    "            \n",
    "        return\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Compute the layer output: out = x @ W + b and return the out.\n",
    "\n",
    "        This method performs the forward computation for a dense neural network layer,\n",
    "        computing the linear transformation `out = x @ W + b`, where `W` is the weight matrix\n",
    "        and `b` is the bias vector. The input tensor `x` is processed through this operation,\n",
    "        and the result is returned as the output of the layer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, in_features) to be transformed by the layer.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor of shape (batch_size, out_features) after applying the dense transformation.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input `x` is not a valid MML.Tensor object.\n",
    "\n",
    "        Attributes:\n",
    "            self.input (Tensor): The input tensor saved for use in backward propagation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Type check, x must be an instance of Tensor\n",
    "        if isinstance(x, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `x` must be in a MML `Tensor` format but you have {type(x)}\")\n",
    "        \n",
    "        # Save input for backward\n",
    "        self.__setattr__(\"input\", x)\n",
    "        \n",
    "        # Perform forward pass x @ W + b\n",
    "        out = x @ self._parameters[\"weight\"].data\n",
    "        if self.has_bias == True:\n",
    "            out += self._parameters[\"bias\"].data\n",
    "        return out\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a dense layer during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): Gradient tensor resulting from the output of the layer, used as input for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object..\n",
    "        \"\"\"\n",
    "        \n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, grad_output must be an instance of Tensor\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"In performing backward(), `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "        \n",
    "        # Gradient wrt. weight: X^T * grad_output\n",
    "        self._parameters[\"weight\"].grad = self.input.transpose() @ grad_output\n",
    "        \n",
    "        # Gradient wrt. bias: sum grad_output over batch dimension\n",
    "        if self.has_bias == True:\n",
    "            # Sum over the samples to get the gradients\n",
    "            self._parameters[\"bias\"].grad = grad_output.sum(axis = 0)\n",
    "        \n",
    "        # Gradient wrt. input: grad_output * W^T\n",
    "        grad_input = grad_output @ self._parameters[\"weight\"].data.transpose()\n",
    "        \n",
    "        # Return the gradient with respect to input for recursive backward calculation\n",
    "        return grad_input\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"nn_Layer_Dense(shape: ({self.in_features}, {self.out_features}) with{'out' if self.has_bias == False else ''} bias).\"\n",
    "    \n",
    "    \n",
    "# Alias for nn_Layer_Dense\n",
    "Dense = nn_Layer_Dense\n",
    "\n",
    "# Implementation of Dropout Layer (Masked Layer)\n",
    "class nn_Layer_Dropout(nn_Module):\n",
    "    \"\"\"\n",
    "    Dropout Layer (Masked Layer) Implementation\n",
    "    \n",
    "    Dropout layer that zeros out inputs with probability p during training, and \n",
    "    it will not mask anything in non-training mode.\n",
    "    Dropout layer can be used to improve anti-over-fitting capabilities of your model.\n",
    "    And it is compatible for any kind of Tensors with any shape (not only a 2D).\n",
    "    It does not have any learnable parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Layer_Dropout\"  \n",
    "    \n",
    "    def __init__(self, \n",
    "                 p: float = 0.1,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Layer_Dropout\", \n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A training active dropout layer.\n",
    "        \n",
    "        This class implements a dropout neural network layer, which performs randomly dropout when training and \n",
    "        do nothing in evaluation process. Dropping out is controlled by a dropout rate which is typically ranging from\n",
    "        0 to 1 and common values are [0.1, 0.4].\n",
    "\n",
    "        Parameters:\n",
    "            p: float, The ratio of dropout when training the neural network. By default, it is 0.1.\n",
    "            module_name: str, The name of the module instance. Defaults to \"nn_Layer_Dense\".\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dropout_p: float, the dropout rate specified and used in training.\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(module_name = module_name, backend = backend, dtype = dtype, device = device, autograd = autograd)\n",
    "        \n",
    "        # Record the dropout rate as a non-trainable parameter\n",
    "        self.__setattr__(\"dropout_p\", p)\n",
    "        \n",
    "        # Record an empty tuple showing the shape of the mask\n",
    "        self.__setattr__(\"shape\", ())\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply dropout during forward pass.\n",
    "\n",
    "        This method implements the forward computation of a dropout layer, which randomly sets elements of the input tensor to zero\n",
    "        with probability `p` during training. In evaluation mode, it returns the input unchanged. The dropout mask is stored for use\n",
    "        in backpropagation during training.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor to apply dropout to. Shape should match the expected dimensions for the layer.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after applying dropout. During training, this tensor has elements randomly zeroed out and scaled.\n",
    "                   In evaluation mode, it returns the input tensor unchanged.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input `x` is not a valid MML.Tensor object.\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check, x must be an instance of Tensor\n",
    "        if isinstance(x, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `x` must be in a MML `Tensor` format but you have {type(x)}\")\n",
    "        \n",
    "        # Mask it in training mode\n",
    "        if self.training == True:\n",
    "            \n",
    "            # Save the shape of the mask\n",
    "            self.shape = x.shape\n",
    "            \n",
    "            # Create a dropout mask: 1 with probability (1-p), 0 with probability p\n",
    "            mask = Tensor.rand(x.shape, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "            mask.data = mask.data >= self.dropout_p\n",
    "            mask.astype(self.dtype)\n",
    "            \n",
    "            # Scale mask by 1 / (1-p) to keep expectation the same\n",
    "            mask = mask / (1 - self.dropout_p)\n",
    "            \n",
    "            # Save the mask as an attribute (non-parameter attribute)\n",
    "            self.__setattr__(\"mask\", mask)\n",
    "            \n",
    "            return x * mask\n",
    "        \n",
    "        # Do nothing in evaluation mode\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a dense layer during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): Gradient tensor resulting from the output of the layer, used as input for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object..\n",
    "        \"\"\"\n",
    "        \n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, grad_output must be an instance of Tensor\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"In performing backward(), `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "        \n",
    "        # If training, apply the same mask to the gradient\n",
    "        if self.training:\n",
    "            return grad_output * self.mask\n",
    "        \n",
    "        # Else, return identity\n",
    "        else:\n",
    "            return grad_output\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"nn_Layer_Dropout(shape: {self.shape} with probability {round(self.dropout_p)}).\"\n",
    "    \n",
    "    \n",
    "# Alias for nn_Layer_Dropout\n",
    "Dropout = nn_Layer_Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These Activation Functions are self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "\n",
    "# Implementation of ReLU Activation\n",
    "class nn_Activation_ReLU(nn_Module):\n",
    "    \"\"\"\n",
    "    ReLU activation function.\n",
    "    \n",
    "    The Rectified Linear Unit (ReLU) is a widely used activation function \n",
    "    defined by the formula: f(x) = \\max(0, x). This function outputs the \n",
    "    input value if it is positive, and zero otherwise. ReLU is celebrated for its \n",
    "    computational efficiency and ability to mitigate vanishing gradient problems \n",
    "    during backpropagation, making it a cornerstone in modern deep learning architectures.\n",
    "    \n",
    "    Formula: f(x) = max(0, x)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Activation_ReLU\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 *,\n",
    "                 module_name: str = \"nn_Activation_ReLU\", \n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        An ReLU activation function.\n",
    "\n",
    "        Parameters:\n",
    "            module_name: str, The name of the module instance.\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(module_name = module_name, backend = backend, dtype = dtype, device = device, autograd = autograd)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply the Rectified Linear Unit (ReLU) activation function to the input tensor.\n",
    "\n",
    "        This method computes the element-wise ReLU activation, which outputs the input if it is positive,\n",
    "        and zero otherwise. It is a fundamental non-linearity in neural networks, enabling the model\n",
    "        to learn complex patterns by introducing non-linearities. The input is saved for backward propagation\n",
    "        to compute gradients during training.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of any shape. The ReLU operation is applied element-wise.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after applying the ReLU activation, with the same shape as the input.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input `x` is not a valid MML.Tensor object.\n",
    "        \"\"\"\n",
    "                \n",
    "        # Type check, x must be an instance of Tensor\n",
    "        if isinstance(x, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `x` must be in a MML `Tensor` format but you have {type(x)}\")\n",
    "        \n",
    "        # Save input for backward\n",
    "        self.__setattr__(\"input\", x)\n",
    "\n",
    "        # Apply ReLU to the input data\n",
    "        return Tensor.where_as(x.data > 0, x.data, 0, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): Gradient tensor resulting from the output of the layer, used as input for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object..\n",
    "        \"\"\"\n",
    "        \n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, grad_output must be an instance of Tensor\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"In performing backward(), `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "        \n",
    "        # Pass gradient only where input was positive\n",
    "        grad_input = Tensor.where_as(self.input.data <= 0, 0, grad_output.data, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "        return grad_input\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"nn_Activation_ReLU(ReLU Activation Function).\"\n",
    "    \n",
    "\n",
    "# Alias for nn_Activation_ReLU\n",
    "ReLU = nn_Activation_ReLU\n",
    "\n",
    "\n",
    "# Implementation of Leaky ReLU Activation\n",
    "class nn_Activation_LeakyReLU(nn_Module):\n",
    "    \"\"\"\n",
    "    Leaky ReLU activation with a small slope for negative inputs.\n",
    "    \n",
    "    The Leaky Rectified Linear Unit (Leaky ReLU) is a variant of the ReLU \n",
    "    activation function that allows a small, non-zero gradient when the input \n",
    "    is negative. This helps mitigate the \"dying ReLU\" problem where neurons \n",
    "    become inactive and cease to learn. The function is defined as:\n",
    "    \n",
    "    Formula: f(x) = max(0, x, *x), where  is a small positive slope (typically 0.01).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Activation_LeakyReLU\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 leaky_slope: float = 0.01,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Activation_ReLU\", \n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A Leaky ReLU activation function.\n",
    "\n",
    "        Parameters:\n",
    "            leaky_slope: float, The slope of negative values.\n",
    "            module_name: str, The name of the module instance.\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.leaky_slope: float, The slope applied to negative values.\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(module_name = module_name, backend = backend, dtype = dtype, device = device, autograd = autograd)\n",
    "    \n",
    "        # Record the leaky slope as a non-Parameter attribute\n",
    "        self.__setattr__(\"leaky_slope\", leaky_slope)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply the Leaky Rectified Linear Unit (Leaky ReLU) activation function to the input tensor.\n",
    "\n",
    "        This method computes the element-wise Leaky ReLU activation, which outputs the input if it is positive,\n",
    "        and a small negative slope multiplied by the input otherwise. This variant of ReLU mitigates the \"dying ReLU\"\n",
    "        problem by allowing a controlled negative slope, improving gradient flow for negative inputs. The input is saved\n",
    "        for backward propagation to compute gradients during training.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of any shape. The Leaky ReLU operation is applied element-wise.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after applying the Leaky ReLU activation, with the same shape as the input.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input `x` is not a valid MML.Tensor object.\n",
    "        \"\"\"\n",
    "                \n",
    "        # Type check, x must be an instance of Tensor\n",
    "        if isinstance(x, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `x` must be in a MML `Tensor` format but you have {type(x)}\")\n",
    "        \n",
    "        # Save input for backward\n",
    "        self.__setattr__(\"input\", x)\n",
    "\n",
    "        # Apply Leaky ReLU to the input data\n",
    "        return Tensor.where_as(x.data > 0, x.data, x.data * self.leaky_slope, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): Gradient tensor resulting from the output of the layer, used as input for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object..\n",
    "        \"\"\"\n",
    "        \n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, grad_output must be an instance of Tensor\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"In performing backward(), `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "        \n",
    "        # Pass gradient only where input was positive\n",
    "        grad_input = Tensor.where_as(self.input.data <= 0, grad_output.data * self.leaky_slope, grad_output.data, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "        return grad_input\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"nn_Activation_LeakyReLU(Leaky ReLU Activation Function with alpha = {self.leaky_slope}).\"\n",
    "    \n",
    "      \n",
    "# Alias for nn_Activation_LeakyReLU\n",
    "LeakyReLU = nn_Activation_LeakyReLU \n",
    "\n",
    "\n",
    "# Implementation of Sigmoid Activation\n",
    "class nn_Activation_Sigmoid(nn_Module):\n",
    "    \"\"\"\n",
    "    Sigmoid activation function.\n",
    "    \n",
    "    The Sigmoid function maps input values to a range between 0 and 1, \n",
    "    making it suitable for binary classification tasks. It is defined by the \n",
    "    formula: f(x) = 1 / (1 + e^(-x)). However, it suffers from vanishing gradient \n",
    "    issues in deep networks due to its saturation regions near 1.\n",
    "    \n",
    "    Formula: f(x) = \\frac{1}{1 + e^{-x}}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Activation_Sigmoid\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 *,\n",
    "                 module_name: str = \"nn_Activation_Sigmoid\", \n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        An Sigmoid activation function.\n",
    "\n",
    "        Parameters:\n",
    "            module_name: str, The name of the module instance.\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(module_name = module_name, backend = backend, dtype = dtype, device = device, autograd = autograd)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply the Sigmoid activation function to the input tensor.\n",
    "\n",
    "        This method computes the element-wise Sigmoid activation, which maps input values\n",
    "        to the range (0, 1). The Sigmoid function is widely used in neural networks for\n",
    "        binary classification tasks due to its smooth, differentiable nature. The output\n",
    "        is saved for use during backward propagation to compute gradients.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of any shape. The Sigmoid operation is applied element-wise.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after applying the Sigmoid activation, with the same shape as the input.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input `x` is not a valid MML.Tensor object.\n",
    "\n",
    "        \"\"\"\n",
    "                \n",
    "        # Type check, x must be an instance of Tensor\n",
    "        if isinstance(x, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `x` must be in a MML `Tensor` format but you have {type(x)}\")\n",
    "        \n",
    "        # Perform a sigmoid function on the input\n",
    "        output = x.sigmoid()\n",
    "        \n",
    "        # Save output for backward\n",
    "        self.__setattr__(\"output\", output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): Gradient tensor resulting from the output of the layer, used as input for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object..\n",
    "        \"\"\"\n",
    "        \n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, grad_output must be an instance of Tensor\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"In performing backward(), `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "        \n",
    "        # grad = grad_output * sigmoid(x) * (1 - sigmoid(x))\n",
    "        grad_input = grad_output * self.output * (1 - self.output)\n",
    "        return grad_input\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"nn_Activation_Sigmoid(Sigmoid Activation Function).\"\n",
    "    \n",
    "    \n",
    "# Alias for nn_Activation_Sigmoid\n",
    "Sigmoid = nn_Activation_Sigmoid\n",
    "\n",
    "\n",
    "# Implementation of Tanh Activation\n",
    "class nn_Activation_Tanh(nn_Module):\n",
    "    \"\"\"\n",
    "    Tanh activation function.\n",
    "    \n",
    "    The hyperbolic tangent (tanh) function maps input values to a range between -1 and 1,\n",
    "    making it suitable for scenarios requiring symmetric output distribution. It is defined as:\n",
    "    \n",
    "    Formula: f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} = \\tanh(x)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Activation_Tanh\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 *,\n",
    "                 module_name: str = \"nn_Activation_Sigmoid\", \n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        An Sigmoid activation function.\n",
    "\n",
    "        Parameters:\n",
    "            module_name: str, The name of the module instance.\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(module_name = module_name, backend = backend, dtype = dtype, device = device, autograd = autograd)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply the Tangent Hyperbolic activation function to the input tensor.\n",
    "\n",
    "        This method computes the element-wise hyperbolic tangent (tanh) activation,\n",
    "        which maps input values to the range (-1, 1). The tanh function is smooth and\n",
    "        differentiable everywhere, making it suitable for neural network layers that\n",
    "        require non-linear transformations. The output is saved for use in backward\n",
    "        propagation to compute gradients during training.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of any shape. The tanh operation is applied element-wise.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after applying the tanh activation, with the same shape as the input.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input `x` is not a valid MML.Tensor object.\n",
    "        \"\"\"\n",
    "                \n",
    "        # Type check, x must be an instance of Tensor\n",
    "        if isinstance(x, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `x` must be in a MML `Tensor` format but you have {type(x)}\")\n",
    "        \n",
    "        # Perform a tanh function on the input\n",
    "        output = x.tanh()\n",
    "        \n",
    "        # Save output for backward\n",
    "        self.__setattr__(\"output\", output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): Gradient tensor resulting from the output of the layer, used as input for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object..\n",
    "        \"\"\"\n",
    "        \n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, grad_output must be an instance of Tensor\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"In performing backward(), `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "        \n",
    "        # grad = grad_output * (1 - tanh(x)^2)\n",
    "        grad_input = grad_output * (1 - self.output ** 2)\n",
    "        return grad_input\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"nn_Activation_Tanh(Tanh Activation Function).\"\n",
    "   \n",
    "    \n",
    "# Alias for nn_Activation_Tanh\n",
    "Tanh = nn_Activation_Tanh\n",
    "\n",
    "   \n",
    "# Implementation of Softmax Activation\n",
    "class nn_Activation_Softmax(nn_Module):\n",
    "    \"\"\"\n",
    "    Softmax activation function.\n",
    "    \n",
    "    The Softmax function converts raw scores (logits) into probabilities \n",
    "    that sum to 1, making it suitable for multi-class classification tasks. \n",
    "    It generalizes the sigmoid function to multiple classes by applying the \n",
    "    formula: f(x_i) = exp(x_i) / sum_j(exp(x_j)), where x_i is the input score \n",
    "    for class i. This ensures the output represents a probability distribution \n",
    "    over the classes.\n",
    "    \n",
    "    Formula: f(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Activation_Softmax\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dim: int = 1,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Activation_Sigmoid\", \n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        An Sigmoid activation function.\n",
    "\n",
    "        Parameters:\n",
    "            dim: int, The dimension to apply softmax on. Defaults to 1.\n",
    "            module_name: str, The name of the module instance.\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.softmax_dim: int, The dimension to apply softmax on.\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(module_name = module_name, backend = backend, dtype = dtype, device = device, autograd = autograd)\n",
    "    \n",
    "        # Record the softmax dimension as a non-Parameter attribute\n",
    "        self.__setattr__(\"softmax_dim\", dim)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply the Softmax activation function to the input tensor.\n",
    "\n",
    "        This method applies the softmax function along the specified axis (softmax_dim)\n",
    "        to convert logits into probabilities. The output is a Tensor with the same shape\n",
    "        as the input, but with values normalized to the range [0, 1] along the specified axis.\n",
    "        This operation is commonly used in classification tasks to produce probability distributions.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor containing logits (unnormalized log probabilities).\n",
    "            softmax_dim (int): The axis along which to apply the softmax function. \n",
    "                              For example, for a batch of images, this could be the channel dimension.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor with probabilities computed via softmax along the specified axis.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input `x` is not a valid MML.Tensor object.\n",
    "\n",
    "        \"\"\"\n",
    "                \n",
    "        # Type check, x must be an instance of Tensor\n",
    "        if isinstance(x, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `x` must be in a MML `Tensor` format but you have {type(x)}\")\n",
    "        \n",
    "        # Perform a softmax function on the input\n",
    "        output = x.softmax(axis = self.softmax_dim, keepdims = True)\n",
    "        \n",
    "        # Save output for backward\n",
    "        self.__setattr__(\"output\", output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): Gradient tensor resulting from the output of the layer, used as input for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `grad_output` is not a valid MML.Tensor object..\n",
    "        \"\"\"\n",
    "        \n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            return None\n",
    "        \n",
    "        # Type check, grad_output must be an instance of Tensor\n",
    "        if isinstance(grad_output, Tensor) == False:\n",
    "            raise ValueError(f\"In performing backward(), `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "        \n",
    "        # Compute gradient w.r.t input using Jacobian: grad_input = y * (grad_out - (grad_out * y).sum_along_dim)\n",
    "        grad_sum = (grad_output * self.output).sum(axis=self.softmax_dim, keepdims=True) \n",
    "        grad_input = self.output * (grad_output - grad_sum)\n",
    "        return grad_input\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"nn_Activation_Softmax(Softmax Activation Function).\"\n",
    "   \n",
    "    \n",
    "# Alias for nn_Activation_Softmax\n",
    "Softmax = nn_Activation_Softmax\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These Loss Functions are self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Implementation of Base Lose Class\n",
    "class nn_Loss_BaseLoss(nn_Module):\n",
    "\n",
    "    __attr__ = \"MML.nn_Loss_BaseLoss\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Loss_Base\",\n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        An abstract Loss Implemetation.\n",
    "\n",
    "        Parameters:\n",
    "            module_name: str, The name of the module instance.\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(module_name=module_name, backend=backend, dtype=dtype, device=device, autograd=autograd)\n",
    "\n",
    "    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass, to calculate the loss.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"forward() is not implemented in the base loss class\")\n",
    "        \n",
    "    def backward(self, grad_output: Tensor | None = None) -> Tensor | None:\n",
    "        \"\"\"\n",
    "        Backward pass, to calculate the chained gradient with respect to parameters and return \n",
    "        the gradients with respect to inputs.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"backward() is not implemented in the base loss class\")\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"nn_Loss_BaseLoss(Abstract Loss Class).\"   \n",
    "\n",
    "\n",
    "# Implementation of Mean Square Error Loss\n",
    "class nn_Loss_MSE(nn_Loss_BaseLoss):\n",
    "    \"\"\"\n",
    "    Mean Squared Error Loss.\n",
    "\n",
    "    The Mean Squared Error (MSE) loss function quantifies the average squared difference \n",
    "    between predicted values and true values. It is widely used in regression tasks \n",
    "    and is defined as: \n",
    "\n",
    "    Formula: L = \\frac{1}{n} \\sum_{i=1}^{n} (y_{true,i} - y_{pred,i})^2\n",
    "\n",
    "    Where:\n",
    "        - $ n $ is the number of samples\n",
    "        - $ y_{true,i} $ is the true value for sample i\n",
    "        - $ y_{pred,i} $ is the predicted value for sample i\n",
    "\n",
    "    MSE penalizes larger errors more heavily due to squaring, making it sensitive \n",
    "    to outliers. It is differentiable and computationally efficient, but not suitable \n",
    "    for classification tasks where probabilistic outputs are required.\n",
    "\n",
    "    Formula: L = \\frac{1}{n} \\sum_{i=1}^{n} (y_{true,i} - y_{pred,i})^2\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    __attr__ = \"MML.nn_Loss_MSE\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Loss_MSE\",\n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A Mean Squared Error Loss Function.\n",
    "\n",
    "        Parameters:\n",
    "            module_name: str, The name of the module instance.\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(module_name=module_name, backend=backend, dtype=dtype, device=device, autograd=autograd)\n",
    "\n",
    "    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply the Mean Squared Error (MSE) Loss function to evaluate the values predicted by the network.\n",
    "\n",
    "        This method computes the average squared difference between predicted values (`pred`) and actual values (`target`), \n",
    "        which is a common loss function for regression tasks. The output is a scalar value representing the loss, \n",
    "        averaged over all elements in the input tensors.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): Predicted tensor containing model outputs.\n",
    "            target (Tensor): Target tensor containing ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Scalar tensor representing the computed MSE loss.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `pred` or `target` is not a valid MML.Tensor object, \n",
    "                        or if `pred` and `target` do not have the same shape.\n",
    "\n",
    "        Attributes:\n",
    "            self.numel (scalar): Total number of elements in the input tensors (product of tensor shapes).\n",
    "            self.mse (Tensor): Saved MSE Computed fpr backward computation.\n",
    "            self.pred (Tensor): Saved predicted tensor for backward computation.\n",
    "            self.target (Tensor): Saved target tensor for backward computation.\n",
    "            self.loss ([Tensor]): Save the computed loss for backpropagation uses.\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check, pred and target must be an instance of Tensor\n",
    "        if isinstance(pred, Tensor) == False or isinstance(target, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` or `target` must be in a MML `Tensor` format but you have {type(pred)} and {type(target)}\")\n",
    "\n",
    "        # Shape check, pred and target must have the same shape\n",
    "        if pred.shape != target.shape:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` and `target` must have the same shape, but you have {pred.shape} and {target.shape}\")\n",
    "\n",
    "        # Compute the MSE loss\n",
    "        mse = ((pred - target) ** 2).mean()\n",
    "\n",
    "        # Save the pred, input, mse, and total number of elements for backward\n",
    "        self.__setattr__(\"numel\", np.array(pred.shape).prod())\n",
    "        self.__setattr__(\"mse\", mse)\n",
    "        self.__setattr__(\"pred\", pred)\n",
    "        self.__setattr__(\"target\", target)\n",
    "        self.__setattr__(\"loss\", [mse])\n",
    "\n",
    "        return mse\n",
    "\n",
    "    def backward(self, grad_output: Tensor | None = None) -> Tensor | None:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            None: Since it is the first in calculating backward.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            self.loss[0].data.backward()\n",
    "            return None\n",
    "\n",
    "        # If grad_output is None (by default), assign it to 1\n",
    "        if grad_output is None:\n",
    "            grad_output = Tensor(1.0, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "        # Else, it must be a scalar.\n",
    "        else:\n",
    "            if isinstance(grad_output, Tensor) == False:\n",
    "                raise ValueError(f\"In performing backward(), input `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "            if len(grad_output.shape) != 0:\n",
    "                raise ValueError(\"In performing backward(), input `grad_output` must be in a MML `Tensor` with a scalar stored in\")\n",
    "\n",
    "        # dL/dpred = 2*(pred - target) / N (N = number of elements)\n",
    "        grad_input = 2 * (self.pred - self.target) / self.numel\n",
    "        return grad_input * grad_output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"nn_Loss_MSE(Mean Square Error Loss).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Loss_MSE\n",
    "MSE = nn_Loss_MSE\n",
    "\n",
    "\n",
    "# Implementation of Root Mean Square Error Loss\n",
    "class nn_Loss_RMSE(nn_Loss_BaseLoss):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Error Loss.\n",
    "\n",
    "    The Root Mean Squared Error (RMSE) is the square root of the Mean Squared Error (MSE), \n",
    "    providing a measure of the magnitude of errors in the same units as the target variable. \n",
    "    It is widely used for evaluating regression models and is defined as:\n",
    "\n",
    "    Formula: L = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_{true,i} - y_{pred,i})^2 }\n",
    "\n",
    "    Where:\n",
    "        - $ n $ is the number of samples\n",
    "        - $ y_{true,i} $ is the true value for sample i\n",
    "        - $ y_{pred,i} $ is the predicted value for sample i\n",
    "\n",
    "    RMSE addresses the interpretability limitation of MSE by scaling the error metric to the same units \n",
    "    as the target variable. It retains the sensitivity to outliers from squaring but offers a more intuitive \n",
    "    interpretation compared to MSE. Like MSE, it is differentiable and computationally efficient.\n",
    "\n",
    "    Formula: L = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_{true,i} - y_{pred,i})^2 }\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    __attr__ = \"MML.nn_Loss_RMSE\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Loss_RMSE\",\n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A Root Mean Squared Error Loss Function.\n",
    "\n",
    "        Parameters:\n",
    "            module_name: str, The name of the module instance. Defaults to \"nn_Loss_RMSE\".\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(module_name=module_name, backend=backend, dtype=dtype, device=device, autograd=autograd)\n",
    "\n",
    "    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Compute the Root Mean Squared Error (RMSE) between predictions and targets.\n",
    "\n",
    "        This method evaluates the square root of the average squared difference \n",
    "        between predicted values (`pred`) and actual values (`target`), providing \n",
    "        a loss measure in the same units as the original data.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): Predicted tensor containing model outputs.\n",
    "            target (Tensor): Target tensor containing ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Scalar tensor representing the computed MSE loss.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `pred` or `target` is not a valid MML.Tensor object, \n",
    "                        or if `pred` and `target` do not have the same shape.\n",
    "\n",
    "        Attributes:\n",
    "            self.numel (scalar): Total number of elements in the input tensors (product of tensor shapes).\n",
    "            self.mse (Tensor): Saved MSE Computed fpr backward computation.\n",
    "            self.rmse (Tensor): Saved RMSE value for use in gradient calculation.\n",
    "            self.pred (Tensor): Saved predicted tensor for backward computation.\n",
    "            self.target (Tensor): Saved target tensor for backward computation.\n",
    "            self.loss (Tensor): Save the computed loss for backpropagation uses.\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check, pred and target must be an instance of Tensor\n",
    "        if isinstance(pred, Tensor) == False or isinstance(target, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` or `target` must be in a MML `Tensor` format but you have {type(pred)} and {type(target)}\")\n",
    "\n",
    "        # Shape check, pred and target must have the same shape\n",
    "        if pred.shape != target.shape:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` and `target` must have the same shape, but you have {pred.shape} and {target.shape}\")\n",
    "\n",
    "        # Compute MSE and RMSE in Tensor\n",
    "        mse = ((pred - target) ** 2).mean()\n",
    "        rmse = mse ** 0.5\n",
    "\n",
    "        # Save the pred, input, mse, rmse, and total number of elements for backward\n",
    "        self.__setattr__(\"numel\", np.array(pred.shape).prod())\n",
    "        self.__setattr__(\"mse\", mse)\n",
    "        self.__setattr__(\"rmse\", rmse)\n",
    "        self.__setattr__(\"pred\", pred)\n",
    "        self.__setattr__(\"target\", target)\n",
    "        self.__setattr__(\"loss\", [rmse])\n",
    "\n",
    "        return rmse\n",
    "\n",
    "    def backward(self, grad_output: Tensor | None = None) -> Tensor | None:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            None: Since it is the first in calculating backward.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            self.loss[0].data.backward()\n",
    "            return None\n",
    "        \n",
    "        # If grad_output is None (by default), assign it to 1\n",
    "        if grad_output is None:\n",
    "            grad_output = Tensor(1.0, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "        # Else, it must be a scalar.\n",
    "        else:\n",
    "            if isinstance(grad_output, Tensor) == False:\n",
    "                raise ValueError(f\"In performing backward(), input `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "            if len(grad_output.shape) != 0:\n",
    "                raise ValueError(\"In performing backward(), input `grad_output` must be in a MML `Tensor` with a scalar stored in\")\n",
    "\n",
    "        # dL/dpred = (pred - target) / (N * RMSE)\n",
    "        grad_input = (self.pred - self.target) / (self.rmse * self.numel)\n",
    "        return grad_input * grad_output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"nn_Loss_RMSE(Root Mean Square Error Loss).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Loss_RMSE\n",
    "RMSE = nn_Loss_RMSE\n",
    "\n",
    "\n",
    "# Implementation of Mean Absolute Error Loss\n",
    "class nn_Loss_MAE(nn_Loss_BaseLoss):\n",
    "    \"\"\"\n",
    "    Mean Absolute Error Loss.\n",
    "\n",
    "    The Mean Absolute Error (MAE) loss function quantifies the average absolute \n",
    "    difference between predicted values and true values. It is widely used in \n",
    "    regression tasks and is defined as: \n",
    "\n",
    "    Formula: L = \\frac{1}{n} \\sum_{i=1}^{n} |y_{true,i} - y_{pred,i}|\n",
    "\n",
    "    Where:\n",
    "        - $ n $ is the number of samples\n",
    "        - $ y_{true,i} $ is the true value for sample i\n",
    "        - $ y_{pred,i} $ is the predicted value for sample i\n",
    "\n",
    "    MAE is less sensitive to outliers compared to Mean Squared Error (MSE), as it \n",
    "    uses absolute differences rather than squared differences. However, it is not \n",
    "    differentiable at zero, which can affect gradient-based optimization methods. \n",
    "    It provides an interpretable measure of error in the same units as the target \n",
    "    variable.\n",
    "\n",
    "    Formula: L = \\frac{1}{n} \\sum_{i=1}^{n} |y_{true,i} - y_{pred,i}|\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    __attr__ = \"MML.nn_Loss_MAE\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Loss_MAE\",\n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A Mean Absolute Error Loss Function.\n",
    "\n",
    "        Parameters:\n",
    "            module_name: str, The name of the module instance. Defaults to \"nn_Loss_MAE\".\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(module_name=module_name, backend=backend, dtype=dtype, device=device, autograd=autograd)\n",
    "\n",
    "    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Compute the Mean Absolute Error (MAE) between predictions and targets.\n",
    "\n",
    "        This method evaluates the average absolute difference \n",
    "        between predicted values (`pred`) and actual values (`target`), \n",
    "        offering a robust loss measure less sensitive to outliers.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): Predicted tensor containing model outputs.\n",
    "            target (Tensor): Target tensor containing ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Scalar tensor representing the computed MSE loss.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `pred` or `target` is not a valid MML.Tensor object, \n",
    "                        or if `pred` and `target` do not have the same shape.\n",
    "\n",
    "        Attributes:\n",
    "            self.numel (scalar): Total number of elements in the input tensors (product of tensor shapes).\n",
    "            self.mae (Tensor): Saved Mean Absolute Error Tensor value for reference.\n",
    "            self.pred (Tensor): Saved predicted tensor for backward computation.\n",
    "            self.target (Tensor): Saved target tensor for backward computation.\n",
    "            self.loss (Tensor): Save the computed loss for backpropagation uses.\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check, pred and target must be an instance of Tensor\n",
    "        if isinstance(pred, Tensor) == False or isinstance(target, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` or `target` must be in a MML `Tensor` format but you have {type(pred)} and {type(target)}\")\n",
    "\n",
    "        # Shape check, pred and target must have the same shape\n",
    "        if pred.shape != target.shape:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` and `target` must have the same shape, but you have {pred.shape} and {target.shape}\")\n",
    "\n",
    "        # Compute MAE in Tensor\n",
    "        abs_diff = (pred - target).abs()\n",
    "        mae = abs_diff.mean()\n",
    "\n",
    "        # Save the pred, input, mse, rmse, and total number of elements for backward\n",
    "        self.__setattr__(\"numel\", np.array(pred.shape).prod())\n",
    "        self.__setattr__(\"mae\", mae)\n",
    "        self.__setattr__(\"pred\", pred)\n",
    "        self.__setattr__(\"target\", target)\n",
    "        self.__setattr__(\"loss\", [mae])\n",
    "\n",
    "        return mae\n",
    "\n",
    "    def backward(self, grad_output: Tensor | None = None) -> Tensor | None:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            None: Since it is the first in calculating backward.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            self.loss[0].data.backward()\n",
    "            return None\n",
    "\n",
    "        # If grad_output is None (by default), assign it to 1\n",
    "        if grad_output is None:\n",
    "            grad_output = Tensor(1.0, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "        # Else, it must be a scalar.\n",
    "        else:\n",
    "            if isinstance(grad_output, Tensor) == False:\n",
    "                raise ValueError(f\"In performing backward(), input `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "            if len(grad_output.shape) != 0:\n",
    "                raise ValueError(\"In performing backward(), input `grad_output` must be in a MML `Tensor` with a scalar stored in\")\n",
    "\n",
    "        # dL/dpred = (pred - target).sign() / N\n",
    "        grad_input = (self.pred - self.target).sign() / self.numel\n",
    "        return grad_input * grad_output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"nn_Loss_MAE(Mean Absolute Error Loss).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Loss_MAE\n",
    "MAE = nn_Loss_MAE\n",
    "\n",
    "\n",
    "# Implementation of Binary Cross Entropy Loss\n",
    "class nn_Loss_BinaryCrossEntropy(nn_Loss_BaseLoss):\n",
    "    \"\"\"\n",
    "    Binary Cross-Entropy for predictions in [0,1] and binary targets.\n",
    "\n",
    "    The Binary Cross-Entropy loss measures the difference between predicted \n",
    "    probabilities (in [0,1]) and true binary labels (0 or 1). It is widely used \n",
    "    in binary classification tasks and is defined as: \n",
    "\n",
    "    Formula: L = -\\frac{1}{n} \\sum_{i=1}^{n} [y_{true,i} \\log(p_i) + (1 - y_{true,i}) \\log(1 - p_i)]\n",
    "\n",
    "    Where:\n",
    "        - $ n $ is the number of samples\n",
    "        - $ y_{true,i} $ is the true binary label for sample i (0 or 1)\n",
    "        - $ p_i $ is the predicted probability for sample i (in [0,1])\n",
    "\n",
    "    This loss function penalizes incorrect predictions more heavily when the model \n",
    "    is confident but wrong. It is differentiable and suitable for optimization via \n",
    "    gradient-based methods. However, it requires care to avoid numerical instability \n",
    "    (e.g., adding a small epsilon to probabilities near 0 or 1).\n",
    "\n",
    "    Formula: L = -\\frac{1}{n} \\sum_{i=1}^{n} [y_{true,i} \\log(p_i) + (1 - y_{true,i}) \\log(1 - p_i)]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    __attr__ = \"MML.nn_Loss_BinaryCrossEntropy\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 eps: float = 1e-16,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Loss_BinaryCrossEntropy\",\n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A Binary Cross Entropy Loss Function for binary classification.\n",
    "\n",
    "        Parameters:\n",
    "            eps: float, The epsilon amount applied to clip() to avoid log(0).\n",
    "            module_name: str, The name of the module instance. Defaults to \"nn_Loss_BinaryCrossEntropy\".\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.eps: float, The epsilon value applied.\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(module_name=module_name, backend=backend, dtype=dtype, device=device, autograd=autograd)\n",
    "\n",
    "        # Record the eps value\n",
    "        self.__setattr__(\"eps\", eps)\n",
    "\n",
    "    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Compute the Binary Cross Entropy between predictions and targets.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): Predicted tensor containing model outputs.\n",
    "            target (Tensor): Target tensor containing ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Scalar tensor representing the computed MSE loss.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `pred` or `target` is not a valid MML.Tensor object, \n",
    "                        or if `pred` and `target` do not have the same shape.\n",
    "\n",
    "        Attributes:\n",
    "            self.n_classes (scalar): The number of classes to be classified.\n",
    "            self.numel (scalar): Total number of elements in the input tensors (product of tensor shapes).\n",
    "            self.pred (Tensor): Saved predicted tensor for backward computation.\n",
    "            self.target (Tensor): Saved target tensor for backward computation.\n",
    "            self.loss (Tensor): Save the computed loss for backpropagation uses.\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check, pred and target must be an instance of Tensor\n",
    "        if isinstance(pred, Tensor) == False or isinstance(target, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` or `target` must be in a MML `Tensor` format but you have {type(pred)} and {type(target)}\")\n",
    "\n",
    "        # Shape check, pred and target must have the same shape\n",
    "        if pred.shape != target.shape:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` and `target` must have the same shape, but you have {pred.shape} and {target.shape}\")\n",
    "\n",
    "        # n_classes check, must only have 1 dimension (DOES NOT SUPPORT ONE-HOT)\n",
    "        if len(pred.shape) == 2:\n",
    "            if pred.shape[1] != 1:\n",
    "                raise ValueError(f\"In performing forward(), input `pred` and `target` must be 1 dimensional or 2 dimension with the 2nd one be 1, but you have {pred.shape} and {target.shape}\")\n",
    "\n",
    "        # Compute clipped predictions to avoid log0\n",
    "        clipped_pred = pred.clip(self.eps, 1-self.eps)\n",
    "\n",
    "        # Compute binary cross-entropy loss\n",
    "        loss = - (target * clipped_pred.log() +\n",
    "                  (1 - target) * (1 - clipped_pred).log())\n",
    "        loss = loss.mean()\n",
    "\n",
    "        # Save the pred, input etc for backward\n",
    "        self.__setattr__(\"n_classes\", 1)\n",
    "        self.__setattr__(\"numel\", np.array(clipped_pred.shape).prod())\n",
    "        self.__setattr__(\"pred\", clipped_pred)\n",
    "        self.__setattr__(\"target\", target)\n",
    "        self.__setattr__(\"loss\", [loss])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, grad_output: Tensor | None = None) -> Tensor | None:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            None: Since it is the first in calculating backward.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            self.loss[0].data.backward()\n",
    "            return None\n",
    "        \n",
    "        # If grad_output is None (by default), assign it to 1\n",
    "        if grad_output is None:\n",
    "            grad_output = Tensor(1.0, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "        # Else, it must be a scalar.\n",
    "        else:\n",
    "            if isinstance(grad_output, Tensor) == False:\n",
    "                raise ValueError(f\"In performing backward(), input `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "            if len(grad_output.shape) != 0:\n",
    "                raise ValueError(\"In performing backward(), input `grad_output` must be in a MML `Tensor` with a scalar stored in\")\n",
    "\n",
    "        # dL/dpred = -(target/pred - (1-target)/(1-pred)) / N\n",
    "        grad_input = - (self.target / self.pred) + \\\n",
    "            ((1 - self.target) / (1 - self.pred))\n",
    "        grad_input = grad_input / self.numel\n",
    "        return grad_input * grad_output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"nn_Loss_BinaryCrossEntropy(Binary Cross Entropy Loss).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Loss_BinaryCrossEntropy\n",
    "BinaryCrossEntropy = nn_Loss_BinaryCrossEntropy\n",
    "\n",
    "\n",
    "# Implementation of Multi Cross Entropy Loss\n",
    "class nn_Loss_MultiCrossEntropy(nn_Loss_BaseLoss):\n",
    "    \"\"\"\n",
    "    Multi Cross-Entropy for predictions in one_hot and probabilities targets.\n",
    "\n",
    "    The Multi-Class Cross-Entropy loss measures the difference between predicted \n",
    "    probability distributions (for multiple classes) and true one-hot encoded labels. \n",
    "    It is widely used in multi-class classification tasks and is defined as: \n",
    "\n",
    "    Formula: L = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{true,i,c} \\log(p_{i,c})\n",
    "\n",
    "    Where:\n",
    "        - $ n $ is the number of samples\n",
    "        - $ C $ is the number of classes\n",
    "        - $ y_{true,i,c} $ is the one-hot encoded true label for sample i (1 if class c is correct, 0 otherwise)\n",
    "        - $ p_{i,c} $ is the predicted probability for sample i belonging to class c\n",
    "\n",
    "    This loss function penalizes incorrect predictions by measuring the discrepancy between \n",
    "    the true distribution (one-hot) and the predicted distribution. It is differentiable and \n",
    "    suitable for optimization via gradient-based methods. However, numerical stability \n",
    "    must be ensured (e.g., adding a small epsilon to probabilities near 0 or 1) to avoid log(0).\n",
    "\n",
    "    Formula: L = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{true,i,c} \\log(p_{i,c})\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    __attr__ = \"MML.nn_Loss_MultiCrossEntropy\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 eps: float = 1e-16,\n",
    "                 raw_logits: bool = True,\n",
    "                 *,\n",
    "                 module_name: str = \"nn_Loss_MultiCrossEntropy\",\n",
    "                 backend: Literal[\"torch\", \"numpy\"] = \"torch\",\n",
    "                 dtype: type | str = None,\n",
    "                 device: str | None = None,\n",
    "                 autograd: bool = False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        A Binary Cross Entropy Loss Function for multi classification.\n",
    "\n",
    "        Parameters:\n",
    "            eps: float, The epsilon amount applied to clip() to avoid log(0).\n",
    "            raw_logits: bool, If True, then not applied softmax, or applied softmax.\n",
    "            module_name: str, The name of the module instance. Defaults to \"nn_Loss_MultiCrossEntropy\".\n",
    "            backend: Literal[\"torch\", \"numpy\"], The computational backend to use. Defaults to \"torch\".\n",
    "            dtype: type, The data type for the tensor values. Defaults to None (auto detection). \n",
    "                    For PyTorch, this corresponds to torch.dtype; for NumPy, it corresponds to np.dtype.\n",
    "            device: str | None, The target device (e.g., \"cpu\", \"cuda\") where the layer's parameters will be placed. \n",
    "                    If None, uses the default device. Defaults to None (auto detection).\n",
    "            autograd: bool, A flag indicating whether to use PyTorch's autograd for gradient computation. \n",
    "                    If True, manual gradient tracking is disabled. Defaults to False.\n",
    "\n",
    "        Attributes:\n",
    "            self.eps: float, The epsilon value applied.\n",
    "            self.raw_logits: bool, Whether raw logits or not (not applied softmax or not).\n",
    "            self.dtype: type, The data type of the tensor values.\n",
    "            self.device: str | None, The device where the parameters are placed.\n",
    "            self.autograd: bool, Whether PyTorch's autograd is enabled for this layer.\n",
    "            self._parameters.weight: nn_Parameter, The weight parameter matrix (shape: [in_features, out_features]).\n",
    "            self._parameters.bias: nn_Parameter | optional, The optional bias vector (shape: [out_features]) if has_bias is True.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(module_name=module_name, backend=backend, dtype=dtype, device=device, autograd=autograd)\n",
    "\n",
    "        # Record the eps value\n",
    "        self.__setattr__(\"eps\", eps)\n",
    "\n",
    "        # Record the status whether it is raw logits\n",
    "        self.__setattr__(\"raw_logits\", raw_logits)\n",
    "\n",
    "    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Compute the Multi-class Cross Entropy between predictions and targets.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): Predicted tensor containing model outputs.\n",
    "            target (Tensor): Target tensor containing ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Scalar tensor representing the computed MSE loss.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `pred` or `target` is not a valid MML.Tensor object, \n",
    "                        or if `pred` and `target` do not have the same shape.\n",
    "\n",
    "        Attributes:\n",
    "            self.n_classes (scalar): The number of classes to be classified.\n",
    "            self.n_samples (scalar): Total number of samples in the data.\n",
    "            self.pred (Tensor): Saved predicted tensor for backward computation.\n",
    "            self.pred_logprobs (Tensor): Saved log probabilities tensor for backward computation.\n",
    "            self.target (Tensor): Saved target tensor for backward computation.\n",
    "            self.target_multiclass (Tensor): Save target but in multiclass form for backward computation.\n",
    "            self.loss (Tensor): Save the computed loss for backpropagation uses.\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check, pred and target must be an instance of Tensor\n",
    "        if isinstance(pred, Tensor) == False or isinstance(target, Tensor) == False:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` or `target` must be in a MML `Tensor` format but you have {type(pred)} and {type(target)}\")\n",
    "\n",
    "        # Shape check, pred and target must have the same shape\n",
    "        if pred.shape != target.shape:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` and `target` must have the same shape, but you have {pred.shape} and {target.shape}\")\n",
    "\n",
    "        # n_classes check, must have 2 dim and greater than 1 2nd dim\n",
    "        if len(pred.shape) != 2:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` and `target` must be 2 dimensional, but you have {pred.shape} and {target.shape}\")\n",
    "        if pred.shape[1] <= 1:\n",
    "            raise ValueError(f\"In performing forward(), input `pred` and `target` must have greater than 1 outputs in Multi Cross Entropy, but you have {pred.shape} and {target.shape}\")\n",
    "\n",
    "        # Input shape: (N, C) where C = number of classes\n",
    "        # Target shape: (N, C) with one-hot encoded\n",
    "        if self.raw_logits == True:\n",
    "            # Compute log-softmax for numerical stability (log probabilities)\n",
    "            pred_log_probs = pred.softmax(axis=1).clip(self.eps).log()\n",
    "        else:\n",
    "            # Input is probabilities; take log\n",
    "            pred_log_probs = pred.clip(self.eps).log()\n",
    "\n",
    "        # Turn the true one_hot result into a multi-class result (N, 1)\n",
    "        target_multiclass = self._to_labels(target)\n",
    "\n",
    "        # Gather the log probs along axis 1 by true indices\n",
    "        gathered_log_probs = pred_log_probs.gather_along(\n",
    "            pred_log_probs, axis=1, index=target_multiclass)\n",
    "\n",
    "        # Compute negative log-likelihood loss for each sample and take mean\n",
    "        losses = -gathered_log_probs\n",
    "        loss = losses.mean()\n",
    "\n",
    "        # Save the pred, input etc for backward\n",
    "        self.__setattr__(\"n_classes\", pred.shape[1])\n",
    "        self.__setattr__(\"n_samples\", pred.shape[0])\n",
    "        self.__setattr__(\"pred\", pred)\n",
    "        self.__setattr__(\"pred_logprobs\", pred_log_probs)\n",
    "        self.__setattr__(\"target\", target)\n",
    "        self.__setattr__(\"target_multiclass\", target_multiclass)\n",
    "        self.__setattr__(\"loss\", [loss])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, grad_output: Tensor | None = None) -> Tensor | None:\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients for weight, bias, and input.\n",
    "\n",
    "        This method performs the gradient computation for a module during backpropagation. \n",
    "        It calculates the gradients of the loss with respect to the weights, biases, and input tensor,\n",
    "        based on the provided `grad_output` (gradient from the next layer). The implementation\n",
    "        supports both PyTorch autograd and manual gradient calculation modes.\n",
    "\n",
    "        Args:\n",
    "            None: Since it is the first in calculating backward.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Gradient with respect to the input tensor, for recursive backward calculations in previous layers.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # If use autograd, pass; if manual mode, then calculate\n",
    "        if self.autograd == True:\n",
    "            self.loss[0].data.backward()\n",
    "            return None\n",
    "        \n",
    "        # If grad_output is None (by default), assign it to 1\n",
    "        if grad_output is None:\n",
    "            grad_output = Tensor(1.0, backend=self.backend, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "        # Else, it must be a scalar.\n",
    "        else:\n",
    "            if isinstance(grad_output, Tensor) == False:\n",
    "                raise ValueError(f\"In performing backward(), input `grad_output` must be in a MML `Tensor` format but you have {type(grad_output)}\")\n",
    "            if len(grad_output.shape) != 0:\n",
    "                raise ValueError(\"In performing backward(), input `grad_output` must be in a MML `Tensor` with a scalar stored in\")\n",
    "\n",
    "        # Initialize grad_input with same shape as predictions\n",
    "        grad_input = self.pred_logprobs.to_zeros()\n",
    "\n",
    "        # Calculate the backward gradients\n",
    "        if self.raw_logits == True:\n",
    "            # grad = (softmax_prob - one_hot(target)) / N\n",
    "            grad_input = self.pred_logprobs.exp() - self.target\n",
    "            grad_input /= self.n_samples\n",
    "        else:\n",
    "            # For probabilities: grad = -1/p_target for target class, 0 for others, divided by N\n",
    "            grad_input = -self.target / (self.pred_logprobs.exp() + self.eps)\n",
    "            grad_input /= self.n_samples\n",
    "\n",
    "        return grad_input * grad_output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"nn_Loss_MultiCrossEntropy(Multi Cross Entropy Loss, with n_classes = {self.n_classes}).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Loss_BinaryCrossEntropy\n",
    "MultiCrossEntropy = nn_Loss_MultiCrossEntropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These Optimizers are self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Base Class for All nn Optimizers\n",
    "class nn_Optm_BaseOptimizer(nn_Base):\n",
    "    \"\"\"\n",
    "    Base optimizer class.\n",
    "    \n",
    "    Any inherited optimizer takes all of the parameters as a reference and\n",
    "    use a method connected with gradients to update trainable parameters.\n",
    "    A typical __init__ at least requires a list/dict of parameters or a nn_Module.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Optm_BaseOptimizer\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize an optimizer. Call this and pass in parameters as\n",
    "        a list/dict of nn_Parameter or a nn_Module which contains all parameters and submodules.\n",
    "\n",
    "        Parameters:\n",
    "            params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, if directly gives a list of parameters,\n",
    "                    which we believe generates by .parameters(), we record them as a list;\n",
    "                    If directly gives an nn_Module, we accepts and record all of the parameters as a list;\n",
    "\n",
    "        Attributes:\n",
    "            self.params: a List of nn_Parameters which may have gradients and needs to be updated.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Record the unfiltered list of parameters\n",
    "        if isinstance(params, list):\n",
    "            self.params = params\n",
    "        elif isinstance(params, dict):\n",
    "            self.params = params.values()\n",
    "        elif isinstance(params, nn_Module):\n",
    "            self.params = params.parameters()\n",
    "        else:\n",
    "            raise ValueError(f\"`params` for an optimizer can either be a list/dict of nn_Parameter or a nn_module, but you have {type(params)}\")\n",
    "            \n",
    "        # Filter all parameters having gradients\n",
    "        self.params = [p for p in self.params if p.requires_grad == True]\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Update all trainable parameters in one step (override in subclasses).\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"step() is not implemented in the base optimizer class\")\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Reset gradients of all parameters to zero.\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        for p in self.params:\n",
    "            p.zero_grad()\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"nn_Optm_BaseOptimizer(with {len(self.params)} trainable parameters).\"\n",
    "\n",
    "\n",
    "# Implementation of Stochastic Gradient Descent Optimzier\n",
    "class nn_Optm_SGD(nn_Optm_BaseOptimizer):\n",
    "    \"\"\"\n",
    "    Stochastic Gradient Descent optimizer with optional momentum.\n",
    "    \n",
    "    This optimizer uses stochastic gradient descent (SGD) to update model parameters \n",
    "    by minimizing a loss function. It supports optional momentum for faster convergence \n",
    "    and better stability in optimization.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Optm_SGD\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, \n",
    "                 *,\n",
    "                 lr: float = 0.01, \n",
    "                 momentum: float = 0.9,\n",
    "                 **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize a SGD optimizer with momentum. Call this and pass in parameters as\n",
    "        a list/dict of nn_Parameter or a nn_Module which contains all parameters and submodules.\n",
    "\n",
    "        Parameters:\n",
    "            params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, if directly gives a list of parameters,\n",
    "                    which we believe generates by .parameters(), we record them as a list;\n",
    "                    If directly gives an nn_Module, we accepts and record all of the parameters as a list;\n",
    "            lr: float, learning rate, the step size functioned on the gradients to update parameters;\n",
    "            momentum: float, momentum factor for acceleration in convergence.\n",
    "\n",
    "        Attributes:\n",
    "            self.params: a List of nn_Parameters which may have gradients and needs to be updated.\n",
    "            self.n: int, the total number of steps performed.\n",
    "            self.lr: float, the learning rate as a plain float.\n",
    "            self.momentum: float, the momentum rate as a plain float.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the base initialization to initialize all trainable parameters\n",
    "        super().__init__(params, **kwargs)\n",
    "        \n",
    "        # Record the SGD parameters\n",
    "        self.n = 0\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        # Initialize velocity buffers if momentum is used\n",
    "        if momentum != 0:\n",
    "            self.velocities = [p.data.to_zeros() for p in self.params]\n",
    "        else:\n",
    "            self.velocities = None\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Update all trainable parameters in one step by SGD and momentum method.\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # For compatibility, n adds at the begining\n",
    "        self.n += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Iterate over trainable parameters\n",
    "            for i, p in enumerate(self.params):\n",
    "    \n",
    "                # If uses momentum method\n",
    "                if self.momentum != 0:\n",
    "                    # Momentum update: v = momentum * v - lr * grad and update parameter: w = w + v\n",
    "                    if p.autograd == False:\n",
    "                        self.velocities[i] = self.velocities[i] * self.momentum - self.lr * p.grad\n",
    "                        p.data += self.velocities[i]\n",
    "                    else:\n",
    "                        self.velocities[i].data = self.velocities[i].data * self.momentum - self.lr * p.data.data.grad\n",
    "                        p.data.data.data += self.velocities[i].data\n",
    "                        \n",
    "                # Use plain vanilla SGD\n",
    "                else:\n",
    "                    # Vanilla SGD: w = w - lr * grad\n",
    "                    if p.autograd == False:\n",
    "                        p.data -= self.lr * p.grad\n",
    "                    else:\n",
    "                        p.data.data.data -= self.lr * p.data.data.grad\n",
    "                        \n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"nn_Optm_SGD(with {len(self.params)} trainable parameters).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Optm_SGD\n",
    "SGD = nn_Optm_SGD\n",
    "\n",
    "\n",
    "# Implementation of Adaptive Momentum Optimzier\n",
    "class nn_Optm_Adam(nn_Optm_BaseOptimizer):\n",
    "    \"\"\"\n",
    "    Adaptive Momentum Estimate (Adam) Optimizer.\n",
    "\n",
    "    Adam is an optimization algorithm that combines the advantages of both RMSProp and SGD. \n",
    "    It maintains two moving averages: one for the gradient (momentum) and another for the square \n",
    "    of the gradient, which are updated over time. The learning rate is adaptively adjusted based \n",
    "    on these estimates to achieve faster convergence and better stability.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_Optm_Adam\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, \n",
    "                 *,\n",
    "                 lr: float = 0.001, \n",
    "                 beta1: float = 0.9, \n",
    "                 beta2: float = 0.999, \n",
    "                 eps: float = 1e-16,\n",
    "                 **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize an Adam optimizer with momentum. Call this and pass in parameters as\n",
    "        a list/dict of nn_Parameter or a nn_Module which contains all parameters and submodules.\n",
    "\n",
    "        Parameters:\n",
    "            params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, if directly gives a list of parameters,\n",
    "                    which we believe generates by .parameters(), we record them as a list;\n",
    "                    If directly gives an nn_Module, we accepts and record all of the parameters as a list;\n",
    "            lr: float, learning rate, the step size functioned on the gradients to update parameters;\n",
    "            beta1: float, momentum term, the decay rate for the first moment estimate.\n",
    "            beta2: float, adaptive scaling, it is the decay rate for the second moment estimate, 0.999 for 1000 steps averaging.\n",
    "\n",
    "        Attributes:\n",
    "            self.params: a List of nn_Parameters which may have gradients and needs to be updated.\n",
    "            self.n: int, the total number of steps performed.\n",
    "            self.lr: float, the learning rate as a plain float.\n",
    "            self.beta1: float, the momentum factor stored in plain float.\n",
    "            self.beta2: float, the adaptive scaling term stored in plain float.\n",
    "            self.eps: float, epsilon to avoid dividing by 0.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the base initialization to initialize all trainable parameters\n",
    "        super().__init__(params, **kwargs)\n",
    "        \n",
    "        # Record the Adam parameters\n",
    "        self.n = 0\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        \n",
    "        # Initialize first and second moment estimates for each param\n",
    "        self.m = [p.data.to_zeros() for p in self.params]  # first moment\n",
    "        self.v = [p.data.to_zeros() for p in self.params]  # second moment\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Update all trainable parameters in one step by Adaptive Momentum Estimate (Adam) method.\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # For compatibility, n adds at the begining\n",
    "        self.n += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Iterate over trainable parameters\n",
    "            for i, p in enumerate(self.params):\n",
    "    \n",
    "                if p.autograd == False:\n",
    "                    # Update biased first moment: m = beta1*m + (1-beta1)*grad\n",
    "                    self.m[i] = self.m[i] * self.beta1 + (1.0 - self.beta1) * p.grad\n",
    "                    # Update biased second moment: v = beta2*v + (1-beta2)*grad^2\n",
    "                    self.v[i] = self.v[i] * self.beta2 + (1.0 - self.beta2) * (p.grad ** 2)            \n",
    "    \n",
    "                    # Compute bias-corrected moments\n",
    "                    m_hat = self.m[i] / (1.0 - (self.beta1 ** self.n))\n",
    "                    v_hat = self.v[i] / (1.0 - (self.beta2 ** self.n))\n",
    "                    \n",
    "                    # Update parameter: w = w - lr * m_hat / (sqrt(v_hat) + eps)\n",
    "                    p.data -= self.lr * m_hat / (v_hat ** 0.5 + self.eps)\n",
    "                \n",
    "                else:\n",
    "                    # Update biased first moment: m = beta1*m + (1-beta1)*grad\n",
    "                    self.m[i].data = self.m[i].data * self.beta1 + (1.0 - self.beta1) * p.data.data.grad\n",
    "                    # Update biased second moment: v = beta2*v + (1-beta2)*grad^2\n",
    "                    self.v[i].data = self.v[i].data * self.beta2 + (1.0 - self.beta2) * (p.data.data.grad ** 2)            \n",
    "    \n",
    "                    # Compute bias-corrected moments\n",
    "                    m_hat = self.m[i] / (1.0 - (self.beta1 ** self.n))\n",
    "                    v_hat = self.v[i] / (1.0 - (self.beta2 ** self.n))\n",
    "                    \n",
    "                    # Update parameter: w = w - lr * m_hat / (sqrt(v_hat) + eps)\n",
    "                    p.data.data.data -= self.lr * m_hat.data / (v_hat.data ** 0.5 + self.eps)\n",
    "                        \n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"nn_Optm_Adam(with {len(self.params)} trainable parameters, beta1 = {self.beta1}, beta2 = {self.beta2}).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Optm_Adam\n",
    "Adam = nn_Optm_Adam\n",
    "\n",
    "\n",
    "# Implementation of Adaptive Momentum Optimzier with Weight Decay\n",
    "class nn_Optm_AdamW(nn_Optm_BaseOptimizer):\n",
    "    \"\"\"\n",
    "    Adaptive Momentum Estimate (AdamW) Optimizer with Weight Decay.\n",
    "\n",
    "    AdamW combines the Adam optimizer with a weight decay regularization term to prevent \n",
    "    overfitting and improve convergence. It applies weight decay to all parameters after \n",
    "    the gradient is computed, ensuring that large weights are penalized in the loss function. \n",
    "    The optimizer uses the same momentum terms as Adam but applies the weight decay during \n",
    "    the update step.\n",
    "\n",
    "    Formula:\n",
    "        For each parameter `p`:\n",
    "        1. Compute gradient `g` and update momentum terms `v`.\n",
    "        2. Apply weight decay: `p.data -= lr * (g + beta_2 * v)`.\n",
    "        3. Update parameters using Adam's updates: `p.data -= lr * (g + beta_1 * v)`.\n",
    "    \"\"\"    \n",
    "    \n",
    "    __attr__ = \"MML.nn_Optm_AdamW\"\n",
    "    \n",
    "    def __init__(self,                 \n",
    "                 params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, \n",
    "                 *, \n",
    "                 lr: float = 0.001, \n",
    "                 beta1: float = 0.9, \n",
    "                 beta2: float = 0.999, \n",
    "                 eps: float = 1e-16,\n",
    "                 weight_decay: float = 0.01,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize an AdamW optimizer with weight decay. Call this and pass in parameters as\n",
    "        a list/dict of nn_Parameter or a nn_Module which contains all parameters and submodules.\n",
    "\n",
    "        Parameters:\n",
    "            params: List[nn_Parameter] | Dict[Any, nn_Parameter] | nn_Module, if directly gives a list of parameters,\n",
    "                    which we believe generates by .parameters(), we record them as a list;\n",
    "                    If directly gives an nn_Module, we accepts and record all of the parameters as a list;\n",
    "            lr: float, learning rate, the step size functioned on the gradients to update parameters;\n",
    "            beta1: float, momentum term, the decay rate for the first moment estimate.\n",
    "            beta2: float, adaptive scaling, it is the decay rate for the second moment estimate, 0.999 for 1000 steps averaging;\n",
    "            weight_decay: float, L2 regularization coefficient (decoupled).\n",
    "\n",
    "        Attributes:\n",
    "            self.params: a List of nn_Parameters which may have gradients and needs to be updated.\n",
    "            self.n: int, the total number of steps performed.\n",
    "            self.lr: float, the learning rate as a plain float.\n",
    "            self.beta1: float, the momentum factor stored in plain float.\n",
    "            self.beta2: float, the adaptive scaling term stored in plain float.\n",
    "            self.eps: float, epsilon to avoid dividing by 0.\n",
    "            self.weight_decay: float, weight decay parameter.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # Call the base initialization to initialize all trainable parameters\n",
    "        super().__init__(params, **kwargs)\n",
    "        \n",
    "        # Record the AdamW parameters\n",
    "        self.n = 0\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # Initialize first and second moment estimates for each param\n",
    "        self.m = [p.data.to_zeros() for p in self.params]  # first moment\n",
    "        self.v = [p.data.to_zeros() for p in self.params]  # second moment\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Update all trainable parameters in one step by Adaptive Momentum Estimate with Weight Decay (AdamW) method.\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # For compatibility, n adds at the begining\n",
    "        self.n += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Iterate over trainable parameters\n",
    "            for i, p in enumerate(self.params):\n",
    "    \n",
    "                if p.autograd == False:\n",
    "                    # Update biased first moment: m = beta1*m + (1-beta1)*grad\n",
    "                    self.m[i] = self.m[i] * self.beta1 + (1.0 - self.beta1) * p.grad\n",
    "                    # Update biased second moment: v = beta2*v + (1-beta2)*grad^2\n",
    "                    self.v[i] = self.v[i] * self.beta2 + (1.0 - self.beta2) * (p.grad ** 2)            \n",
    "    \n",
    "                    # Compute bias-corrected moments\n",
    "                    m_hat = self.m[i] / (1.0 - (self.beta1 ** self.n))\n",
    "                    v_hat = self.v[i] / (1.0 - (self.beta2 ** self.n))\n",
    "                    \n",
    "                    # Apply decoupled weight decay\n",
    "                    p.data *= (1.0 - self.lr * self.weight_decay)\n",
    "                    \n",
    "                    # Update parameter: w = w - lr * m_hat / (sqrt(v_hat) + eps)\n",
    "                    p.data -= self.lr * m_hat / (v_hat ** 0.5 + self.eps)\n",
    "                \n",
    "                else:\n",
    "                    # Update biased first moment: m = beta1*m + (1-beta1)*grad\n",
    "                    self.m[i].data = self.m[i].data * self.beta1 + (1.0 - self.beta1) * p.data.data.grad\n",
    "                    # Update biased second moment: v = beta2*v + (1-beta2)*grad^2\n",
    "                    self.v[i].data = self.v[i].data * self.beta2 + (1.0 - self.beta2) * (p.data.data.grad ** 2)            \n",
    "    \n",
    "                    # Compute bias-corrected moments\n",
    "                    m_hat = self.m[i] / (1.0 - (self.beta1 ** self.n))\n",
    "                    v_hat = self.v[i] / (1.0 - (self.beta2 ** self.n))\n",
    "                    \n",
    "                    # Apply decoupled weight decay\n",
    "                    p.data.data.data *= (1.0 - self.lr * self.weight_decay)\n",
    "                    \n",
    "                    # Update parameter: w = w - lr * m_hat / (sqrt(v_hat) + eps)\n",
    "                    p.data.data.data -= self.lr * m_hat.data / (v_hat.data ** 0.5 + self.eps)\n",
    "                        \n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"nn_Optm_AdamW(with {len(self.params)} trainable parameters, beta1 = {self.beta1}, beta2 = {self.beta2}, weight_decay = {self.weight_decay}).\"\n",
    "\n",
    "\n",
    "# Alias for nn_Optm_AdamW\n",
    "AdamW = nn_Optm_AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Evauator is self implemented and open-sourced\n",
    "# Available at https://github.com/dof-studio/MML/\n",
    "# By Nathmath Huang (bh2821)\n",
    "# License: Apache License Version 2.0\n",
    "\n",
    "# Neural Network Fast Evaluation Pipeline\n",
    "class nn_SInterf_Evaluator(nn_Base, Regression, Classification):\n",
    "    \"\"\"\n",
    "    Neural Network Simple Interface - Evaluation pipeline.\n",
    "    \n",
    "    This evaluator accepts a neural network module, a ctiterion module (loss function),\n",
    "    an optimizer instance and conduct controlled automatic training and evaluation job.\n",
    "    You may use fit(), predict(), or other APIs to experience an easy-to-use and optimized\n",
    "    neural network training process with full automation loaded.\n",
    "    \"\"\"\n",
    "    \n",
    "    __attr__ = \"MML.nn_SInterf_Evaluator\"\n",
    "    \n",
    "    def __init__(self, name: str = \"Evaluator\",\n",
    "                       task: str = \"classification\",\n",
    "                       module: nn_Module | None = None,\n",
    "                       criterion: nn_Loss_BaseLoss | None = None,\n",
    "                       optimizer: nn_Optm_BaseOptimizer | None = None,\n",
    "                       **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Initialize an easy-interface evaluator pipeline object by passing in modules.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            task: str, one of {\"classification\", \"regression\"}, showing the learning task.\n",
    "            module: nn_Module | None, you must pass an nn_Module which is the root node of your neural network structure.\n",
    "            criterion: nn_Loss_BaseLoss, you must pass an instance of a loss function that is the child of the base class.\n",
    "            optimizer: nn_Optm_BaseOptimizer, you must pass an instance of an optimizer that is the child of the base class.\n",
    "            Optional:\n",
    "                **kwargs: other key word arguments, reserved for compatibility use.\n",
    "            \n",
    "        Raise\n",
    "        ----------\n",
    "            ValueError, if task it not valid.\n",
    "            TypeError, if any of the parameter is None or does not have the correct type.\n",
    "        \"\"\"\n",
    "        # Task check\n",
    "        if task not in {\"classification\", \"regression\"}:\n",
    "            raise ValueError(f\"In initializing an evaluator, `task` must be either 'classification' or 'regression', but got {task}\")\n",
    "\n",
    "        # Type check (must be the type specified but not None or others)\n",
    "        if module is not None and not isinstance(module, nn_Module):\n",
    "            raise TypeError(\"In initializing an evaluator, `module` must be an instance of nn_Module\")\n",
    "        elif module is None:\n",
    "            raise TypeError(\"In initializing an evaluator, `module` must be initialized and cannot be None\")\n",
    "    \n",
    "        if criterion is not None and not isinstance(criterion, nn_Loss_BaseLoss):\n",
    "            raise TypeError(\"In initializing an evaluator, `criterion` must be an instance of nn_Loss_BaseLoss\")\n",
    "        elif criterion is None:\n",
    "            raise TypeError(\"In initializing an evaluator, `criterion` must be initialized and cannot be None\")\n",
    "        \n",
    "        if optimizer is not None and not isinstance(optimizer, nn_Optm_BaseOptimizer):\n",
    "            raise TypeError(\"In initializing an evaluator, `optimizer` must be an instance of nn_Optm_BaseOptimizer\")\n",
    "        elif optimizer is None:\n",
    "            raise TypeError(\"In initializing an evaluator, `optimizer` must be initialized and cannot be None\")\n",
    "            \n",
    "        # Call the nn_Base to keep the format consistent\n",
    "        super().__init__()\n",
    "        \n",
    "        # Record name, task, module, criterion, optimizer\n",
    "        self.name = name\n",
    "        self.task = task\n",
    "        self.module = module\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # Create a reference of reference_X and reference_y WITHOUT COPY\n",
    "        self.reference_X = None   # NO COPY\n",
    "        self.reference_y = None   # ON COPY\n",
    "        \n",
    "        # Create a recoder of batch_size\n",
    "        self.batch_size = None\n",
    "        \n",
    "        # Create a counter of how may epoches and steps trainned\n",
    "        self.n_epoch = 0\n",
    "        self.n_step = 0\n",
    "        \n",
    "        # Create a dictionary to collect training loss and evaluation information (if any)\n",
    "        self.losses_ = {}    # Stepwise, index: step number\n",
    "        self.evalhist_ = {}  # Some_epoch-wise, index: epoch number\n",
    "        \n",
    "        # Create a record of random state\n",
    "        self.random_state = None\n",
    "        \n",
    "        # Create a record of to_device which means we need to redevice the data before training/testing\n",
    "        self.to_device = None\n",
    "        \n",
    "    def _fit_epoch_prep(self, X: Tensor, y: Tensor,\n",
    "                        batch_size: int | None = None,\n",
    "                        shuffle: bool = True, \n",
    "                        random_state: int | None = None, \n",
    "                        **kwargs) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Prepare datasets and calculate initial values (for regression tasks and classification tasks).\n",
    "\n",
    "        Parameters:\n",
    "            ----------\n",
    "            X: Tensor, the feature tensor (the 1st dimension is sample).\n",
    "            y: Tensor, the target values (for regression, numerical; for classification, one-hot or multi-label).\n",
    "            batch_size: int, the number of samples trained each time. Must be greater than 1. If None, then use all.\n",
    "            shuffle: bool, whether data will be shuffled for each round (same device same type). By default, True (if batch_size is None then omitted).\n",
    "            random_seed: int | None, the random seed set to perform shuffle, can be None which means to randomly choose one.\n",
    "\n",
    "        Returns:\n",
    "            ----------\n",
    "            Tuple(X, y) shuffled copy or original reference\n",
    "        \"\"\"\n",
    "        \n",
    "        # We don't conduct type checks but checks if X or y are None\n",
    "        if X is None or y is None:\n",
    "            raise ValueError(\"In _fit_epoch_prep(), input `X` or `y` is/are None-type.\")\n",
    "        \n",
    "        # If no need to shuffle, then JUST RETURN without shuffling and copying\n",
    "        if shuffle == False or batch_size is None:\n",
    "            return X,y\n",
    "        elif batch_size >= X.shape[0]:\n",
    "            return X,y\n",
    "        \n",
    "        # Else, we shuffle based on the seed\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        idx = list(range(X.shape[0]))\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "        return X[idx], y[idx]\n",
    "     \n",
    "    def _fit_slice_batch(self, X: Tensor, y: Tensor,\n",
    "                         start: int | None = None,\n",
    "                         batch_size: int | None = None,\n",
    "                         to_device: str | None = None,\n",
    "                         **kwargs) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Slice the input to create one mini-batch for training/testing.\n",
    "        \n",
    "        Parameters:\n",
    "            ----------\n",
    "            X: Tensor, the feature tensor (the 1st dimension is sample).\n",
    "            y: Tensor, the target values (for regression, numerical; for classification, one-hot or multi-label).\n",
    "            start: int | None, the starting index (begining) to be sliced for this round.\n",
    "            batch_size: int | None, the number of samples trained each time. Must be greater than 1. If None, then use all.\n",
    "            to_device: str | None, if non-None, we will perform device transformation after slicing them.\n",
    "            \n",
    "        Returns:\n",
    "            ----------\n",
    "            Tuple(X, y) sliced copy or original reference.\n",
    "        \"\"\"\n",
    "        \n",
    "        # We don't conduct type checks but checks if X or y are None\n",
    "        if X is None or y is None:\n",
    "            raise ValueError(\"In _fit_slice_batch(), input `X` or `y` is/are None-type.\")\n",
    "            \n",
    "        # If no need to slice, then JUST RETURN without shuffling and copying\n",
    "        if batch_size is None and start is None:\n",
    "            if to_device is None:\n",
    "                return X,y\n",
    "            else:\n",
    "                return X.to(backend=X._backend, dtype=X.dtype, device=to_device), y.to(backend=y._backend, dtype=y.dtype, device=to_device)\n",
    "        elif batch_size >= X.shape[0] and start is None:\n",
    "            if to_device is None:\n",
    "                return X,y\n",
    "            else:\n",
    "                return X.to(backend=X._backend, dtype=X.dtype, device=to_device), y.to(backend=y._backend, dtype=y.dtype, device=to_device)\n",
    "        \n",
    "        # Then, we need to slice.\n",
    "        if start is None:\n",
    "            raise ValueError(\"In _fit_slice_batch(), input `start` is None while a small batch_size is specified\")\n",
    "        if batch_size is None:\n",
    "            raise ValueError(\"In _fit_slice_batch(), input `batch_size` is None while a start is specified\")\n",
    "        if start >= X.shape[0]:\n",
    "            raise ValueError(f\"In _fit_slice_batch(), input `start` {start} is greater than the number of samples in `X`\")\n",
    "        \n",
    "        # Slice and return a copy.\n",
    "        if start + batch_size <= X.shape[0]:\n",
    "            idx = list(range(start, start + batch_size))\n",
    "        else:\n",
    "            idx = list(range(start, X.shape[0]))\n",
    "        if to_device is None:\n",
    "            return X[idx],y[idx]\n",
    "        else:\n",
    "            return X[idx].to(backend=X._backend, dtype=X.dtype, device=to_device), y[idx].to(backend=y._backend, dtype=y.dtype, device=to_device)\n",
    "    \n",
    "    def _fit_slice_batch_X(self, X: Tensor,\n",
    "                         start: int | None = None,\n",
    "                         batch_size: int | None = None,\n",
    "                         to_device: str | None = None,\n",
    "                         **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Slice the input to create one mini-batch for training/testing.\n",
    "        \n",
    "        Parameters:\n",
    "            ----------\n",
    "            X: Tensor, the feature tensor (the 1st dimension is sample).\n",
    "            y: Tensor, the target values (for regression, numerical; for classification, one-hot or multi-label).\n",
    "            start: int | None, the starting index (begining) to be sliced for this round.\n",
    "            batch_size: int | None, the number of samples trained each time. Must be greater than 1. If None, then use all.\n",
    "            to_device: str | None, if non-None, we will perform device transformation after slicing them.\n",
    "            \n",
    "        Returns:\n",
    "            ----------\n",
    "            X sliced copy or original reference.\n",
    "        \"\"\"\n",
    "        \n",
    "        # We don't conduct type checks but checks if X or y are None\n",
    "        if X is None:\n",
    "            raise ValueError(\"In _fit_slice_batch_X(), input `X` is/are None-type.\")\n",
    "            \n",
    "        # If no need to slice, then JUST RETURN without shuffling and copying\n",
    "        if batch_size is None and start is None:\n",
    "            if to_device is None:\n",
    "                return X\n",
    "            else:\n",
    "                return X.to(backend=X._backend, dtype=X.dtype, device=to_device)\n",
    "        elif batch_size >= X.shape[0] and start is None:\n",
    "            if to_device is None:\n",
    "                return X\n",
    "            else:\n",
    "                return X.to(backend=X._backend, dtype=X.dtype, device=to_device)\n",
    "        \n",
    "        # Then, we need to slice.\n",
    "        if start is None:\n",
    "            raise ValueError(\"In _fit_slice_batch(), input `start` is None while a small batch_size is specified\")\n",
    "        if batch_size is None:\n",
    "            raise ValueError(\"In _fit_slice_batch(), input `batch_size` is None while a start is specified\")\n",
    "        if start >= X.shape[0]:\n",
    "            raise ValueError(f\"In _fit_slice_batch(), input `start` {start} is greater than the number of samples in `X`\")\n",
    "        \n",
    "        # Slice and return a copy.\n",
    "        if start + batch_size <= X.shape[0]:\n",
    "            idx = list(range(start, start + batch_size))\n",
    "        else:\n",
    "            idx = list(range(start, X.shape[0]))\n",
    "        if to_device is None:\n",
    "            return X[idx]\n",
    "        else:\n",
    "            return X[idx]    \n",
    "    \n",
    "    def _fit_train_one_step(self, X: Tensor, y: Tensor, **kwargs) -> Tuple[int, int, float]:\n",
    "        \"\"\"\n",
    "        Train the model for 1 complete step without switching to evaluation mode.\n",
    "        \n",
    "        Parameters:\n",
    "            ----------\n",
    "            X: Tensor, the mini-batch feature tensor (the 1st dimension is sample).\n",
    "            y: Tensor, the mini-batch target values (for regression, numerical; for classification, one-hot or multi-label).\n",
    "            \n",
    "        Returns:\n",
    "            ----------\n",
    "            Tuple[int, int, float]: (epoch, step, train_loss)\n",
    "\n",
    "        \"\"\"\n",
    "        # We don't conduct type checks but checks if X or y are None\n",
    "        if X is None or y is None:\n",
    "            raise ValueError(\"In _fit_slice_batch(), input `X` or `y` is/are None-type.\")\n",
    "        \n",
    "        # Module must be in training mode\n",
    "        if self.module.training == False:\n",
    "            raise RuntimeError(\"Called _fit_train_one_step() to perform one step training but the module is in non-training mode.\")\n",
    "        \n",
    "        # Module must have the same dtype, device with X\n",
    "        if self.module.dtype != X.dtype or self.module.device != X.device:\n",
    "            raise RuntimeError(\"Called _fit_train_one_step() to perform one step training but the module and your data have different dtype/device.\")\n",
    "        \n",
    "        # Perform a forward pass on the inputs\n",
    "        out = self.module.forward(X)\n",
    "        \n",
    "        # Calculate loss of this step\n",
    "        loss = self.criterion(out, y)\n",
    "        \n",
    "        # Perform the backward propagation of the loss function\n",
    "        lossgrad = self.criterion.backward()\n",
    "    \n",
    "        # Perform the backward propagation of the neural network module\n",
    "        self.module.backward(lossgrad)\n",
    "        \n",
    "        # Apply one step on optimizer to update the parameters\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Apply zero grad to clear the gradients\n",
    "        self.module.zero_grad()\n",
    "        \n",
    "        # Increment the step += 1\n",
    "        self.n_step += 1\n",
    "        return self.n_epoch, self.n_step, loss.to_list()\n",
    "        \n",
    "    def _fit_switch_to_mode(self, mode: Literal[\"train\", \"eval\"] = \"train\", **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Switch the module to train mode or evaluation mode.\n",
    "        \"\"\"\n",
    "        if mode not in {\"train\", \"eval\"}:\n",
    "            raise ValueError(f\"In _fit_switch_to_mode(), you gave a mode {mode} which is neither `train` nor `eval`.\")\n",
    "    \n",
    "        if mode == \"train\":\n",
    "            self.module.train()\n",
    "        elif mode == \"eval\":\n",
    "            self.module.eval()\n",
    "        return\n",
    "    \n",
    "    def _eval_one_batch(self, evalset: Dict[str, Tuple[Tensor, Tensor]] | None = None, evalmetrics: List[str] | str | None = None, one_hot: bool = True, **kwargs):\n",
    "        \"\"\"\n",
    "        Evaluate the `evalset` after training for one batch.    \n",
    "\n",
    "        Returns\n",
    "            -------\n",
    "            result_dict : dict  # Key: evalset name\n",
    "                                # Value dict {metric_name: metric_value}\n",
    "            or \n",
    "            {} if failed or did not evaluate\n",
    "        \"\"\"\n",
    "        # First switch to evaluation mode\n",
    "        self._fit_switch_to_mode(mode = \"eval\")\n",
    "        \n",
    "        # If:\n",
    "        # 1. sequential_batch non-None\n",
    "        # 2. evalset is at least len = 1\n",
    "        # 3. evalmetrics is non-None and at least len = 1\n",
    "        # Do evaluation\n",
    "        result_dict = {}\n",
    "        if evalmetrics is not None and evalset is not None:\n",
    "            if len(evalset) > 0 and len(evalmetrics) > 0:\n",
    "                # Record the result for each eval group\n",
    "                result_dict = {}    # Key: evalset name\n",
    "                                    # Value dict {metric_name: metric_value}\n",
    "                for eval_name in evalset.keys():\n",
    "                    X_sub, y_sub = evalset[eval_name]\n",
    "                    y_pred = self.predict(X_sub)\n",
    "                    \n",
    "                    # Inner metric dict, for values of result dict\n",
    "                    metrics = {}\n",
    "                    for metric_name in evalmetrics:\n",
    "                        \n",
    "                        # Evaluation: regression\n",
    "                        if self.task == \"regression\":\n",
    "                            eval_metric = RegressionMetrics(y_pred, y_sub, metric_type = metric_name).compute()\n",
    "                            # Matrix | Tensor\n",
    "                        \n",
    "                        # Evaluation: this is classification\n",
    "                        else:\n",
    "                            if (y_pred.shape[1] == 2 and one_hot == False) or y_pred.shape[1] == 1:\n",
    "                                # Binary and non-one hot\n",
    "                                eval_metric = BinaryClassificationMetrics(self._to_binary_prob(y_pred), y_sub, metric_type = metric_name).compute()\n",
    "                            else:\n",
    "                                # Since the aggregation output is alway one-hot, use Multiple then\n",
    "                                eval_metric = MultiClassificationMetrics(y_pred, y_sub, metric_type = metric_name).compute()\n",
    "                            # Matrix | Tensor\n",
    "                        metrics[metric_name] = eval_metric\n",
    "                    # For all metrics, put them into result_dict\n",
    "                    result_dict[eval_name] = metrics\n",
    "        \n",
    "        # If it is empty, then exit since nothing valid\n",
    "        if len(result_dict) == 0:\n",
    "            return {}\n",
    "        \n",
    "        # Else, return the dict\n",
    "        else:\n",
    "            return result_dict\n",
    "\n",
    "    def fit(self, \n",
    "            X: Tensor, \n",
    "            y: Tensor,\n",
    "            epoches: int = 100,\n",
    "            batch_size: int | None = None,\n",
    "            shuffle: bool = True,\n",
    "            random_state: int | None = None,\n",
    "            to_device: str | None = None,\n",
    "            *,\n",
    "            one_hot: bool = True,\n",
    "            verbosity: int | None = None,\n",
    "            evalper: int = 1,\n",
    "            evalset: Dict[str, Tuple[Tensor, Tensor]] | None = None,\n",
    "            evalmetrics: List[str] | str | None = None,\n",
    "            early_stop: int | None = None,\n",
    "            early_stop_logic: str = \"some\",\n",
    "            continue_to_train: bool | None = True,\n",
    "            **kwargs):\n",
    "        \"\"\"\n",
    "        Train n_estimators gradient boosting trees sequentially.\n",
    "        \n",
    "        Evaluation Remark:\n",
    "            ----------\n",
    "            You may want to evaluate datasets while training. If so, please do the following things:\n",
    "                1. set `verbosity` = 1 to print the evaluation\n",
    "                2. set the `evalset` to a dict of tuples of your dataset that is going to be evaluated\n",
    "                3. set the `evalmetrics` either to a string of metrics or a list of strings\n",
    "            You may want the algorithm to decide to stop training automatically. If so, please do things above, plus:\n",
    "                1. set `early_stop` to a number of batches, like 1 or 2, which acts like: \n",
    "                    if the metrics for all/some/any/most of the evaluation sets do not decrease anymore, \n",
    "                    the training process will be terminated and return\n",
    "                2. set `early_stop_logic` to determine the way of processing non-decreasing datasets/metrics\n",
    "                3. If you hope to continue to train again, call this `fit` again with `continue_to_train` set to True\n",
    "\n",
    "        Parameters:\n",
    "            ----------\n",
    "            X: Tensor, the feature tensor (the 1st dimension is sample).\n",
    "            y: Tensor, the target values (for regression, numerical; for classification, one-hot or multi-label).\n",
    "            epoches: int, the number of rounds (maximum rounds) to be trainned. Default is 100.\n",
    "            batch_size: int, the number of samples trained each time. Must be greater than 1. If None, then use all.\n",
    "            shuffle: bool, whether data will be shuffled for each round (same device same type). By default, True (if batch_size is None then omitted).\n",
    "            random_seed: int | None, the random seed set to perform shuffle, can be None which means to randomly choose one.\n",
    "            Optional:\n",
    "                one_hot : bool, if y is one-hot encoded for classification tasks.\n",
    "                verbosity: int | None, if >= 1 and having `evalset`, then will report metrics each batch.\n",
    "                evalper: int, the number of rounds to perform before evaluation conducted again.\n",
    "                evalset: Dict[name : Tuple[X, y],\n",
    "                              ...], | None, if provided, it may be used as evaluation set. XGBoost style.\n",
    "                evalmetrics: list of str | str | None, metrics used to do the evaluation. Will be printed.\n",
    "                early_stop: int | None, if non-None, then if metrics NOT gained for `early_stop` times, the forest will stop training.\n",
    "                early_stop_logic: str, the logic when deciding on multiple metrics, can be {\"any\", \"some\", \"most\", \"all\"}.\n",
    "                continue_to_train: bool | None, if non-None and True, the machine will try to restore the place it was and continue\n",
    "                                   to train new estimators until a new stopping criterion meets or until reaches the max number of allowed estimators.\n",
    "                \n",
    "        Returns:\n",
    "            ----------\n",
    "            self\n",
    "        \"\"\"\n",
    "\n",
    "        # Type Check (must be an Tensor type).\n",
    "        if isinstance(X, Tensor) == False or isinstance(y, Tensor) == False:\n",
    "            raise ValueError(\"Input dataset must be Tensor for neural networks. Use Tensor(data) or Tensor(data) to convert.\")\n",
    "        if type(X) != type(y):\n",
    "            raise ValueError(\"Input feature `X` and target `y` must have the same type, use Tensor instead.\")\n",
    "        \n",
    "        # Dimension Check.\n",
    "        if len(X.shape) < 2:\n",
    "            raise ValueError(\"Input feature `X` must be at least 2 dimensional (the first is for samples).\")\n",
    "        if len(y.shape) == 1:\n",
    "            raise ValueError(\"Input target `y` must also be a 2d data. If only one label or value, use data.reshape([-1, 1])\")\n",
    "                    \n",
    "        # Batch size Check.\n",
    "        if batch_size is not None:\n",
    "            if int(batch_size) < 1:\n",
    "                raise ValueError(\"Input `batch_size` must be an interger which is greater or equal to 1.\")\n",
    "                        \n",
    "        # Stopping Logic Check.\n",
    "        if early_stop_logic not in (\"any\", \"some\", \"most\", \"all\"):\n",
    "            raise ValueError(\"Stopping logic `early_stop_logic` must be one of ('any', 'some', 'most', 'all')\")\n",
    "    \n",
    "        # Record the original data, random seeds, and to_device\n",
    "        self.reference_X = X\n",
    "        self.reference_y = y\n",
    "        self.random_state = random_state\n",
    "        self.to_device = to_device\n",
    "        \n",
    "        # Record batch size\n",
    "        self.batch_size = int(batch_size) if batch_size is not None else None\n",
    "        \n",
    "        # Special evalmetrics type conversion\n",
    "        if isinstance(evalmetrics, str) == True:\n",
    "            evalmetrics = [evalmetrics]\n",
    "            \n",
    "        # Verbosity Conversion\n",
    "        verbosity = verbosity if verbosity is not None else 0\n",
    "        \n",
    "        # Create Evaluation Related Objects\n",
    "        undecreased_no = 0\n",
    "        last_eval_dict = {} # Please use deepcopy() here to avoid being errorly referred\n",
    "        \n",
    "        # Helper: Print and decide the evaluated results\n",
    "        def _decide_stop_with_print(batch: int, undecreased_no: int, eval_dict: dict, last_eval_dict: dict, **kwargs):\n",
    "            \"\"\"\n",
    "            Compare the metics and decide if stop or not.\n",
    "\n",
    "            Parameters\n",
    "                ----------\n",
    "                batch: int, batch no, for printing uses.\n",
    "                undecreased_no : int, cumulative number that loss did NOT decrease before evaluation.\n",
    "                eval_dict : dict, the passed evaluation dict.\n",
    "\n",
    "            Returns\n",
    "                -------\n",
    "                Tuple of (int, bool):\n",
    "                    int, updated undecreased_no\n",
    "                    bool, whether to stop (True) training or continue (False)\n",
    "\n",
    "            \"\"\"\n",
    "            # Dict is empty, abort\n",
    "            if len(eval_dict) == 0:\n",
    "                return undecreased_no, False\n",
    "            if len(last_eval_dict) == 0:\n",
    "                return undecreased_no, False\n",
    "            \n",
    "            # Difference dict copy\n",
    "            diff_dict = deepcopy(eval_dict)\n",
    "            \n",
    "            # Calculate the difference (this - last)\n",
    "            # and\n",
    "            # If verbosity, print the new evaluation dict\n",
    "            undes_count = 0\n",
    "            allmetric_count = 0\n",
    "            for evalset_name in eval_dict.keys():\n",
    "                eval_result = eval_dict[evalset_name]\n",
    "                if verbosity >= 1:\n",
    "                    print(\"Evalset: [\", evalset_name, \" : Metrics {\", end = \" \", sep = \"\")\n",
    "                for metric_name in eval_result.keys():\n",
    "                    metric_value = eval_result[metric_name]\n",
    "                    diff_dict[evalset_name][metric_name] = metric_value - last_eval_dict[evalset_name][metric_name]\n",
    "                    if diff_dict[evalset_name][metric_name].to_list() > 0:\n",
    "                        undes_count += 1\n",
    "                    allmetric_count += 1\n",
    "                    if verbosity >= 1:\n",
    "                        print(metric_name, \":\", round(metric_value.to_list(), 4), \", \", end = \" \", sep = \"\")\n",
    "                if verbosity >= 1:\n",
    "                    print(\"}]\", end = \"\\n\")\n",
    "                    \n",
    "            # If no early stop, directly return 0, False\n",
    "            if early_stop is None:\n",
    "                return 0, False\n",
    "                    \n",
    "            # If meets the requirement, stop training\n",
    "            if early_stop_logic == \"any\":\n",
    "                if undes_count > 0:\n",
    "                    undecreased_no += 1\n",
    "                    if undecreased_no >= early_stop:\n",
    "                        return undecreased_no, True\n",
    "                    else:\n",
    "                        return undecreased_no, False\n",
    "            elif early_stop_logic == \"some\":\n",
    "                if undes_count * 3 >= allmetric_count:\n",
    "                    undecreased_no += 1\n",
    "                    if undecreased_no >= early_stop:\n",
    "                        return undecreased_no, True\n",
    "                    else:\n",
    "                        return undecreased_no, False\n",
    "            elif early_stop_logic == \"most\":\n",
    "                if undes_count * 2 >= allmetric_count:\n",
    "                    undecreased_no += 1\n",
    "                    if undecreased_no >= early_stop:\n",
    "                        return undecreased_no, True\n",
    "                    else:\n",
    "                        return undecreased_no, False\n",
    "            elif early_stop_logic == \"all\":\n",
    "                if undes_count * 1 >= allmetric_count:\n",
    "                    undecreased_no += 1\n",
    "                    if undecreased_no >= early_stop:\n",
    "                        return undecreased_no, True\n",
    "                    else:\n",
    "                        return undecreased_no, False\n",
    "                    \n",
    "            # If survives here, return 0, False to refresh the undecreased_no\n",
    "            return 0, False\n",
    "                \n",
    "        #######################################################################\n",
    "        #        \n",
    "        # Iteratively train the neural network\n",
    "        rounds = 0\n",
    "        while rounds < epoches:\n",
    "            \n",
    "            # Verbosity\n",
    "            if verbosity >= 1:\n",
    "                print(f\"Training on Total Epoch: {self.n_epoch}, Round: {rounds}\")\n",
    "\n",
    "            ###################################################################\n",
    "            #\n",
    "            # If needs to shuffle the data, then shuffle it\n",
    "            epo_X, epo_y = self._fit_epoch_prep(X, y, \n",
    "                    batch_size=batch_size, shuffle=shuffle, random_state=self._random_state_next(), **kwargs)\n",
    "            \n",
    "            # Calculate number of steps in this round\n",
    "            if batch_size is None:\n",
    "                this_steps = 1\n",
    "            elif batch_size >= epo_X.shape[0]:\n",
    "                this_steps = 1\n",
    "            else:\n",
    "                this_steps = int(np.ceil(epo_X.shape[0] / batch_size))\n",
    "            \n",
    "            ###################################################################\n",
    "            #\n",
    "            # Formally strat to train this epoch, we first transfer to train mode\n",
    "            self._fit_switch_to_mode(mode = \"train\")\n",
    "            \n",
    "            # For steps in one epoch, train iteratively\n",
    "            if this_steps == 1:\n",
    "                # Just train and get the results\n",
    "                stp_X, stp_y = self._fit_slice_batch(epo_X, epo_y, start = None, batch_size = None, to_device = to_device, **kwargs)\n",
    "                _epoch, _step, _loss = self._fit_train_one_step(stp_X, stp_y, **kwargs)\n",
    "                # Record the step loss\n",
    "                self.losses_[_step] = _loss\n",
    "                \n",
    "            else:\n",
    "                for step in range(this_steps):\n",
    "                    # Prepare step-sliced data\n",
    "                    stp_X, stp_y = self._fit_slice_batch(epo_X, epo_y, start = step * batch_size, \n",
    "                         batch_size = batch_size, to_device = to_device, **kwargs)\n",
    "                    # Train one step\n",
    "                    _epoch, _step, _loss = self._fit_train_one_step(stp_X, stp_y, **kwargs)\n",
    "                    # Record the step loss\n",
    "                    self.losses_[_step] = _loss\n",
    "                                        \n",
    "            # Self-increment epoch\n",
    "            self.n_epoch += 1\n",
    "            \n",
    "            ###################################################################\n",
    "            #\n",
    "            # Evaluation if needed\n",
    "            if rounds % evalper != 0 or rounds == 0:\n",
    "                # Count self increasing\n",
    "                rounds += 1\n",
    "                continue\n",
    "            \n",
    "            # Evaluate and decide if stop training from now\n",
    "            eval_dict = self._eval_one_batch(evalset = evalset, evalmetrics = evalmetrics, one_hot = one_hot, **kwargs)\n",
    "            \n",
    "            # Try stop maker and receive the advice\n",
    "            undecreased_no, decision = _decide_stop_with_print(rounds, undecreased_no = undecreased_no, eval_dict = eval_dict, last_eval_dict = last_eval_dict)\n",
    "            \n",
    "            # Record the evaluation result\n",
    "            self.evalhist_[self.n_epoch] = deepcopy(eval_dict)\n",
    "            \n",
    "            # Copy last evaluated dict\n",
    "            last_eval_dict = deepcopy(eval_dict)\n",
    "            \n",
    "            # Count self increasing\n",
    "            rounds += 1\n",
    "            \n",
    "            # Make decision to terminate or not\n",
    "            if decision == True:\n",
    "                break\n",
    "            \n",
    "        return self\n",
    "            \n",
    "    def eval(self) -> None:\n",
    "        \"\"\"\n",
    "        Switch the module to evaluation mode.\n",
    "        \"\"\"\n",
    "        self.module.eval()\n",
    "        return\n",
    "    \n",
    "    def predict(self, X: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Predict target values for samples in X in batches.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor, output of predictions.\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: if you did NOT switched to evalation mode.\n",
    "        \"\"\"\n",
    "        # Check the module training status\n",
    "        if self.module.training == True:\n",
    "            raise RuntimeError(\"In predict(), you called this in training mode. Please call .eval() to make the model safe in evaluation mode.\")\n",
    "        \n",
    "        # Type Check (must be an Tensor type).\n",
    "        if isinstance(X, Tensor) == False:\n",
    "            raise ValueError(\"Input dataset must be a Tensor. Use Tensor(data) to convert.\")\n",
    "        \n",
    "        # If does not need mini-batch, directly go with X to deviced\n",
    "        if self.batch_size is None:\n",
    "            epo_X = X if self.to_device is None else X.to(X._backend, dtype=X.dtype, device=self.to_device)\n",
    "            return self.module.forward(epo_X)\n",
    "        elif self.batch_size >= X.shape[0]:\n",
    "            epo_X = X if self.to_device is None else X.to(X._backend, dtype=X.dtype, device=self.to_device)\n",
    "            return self.module.forward(epo_X)\n",
    "        \n",
    "        # We have to batchly predict to avoid exceeding the limit of memory\n",
    "        else:\n",
    "            pred = None\n",
    "            start = 0\n",
    "            while start < X.shape[0]:\n",
    "                stp_X = self._fit_slice_batch_X(X, start = start, batch_size = self.batch_size, to_device = self.to_device, **kwargs)\n",
    "                stp_pred = self.module.forward(stp_X)\n",
    "                if pred is None:\n",
    "                    pred = stp_pred\n",
    "                else:\n",
    "                    pred = pred.vstack(stp_pred)\n",
    "                start += self.batch_size\n",
    "            return pred\n",
    "\n",
    "    def predict_loss(self, X: Tensor, y: Tensor, **kwargs) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Predict target values for samples in X and calculate the loss by a given target y.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: output of predictions, loss.\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: if you did NOT switched to evalation mode.\n",
    "        \"\"\"\n",
    "        # Check the module training status\n",
    "        if self.module.training == True:\n",
    "            raise RuntimeError(\"In predict(), you called this in training mode. Please call .eval() to make the model safe in evaluation mode.\")\n",
    "        \n",
    "        # Type Check (must be an Tensor type).\n",
    "        if isinstance(X, Tensor) == False:\n",
    "            raise ValueError(\"Input dataset must be either Matrix and Tensor. Use Matrix(data) or Tensor(data) to convert.\")\n",
    "        \n",
    "        # Conduct a forward pass and return result\n",
    "        pred = self.predict(X, kwargs)    \n",
    "        \n",
    "        # Compute loss function\n",
    "        loss = self.criterion.forward(pred, y if self.to_device is None else y.to(backend=y._backend, dtype=y.dtype, device=self.to_device))\n",
    "        return pred, loss\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"NN Simple Interf Evaluator(name = {self.name}, task = {self.task}, has trained n_epoch = {self.n_epoch}, n_step = {self.n_step}).\"\n",
    "    \n",
    "    \n",
    "# Alias for nn_SInterf_Evaluator\n",
    "Evaluator = nn_SInterf_Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!\n",
    "# Comments about points in the 1st part of this assignment:\n",
    "# \n",
    "# > Build an MLP with 2 hidden layers, ReLU activations, and softmax output\n",
    "#   All components can be achieved by combing nn_Modules defined above. Softmax and ReLU are also defined.\n",
    "#\n",
    "# > Use cross-entropy loss for classification\n",
    "#   Cross-entropy for multi-classification is defined as `MultiCrossEntropy`. We just need to use it.\n",
    "#\n",
    "# > Implement forward and backward propagation\n",
    "# > Mathematical derivation of the gradients used in backpropagation.\n",
    "#   We by default use manual gradient calculation, which means we opt-out torch's autograd.\n",
    "#   Note, you may opt-in autograd by explicitly set `autograd` = True.\n",
    "#   Forward and Backward are manually implemented for each component, please see the classes for reference.\n",
    "#\n",
    "# > Support for tuning learning rate, batch size, hidden units, epochs\n",
    "#   Learning rate can be set in the optimizer, batch_size can be set in Evaluator,\n",
    "#   Hidden Units can be set when constructing your network,\n",
    "#   Epochs can be set in Evaluator and we support continue to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.1 Load MINIST into the Notebook Environment do Pre-processing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat_0</th>\n",
       "      <th>Feat_1</th>\n",
       "      <th>Feat_2</th>\n",
       "      <th>Feat_3</th>\n",
       "      <th>Feat_4</th>\n",
       "      <th>Feat_5</th>\n",
       "      <th>Feat_6</th>\n",
       "      <th>Feat_7</th>\n",
       "      <th>Feat_8</th>\n",
       "      <th>Feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat_55</th>\n",
       "      <th>Feat_56</th>\n",
       "      <th>Feat_57</th>\n",
       "      <th>Feat_58</th>\n",
       "      <th>Feat_59</th>\n",
       "      <th>Feat_60</th>\n",
       "      <th>Feat_61</th>\n",
       "      <th>Feat_62</th>\n",
       "      <th>Feat_63</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5620 rows  65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feat_0  Feat_1  Feat_2  Feat_3  Feat_4  Feat_5  Feat_6  Feat_7  Feat_8  \\\n",
       "0        0.0     1.0     6.0    15.0    12.0     1.0     0.0     0.0     0.0   \n",
       "1        0.0     0.0    10.0    16.0     6.0     0.0     0.0     0.0     0.0   \n",
       "2        0.0     0.0     8.0    15.0    16.0    13.0     0.0     0.0     0.0   \n",
       "3        0.0     0.0     0.0     3.0    11.0    16.0     0.0     0.0     0.0   \n",
       "4        0.0     0.0     5.0    14.0     4.0     0.0     0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "5615     0.0     0.0     4.0    10.0    13.0     6.0     0.0     0.0     0.0   \n",
       "5616     0.0     0.0     6.0    16.0    13.0    11.0     1.0     0.0     0.0   \n",
       "5617     0.0     0.0     1.0    11.0    15.0     1.0     0.0     0.0     0.0   \n",
       "5618     0.0     0.0     2.0    10.0     7.0     0.0     0.0     0.0     0.0   \n",
       "5619     0.0     0.0    10.0    14.0     8.0     1.0     0.0     0.0     0.0   \n",
       "\n",
       "      Feat_9  ...  Feat_55  Feat_56  Feat_57  Feat_58  Feat_59  Feat_60  \\\n",
       "0        7.0  ...      0.0      0.0      0.0      6.0     14.0      7.0   \n",
       "1        7.0  ...      0.0      0.0      0.0     10.0     16.0     15.0   \n",
       "2        1.0  ...      0.0      0.0      0.0      9.0     14.0      0.0   \n",
       "3        0.0  ...      0.0      0.0      0.0      0.0      1.0     15.0   \n",
       "4        0.0  ...      0.0      0.0      0.0      4.0     12.0     14.0   \n",
       "...      ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "5615     1.0  ...      0.0      0.0      0.0      2.0     14.0     15.0   \n",
       "5616     0.0  ...      0.0      0.0      0.0      6.0     16.0     14.0   \n",
       "5617     0.0  ...      0.0      0.0      0.0      2.0      9.0     13.0   \n",
       "5618     0.0  ...      0.0      0.0      0.0      5.0     12.0     16.0   \n",
       "5619     2.0  ...      0.0      0.0      1.0      8.0     12.0     14.0   \n",
       "\n",
       "      Feat_61  Feat_62  Feat_63  Target  \n",
       "0         1.0      0.0      0.0     0.0  \n",
       "1         3.0      0.0      0.0     0.0  \n",
       "2         0.0      0.0      0.0     7.0  \n",
       "3         2.0      0.0      0.0     4.0  \n",
       "4         7.0      0.0      0.0     6.0  \n",
       "...       ...      ...      ...     ...  \n",
       "5615      9.0      0.0      0.0     9.0  \n",
       "5616      6.0      0.0      0.0     0.0  \n",
       "5617      6.0      0.0      0.0     8.0  \n",
       "5618     12.0      0.0      0.0     9.0  \n",
       "5619     12.0      1.0      0.0     8.0  \n",
       "\n",
       "[5620 rows x 65 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess the Hand Writing dataset\n",
    "#\n",
    "\n",
    "# Load the housing dataset into the environment.\n",
    "url = \"https://raw.githubusercontent.com/dof-studio/dtafina/refs/heads/main/MachineLearning/opt-minist-digits-merged.csv\"\n",
    "raw_minist = pd.read_csv(url)\n",
    "\n",
    "# Astype into float32.\n",
    "merged_digits = raw_minist.astype(\"float32\")\n",
    "merged_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(backend=torch, shape=torch.Size([5620, 64]), data=\n",
      "tensor([[0.0000, 0.0625, 0.3750,  ..., 0.0625, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6250,  ..., 0.1875, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.5000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0625,  ..., 0.3750, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1250,  ..., 0.7500, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6250,  ..., 0.7500, 0.0625, 0.0000]],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# Let's split the data into features and target, with features divided by 16 (normalize to 0, 1)\n",
    "\n",
    "# Create the Features Tensor\n",
    "features_digits = Tensor(merged_digits.drop([\"Target\"], axis = 1).to_numpy(), backend=backend, device=device)\n",
    "features_digits /= 16\n",
    "\n",
    "# Create the Targets Tensor\n",
    "targets_digits = Tensor(merged_digits[[\"Target\"]].to_numpy(), backend=backend, device=device)\n",
    "\n",
    "# Show how is the feature Tensor like\n",
    "print(features_digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.2 Split the dataset into 60% training, 20% validation, and 20% test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Train Feature Tensor: \n",
      " Tensor(backend=torch, shape=torch.Size([3372, 64]), data=\n",
      "tensor([[0.0000, 0.0000, 0.3750,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2500,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3125,  ..., 0.6875, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.1250, 0.9375,  ..., 0.3750, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7500,  ..., 0.2500, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0625,  ..., 0.6875, 0.0000, 0.0000]],\n",
      "       device='cuda:0'))\n",
      "### Train Target  Tensor: \n",
      " Tensor(backend=torch, shape=torch.Size([3372, 10]), data=\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (60%), validation (20%), and test (20%) sets\n",
    "# \n",
    "\n",
    "# First split into 60% train and 40% test\n",
    "train_feature, test_feature, train_target, test_target = MLBase.train_test_split(\n",
    "                                        features_digits, targets_digits, test_size=0.4, random_state=202821)\n",
    "\n",
    "# Then split test into 50% validation and 50% test\n",
    "valid_feature, test_feature, valid_target, test_target  = MLBase.train_test_split(\n",
    "                                        test_feature, test_target, test_size=0.5, random_state=202821)\n",
    "\n",
    "# Make every target into a sparse matrix\n",
    "train_target = nn_Module._to_onehot(train_target, n_classes=10).astype(torch.float32)\n",
    "valid_target = nn_Module._to_onehot(valid_target, n_classes=10).astype(torch.float32)\n",
    "test_target = nn_Module._to_onehot(test_target, n_classes=10).astype(torch.float32)\n",
    "\n",
    "\n",
    "# Show the train features and train target\n",
    "print(\"### Train Feature Tensor: \\n\", train_feature)\n",
    "print(\"### Train Target  Tensor: \\n\", train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Like the homework before, we plot the distribution of the target\n",
    "\n",
    "def plot_gradient_histogram(df: pd.DataFrame, bins=100, cmap_name='plasma', which='Target'):\n",
    "    \"\"\"\n",
    "    Plots a histogram of all values in the DataFrame with a gradient color map.\n",
    "    \"\"\"\n",
    "\n",
    "    import matplotlib\n",
    "    from matplotlib.colors import Normalize\n",
    "    # Flatten data and remove NaNs\n",
    "    data = df.values.flatten()\n",
    "    data = data[~np.isnan(data)]\n",
    "    \n",
    "    # Compute histogram\n",
    "    counts, bin_edges, patches = plt.hist(data, bins=bins)\n",
    "    cmap = matplotlib.colormaps.get_cmap(cmap_name)\n",
    "    norm = Normalize(vmin=bin_edges.min(), vmax=bin_edges.max())\n",
    "    for edge, patch in zip(bin_edges, patches):\n",
    "        patch.set_facecolor(cmap(norm(edge)))\n",
    "    \n",
    "    # Enhance plot aesthetics\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {which} Values')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the distribution of the train target\n",
    "plot_gradient_histogram(pd.DataFrame(nn_Module._to_labels(train_target).data.cpu()))\n",
    "\n",
    "# Distribution of samples are balanced generally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.3 Train and test models with different hyperparameters`\n",
    "\n",
    "and\n",
    "\n",
    "`2.3.1 Evaluate using accuracy, precision, recall, F1-score, and confusion matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Evaluation Pipeline\n",
    "def eval_pipeline(evaluator: nn_SInterf_Evaluator, X: Tensor, y_true: Tensor) -> tuple:\n",
    "\n",
    "    pred = evaluator.predict(X)\n",
    "    acc = MultiClassificationMetrics(pred, y_true, \"accuracy\").compute().to_list()\n",
    "    prec = MultiClassificationMetrics(pred, y_true, \"precision\").compute().to_list()\n",
    "    recall = MultiClassificationMetrics(pred, y_true, \"recall\").compute().to_list()\n",
    "    f1s = MultiClassificationMetrics(pred, y_true, \"f1\").compute().to_list()\n",
    "    cfm = MultiClassificationMetrics(pred, y_true, \"confusion_matrix\").compute()\n",
    "    # Normalize the confusion matrix\n",
    "    cfm = cfm.astype(torch.float32)\n",
    "    cfm_sum = cfm.sum(axis = 0).reshape([-1, 1]).repeat(cfm.shape[0], axis = 1)\n",
    "    cfm = cfm / cfm_sum\n",
    "    return pred, acc, prec, recall, f1s, cfm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Model Structure - Benchmark Model 1 - 2 Layers, Small Model\n",
    "\n",
    "class Model_1(nn_Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Nathmath Huang (This is a template definition)\n",
    "        super().__init__(module_name=\"Model_1\", **kwargs)\n",
    "        # In one module, layers should be sequential.\n",
    "        self.dense_1 = Dense(64, 32, True, **kwargs)\n",
    "        self.actv_1 = ReLU(**kwargs)\n",
    "        self.dense_2 = Dense(32, 10, True, **kwargs)\n",
    "        self.softmax_1 = Softmax(**kwargs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.dense_1(inputs)\n",
    "        out = self.actv_1(out)\n",
    "        out = self.dense_2(out)\n",
    "        out = self.softmax_1(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Model Structure - Benchmark Model 2 - 3 Layers, Meidum Sized Model with Dropout\n",
    "\n",
    "class Model_2(nn_Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Nathmath Huang (This is a template definition)\n",
    "        super().__init__(module_name=\"Model_2\", **kwargs)\n",
    "        # In one module, layers should be sequential.\n",
    "        self.dense_1 = Dense(64, 128, True, init_scale=0.1, **kwargs)\n",
    "        self.actv_1 = LeakyReLU(**kwargs)\n",
    "        self.dropout1 = Dropout(0.5, **kwargs)\n",
    "        self.dense_2 = Dense(128, 32, True, init_scale=0.1, **kwargs)\n",
    "        self.actv_2 = Tanh(**kwargs)\n",
    "        self.dense_3 = Dense(32, 10, True, init_scale=0.1, **kwargs)\n",
    "        self.softmax_1 = Softmax(**kwargs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.dense_1(inputs)\n",
    "        out = self.actv_1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.dense_2(out)\n",
    "        out = self.actv_2(out)\n",
    "        out = self.dense_3(out)\n",
    "        out = self.softmax_1(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Model Structure - Benchmark Model 3 - 3 Layers, Large Sized Model with Higher Rate Dropout\n",
    "\n",
    "class Model_3(nn_Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Nathmath Huang (This is a template definition)\n",
    "        super().__init__(module_name=\"Model_3\", **kwargs)\n",
    "        # In one module, layers should be sequential.\n",
    "        self.dense_1 = Dense(64, 256, True, init_scale=0.1, **kwargs)\n",
    "        self.actv_1 = LeakyReLU(**kwargs)\n",
    "        self.dropout_1 = Dropout(0.5, **kwargs)\n",
    "        self.dense_2 = Dense(256, 128, True, init_scale=0.1, **kwargs)\n",
    "        self.actv_2 = Tanh(**kwargs)\n",
    "        self.dropout_2 = Dropout(0.2, **kwargs)\n",
    "        self.dense_3 = Dense(128, 10, True, init_scale=0.1, **kwargs)\n",
    "        self.softmax_1 = Softmax(**kwargs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.dense_1(inputs)\n",
    "        out = self.actv_1(out)\n",
    "        out = self.dropout_1(out)\n",
    "        out = self.dense_2(out)\n",
    "        out = self.actv_2(out)\n",
    "        out = self.dropout_2(out)\n",
    "        out = self.dense_3(out)\n",
    "        out = self.softmax_1(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1.1 Results from the 1st Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Total Epoch: 0, Round: 0\n",
      "Training on Total Epoch: 1, Round: 1\n",
      "Training on Total Epoch: 2, Round: 2\n",
      "Evalset: [Train : Metrics { logloss:2.3015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3018,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3016,  }]\n",
      "Training on Total Epoch: 3, Round: 3\n",
      "Evalset: [Train : Metrics { logloss:2.3009,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3014,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3011,  }]\n",
      "Training on Total Epoch: 4, Round: 4\n",
      "Evalset: [Train : Metrics { logloss:2.3001,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3007,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3004,  }]\n",
      "Training on Total Epoch: 5, Round: 5\n",
      "Evalset: [Train : Metrics { logloss:2.2991,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2999,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2995,  }]\n",
      "Training on Total Epoch: 6, Round: 6\n",
      "Evalset: [Train : Metrics { logloss:2.2979,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2987,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2983,  }]\n",
      "Training on Total Epoch: 7, Round: 7\n",
      "Evalset: [Train : Metrics { logloss:2.2963,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2973,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2968,  }]\n",
      "Training on Total Epoch: 8, Round: 8\n",
      "Evalset: [Train : Metrics { logloss:2.2945,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2956,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2949,  }]\n",
      "Training on Total Epoch: 9, Round: 9\n",
      "Evalset: [Train : Metrics { logloss:2.2923,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2935,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2928,  }]\n",
      "Training on Total Epoch: 10, Round: 10\n",
      "Evalset: [Train : Metrics { logloss:2.2897,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2911,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2902,  }]\n",
      "Training on Total Epoch: 11, Round: 11\n",
      "Evalset: [Train : Metrics { logloss:2.2868,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2883,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2874,  }]\n",
      "Training on Total Epoch: 12, Round: 12\n",
      "Evalset: [Train : Metrics { logloss:2.2835,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2851,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2841,  }]\n",
      "Training on Total Epoch: 13, Round: 13\n",
      "Evalset: [Train : Metrics { logloss:2.2798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2815,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2804,  }]\n",
      "Training on Total Epoch: 14, Round: 14\n",
      "Evalset: [Train : Metrics { logloss:2.2757,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2776,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2763,  }]\n",
      "Training on Total Epoch: 15, Round: 15\n",
      "Evalset: [Train : Metrics { logloss:2.2712,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2733,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2718,  }]\n",
      "Training on Total Epoch: 16, Round: 16\n",
      "Evalset: [Train : Metrics { logloss:2.2663,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2685,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2668,  }]\n",
      "Training on Total Epoch: 17, Round: 17\n",
      "Evalset: [Train : Metrics { logloss:2.2609,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2633,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2615,  }]\n",
      "Training on Total Epoch: 18, Round: 18\n",
      "Evalset: [Train : Metrics { logloss:2.2551,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2578,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2557,  }]\n",
      "Training on Total Epoch: 19, Round: 19\n",
      "Evalset: [Train : Metrics { logloss:2.2489,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2518,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2494,  }]\n",
      "Training on Total Epoch: 20, Round: 20\n",
      "Evalset: [Train : Metrics { logloss:2.2423,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2454,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2428,  }]\n",
      "Training on Total Epoch: 21, Round: 21\n",
      "Evalset: [Train : Metrics { logloss:2.2353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2387,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2358,  }]\n",
      "Training on Total Epoch: 22, Round: 22\n",
      "Evalset: [Train : Metrics { logloss:2.2279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2315,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2284,  }]\n",
      "Training on Total Epoch: 23, Round: 23\n",
      "Evalset: [Train : Metrics { logloss:2.2201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.224,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2205,  }]\n",
      "Training on Total Epoch: 24, Round: 24\n",
      "Evalset: [Train : Metrics { logloss:2.2119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2161,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2123,  }]\n",
      "Training on Total Epoch: 25, Round: 25\n",
      "Evalset: [Train : Metrics { logloss:2.2034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2079,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2036,  }]\n",
      "Training on Total Epoch: 26, Round: 26\n",
      "Evalset: [Train : Metrics { logloss:2.1944,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1992,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1946,  }]\n",
      "Training on Total Epoch: 27, Round: 27\n",
      "Evalset: [Train : Metrics { logloss:2.1852,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1903,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1852,  }]\n",
      "Training on Total Epoch: 28, Round: 28\n",
      "Evalset: [Train : Metrics { logloss:2.1756,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.181,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1755,  }]\n",
      "Training on Total Epoch: 29, Round: 29\n",
      "Evalset: [Train : Metrics { logloss:2.1656,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1713,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1654,  }]\n",
      "Training on Total Epoch: 30, Round: 30\n",
      "Evalset: [Train : Metrics { logloss:2.1554,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1613,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1551,  }]\n",
      "Training on Total Epoch: 31, Round: 31\n",
      "Evalset: [Train : Metrics { logloss:2.1448,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1511,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1445,  }]\n",
      "Training on Total Epoch: 32, Round: 32\n",
      "Evalset: [Train : Metrics { logloss:2.134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1404,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1335,  }]\n",
      "Training on Total Epoch: 33, Round: 33\n",
      "Evalset: [Train : Metrics { logloss:2.1229,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1222,  }]\n",
      "Training on Total Epoch: 34, Round: 34\n",
      "Evalset: [Train : Metrics { logloss:2.1115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1106,  }]\n",
      "Training on Total Epoch: 35, Round: 35\n",
      "Evalset: [Train : Metrics { logloss:2.0998,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1069,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0988,  }]\n",
      "Training on Total Epoch: 36, Round: 36\n",
      "Evalset: [Train : Metrics { logloss:2.0878,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0952,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0866,  }]\n",
      "Training on Total Epoch: 37, Round: 37\n",
      "Evalset: [Train : Metrics { logloss:2.0756,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0834,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0741,  }]\n",
      "Training on Total Epoch: 38, Round: 38\n",
      "Evalset: [Train : Metrics { logloss:2.0631,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0711,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0614,  }]\n",
      "Training on Total Epoch: 39, Round: 39\n",
      "Evalset: [Train : Metrics { logloss:2.0504,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0586,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0485,  }]\n",
      "Training on Total Epoch: 40, Round: 40\n",
      "Evalset: [Train : Metrics { logloss:2.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0459,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0352,  }]\n",
      "Training on Total Epoch: 41, Round: 41\n",
      "Evalset: [Train : Metrics { logloss:2.0244,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.033,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0218,  }]\n",
      "Training on Total Epoch: 42, Round: 42\n",
      "Evalset: [Train : Metrics { logloss:2.011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0199,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0081,  }]\n",
      "Training on Total Epoch: 43, Round: 43\n",
      "Evalset: [Train : Metrics { logloss:1.9975,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0067,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9943,  }]\n",
      "Training on Total Epoch: 44, Round: 44\n",
      "Evalset: [Train : Metrics { logloss:1.9838,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9932,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9803,  }]\n",
      "Training on Total Epoch: 45, Round: 45\n",
      "Evalset: [Train : Metrics { logloss:1.9699,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9795,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9661,  }]\n",
      "Training on Total Epoch: 46, Round: 46\n",
      "Evalset: [Train : Metrics { logloss:1.9558,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9656,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9518,  }]\n",
      "Training on Total Epoch: 47, Round: 47\n",
      "Evalset: [Train : Metrics { logloss:1.9417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9516,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9373,  }]\n",
      "Training on Total Epoch: 48, Round: 48\n",
      "Evalset: [Train : Metrics { logloss:1.9273,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9374,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9226,  }]\n",
      "Training on Total Epoch: 49, Round: 49\n",
      "Evalset: [Train : Metrics { logloss:1.9129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9231,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9078,  }]\n",
      "Training on Total Epoch: 50, Round: 50\n",
      "Evalset: [Train : Metrics { logloss:1.8983,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9086,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8928,  }]\n",
      "Training on Total Epoch: 51, Round: 51\n",
      "Evalset: [Train : Metrics { logloss:1.8836,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8941,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8777,  }]\n",
      "Training on Total Epoch: 52, Round: 52\n",
      "Evalset: [Train : Metrics { logloss:1.8688,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8793,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8625,  }]\n",
      "Training on Total Epoch: 53, Round: 53\n",
      "Evalset: [Train : Metrics { logloss:1.8539,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8646,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8473,  }]\n",
      "Training on Total Epoch: 54, Round: 54\n",
      "Evalset: [Train : Metrics { logloss:1.8389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8497,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8319,  }]\n",
      "Training on Total Epoch: 55, Round: 55\n",
      "Evalset: [Train : Metrics { logloss:1.8238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8348,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8165,  }]\n",
      "Training on Total Epoch: 56, Round: 56\n",
      "Evalset: [Train : Metrics { logloss:1.8087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8198,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.801,  }]\n",
      "Training on Total Epoch: 57, Round: 57\n",
      "Evalset: [Train : Metrics { logloss:1.7936,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.805,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7855,  }]\n",
      "Training on Total Epoch: 58, Round: 58\n",
      "Evalset: [Train : Metrics { logloss:1.7784,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7899,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7699,  }]\n",
      "Training on Total Epoch: 59, Round: 59\n",
      "Evalset: [Train : Metrics { logloss:1.7632,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7747,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7543,  }]\n",
      "Training on Total Epoch: 60, Round: 60\n",
      "Evalset: [Train : Metrics { logloss:1.7479,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7595,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7387,  }]\n",
      "Training on Total Epoch: 61, Round: 61\n",
      "Evalset: [Train : Metrics { logloss:1.7327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7443,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7231,  }]\n",
      "Training on Total Epoch: 62, Round: 62\n",
      "Evalset: [Train : Metrics { logloss:1.7175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.729,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7074,  }]\n",
      "Training on Total Epoch: 63, Round: 63\n",
      "Evalset: [Train : Metrics { logloss:1.7022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7137,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6917,  }]\n",
      "Training on Total Epoch: 64, Round: 64\n",
      "Evalset: [Train : Metrics { logloss:1.6869,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6983,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.676,  }]\n",
      "Training on Total Epoch: 65, Round: 65\n",
      "Evalset: [Train : Metrics { logloss:1.6716,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6831,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6604,  }]\n",
      "Training on Total Epoch: 66, Round: 66\n",
      "Evalset: [Train : Metrics { logloss:1.6564,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6679,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6447,  }]\n",
      "Training on Total Epoch: 67, Round: 67\n",
      "Evalset: [Train : Metrics { logloss:1.6412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6527,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6291,  }]\n",
      "Training on Total Epoch: 68, Round: 68\n",
      "Evalset: [Train : Metrics { logloss:1.6261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6375,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6136,  }]\n",
      "Training on Total Epoch: 69, Round: 69\n",
      "Evalset: [Train : Metrics { logloss:1.611,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6224,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5981,  }]\n",
      "Training on Total Epoch: 70, Round: 70\n",
      "Evalset: [Train : Metrics { logloss:1.5959,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6074,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5828,  }]\n",
      "Training on Total Epoch: 71, Round: 71\n",
      "Evalset: [Train : Metrics { logloss:1.5809,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5923,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5673,  }]\n",
      "Training on Total Epoch: 72, Round: 72\n",
      "Evalset: [Train : Metrics { logloss:1.566,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5773,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.552,  }]\n",
      "Training on Total Epoch: 73, Round: 73\n",
      "Evalset: [Train : Metrics { logloss:1.5511,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5624,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5369,  }]\n",
      "Training on Total Epoch: 74, Round: 74\n",
      "Evalset: [Train : Metrics { logloss:1.5363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5477,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5217,  }]\n",
      "Training on Total Epoch: 75, Round: 75\n",
      "Evalset: [Train : Metrics { logloss:1.5215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5331,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5066,  }]\n",
      "Training on Total Epoch: 76, Round: 76\n",
      "Evalset: [Train : Metrics { logloss:1.5069,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5188,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4918,  }]\n",
      "Training on Total Epoch: 77, Round: 77\n",
      "Evalset: [Train : Metrics { logloss:1.4923,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5043,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.477,  }]\n",
      "Training on Total Epoch: 78, Round: 78\n",
      "Evalset: [Train : Metrics { logloss:1.4778,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4897,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4621,  }]\n",
      "Training on Total Epoch: 79, Round: 79\n",
      "Evalset: [Train : Metrics { logloss:1.4634,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4753,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4474,  }]\n",
      "Training on Total Epoch: 80, Round: 80\n",
      "Evalset: [Train : Metrics { logloss:1.4492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.461,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4328,  }]\n",
      "Training on Total Epoch: 81, Round: 81\n",
      "Evalset: [Train : Metrics { logloss:1.4349,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4469,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4182,  }]\n",
      "Training on Total Epoch: 82, Round: 82\n",
      "Evalset: [Train : Metrics { logloss:1.4208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4327,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4038,  }]\n",
      "Training on Total Epoch: 83, Round: 83\n",
      "Evalset: [Train : Metrics { logloss:1.4069,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4186,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3895,  }]\n",
      "Training on Total Epoch: 84, Round: 84\n",
      "Evalset: [Train : Metrics { logloss:1.3929,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4045,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3754,  }]\n",
      "Training on Total Epoch: 85, Round: 85\n",
      "Evalset: [Train : Metrics { logloss:1.3792,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3905,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3614,  }]\n",
      "Training on Total Epoch: 86, Round: 86\n",
      "Evalset: [Train : Metrics { logloss:1.3655,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3766,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3475,  }]\n",
      "Training on Total Epoch: 87, Round: 87\n",
      "Evalset: [Train : Metrics { logloss:1.352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3628,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3336,  }]\n",
      "Training on Total Epoch: 88, Round: 88\n",
      "Evalset: [Train : Metrics { logloss:1.3385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3493,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.32,  }]\n",
      "Training on Total Epoch: 89, Round: 89\n",
      "Evalset: [Train : Metrics { logloss:1.3252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3359,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3064,  }]\n",
      "Training on Total Epoch: 90, Round: 90\n",
      "Evalset: [Train : Metrics { logloss:1.312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3228,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.293,  }]\n",
      "Training on Total Epoch: 91, Round: 91\n",
      "Evalset: [Train : Metrics { logloss:1.299,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3097,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2798,  }]\n",
      "Training on Total Epoch: 92, Round: 92\n",
      "Evalset: [Train : Metrics { logloss:1.2861,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2967,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2668,  }]\n",
      "Training on Total Epoch: 93, Round: 93\n",
      "Evalset: [Train : Metrics { logloss:1.2734,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2838,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2539,  }]\n",
      "Training on Total Epoch: 94, Round: 94\n",
      "Evalset: [Train : Metrics { logloss:1.2607,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2712,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2411,  }]\n",
      "Training on Total Epoch: 95, Round: 95\n",
      "Evalset: [Train : Metrics { logloss:1.2482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2588,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2284,  }]\n",
      "Training on Total Epoch: 96, Round: 96\n",
      "Evalset: [Train : Metrics { logloss:1.2359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2463,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2158,  }]\n",
      "Training on Total Epoch: 97, Round: 97\n",
      "Evalset: [Train : Metrics { logloss:1.2236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.234,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2033,  }]\n",
      "Training on Total Epoch: 98, Round: 98\n",
      "Evalset: [Train : Metrics { logloss:1.2115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2217,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1909,  }]\n",
      "Training on Total Epoch: 99, Round: 99\n",
      "Evalset: [Train : Metrics { logloss:1.1995,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2097,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1787,  }]\n",
      "Training on Total Epoch: 100, Round: 100\n",
      "Evalset: [Train : Metrics { logloss:1.1877,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1977,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1667,  }]\n",
      "Training on Total Epoch: 101, Round: 101\n",
      "Evalset: [Train : Metrics { logloss:1.1759,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1859,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1547,  }]\n",
      "Training on Total Epoch: 102, Round: 102\n",
      "Evalset: [Train : Metrics { logloss:1.1644,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1744,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1429,  }]\n",
      "Training on Total Epoch: 103, Round: 103\n",
      "Evalset: [Train : Metrics { logloss:1.153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1632,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1312,  }]\n",
      "Training on Total Epoch: 104, Round: 104\n",
      "Evalset: [Train : Metrics { logloss:1.1416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1516,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1196,  }]\n",
      "Training on Total Epoch: 105, Round: 105\n",
      "Evalset: [Train : Metrics { logloss:1.1305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1403,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1082,  }]\n",
      "Training on Total Epoch: 106, Round: 106\n",
      "Evalset: [Train : Metrics { logloss:1.1195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.097,  }]\n",
      "Training on Total Epoch: 107, Round: 107\n",
      "Evalset: [Train : Metrics { logloss:1.1086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1181,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.086,  }]\n",
      "Training on Total Epoch: 108, Round: 108\n",
      "Evalset: [Train : Metrics { logloss:1.0978,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1073,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0752,  }]\n",
      "Training on Total Epoch: 109, Round: 109\n",
      "Evalset: [Train : Metrics { logloss:1.0872,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0966,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0643,  }]\n",
      "Training on Total Epoch: 110, Round: 110\n",
      "Evalset: [Train : Metrics { logloss:1.0767,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0862,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0537,  }]\n",
      "Training on Total Epoch: 111, Round: 111\n",
      "Evalset: [Train : Metrics { logloss:1.0664,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0756,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0432,  }]\n",
      "Training on Total Epoch: 112, Round: 112\n",
      "Evalset: [Train : Metrics { logloss:1.0561,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0653,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0329,  }]\n",
      "Training on Total Epoch: 113, Round: 113\n",
      "Evalset: [Train : Metrics { logloss:1.0461,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0548,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0225,  }]\n",
      "Training on Total Epoch: 114, Round: 114\n",
      "Evalset: [Train : Metrics { logloss:1.0361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0445,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0124,  }]\n",
      "Training on Total Epoch: 115, Round: 115\n",
      "Evalset: [Train : Metrics { logloss:1.0263,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0343,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0025,  }]\n",
      "Training on Total Epoch: 116, Round: 116\n",
      "Evalset: [Train : Metrics { logloss:1.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9925,  }]\n",
      "Training on Total Epoch: 117, Round: 117\n",
      "Evalset: [Train : Metrics { logloss:1.007,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0147,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9829,  }]\n",
      "Training on Total Epoch: 118, Round: 118\n",
      "Evalset: [Train : Metrics { logloss:0.9976,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0052,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9734,  }]\n",
      "Training on Total Epoch: 119, Round: 119\n",
      "Evalset: [Train : Metrics { logloss:0.9883,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.996,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9639,  }]\n",
      "Training on Total Epoch: 120, Round: 120\n",
      "Evalset: [Train : Metrics { logloss:0.9791,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9867,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9547,  }]\n",
      "Training on Total Epoch: 121, Round: 121\n",
      "Evalset: [Train : Metrics { logloss:0.97,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9777,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9457,  }]\n",
      "Training on Total Epoch: 122, Round: 122\n",
      "Evalset: [Train : Metrics { logloss:0.961,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.969,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9368,  }]\n",
      "Training on Total Epoch: 123, Round: 123\n",
      "Evalset: [Train : Metrics { logloss:0.9522,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9601,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9279,  }]\n",
      "Training on Total Epoch: 124, Round: 124\n",
      "Evalset: [Train : Metrics { logloss:0.9435,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9512,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9191,  }]\n",
      "Training on Total Epoch: 125, Round: 125\n",
      "Evalset: [Train : Metrics { logloss:0.9348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9423,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9103,  }]\n",
      "Training on Total Epoch: 126, Round: 126\n",
      "Evalset: [Train : Metrics { logloss:0.9264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9017,  }]\n",
      "Training on Total Epoch: 127, Round: 127\n",
      "Evalset: [Train : Metrics { logloss:0.918,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8933,  }]\n",
      "Training on Total Epoch: 128, Round: 128\n",
      "Evalset: [Train : Metrics { logloss:0.9097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9165,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.885,  }]\n",
      "Training on Total Epoch: 129, Round: 129\n",
      "Evalset: [Train : Metrics { logloss:0.9016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9083,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8767,  }]\n",
      "Training on Total Epoch: 130, Round: 130\n",
      "Evalset: [Train : Metrics { logloss:0.8936,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9004,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8686,  }]\n",
      "Training on Total Epoch: 131, Round: 131\n",
      "Evalset: [Train : Metrics { logloss:0.8857,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8923,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8605,  }]\n",
      "Training on Total Epoch: 132, Round: 132\n",
      "Evalset: [Train : Metrics { logloss:0.8779,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8844,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8527,  }]\n",
      "Training on Total Epoch: 133, Round: 133\n",
      "Evalset: [Train : Metrics { logloss:0.8701,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8764,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8448,  }]\n",
      "Training on Total Epoch: 134, Round: 134\n",
      "Evalset: [Train : Metrics { logloss:0.8625,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8687,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8372,  }]\n",
      "Training on Total Epoch: 135, Round: 135\n",
      "Evalset: [Train : Metrics { logloss:0.8549,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8609,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8296,  }]\n",
      "Training on Total Epoch: 136, Round: 136\n",
      "Evalset: [Train : Metrics { logloss:0.8475,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8535,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8222,  }]\n",
      "Training on Total Epoch: 137, Round: 137\n",
      "Evalset: [Train : Metrics { logloss:0.8402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8462,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8149,  }]\n",
      "Training on Total Epoch: 138, Round: 138\n",
      "Evalset: [Train : Metrics { logloss:0.8329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8389,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8078,  }]\n",
      "Training on Total Epoch: 139, Round: 139\n",
      "Evalset: [Train : Metrics { logloss:0.8258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8007,  }]\n",
      "Training on Total Epoch: 140, Round: 140\n",
      "Evalset: [Train : Metrics { logloss:0.8188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7936,  }]\n",
      "Training on Total Epoch: 141, Round: 141\n",
      "Evalset: [Train : Metrics { logloss:0.8118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7867,  }]\n",
      "Training on Total Epoch: 142, Round: 142\n",
      "Evalset: [Train : Metrics { logloss:0.8049,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8103,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7797,  }]\n",
      "Training on Total Epoch: 143, Round: 143\n",
      "Evalset: [Train : Metrics { logloss:0.7981,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8033,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7728,  }]\n",
      "Training on Total Epoch: 144, Round: 144\n",
      "Evalset: [Train : Metrics { logloss:0.7915,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7968,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7662,  }]\n",
      "Training on Total Epoch: 145, Round: 145\n",
      "Evalset: [Train : Metrics { logloss:0.7849,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7901,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7596,  }]\n",
      "Training on Total Epoch: 146, Round: 146\n",
      "Evalset: [Train : Metrics { logloss:0.7784,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7835,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.753,  }]\n",
      "Training on Total Epoch: 147, Round: 147\n",
      "Evalset: [Train : Metrics { logloss:0.772,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7771,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7465,  }]\n",
      "Training on Total Epoch: 148, Round: 148\n",
      "Evalset: [Train : Metrics { logloss:0.7656,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7706,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7401,  }]\n",
      "Training on Total Epoch: 149, Round: 149\n",
      "Evalset: [Train : Metrics { logloss:0.7593,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7642,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7338,  }]\n",
      "Training on Total Epoch: 150, Round: 150\n",
      "Evalset: [Train : Metrics { logloss:0.7531,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7577,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7276,  }]\n",
      "Training on Total Epoch: 151, Round: 151\n",
      "Evalset: [Train : Metrics { logloss:0.747,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7515,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7215,  }]\n",
      "Training on Total Epoch: 152, Round: 152\n",
      "Evalset: [Train : Metrics { logloss:0.741,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7453,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7154,  }]\n",
      "Training on Total Epoch: 153, Round: 153\n",
      "Evalset: [Train : Metrics { logloss:0.735,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7392,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7095,  }]\n",
      "Training on Total Epoch: 154, Round: 154\n",
      "Evalset: [Train : Metrics { logloss:0.7291,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7035,  }]\n",
      "Training on Total Epoch: 155, Round: 155\n",
      "Evalset: [Train : Metrics { logloss:0.7233,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6976,  }]\n",
      "Training on Total Epoch: 156, Round: 156\n",
      "Evalset: [Train : Metrics { logloss:0.7176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6918,  }]\n",
      "Training on Total Epoch: 157, Round: 157\n",
      "Evalset: [Train : Metrics { logloss:0.7119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7156,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6861,  }]\n",
      "Training on Total Epoch: 158, Round: 158\n",
      "Evalset: [Train : Metrics { logloss:0.7063,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7098,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6806,  }]\n",
      "Training on Total Epoch: 159, Round: 159\n",
      "Evalset: [Train : Metrics { logloss:0.7008,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.704,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6751,  }]\n",
      "Training on Total Epoch: 160, Round: 160\n",
      "Evalset: [Train : Metrics { logloss:0.6953,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6986,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6698,  }]\n",
      "Training on Total Epoch: 161, Round: 161\n",
      "Evalset: [Train : Metrics { logloss:0.6899,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6934,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6644,  }]\n",
      "Training on Total Epoch: 162, Round: 162\n",
      "Evalset: [Train : Metrics { logloss:0.6846,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.659,  }]\n",
      "Training on Total Epoch: 163, Round: 163\n",
      "Evalset: [Train : Metrics { logloss:0.6794,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6826,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6538,  }]\n",
      "Training on Total Epoch: 164, Round: 164\n",
      "Evalset: [Train : Metrics { logloss:0.6742,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6775,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6487,  }]\n",
      "Training on Total Epoch: 165, Round: 165\n",
      "Evalset: [Train : Metrics { logloss:0.6691,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6723,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6436,  }]\n",
      "Training on Total Epoch: 166, Round: 166\n",
      "Evalset: [Train : Metrics { logloss:0.664,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6671,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6385,  }]\n",
      "Training on Total Epoch: 167, Round: 167\n",
      "Evalset: [Train : Metrics { logloss:0.659,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6618,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6334,  }]\n",
      "Training on Total Epoch: 168, Round: 168\n",
      "Evalset: [Train : Metrics { logloss:0.6541,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6568,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6285,  }]\n",
      "Training on Total Epoch: 169, Round: 169\n",
      "Evalset: [Train : Metrics { logloss:0.6492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6522,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6236,  }]\n",
      "Training on Total Epoch: 170, Round: 170\n",
      "Evalset: [Train : Metrics { logloss:0.6444,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6474,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6189,  }]\n",
      "Training on Total Epoch: 171, Round: 171\n",
      "Evalset: [Train : Metrics { logloss:0.6396,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6426,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6143,  }]\n",
      "Training on Total Epoch: 172, Round: 172\n",
      "Evalset: [Train : Metrics { logloss:0.6349,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6097,  }]\n",
      "Training on Total Epoch: 173, Round: 173\n",
      "Evalset: [Train : Metrics { logloss:0.6303,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.605,  }]\n",
      "Training on Total Epoch: 174, Round: 174\n",
      "Evalset: [Train : Metrics { logloss:0.6257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6003,  }]\n",
      "Training on Total Epoch: 175, Round: 175\n",
      "Evalset: [Train : Metrics { logloss:0.6211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5956,  }]\n",
      "Training on Total Epoch: 176, Round: 176\n",
      "Evalset: [Train : Metrics { logloss:0.6166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5913,  }]\n",
      "Training on Total Epoch: 177, Round: 177\n",
      "Evalset: [Train : Metrics { logloss:0.6122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6147,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5869,  }]\n",
      "Training on Total Epoch: 178, Round: 178\n",
      "Evalset: [Train : Metrics { logloss:0.6079,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6102,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5826,  }]\n",
      "Training on Total Epoch: 179, Round: 179\n",
      "Evalset: [Train : Metrics { logloss:0.6036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.606,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5784,  }]\n",
      "Training on Total Epoch: 180, Round: 180\n",
      "Evalset: [Train : Metrics { logloss:0.5993,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6017,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5742,  }]\n",
      "Training on Total Epoch: 181, Round: 181\n",
      "Evalset: [Train : Metrics { logloss:0.5951,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5975,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.57,  }]\n",
      "Training on Total Epoch: 182, Round: 182\n",
      "Evalset: [Train : Metrics { logloss:0.5909,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5931,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5657,  }]\n",
      "Training on Total Epoch: 183, Round: 183\n",
      "Evalset: [Train : Metrics { logloss:0.5868,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5614,  }]\n",
      "Training on Total Epoch: 184, Round: 184\n",
      "Evalset: [Train : Metrics { logloss:0.5827,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5844,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5574,  }]\n",
      "Training on Total Epoch: 185, Round: 185\n",
      "Evalset: [Train : Metrics { logloss:0.5786,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5804,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5533,  }]\n",
      "Training on Total Epoch: 186, Round: 186\n",
      "Evalset: [Train : Metrics { logloss:0.5746,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5765,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5495,  }]\n",
      "Training on Total Epoch: 187, Round: 187\n",
      "Evalset: [Train : Metrics { logloss:0.5707,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5727,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5457,  }]\n",
      "Training on Total Epoch: 188, Round: 188\n",
      "Evalset: [Train : Metrics { logloss:0.5668,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.569,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5419,  }]\n",
      "Training on Total Epoch: 189, Round: 189\n",
      "Evalset: [Train : Metrics { logloss:0.5629,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5651,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.538,  }]\n",
      "Training on Total Epoch: 190, Round: 190\n",
      "Evalset: [Train : Metrics { logloss:0.5591,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5612,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5341,  }]\n",
      "Training on Total Epoch: 191, Round: 191\n",
      "Evalset: [Train : Metrics { logloss:0.5554,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5572,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5303,  }]\n",
      "Training on Total Epoch: 192, Round: 192\n",
      "Evalset: [Train : Metrics { logloss:0.5516,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5532,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5266,  }]\n",
      "Training on Total Epoch: 193, Round: 193\n",
      "Evalset: [Train : Metrics { logloss:0.5479,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5493,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5229,  }]\n",
      "Training on Total Epoch: 194, Round: 194\n",
      "Evalset: [Train : Metrics { logloss:0.5443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5457,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5194,  }]\n",
      "Training on Total Epoch: 195, Round: 195\n",
      "Evalset: [Train : Metrics { logloss:0.5407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.542,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5159,  }]\n",
      "Training on Total Epoch: 196, Round: 196\n",
      "Evalset: [Train : Metrics { logloss:0.5371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5386,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5125,  }]\n",
      "Training on Total Epoch: 197, Round: 197\n",
      "Evalset: [Train : Metrics { logloss:0.5336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.509,  }]\n",
      "Training on Total Epoch: 198, Round: 198\n",
      "Evalset: [Train : Metrics { logloss:0.5301,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5056,  }]\n",
      "Training on Total Epoch: 199, Round: 199\n",
      "Evalset: [Train : Metrics { logloss:0.5266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5022,  }]\n",
      "Training on Total Epoch: 200, Round: 200\n",
      "Evalset: [Train : Metrics { logloss:0.5232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4988,  }]\n",
      "Training on Total Epoch: 201, Round: 201\n",
      "Evalset: [Train : Metrics { logloss:0.5198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4955,  }]\n",
      "Training on Total Epoch: 202, Round: 202\n",
      "Evalset: [Train : Metrics { logloss:0.5165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5178,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4923,  }]\n",
      "Training on Total Epoch: 203, Round: 203\n",
      "Evalset: [Train : Metrics { logloss:0.5131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5145,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.489,  }]\n",
      "Training on Total Epoch: 204, Round: 204\n",
      "Evalset: [Train : Metrics { logloss:0.5098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.511,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4858,  }]\n",
      "Training on Total Epoch: 205, Round: 205\n",
      "Evalset: [Train : Metrics { logloss:0.5066,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5077,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4825,  }]\n",
      "Training on Total Epoch: 206, Round: 206\n",
      "Evalset: [Train : Metrics { logloss:0.5034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5047,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4793,  }]\n",
      "Training on Total Epoch: 207, Round: 207\n",
      "Evalset: [Train : Metrics { logloss:0.5002,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5016,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4761,  }]\n",
      "Training on Total Epoch: 208, Round: 208\n",
      "Evalset: [Train : Metrics { logloss:0.497,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4986,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4732,  }]\n",
      "Training on Total Epoch: 209, Round: 209\n",
      "Evalset: [Train : Metrics { logloss:0.494,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4957,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4702,  }]\n",
      "Training on Total Epoch: 210, Round: 210\n",
      "Evalset: [Train : Metrics { logloss:0.4909,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4926,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4672,  }]\n",
      "Training on Total Epoch: 211, Round: 211\n",
      "Evalset: [Train : Metrics { logloss:0.4878,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4643,  }]\n",
      "Training on Total Epoch: 212, Round: 212\n",
      "Evalset: [Train : Metrics { logloss:0.4848,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4865,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4613,  }]\n",
      "Training on Total Epoch: 213, Round: 213\n",
      "Evalset: [Train : Metrics { logloss:0.4818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4834,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4584,  }]\n",
      "Training on Total Epoch: 214, Round: 214\n",
      "Evalset: [Train : Metrics { logloss:0.4789,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4803,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4555,  }]\n",
      "Training on Total Epoch: 215, Round: 215\n",
      "Evalset: [Train : Metrics { logloss:0.4759,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4773,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4526,  }]\n",
      "Training on Total Epoch: 216, Round: 216\n",
      "Evalset: [Train : Metrics { logloss:0.4731,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4744,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4497,  }]\n",
      "Training on Total Epoch: 217, Round: 217\n",
      "Evalset: [Train : Metrics { logloss:0.4702,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4468,  }]\n",
      "Training on Total Epoch: 218, Round: 218\n",
      "Evalset: [Train : Metrics { logloss:0.4674,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4685,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.444,  }]\n",
      "Training on Total Epoch: 219, Round: 219\n",
      "Evalset: [Train : Metrics { logloss:0.4645,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4659,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4412,  }]\n",
      "Training on Total Epoch: 220, Round: 220\n",
      "Evalset: [Train : Metrics { logloss:0.4617,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4631,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4384,  }]\n",
      "Training on Total Epoch: 221, Round: 221\n",
      "Evalset: [Train : Metrics { logloss:0.459,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4604,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4357,  }]\n",
      "Training on Total Epoch: 222, Round: 222\n",
      "Evalset: [Train : Metrics { logloss:0.4562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.458,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4332,  }]\n",
      "Training on Total Epoch: 223, Round: 223\n",
      "Evalset: [Train : Metrics { logloss:0.4535,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4553,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4306,  }]\n",
      "Training on Total Epoch: 224, Round: 224\n",
      "Evalset: [Train : Metrics { logloss:0.4508,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4526,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4279,  }]\n",
      "Training on Total Epoch: 225, Round: 225\n",
      "Evalset: [Train : Metrics { logloss:0.4482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4499,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4253,  }]\n",
      "Training on Total Epoch: 226, Round: 226\n",
      "Evalset: [Train : Metrics { logloss:0.4456,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4473,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4227,  }]\n",
      "Training on Total Epoch: 227, Round: 227\n",
      "Evalset: [Train : Metrics { logloss:0.443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4448,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4202,  }]\n",
      "Training on Total Epoch: 228, Round: 228\n",
      "Evalset: [Train : Metrics { logloss:0.4404,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4422,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4177,  }]\n",
      "Training on Total Epoch: 229, Round: 229\n",
      "Evalset: [Train : Metrics { logloss:0.4378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4396,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4152,  }]\n",
      "Training on Total Epoch: 230, Round: 230\n",
      "Evalset: [Train : Metrics { logloss:0.4353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4372,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4127,  }]\n",
      "Training on Total Epoch: 231, Round: 231\n",
      "Evalset: [Train : Metrics { logloss:0.4328,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4103,  }]\n",
      "Training on Total Epoch: 232, Round: 232\n",
      "Evalset: [Train : Metrics { logloss:0.4304,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4079,  }]\n",
      "Training on Total Epoch: 233, Round: 233\n",
      "Evalset: [Train : Metrics { logloss:0.4279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.43,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4055,  }]\n",
      "Training on Total Epoch: 234, Round: 234\n",
      "Evalset: [Train : Metrics { logloss:0.4255,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4032,  }]\n",
      "Training on Total Epoch: 235, Round: 235\n",
      "Evalset: [Train : Metrics { logloss:0.4231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4009,  }]\n",
      "Training on Total Epoch: 236, Round: 236\n",
      "Evalset: [Train : Metrics { logloss:0.4207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3985,  }]\n",
      "Training on Total Epoch: 237, Round: 237\n",
      "Evalset: [Train : Metrics { logloss:0.4184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4205,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3962,  }]\n",
      "Training on Total Epoch: 238, Round: 238\n",
      "Evalset: [Train : Metrics { logloss:0.416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4182,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.394,  }]\n",
      "Training on Total Epoch: 239, Round: 239\n",
      "Evalset: [Train : Metrics { logloss:0.4137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4159,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3917,  }]\n",
      "Training on Total Epoch: 240, Round: 240\n",
      "Evalset: [Train : Metrics { logloss:0.4114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4137,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3895,  }]\n",
      "Training on Total Epoch: 241, Round: 241\n",
      "Evalset: [Train : Metrics { logloss:0.4092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4114,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3873,  }]\n",
      "Training on Total Epoch: 242, Round: 242\n",
      "Evalset: [Train : Metrics { logloss:0.4069,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3852,  }]\n",
      "Training on Total Epoch: 243, Round: 243\n",
      "Evalset: [Train : Metrics { logloss:0.4047,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4072,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3831,  }]\n",
      "Training on Total Epoch: 244, Round: 244\n",
      "Evalset: [Train : Metrics { logloss:0.4025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4052,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.381,  }]\n",
      "Training on Total Epoch: 245, Round: 245\n",
      "Evalset: [Train : Metrics { logloss:0.4003,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4029,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3789,  }]\n",
      "Training on Total Epoch: 246, Round: 246\n",
      "Evalset: [Train : Metrics { logloss:0.3981,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4007,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3768,  }]\n",
      "Training on Total Epoch: 247, Round: 247\n",
      "Evalset: [Train : Metrics { logloss:0.396,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3986,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3748,  }]\n",
      "Training on Total Epoch: 248, Round: 248\n",
      "Evalset: [Train : Metrics { logloss:0.3939,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3968,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3729,  }]\n",
      "Training on Total Epoch: 249, Round: 249\n",
      "Evalset: [Train : Metrics { logloss:0.3918,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3949,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3708,  }]\n",
      "Training on Total Epoch: 250, Round: 250\n",
      "Evalset: [Train : Metrics { logloss:0.3897,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.393,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3689,  }]\n",
      "Training on Total Epoch: 251, Round: 251\n",
      "Evalset: [Train : Metrics { logloss:0.3877,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.391,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3668,  }]\n",
      "Training on Total Epoch: 252, Round: 252\n",
      "Evalset: [Train : Metrics { logloss:0.3856,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.389,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3648,  }]\n",
      "Training on Total Epoch: 253, Round: 253\n",
      "Evalset: [Train : Metrics { logloss:0.3836,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.387,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3628,  }]\n",
      "Training on Total Epoch: 254, Round: 254\n",
      "Evalset: [Train : Metrics { logloss:0.3816,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3849,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3608,  }]\n",
      "Training on Total Epoch: 255, Round: 255\n",
      "Evalset: [Train : Metrics { logloss:0.3796,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3828,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3588,  }]\n",
      "Training on Total Epoch: 256, Round: 256\n",
      "Evalset: [Train : Metrics { logloss:0.3776,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3808,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3569,  }]\n",
      "Training on Total Epoch: 257, Round: 257\n",
      "Evalset: [Train : Metrics { logloss:0.3757,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3788,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.355,  }]\n",
      "Training on Total Epoch: 258, Round: 258\n",
      "Evalset: [Train : Metrics { logloss:0.3737,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3771,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3532,  }]\n",
      "Training on Total Epoch: 259, Round: 259\n",
      "Evalset: [Train : Metrics { logloss:0.3718,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3751,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3514,  }]\n",
      "Training on Total Epoch: 260, Round: 260\n",
      "Evalset: [Train : Metrics { logloss:0.3699,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3732,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3496,  }]\n",
      "Training on Total Epoch: 261, Round: 261\n",
      "Evalset: [Train : Metrics { logloss:0.368,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3713,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3478,  }]\n",
      "Training on Total Epoch: 262, Round: 262\n",
      "Evalset: [Train : Metrics { logloss:0.3661,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3696,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.346,  }]\n",
      "Training on Total Epoch: 263, Round: 263\n",
      "Evalset: [Train : Metrics { logloss:0.3643,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3678,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3441,  }]\n",
      "Training on Total Epoch: 264, Round: 264\n",
      "Evalset: [Train : Metrics { logloss:0.3625,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.366,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3423,  }]\n",
      "Training on Total Epoch: 265, Round: 265\n",
      "Evalset: [Train : Metrics { logloss:0.3607,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3642,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3406,  }]\n",
      "Training on Total Epoch: 266, Round: 266\n",
      "Evalset: [Train : Metrics { logloss:0.3589,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3626,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3389,  }]\n",
      "Training on Total Epoch: 267, Round: 267\n",
      "Evalset: [Train : Metrics { logloss:0.3571,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3611,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3372,  }]\n",
      "Training on Total Epoch: 268, Round: 268\n",
      "Evalset: [Train : Metrics { logloss:0.3553,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3596,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3355,  }]\n",
      "Training on Total Epoch: 269, Round: 269\n",
      "Evalset: [Train : Metrics { logloss:0.3536,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3578,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3338,  }]\n",
      "Training on Total Epoch: 270, Round: 270\n",
      "Evalset: [Train : Metrics { logloss:0.3518,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3561,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3321,  }]\n",
      "Training on Total Epoch: 271, Round: 271\n",
      "Evalset: [Train : Metrics { logloss:0.3501,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3543,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3304,  }]\n",
      "Training on Total Epoch: 272, Round: 272\n",
      "Evalset: [Train : Metrics { logloss:0.3484,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3526,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3288,  }]\n",
      "Training on Total Epoch: 273, Round: 273\n",
      "Evalset: [Train : Metrics { logloss:0.3467,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3272,  }]\n",
      "Training on Total Epoch: 274, Round: 274\n",
      "Evalset: [Train : Metrics { logloss:0.3451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3496,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3256,  }]\n",
      "Training on Total Epoch: 275, Round: 275\n",
      "Evalset: [Train : Metrics { logloss:0.3434,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.324,  }]\n",
      "Training on Total Epoch: 276, Round: 276\n",
      "Evalset: [Train : Metrics { logloss:0.3418,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3469,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3226,  }]\n",
      "Training on Total Epoch: 277, Round: 277\n",
      "Evalset: [Train : Metrics { logloss:0.3401,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3211,  }]\n",
      "Training on Total Epoch: 278, Round: 278\n",
      "Evalset: [Train : Metrics { logloss:0.3385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3195,  }]\n",
      "Training on Total Epoch: 279, Round: 279\n",
      "Evalset: [Train : Metrics { logloss:0.3369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3422,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3178,  }]\n",
      "Training on Total Epoch: 280, Round: 280\n",
      "Evalset: [Train : Metrics { logloss:0.3353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3404,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3162,  }]\n",
      "Training on Total Epoch: 281, Round: 281\n",
      "Evalset: [Train : Metrics { logloss:0.3338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3388,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3147,  }]\n",
      "Training on Total Epoch: 282, Round: 282\n",
      "Evalset: [Train : Metrics { logloss:0.3322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3372,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3132,  }]\n",
      "Training on Total Epoch: 283, Round: 283\n",
      "Evalset: [Train : Metrics { logloss:0.3307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3117,  }]\n",
      "Training on Total Epoch: 284, Round: 284\n",
      "Evalset: [Train : Metrics { logloss:0.3291,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3342,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3103,  }]\n",
      "Training on Total Epoch: 285, Round: 285\n",
      "Evalset: [Train : Metrics { logloss:0.3276,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.309,  }]\n",
      "Training on Total Epoch: 286, Round: 286\n",
      "Evalset: [Train : Metrics { logloss:0.3261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3316,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3076,  }]\n",
      "Training on Total Epoch: 287, Round: 287\n",
      "Evalset: [Train : Metrics { logloss:0.3246,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3062,  }]\n",
      "Training on Total Epoch: 288, Round: 288\n",
      "Evalset: [Train : Metrics { logloss:0.3231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3048,  }]\n",
      "Training on Total Epoch: 289, Round: 289\n",
      "Evalset: [Train : Metrics { logloss:0.3217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3034,  }]\n",
      "Training on Total Epoch: 290, Round: 290\n",
      "Evalset: [Train : Metrics { logloss:0.3202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3266,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3021,  }]\n",
      "Training on Total Epoch: 291, Round: 291\n",
      "Evalset: [Train : Metrics { logloss:0.3188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3007,  }]\n",
      "Training on Total Epoch: 292, Round: 292\n",
      "Evalset: [Train : Metrics { logloss:0.3173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2993,  }]\n",
      "Training on Total Epoch: 293, Round: 293\n",
      "Evalset: [Train : Metrics { logloss:0.3159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.298,  }]\n",
      "Training on Total Epoch: 294, Round: 294\n",
      "Evalset: [Train : Metrics { logloss:0.3145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2966,  }]\n",
      "Training on Total Epoch: 295, Round: 295\n",
      "Evalset: [Train : Metrics { logloss:0.3132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2953,  }]\n",
      "Training on Total Epoch: 296, Round: 296\n",
      "Evalset: [Train : Metrics { logloss:0.3118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2939,  }]\n",
      "Training on Total Epoch: 297, Round: 297\n",
      "Evalset: [Train : Metrics { logloss:0.3104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2927,  }]\n",
      "Training on Total Epoch: 298, Round: 298\n",
      "Evalset: [Train : Metrics { logloss:0.309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3156,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2914,  }]\n",
      "Training on Total Epoch: 299, Round: 299\n",
      "Evalset: [Train : Metrics { logloss:0.3077,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3142,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2901,  }]\n",
      "Training on Total Epoch: 300, Round: 300\n",
      "Evalset: [Train : Metrics { logloss:0.3064,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2888,  }]\n",
      "Training on Total Epoch: 301, Round: 301\n",
      "Evalset: [Train : Metrics { logloss:0.305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3115,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2875,  }]\n",
      "Training on Total Epoch: 302, Round: 302\n",
      "Evalset: [Train : Metrics { logloss:0.3037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3101,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2863,  }]\n",
      "Training on Total Epoch: 303, Round: 303\n",
      "Evalset: [Train : Metrics { logloss:0.3024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3091,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.285,  }]\n",
      "Training on Total Epoch: 304, Round: 304\n",
      "Evalset: [Train : Metrics { logloss:0.3011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3079,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2838,  }]\n",
      "Training on Total Epoch: 305, Round: 305\n",
      "Evalset: [Train : Metrics { logloss:0.2999,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3068,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2827,  }]\n",
      "Training on Total Epoch: 306, Round: 306\n",
      "Evalset: [Train : Metrics { logloss:0.2986,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3056,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2816,  }]\n",
      "Training on Total Epoch: 307, Round: 307\n",
      "Evalset: [Train : Metrics { logloss:0.2973,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3045,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2805,  }]\n",
      "Training on Total Epoch: 308, Round: 308\n",
      "Evalset: [Train : Metrics { logloss:0.2961,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3036,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2794,  }]\n",
      "Training on Total Epoch: 309, Round: 309\n",
      "Evalset: [Train : Metrics { logloss:0.2948,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3025,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2782,  }]\n",
      "Training on Total Epoch: 310, Round: 310\n",
      "Evalset: [Train : Metrics { logloss:0.2936,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3013,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.277,  }]\n",
      "Training on Total Epoch: 311, Round: 311\n",
      "Evalset: [Train : Metrics { logloss:0.2924,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3003,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2758,  }]\n",
      "Training on Total Epoch: 312, Round: 312\n",
      "Evalset: [Train : Metrics { logloss:0.2912,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2991,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2747,  }]\n",
      "Training on Total Epoch: 313, Round: 313\n",
      "Evalset: [Train : Metrics { logloss:0.29,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2982,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2736,  }]\n",
      "Training on Total Epoch: 314, Round: 314\n",
      "Evalset: [Train : Metrics { logloss:0.2888,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2724,  }]\n",
      "Training on Total Epoch: 315, Round: 315\n",
      "Evalset: [Train : Metrics { logloss:0.2876,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2958,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2712,  }]\n",
      "Training on Total Epoch: 316, Round: 316\n",
      "Evalset: [Train : Metrics { logloss:0.2864,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2946,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2701,  }]\n",
      "Training on Total Epoch: 317, Round: 317\n",
      "Evalset: [Train : Metrics { logloss:0.2853,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2936,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.269,  }]\n",
      "Training on Total Epoch: 318, Round: 318\n",
      "Evalset: [Train : Metrics { logloss:0.2841,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2926,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.268,  }]\n",
      "Training on Total Epoch: 319, Round: 319\n",
      "Evalset: [Train : Metrics { logloss:0.283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.267,  }]\n",
      "Training on Total Epoch: 320, Round: 320\n",
      "Evalset: [Train : Metrics { logloss:0.2818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.266,  }]\n",
      "Training on Total Epoch: 321, Round: 321\n",
      "Evalset: [Train : Metrics { logloss:0.2807,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2649,  }]\n",
      "Training on Total Epoch: 322, Round: 322\n",
      "Evalset: [Train : Metrics { logloss:0.2796,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2638,  }]\n",
      "Training on Total Epoch: 323, Round: 323\n",
      "Evalset: [Train : Metrics { logloss:0.2785,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2873,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2627,  }]\n",
      "Training on Total Epoch: 324, Round: 324\n",
      "Evalset: [Train : Metrics { logloss:0.2774,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2864,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2617,  }]\n",
      "Training on Total Epoch: 325, Round: 325\n",
      "Evalset: [Train : Metrics { logloss:0.2763,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2854,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2607,  }]\n",
      "Training on Total Epoch: 326, Round: 326\n",
      "Evalset: [Train : Metrics { logloss:0.2752,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2844,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2597,  }]\n",
      "Training on Total Epoch: 327, Round: 327\n",
      "Evalset: [Train : Metrics { logloss:0.2741,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2834,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2586,  }]\n",
      "Training on Total Epoch: 328, Round: 328\n",
      "Evalset: [Train : Metrics { logloss:0.2731,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2822,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2575,  }]\n",
      "Training on Total Epoch: 329, Round: 329\n",
      "Evalset: [Train : Metrics { logloss:0.272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2812,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2565,  }]\n",
      "Training on Total Epoch: 330, Round: 330\n",
      "Evalset: [Train : Metrics { logloss:0.271,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2803,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2555,  }]\n",
      "Training on Total Epoch: 331, Round: 331\n",
      "Evalset: [Train : Metrics { logloss:0.2699,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2794,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2546,  }]\n",
      "Training on Total Epoch: 332, Round: 332\n",
      "Evalset: [Train : Metrics { logloss:0.2689,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2785,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2537,  }]\n",
      "Training on Total Epoch: 333, Round: 333\n",
      "Evalset: [Train : Metrics { logloss:0.2679,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2775,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2527,  }]\n",
      "Training on Total Epoch: 334, Round: 334\n",
      "Evalset: [Train : Metrics { logloss:0.2668,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2764,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2517,  }]\n",
      "Training on Total Epoch: 335, Round: 335\n",
      "Evalset: [Train : Metrics { logloss:0.2658,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2754,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2508,  }]\n",
      "Training on Total Epoch: 336, Round: 336\n",
      "Evalset: [Train : Metrics { logloss:0.2648,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2745,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2498,  }]\n",
      "Training on Total Epoch: 337, Round: 337\n",
      "Evalset: [Train : Metrics { logloss:0.2638,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2737,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2489,  }]\n",
      "Training on Total Epoch: 338, Round: 338\n",
      "Evalset: [Train : Metrics { logloss:0.2628,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2729,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.248,  }]\n",
      "Training on Total Epoch: 339, Round: 339\n",
      "Evalset: [Train : Metrics { logloss:0.2619,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2722,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2472,  }]\n",
      "Training on Total Epoch: 340, Round: 340\n",
      "Evalset: [Train : Metrics { logloss:0.2609,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2712,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2463,  }]\n",
      "Training on Total Epoch: 341, Round: 341\n",
      "Evalset: [Train : Metrics { logloss:0.2599,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2704,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2454,  }]\n",
      "Training on Total Epoch: 342, Round: 342\n",
      "Evalset: [Train : Metrics { logloss:0.259,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2698,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2446,  }]\n",
      "Training on Total Epoch: 343, Round: 343\n",
      "Evalset: [Train : Metrics { logloss:0.258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2438,  }]\n",
      "Training on Total Epoch: 344, Round: 344\n",
      "Evalset: [Train : Metrics { logloss:0.257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2681,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2429,  }]\n",
      "Training on Total Epoch: 345, Round: 345\n",
      "Evalset: [Train : Metrics { logloss:0.2561,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2671,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.242,  }]\n",
      "Training on Total Epoch: 346, Round: 346\n",
      "Evalset: [Train : Metrics { logloss:0.2552,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2661,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2411,  }]\n",
      "Training on Total Epoch: 347, Round: 347\n",
      "Evalset: [Train : Metrics { logloss:0.2542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2653,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2403,  }]\n",
      "Training on Total Epoch: 348, Round: 348\n",
      "Evalset: [Train : Metrics { logloss:0.2533,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2647,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2395,  }]\n",
      "Training on Total Epoch: 349, Round: 349\n",
      "Evalset: [Train : Metrics { logloss:0.2524,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2642,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2388,  }]\n",
      "Training on Total Epoch: 350, Round: 350\n",
      "Evalset: [Train : Metrics { logloss:0.2515,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2635,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.238,  }]\n",
      "Training on Total Epoch: 351, Round: 351\n",
      "Evalset: [Train : Metrics { logloss:0.2506,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2624,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2371,  }]\n",
      "Training on Total Epoch: 352, Round: 352\n",
      "Evalset: [Train : Metrics { logloss:0.2497,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2613,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2362,  }]\n",
      "Training on Total Epoch: 353, Round: 353\n",
      "Evalset: [Train : Metrics { logloss:0.2488,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2604,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2353,  }]\n",
      "Training on Total Epoch: 354, Round: 354\n",
      "Evalset: [Train : Metrics { logloss:0.248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2596,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2345,  }]\n",
      "Training on Total Epoch: 355, Round: 355\n",
      "Evalset: [Train : Metrics { logloss:0.2471,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2588,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2337,  }]\n",
      "Training on Total Epoch: 356, Round: 356\n",
      "Evalset: [Train : Metrics { logloss:0.2462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2581,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.233,  }]\n",
      "Training on Total Epoch: 357, Round: 357\n",
      "Evalset: [Train : Metrics { logloss:0.2454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2576,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2322,  }]\n",
      "Training on Total Epoch: 358, Round: 358\n",
      "Evalset: [Train : Metrics { logloss:0.2445,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2567,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2314,  }]\n",
      "Training on Total Epoch: 359, Round: 359\n",
      "Evalset: [Train : Metrics { logloss:0.2437,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2558,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2307,  }]\n",
      "Training on Total Epoch: 360, Round: 360\n",
      "Evalset: [Train : Metrics { logloss:0.2429,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2548,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2298,  }]\n",
      "Training on Total Epoch: 361, Round: 361\n",
      "Evalset: [Train : Metrics { logloss:0.242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.229,  }]\n",
      "Training on Total Epoch: 362, Round: 362\n",
      "Evalset: [Train : Metrics { logloss:0.2412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2533,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2281,  }]\n",
      "Training on Total Epoch: 363, Round: 363\n",
      "Evalset: [Train : Metrics { logloss:0.2404,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2529,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2275,  }]\n",
      "Training on Total Epoch: 364, Round: 364\n",
      "Evalset: [Train : Metrics { logloss:0.2395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2523,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2268,  }]\n",
      "Training on Total Epoch: 365, Round: 365\n",
      "Evalset: [Train : Metrics { logloss:0.2387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2515,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2261,  }]\n",
      "Training on Total Epoch: 366, Round: 366\n",
      "Evalset: [Train : Metrics { logloss:0.2379,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2509,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2253,  }]\n",
      "Training on Total Epoch: 367, Round: 367\n",
      "Evalset: [Train : Metrics { logloss:0.2371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2502,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2246,  }]\n",
      "Training on Total Epoch: 368, Round: 368\n",
      "Evalset: [Train : Metrics { logloss:0.2363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2495,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2238,  }]\n",
      "Training on Total Epoch: 369, Round: 369\n",
      "Evalset: [Train : Metrics { logloss:0.2355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2489,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2231,  }]\n",
      "Training on Total Epoch: 370, Round: 370\n",
      "Evalset: [Train : Metrics { logloss:0.2348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2482,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2224,  }]\n",
      "Training on Total Epoch: 371, Round: 371\n",
      "Evalset: [Train : Metrics { logloss:0.234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2475,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2217,  }]\n",
      "Training on Total Epoch: 372, Round: 372\n",
      "Evalset: [Train : Metrics { logloss:0.2332,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2468,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.221,  }]\n",
      "Training on Total Epoch: 373, Round: 373\n",
      "Evalset: [Train : Metrics { logloss:0.2324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2461,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2204,  }]\n",
      "Training on Total Epoch: 374, Round: 374\n",
      "Evalset: [Train : Metrics { logloss:0.2317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2197,  }]\n",
      "Training on Total Epoch: 375, Round: 375\n",
      "Evalset: [Train : Metrics { logloss:0.2309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2447,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.219,  }]\n",
      "Training on Total Epoch: 376, Round: 376\n",
      "Evalset: [Train : Metrics { logloss:0.2301,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2183,  }]\n",
      "Training on Total Epoch: 377, Round: 377\n",
      "Evalset: [Train : Metrics { logloss:0.2294,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2176,  }]\n",
      "Training on Total Epoch: 378, Round: 378\n",
      "Evalset: [Train : Metrics { logloss:0.2286,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2428,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.217,  }]\n",
      "Training on Total Epoch: 379, Round: 379\n",
      "Evalset: [Train : Metrics { logloss:0.2279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2422,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2163,  }]\n",
      "Training on Total Epoch: 380, Round: 380\n",
      "Evalset: [Train : Metrics { logloss:0.2272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2156,  }]\n",
      "Training on Total Epoch: 381, Round: 381\n",
      "Evalset: [Train : Metrics { logloss:0.2264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2149,  }]\n",
      "Training on Total Epoch: 382, Round: 382\n",
      "Evalset: [Train : Metrics { logloss:0.2257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2406,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2144,  }]\n",
      "Training on Total Epoch: 383, Round: 383\n",
      "Evalset: [Train : Metrics { logloss:0.225,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.24,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2137,  }]\n",
      "Training on Total Epoch: 384, Round: 384\n",
      "Evalset: [Train : Metrics { logloss:0.2243,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2394,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.213,  }]\n",
      "Training on Total Epoch: 385, Round: 385\n",
      "Evalset: [Train : Metrics { logloss:0.2236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2385,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2123,  }]\n",
      "Training on Total Epoch: 386, Round: 386\n",
      "Evalset: [Train : Metrics { logloss:0.2229,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2378,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2117,  }]\n",
      "Training on Total Epoch: 387, Round: 387\n",
      "Evalset: [Train : Metrics { logloss:0.2222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.211,  }]\n",
      "Training on Total Epoch: 388, Round: 388\n",
      "Evalset: [Train : Metrics { logloss:0.2215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2104,  }]\n",
      "Training on Total Epoch: 389, Round: 389\n",
      "Evalset: [Train : Metrics { logloss:0.2208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2098,  }]\n",
      "Training on Total Epoch: 390, Round: 390\n",
      "Evalset: [Train : Metrics { logloss:0.2201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2092,  }]\n",
      "Training on Total Epoch: 391, Round: 391\n",
      "Evalset: [Train : Metrics { logloss:0.2194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2087,  }]\n",
      "Training on Total Epoch: 392, Round: 392\n",
      "Evalset: [Train : Metrics { logloss:0.2187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2343,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.208,  }]\n",
      "Training on Total Epoch: 393, Round: 393\n",
      "Evalset: [Train : Metrics { logloss:0.2181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2075,  }]\n",
      "Training on Total Epoch: 394, Round: 394\n",
      "Evalset: [Train : Metrics { logloss:0.2174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2068,  }]\n",
      "Training on Total Epoch: 395, Round: 395\n",
      "Evalset: [Train : Metrics { logloss:0.2167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2062,  }]\n",
      "Training on Total Epoch: 396, Round: 396\n",
      "Evalset: [Train : Metrics { logloss:0.2161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2057,  }]\n",
      "Training on Total Epoch: 397, Round: 397\n",
      "Evalset: [Train : Metrics { logloss:0.2154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2051,  }]\n",
      "Training on Total Epoch: 398, Round: 398\n",
      "Evalset: [Train : Metrics { logloss:0.2148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2046,  }]\n",
      "Training on Total Epoch: 399, Round: 399\n",
      "Evalset: [Train : Metrics { logloss:0.2141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2039,  }]\n",
      "Training on Total Epoch: 400, Round: 400\n",
      "Evalset: [Train : Metrics { logloss:0.2135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2033,  }]\n",
      "Training on Total Epoch: 401, Round: 401\n",
      "Evalset: [Train : Metrics { logloss:0.2128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2028,  }]\n",
      "Training on Total Epoch: 402, Round: 402\n",
      "Evalset: [Train : Metrics { logloss:0.2122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2022,  }]\n",
      "Training on Total Epoch: 403, Round: 403\n",
      "Evalset: [Train : Metrics { logloss:0.2115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2017,  }]\n",
      "Training on Total Epoch: 404, Round: 404\n",
      "Evalset: [Train : Metrics { logloss:0.2109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2012,  }]\n",
      "Training on Total Epoch: 405, Round: 405\n",
      "Evalset: [Train : Metrics { logloss:0.2103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2005,  }]\n",
      "Training on Total Epoch: 406, Round: 406\n",
      "Evalset: [Train : Metrics { logloss:0.2097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1999,  }]\n",
      "Training on Total Epoch: 407, Round: 407\n",
      "Evalset: [Train : Metrics { logloss:0.209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1994,  }]\n",
      "Training on Total Epoch: 408, Round: 408\n",
      "Evalset: [Train : Metrics { logloss:0.2084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1989,  }]\n",
      "Training on Total Epoch: 409, Round: 409\n",
      "Evalset: [Train : Metrics { logloss:0.2078,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1982,  }]\n",
      "Training on Total Epoch: 410, Round: 410\n",
      "Evalset: [Train : Metrics { logloss:0.2072,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1976,  }]\n",
      "Training on Total Epoch: 411, Round: 411\n",
      "Evalset: [Train : Metrics { logloss:0.2066,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1971,  }]\n",
      "Training on Total Epoch: 412, Round: 412\n",
      "Evalset: [Train : Metrics { logloss:0.206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1967,  }]\n",
      "Training on Total Epoch: 413, Round: 413\n",
      "Evalset: [Train : Metrics { logloss:0.2054,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1962,  }]\n",
      "Training on Total Epoch: 414, Round: 414\n",
      "Evalset: [Train : Metrics { logloss:0.2048,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1957,  }]\n",
      "Training on Total Epoch: 415, Round: 415\n",
      "Evalset: [Train : Metrics { logloss:0.2042,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1952,  }]\n",
      "Training on Total Epoch: 416, Round: 416\n",
      "Evalset: [Train : Metrics { logloss:0.2037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1946,  }]\n",
      "Training on Total Epoch: 417, Round: 417\n",
      "Evalset: [Train : Metrics { logloss:0.2031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1941,  }]\n",
      "Training on Total Epoch: 418, Round: 418\n",
      "Evalset: [Train : Metrics { logloss:0.2025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2205,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1936,  }]\n",
      "Training on Total Epoch: 419, Round: 419\n",
      "Evalset: [Train : Metrics { logloss:0.2019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1931,  }]\n",
      "Training on Total Epoch: 420, Round: 420\n",
      "Evalset: [Train : Metrics { logloss:0.2014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2198,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1927,  }]\n",
      "Training on Total Epoch: 421, Round: 421\n",
      "Evalset: [Train : Metrics { logloss:0.2008,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1923,  }]\n",
      "Training on Total Epoch: 422, Round: 422\n",
      "Evalset: [Train : Metrics { logloss:0.2002,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2189,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1917,  }]\n",
      "Training on Total Epoch: 423, Round: 423\n",
      "Evalset: [Train : Metrics { logloss:0.1996,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2182,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1912,  }]\n",
      "Training on Total Epoch: 424, Round: 424\n",
      "Evalset: [Train : Metrics { logloss:0.1991,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1906,  }]\n",
      "Training on Total Epoch: 425, Round: 425\n",
      "Evalset: [Train : Metrics { logloss:0.1985,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1901,  }]\n",
      "Training on Total Epoch: 426, Round: 426\n",
      "Evalset: [Train : Metrics { logloss:0.198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1896,  }]\n",
      "Training on Total Epoch: 427, Round: 427\n",
      "Evalset: [Train : Metrics { logloss:0.1974,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1891,  }]\n",
      "Training on Total Epoch: 428, Round: 428\n",
      "Evalset: [Train : Metrics { logloss:0.1969,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2157,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1887,  }]\n",
      "Training on Total Epoch: 429, Round: 429\n",
      "Evalset: [Train : Metrics { logloss:0.1963,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2152,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1882,  }]\n",
      "Training on Total Epoch: 430, Round: 430\n",
      "Evalset: [Train : Metrics { logloss:0.1958,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1877,  }]\n",
      "Training on Total Epoch: 431, Round: 431\n",
      "Evalset: [Train : Metrics { logloss:0.1953,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2144,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1873,  }]\n",
      "Training on Total Epoch: 432, Round: 432\n",
      "Evalset: [Train : Metrics { logloss:0.1947,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2141,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1869,  }]\n",
      "Training on Total Epoch: 433, Round: 433\n",
      "Evalset: [Train : Metrics { logloss:0.1942,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2137,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1865,  }]\n",
      "Training on Total Epoch: 434, Round: 434\n",
      "Evalset: [Train : Metrics { logloss:0.1937,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.186,  }]\n",
      "Training on Total Epoch: 435, Round: 435\n",
      "Evalset: [Train : Metrics { logloss:0.1931,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1855,  }]\n",
      "Training on Total Epoch: 436, Round: 436\n",
      "Evalset: [Train : Metrics { logloss:0.1926,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1851,  }]\n",
      "Training on Total Epoch: 437, Round: 437\n",
      "Evalset: [Train : Metrics { logloss:0.1921,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2119,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1846,  }]\n",
      "Training on Total Epoch: 438, Round: 438\n",
      "Evalset: [Train : Metrics { logloss:0.1916,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2116,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1841,  }]\n",
      "Training on Total Epoch: 439, Round: 439\n",
      "Evalset: [Train : Metrics { logloss:0.1911,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1836,  }]\n",
      "Training on Total Epoch: 440, Round: 440\n",
      "Evalset: [Train : Metrics { logloss:0.1906,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2107,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1832,  }]\n",
      "Training on Total Epoch: 441, Round: 441\n",
      "Evalset: [Train : Metrics { logloss:0.1901,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2104,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1828,  }]\n",
      "Training on Total Epoch: 442, Round: 442\n",
      "Evalset: [Train : Metrics { logloss:0.1896,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2099,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1823,  }]\n",
      "Training on Total Epoch: 443, Round: 443\n",
      "Evalset: [Train : Metrics { logloss:0.1891,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1817,  }]\n",
      "Training on Total Epoch: 444, Round: 444\n",
      "Evalset: [Train : Metrics { logloss:0.1885,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1813,  }]\n",
      "Training on Total Epoch: 445, Round: 445\n",
      "Evalset: [Train : Metrics { logloss:0.188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2084,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1809,  }]\n",
      "Training on Total Epoch: 446, Round: 446\n",
      "Evalset: [Train : Metrics { logloss:0.1875,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2081,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1805,  }]\n",
      "Training on Total Epoch: 447, Round: 447\n",
      "Evalset: [Train : Metrics { logloss:0.187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2079,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1802,  }]\n",
      "Training on Total Epoch: 448, Round: 448\n",
      "Evalset: [Train : Metrics { logloss:0.1866,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2076,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1799,  }]\n",
      "Training on Total Epoch: 449, Round: 449\n",
      "Evalset: [Train : Metrics { logloss:0.1861,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2072,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1796,  }]\n",
      "Training on Total Epoch: 450, Round: 450\n",
      "Evalset: [Train : Metrics { logloss:0.1856,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2068,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1792,  }]\n",
      "Training on Total Epoch: 451, Round: 451\n",
      "Evalset: [Train : Metrics { logloss:0.1851,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2064,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1788,  }]\n",
      "Training on Total Epoch: 452, Round: 452\n",
      "Evalset: [Train : Metrics { logloss:0.1846,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2058,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1783,  }]\n",
      "Training on Total Epoch: 453, Round: 453\n",
      "Evalset: [Train : Metrics { logloss:0.1842,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2055,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1778,  }]\n",
      "Training on Total Epoch: 454, Round: 454\n",
      "Evalset: [Train : Metrics { logloss:0.1837,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2053,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1775,  }]\n",
      "Training on Total Epoch: 455, Round: 455\n",
      "Evalset: [Train : Metrics { logloss:0.1832,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2049,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1771,  }]\n",
      "Training on Total Epoch: 456, Round: 456\n",
      "Evalset: [Train : Metrics { logloss:0.1828,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2045,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1766,  }]\n",
      "Training on Total Epoch: 457, Round: 457\n",
      "Evalset: [Train : Metrics { logloss:0.1823,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2041,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1762,  }]\n",
      "Training on Total Epoch: 458, Round: 458\n",
      "Evalset: [Train : Metrics { logloss:0.1818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2037,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1757,  }]\n",
      "Training on Total Epoch: 459, Round: 459\n",
      "Evalset: [Train : Metrics { logloss:0.1814,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2033,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1753,  }]\n",
      "Training on Total Epoch: 460, Round: 460\n",
      "Evalset: [Train : Metrics { logloss:0.1809,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2028,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1749,  }]\n",
      "Training on Total Epoch: 461, Round: 461\n",
      "Evalset: [Train : Metrics { logloss:0.1805,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2024,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1745,  }]\n",
      "Training on Total Epoch: 462, Round: 462\n",
      "Evalset: [Train : Metrics { logloss:0.18,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2021,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1741,  }]\n",
      "Training on Total Epoch: 463, Round: 463\n",
      "Evalset: [Train : Metrics { logloss:0.1795,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2017,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1738,  }]\n",
      "Training on Total Epoch: 464, Round: 464\n",
      "Evalset: [Train : Metrics { logloss:0.1791,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2013,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1734,  }]\n",
      "Training on Total Epoch: 465, Round: 465\n",
      "Evalset: [Train : Metrics { logloss:0.1787,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.173,  }]\n",
      "Training on Total Epoch: 466, Round: 466\n",
      "Evalset: [Train : Metrics { logloss:0.1782,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2006,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1727,  }]\n",
      "Training on Total Epoch: 467, Round: 467\n",
      "Evalset: [Train : Metrics { logloss:0.1778,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2004,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1723,  }]\n",
      "Training on Total Epoch: 468, Round: 468\n",
      "Evalset: [Train : Metrics { logloss:0.1774,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2002,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.172,  }]\n",
      "Training on Total Epoch: 469, Round: 469\n",
      "Evalset: [Train : Metrics { logloss:0.1769,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1999,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1717,  }]\n",
      "Training on Total Epoch: 470, Round: 470\n",
      "Evalset: [Train : Metrics { logloss:0.1765,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1995,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1712,  }]\n",
      "Training on Total Epoch: 471, Round: 471\n",
      "Evalset: [Train : Metrics { logloss:0.1761,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1993,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1708,  }]\n",
      "Training on Total Epoch: 472, Round: 472\n",
      "Evalset: [Train : Metrics { logloss:0.1756,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1989,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1705,  }]\n",
      "Training on Total Epoch: 473, Round: 473\n",
      "Evalset: [Train : Metrics { logloss:0.1752,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1985,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1701,  }]\n",
      "Training on Total Epoch: 474, Round: 474\n",
      "Evalset: [Train : Metrics { logloss:0.1748,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1979,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1696,  }]\n",
      "Training on Total Epoch: 475, Round: 475\n",
      "Evalset: [Train : Metrics { logloss:0.1743,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1975,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1692,  }]\n",
      "Training on Total Epoch: 476, Round: 476\n",
      "Evalset: [Train : Metrics { logloss:0.1739,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.197,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1689,  }]\n",
      "Training on Total Epoch: 477, Round: 477\n",
      "Evalset: [Train : Metrics { logloss:0.1735,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1966,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1684,  }]\n",
      "Training on Total Epoch: 478, Round: 478\n",
      "Evalset: [Train : Metrics { logloss:0.1731,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1962,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.168,  }]\n",
      "Training on Total Epoch: 479, Round: 479\n",
      "Evalset: [Train : Metrics { logloss:0.1727,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1676,  }]\n",
      "Training on Total Epoch: 480, Round: 480\n",
      "Evalset: [Train : Metrics { logloss:0.1722,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1958,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1673,  }]\n",
      "Training on Total Epoch: 481, Round: 481\n",
      "Evalset: [Train : Metrics { logloss:0.1718,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1956,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.167,  }]\n",
      "Training on Total Epoch: 482, Round: 482\n",
      "Evalset: [Train : Metrics { logloss:0.1714,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1952,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1666,  }]\n",
      "Training on Total Epoch: 483, Round: 483\n",
      "Evalset: [Train : Metrics { logloss:0.171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1949,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1663,  }]\n",
      "Training on Total Epoch: 484, Round: 484\n",
      "Evalset: [Train : Metrics { logloss:0.1706,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1945,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.166,  }]\n",
      "Training on Total Epoch: 485, Round: 485\n",
      "Evalset: [Train : Metrics { logloss:0.1702,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1942,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1656,  }]\n",
      "Training on Total Epoch: 486, Round: 486\n",
      "Evalset: [Train : Metrics { logloss:0.1698,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1939,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1653,  }]\n",
      "Training on Total Epoch: 487, Round: 487\n",
      "Evalset: [Train : Metrics { logloss:0.1694,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1935,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.165,  }]\n",
      "Training on Total Epoch: 488, Round: 488\n",
      "Evalset: [Train : Metrics { logloss:0.169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1932,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1647,  }]\n",
      "Training on Total Epoch: 489, Round: 489\n",
      "Evalset: [Train : Metrics { logloss:0.1686,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1644,  }]\n",
      "Training on Total Epoch: 490, Round: 490\n",
      "Evalset: [Train : Metrics { logloss:0.1682,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1929,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1642,  }]\n",
      "Training on Total Epoch: 491, Round: 491\n",
      "Evalset: [Train : Metrics { logloss:0.1678,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1926,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1638,  }]\n",
      "Training on Total Epoch: 492, Round: 492\n",
      "Evalset: [Train : Metrics { logloss:0.1675,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1922,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1634,  }]\n",
      "Training on Total Epoch: 493, Round: 493\n",
      "Evalset: [Train : Metrics { logloss:0.1671,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.163,  }]\n",
      "Training on Total Epoch: 494, Round: 494\n",
      "Evalset: [Train : Metrics { logloss:0.1667,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1626,  }]\n",
      "Training on Total Epoch: 495, Round: 495\n",
      "Evalset: [Train : Metrics { logloss:0.1663,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1623,  }]\n",
      "Training on Total Epoch: 496, Round: 496\n",
      "Evalset: [Train : Metrics { logloss:0.1659,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1621,  }]\n",
      "Training on Total Epoch: 497, Round: 497\n",
      "Evalset: [Train : Metrics { logloss:0.1655,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1906,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1618,  }]\n",
      "Training on Total Epoch: 498, Round: 498\n",
      "Evalset: [Train : Metrics { logloss:0.1651,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1902,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1615,  }]\n",
      "Training on Total Epoch: 499, Round: 499\n",
      "Evalset: [Train : Metrics { logloss:0.1648,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.19,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1612,  }]\n",
      "Training on Total Epoch: 500, Round: 500\n",
      "Evalset: [Train : Metrics { logloss:0.1644,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1609,  }]\n",
      "Training on Total Epoch: 501, Round: 501\n",
      "Evalset: [Train : Metrics { logloss:0.164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1606,  }]\n",
      "Training on Total Epoch: 502, Round: 502\n",
      "Evalset: [Train : Metrics { logloss:0.1636,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.189,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1602,  }]\n",
      "Training on Total Epoch: 503, Round: 503\n",
      "Evalset: [Train : Metrics { logloss:0.1633,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1598,  }]\n",
      "Training on Total Epoch: 504, Round: 504\n",
      "Evalset: [Train : Metrics { logloss:0.1629,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1595,  }]\n",
      "Training on Total Epoch: 505, Round: 505\n",
      "Evalset: [Train : Metrics { logloss:0.1625,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1592,  }]\n",
      "Training on Total Epoch: 506, Round: 506\n",
      "Evalset: [Train : Metrics { logloss:0.1622,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1589,  }]\n",
      "Training on Total Epoch: 507, Round: 507\n",
      "Evalset: [Train : Metrics { logloss:0.1618,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1586,  }]\n",
      "Training on Total Epoch: 508, Round: 508\n",
      "Evalset: [Train : Metrics { logloss:0.1614,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1875,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1582,  }]\n",
      "Training on Total Epoch: 509, Round: 509\n",
      "Evalset: [Train : Metrics { logloss:0.1611,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1871,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1579,  }]\n",
      "Training on Total Epoch: 510, Round: 510\n",
      "Evalset: [Train : Metrics { logloss:0.1607,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1868,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1576,  }]\n",
      "Training on Total Epoch: 511, Round: 511\n",
      "Evalset: [Train : Metrics { logloss:0.1604,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1863,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1572,  }]\n",
      "Training on Total Epoch: 512, Round: 512\n",
      "Evalset: [Train : Metrics { logloss:0.16,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1861,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.157,  }]\n",
      "Training on Total Epoch: 513, Round: 513\n",
      "Evalset: [Train : Metrics { logloss:0.1597,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1859,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1567,  }]\n",
      "Training on Total Epoch: 514, Round: 514\n",
      "Evalset: [Train : Metrics { logloss:0.1593,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1856,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1564,  }]\n",
      "Training on Total Epoch: 515, Round: 515\n",
      "Evalset: [Train : Metrics { logloss:0.159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1854,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1561,  }]\n",
      "Training on Total Epoch: 516, Round: 516\n",
      "Evalset: [Train : Metrics { logloss:0.1586,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1851,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1559,  }]\n",
      "Training on Total Epoch: 517, Round: 517\n",
      "Evalset: [Train : Metrics { logloss:0.1583,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1847,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1556,  }]\n",
      "Training on Total Epoch: 518, Round: 518\n",
      "Evalset: [Train : Metrics { logloss:0.1579,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1844,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1554,  }]\n",
      "Training on Total Epoch: 519, Round: 519\n",
      "Evalset: [Train : Metrics { logloss:0.1576,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1842,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1551,  }]\n",
      "Training on Total Epoch: 520, Round: 520\n",
      "Evalset: [Train : Metrics { logloss:0.1572,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1839,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1548,  }]\n",
      "Training on Total Epoch: 521, Round: 521\n",
      "Evalset: [Train : Metrics { logloss:0.1569,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1838,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1546,  }]\n",
      "Training on Total Epoch: 522, Round: 522\n",
      "Evalset: [Train : Metrics { logloss:0.1565,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1838,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1544,  }]\n",
      "Training on Total Epoch: 523, Round: 523\n",
      "Evalset: [Train : Metrics { logloss:0.1562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1837,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1542,  }]\n",
      "Training on Total Epoch: 524, Round: 524\n",
      "Evalset: [Train : Metrics { logloss:0.1559,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1834,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1539,  }]\n",
      "Training on Total Epoch: 525, Round: 525\n",
      "Evalset: [Train : Metrics { logloss:0.1555,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1831,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1535,  }]\n",
      "Training on Total Epoch: 526, Round: 526\n",
      "Evalset: [Train : Metrics { logloss:0.1552,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1827,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1531,  }]\n",
      "Training on Total Epoch: 527, Round: 527\n",
      "Evalset: [Train : Metrics { logloss:0.1549,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1824,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1527,  }]\n",
      "Training on Total Epoch: 528, Round: 528\n",
      "Evalset: [Train : Metrics { logloss:0.1546,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1821,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1523,  }]\n",
      "Training on Total Epoch: 529, Round: 529\n",
      "Evalset: [Train : Metrics { logloss:0.1542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1819,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.152,  }]\n",
      "Training on Total Epoch: 530, Round: 530\n",
      "Evalset: [Train : Metrics { logloss:0.1539,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1816,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1518,  }]\n",
      "Training on Total Epoch: 531, Round: 531\n",
      "Evalset: [Train : Metrics { logloss:0.1536,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1814,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1516,  }]\n",
      "Training on Total Epoch: 532, Round: 532\n",
      "Evalset: [Train : Metrics { logloss:0.1532,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1811,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1514,  }]\n",
      "Training on Total Epoch: 533, Round: 533\n",
      "Evalset: [Train : Metrics { logloss:0.1529,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1809,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1512,  }]\n",
      "Training on Total Epoch: 534, Round: 534\n",
      "Evalset: [Train : Metrics { logloss:0.1526,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1807,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.151,  }]\n",
      "Training on Total Epoch: 535, Round: 535\n",
      "Evalset: [Train : Metrics { logloss:0.1523,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1804,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1507,  }]\n",
      "Training on Total Epoch: 536, Round: 536\n",
      "Evalset: [Train : Metrics { logloss:0.152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1802,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1505,  }]\n",
      "Training on Total Epoch: 537, Round: 537\n",
      "Evalset: [Train : Metrics { logloss:0.1517,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.18,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1503,  }]\n",
      "Training on Total Epoch: 538, Round: 538\n",
      "Evalset: [Train : Metrics { logloss:0.1513,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1798,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.15,  }]\n",
      "Training on Total Epoch: 539, Round: 539\n",
      "Evalset: [Train : Metrics { logloss:0.151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1797,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1497,  }]\n",
      "Training on Total Epoch: 540, Round: 540\n",
      "Evalset: [Train : Metrics { logloss:0.1507,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1796,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1495,  }]\n",
      "Training on Total Epoch: 541, Round: 541\n",
      "Evalset: [Train : Metrics { logloss:0.1504,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1793,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1492,  }]\n",
      "Training on Total Epoch: 542, Round: 542\n",
      "Evalset: [Train : Metrics { logloss:0.1501,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1789,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1489,  }]\n",
      "Training on Total Epoch: 543, Round: 543\n",
      "Evalset: [Train : Metrics { logloss:0.1498,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1786,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1487,  }]\n",
      "Training on Total Epoch: 544, Round: 544\n",
      "Evalset: [Train : Metrics { logloss:0.1495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1783,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1484,  }]\n",
      "Training on Total Epoch: 545, Round: 545\n",
      "Evalset: [Train : Metrics { logloss:0.1492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1782,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1481,  }]\n",
      "Training on Total Epoch: 546, Round: 546\n",
      "Evalset: [Train : Metrics { logloss:0.1489,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1779,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1479,  }]\n",
      "Training on Total Epoch: 547, Round: 547\n",
      "Evalset: [Train : Metrics { logloss:0.1486,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1778,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1476,  }]\n",
      "Training on Total Epoch: 548, Round: 548\n",
      "Evalset: [Train : Metrics { logloss:0.1483,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1776,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1474,  }]\n",
      "Training on Total Epoch: 549, Round: 549\n",
      "Evalset: [Train : Metrics { logloss:0.148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1775,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1472,  }]\n",
      "Training on Total Epoch: 550, Round: 550\n",
      "Evalset: [Train : Metrics { logloss:0.1477,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1772,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.147,  }]\n",
      "Training on Total Epoch: 551, Round: 551\n",
      "Evalset: [Train : Metrics { logloss:0.1474,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1769,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1467,  }]\n",
      "Training on Total Epoch: 552, Round: 552\n",
      "Evalset: [Train : Metrics { logloss:0.1471,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1765,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1464,  }]\n",
      "Training on Total Epoch: 553, Round: 553\n",
      "Evalset: [Train : Metrics { logloss:0.1468,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1761,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1461,  }]\n",
      "Training on Total Epoch: 554, Round: 554\n",
      "Evalset: [Train : Metrics { logloss:0.1465,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1759,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1458,  }]\n",
      "Training on Total Epoch: 555, Round: 555\n",
      "Evalset: [Train : Metrics { logloss:0.1462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1757,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1456,  }]\n",
      "Training on Total Epoch: 556, Round: 556\n",
      "Evalset: [Train : Metrics { logloss:0.1459,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1757,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1454,  }]\n",
      "Training on Total Epoch: 557, Round: 557\n",
      "Evalset: [Train : Metrics { logloss:0.1456,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1756,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1452,  }]\n",
      "Training on Total Epoch: 558, Round: 558\n",
      "Evalset: [Train : Metrics { logloss:0.1453,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1756,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.145,  }]\n",
      "Training on Total Epoch: 559, Round: 559\n",
      "Evalset: [Train : Metrics { logloss:0.145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1754,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1448,  }]\n",
      "Training on Total Epoch: 560, Round: 560\n",
      "Evalset: [Train : Metrics { logloss:0.1447,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1445,  }]\n",
      "Training on Total Epoch: 561, Round: 561\n",
      "Evalset: [Train : Metrics { logloss:0.1444,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1745,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1443,  }]\n",
      "Training on Total Epoch: 562, Round: 562\n",
      "Evalset: [Train : Metrics { logloss:0.1442,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1741,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.144,  }]\n",
      "Training on Total Epoch: 563, Round: 563\n",
      "Evalset: [Train : Metrics { logloss:0.1439,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1438,  }]\n",
      "Training on Total Epoch: 564, Round: 564\n",
      "Evalset: [Train : Metrics { logloss:0.1436,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1436,  }]\n",
      "Training on Total Epoch: 565, Round: 565\n",
      "Evalset: [Train : Metrics { logloss:0.1433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1434,  }]\n",
      "Training on Total Epoch: 566, Round: 566\n",
      "Evalset: [Train : Metrics { logloss:0.143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1738,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1432,  }]\n",
      "Training on Total Epoch: 567, Round: 567\n",
      "Evalset: [Train : Metrics { logloss:0.1427,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1735,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.143,  }]\n",
      "Training on Total Epoch: 568, Round: 568\n",
      "Evalset: [Train : Metrics { logloss:0.1425,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.173,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1427,  }]\n",
      "Training on Total Epoch: 569, Round: 569\n",
      "Evalset: [Train : Metrics { logloss:0.1422,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1727,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1424,  }]\n",
      "Training on Total Epoch: 570, Round: 570\n",
      "Evalset: [Train : Metrics { logloss:0.1419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1724,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1422,  }]\n",
      "Training on Total Epoch: 571, Round: 571\n",
      "Evalset: [Train : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1722,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.142,  }]\n",
      "Training on Total Epoch: 572, Round: 572\n",
      "Evalset: [Train : Metrics { logloss:0.1414,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.172,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1417,  }]\n",
      "Training on Total Epoch: 573, Round: 573\n",
      "Evalset: [Train : Metrics { logloss:0.1411,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1719,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1414,  }]\n",
      "Training on Total Epoch: 574, Round: 574\n",
      "Evalset: [Train : Metrics { logloss:0.1408,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1717,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1412,  }]\n",
      "Training on Total Epoch: 575, Round: 575\n",
      "Evalset: [Train : Metrics { logloss:0.1405,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1411,  }]\n",
      "Training on Total Epoch: 576, Round: 576\n",
      "Evalset: [Train : Metrics { logloss:0.1403,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.141,  }]\n",
      "Training on Total Epoch: 577, Round: 577\n",
      "Evalset: [Train : Metrics { logloss:0.14,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1408,  }]\n",
      "Training on Total Epoch: 578, Round: 578\n",
      "Evalset: [Train : Metrics { logloss:0.1398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1407,  }]\n",
      "Training on Total Epoch: 579, Round: 579\n",
      "Evalset: [Train : Metrics { logloss:0.1395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1714,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1405,  }]\n",
      "Training on Total Epoch: 580, Round: 580\n",
      "Evalset: [Train : Metrics { logloss:0.1392,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.171,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1401,  }]\n",
      "Training on Total Epoch: 581, Round: 581\n",
      "Evalset: [Train : Metrics { logloss:0.139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1707,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1398,  }]\n",
      "Training on Total Epoch: 582, Round: 582\n",
      "Evalset: [Train : Metrics { logloss:0.1387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1703,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1396,  }]\n",
      "Training on Total Epoch: 583, Round: 583\n",
      "Evalset: [Train : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1701,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1394,  }]\n",
      "Training on Total Epoch: 584, Round: 584\n",
      "Evalset: [Train : Metrics { logloss:0.1382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1697,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1392,  }]\n",
      "Training on Total Epoch: 585, Round: 585\n",
      "Evalset: [Train : Metrics { logloss:0.1379,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1695,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.139,  }]\n",
      "Training on Total Epoch: 586, Round: 586\n",
      "Evalset: [Train : Metrics { logloss:0.1376,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1695,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1388,  }]\n",
      "Training on Total Epoch: 587, Round: 587\n",
      "Evalset: [Train : Metrics { logloss:0.1374,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1694,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1386,  }]\n",
      "Training on Total Epoch: 588, Round: 588\n",
      "Evalset: [Train : Metrics { logloss:0.1371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1692,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1383,  }]\n",
      "Training on Total Epoch: 589, Round: 589\n",
      "Evalset: [Train : Metrics { logloss:0.1369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1691,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1381,  }]\n",
      "Training on Total Epoch: 590, Round: 590\n",
      "Evalset: [Train : Metrics { logloss:0.1366,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1689,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1379,  }]\n",
      "Training on Total Epoch: 591, Round: 591\n",
      "Evalset: [Train : Metrics { logloss:0.1363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1686,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1376,  }]\n",
      "Training on Total Epoch: 592, Round: 592\n",
      "Evalset: [Train : Metrics { logloss:0.1361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1682,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1375,  }]\n",
      "Training on Total Epoch: 593, Round: 593\n",
      "Evalset: [Train : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1373,  }]\n",
      "Training on Total Epoch: 594, Round: 594\n",
      "Evalset: [Train : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1678,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1371,  }]\n",
      "Training on Total Epoch: 595, Round: 595\n",
      "Evalset: [Train : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1676,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1369,  }]\n",
      "Training on Total Epoch: 596, Round: 596\n",
      "Evalset: [Train : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1676,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1368,  }]\n",
      "Training on Total Epoch: 597, Round: 597\n",
      "Evalset: [Train : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1675,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1366,  }]\n",
      "Training on Total Epoch: 598, Round: 598\n",
      "Evalset: [Train : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1675,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1365,  }]\n",
      "Training on Total Epoch: 599, Round: 599\n",
      "Evalset: [Train : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1674,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1363,  }]\n",
      "Training on Total Epoch: 600, Round: 600\n",
      "Evalset: [Train : Metrics { logloss:0.1341,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1672,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1361,  }]\n",
      "Training on Total Epoch: 601, Round: 601\n",
      "Evalset: [Train : Metrics { logloss:0.1338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1359,  }]\n",
      "Training on Total Epoch: 602, Round: 602\n",
      "Evalset: [Train : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1669,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1356,  }]\n",
      "Training on Total Epoch: 603, Round: 603\n",
      "Evalset: [Train : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1665,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1355,  }]\n",
      "Training on Total Epoch: 604, Round: 604\n",
      "Evalset: [Train : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1663,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1354,  }]\n",
      "Training on Total Epoch: 605, Round: 605\n",
      "Evalset: [Train : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1351,  }]\n",
      "Training on Total Epoch: 606, Round: 606\n",
      "Evalset: [Train : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1659,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1349,  }]\n",
      "Training on Total Epoch: 607, Round: 607\n",
      "Evalset: [Train : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1658,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1348,  }]\n",
      "Training on Total Epoch: 608, Round: 608\n",
      "Evalset: [Train : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1657,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1346,  }]\n",
      "Training on Total Epoch: 609, Round: 609\n",
      "Evalset: [Train : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1656,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1344,  }]\n",
      "Training on Total Epoch: 610, Round: 610\n",
      "Evalset: [Train : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1655,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1341,  }]\n",
      "Training on Total Epoch: 611, Round: 611\n",
      "Evalset: [Train : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1653,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.134,  }]\n",
      "Training on Total Epoch: 612, Round: 612\n",
      "Evalset: [Train : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1652,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1338,  }]\n",
      "Training on Total Epoch: 613, Round: 613\n",
      "Evalset: [Train : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1652,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1337,  }]\n",
      "Training on Total Epoch: 614, Round: 614\n",
      "Evalset: [Train : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1653,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1335,  }]\n",
      "Training on Total Epoch: 615, Round: 615\n",
      "Evalset: [Train : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.165,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1333,  }]\n",
      "Training on Total Epoch: 616, Round: 616\n",
      "Evalset: [Train : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1645,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1331,  }]\n",
      "Training on Total Epoch: 617, Round: 617\n",
      "Evalset: [Train : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1641,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1329,  }]\n",
      "Training on Total Epoch: 618, Round: 618\n",
      "Evalset: [Train : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1638,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1326,  }]\n",
      "Training on Total Epoch: 619, Round: 619\n",
      "Evalset: [Train : Metrics { logloss:0.1296,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1638,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1326,  }]\n",
      "Training on Total Epoch: 620, Round: 620\n",
      "Evalset: [Train : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1638,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1324,  }]\n",
      "Training on Total Epoch: 621, Round: 621\n",
      "Evalset: [Train : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1636,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1322,  }]\n",
      "Training on Total Epoch: 622, Round: 622\n",
      "Evalset: [Train : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1634,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.132,  }]\n",
      "Training on Total Epoch: 623, Round: 623\n",
      "Evalset: [Train : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1632,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1319,  }]\n",
      "Training on Total Epoch: 624, Round: 624\n",
      "Evalset: [Train : Metrics { logloss:0.1284,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1631,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1319,  }]\n",
      "Training on Total Epoch: 625, Round: 625\n",
      "Evalset: [Train : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1318,  }]\n",
      "Training on Total Epoch: 626, Round: 626\n",
      "Evalset: [Train : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1627,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1316,  }]\n",
      "Training on Total Epoch: 627, Round: 627\n",
      "Evalset: [Train : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1625,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1314,  }]\n",
      "Training on Total Epoch: 628, Round: 628\n",
      "Evalset: [Train : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1622,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1311,  }]\n",
      "Training on Total Epoch: 629, Round: 629\n",
      "Evalset: [Train : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.162,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1309,  }]\n",
      "Training on Total Epoch: 630, Round: 630\n",
      "Evalset: [Train : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1619,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1307,  }]\n",
      "Training on Total Epoch: 631, Round: 631\n",
      "Evalset: [Train : Metrics { logloss:0.1268,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1617,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1305,  }]\n",
      "Training on Total Epoch: 632, Round: 632\n",
      "Evalset: [Train : Metrics { logloss:0.1266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1616,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1302,  }]\n",
      "Training on Total Epoch: 633, Round: 633\n",
      "Evalset: [Train : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1616,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1301,  }]\n",
      "Training on Total Epoch: 634, Round: 634\n",
      "Evalset: [Train : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1616,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1299,  }]\n",
      "Training on Total Epoch: 635, Round: 635\n",
      "Evalset: [Train : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1614,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1298,  }]\n",
      "Training on Total Epoch: 636, Round: 636\n",
      "Evalset: [Train : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1612,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1296,  }]\n",
      "Training on Total Epoch: 637, Round: 637\n",
      "Evalset: [Train : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1611,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1295,  }]\n",
      "Training on Total Epoch: 638, Round: 638\n",
      "Evalset: [Train : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1611,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1294,  }]\n",
      "Training on Total Epoch: 639, Round: 639\n",
      "Evalset: [Train : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.161,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1293,  }]\n",
      "Training on Total Epoch: 640, Round: 640\n",
      "Evalset: [Train : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1607,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1291,  }]\n",
      "Training on Total Epoch: 641, Round: 641\n",
      "Evalset: [Train : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1605,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1288,  }]\n",
      "Training on Total Epoch: 642, Round: 642\n",
      "Evalset: [Train : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1602,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1286,  }]\n",
      "Training on Total Epoch: 643, Round: 643\n",
      "Evalset: [Train : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1602,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1284,  }]\n",
      "Training on Total Epoch: 644, Round: 644\n",
      "Evalset: [Train : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.16,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1282,  }]\n",
      "Training on Total Epoch: 645, Round: 645\n",
      "Evalset: [Train : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1599,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.128,  }]\n",
      "Training on Total Epoch: 646, Round: 646\n",
      "Evalset: [Train : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1597,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1278,  }]\n",
      "Training on Total Epoch: 647, Round: 647\n",
      "Evalset: [Train : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1597,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1277,  }]\n",
      "Training on Total Epoch: 648, Round: 648\n",
      "Evalset: [Train : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1597,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1276,  }]\n",
      "Training on Total Epoch: 649, Round: 649\n",
      "Evalset: [Train : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1596,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1274,  }]\n",
      "Training on Total Epoch: 650, Round: 650\n",
      "Evalset: [Train : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1594,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1273,  }]\n",
      "Training on Total Epoch: 651, Round: 651\n",
      "Evalset: [Train : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1591,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1271,  }]\n",
      "Training on Total Epoch: 652, Round: 652\n",
      "Evalset: [Train : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1587,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.127,  }]\n",
      "Training on Total Epoch: 653, Round: 653\n",
      "Evalset: [Train : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1269,  }]\n",
      "Training on Total Epoch: 654, Round: 654\n",
      "Evalset: [Train : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1267,  }]\n",
      "Training on Total Epoch: 655, Round: 655\n",
      "Evalset: [Train : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1266,  }]\n",
      "Training on Total Epoch: 656, Round: 656\n",
      "Evalset: [Train : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1265,  }]\n",
      "Training on Total Epoch: 657, Round: 657\n",
      "Evalset: [Train : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1586,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1263,  }]\n",
      "Training on Total Epoch: 658, Round: 658\n",
      "Evalset: [Train : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1262,  }]\n",
      "Training on Total Epoch: 659, Round: 659\n",
      "Evalset: [Train : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1583,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1261,  }]\n",
      "Training on Total Epoch: 660, Round: 660\n",
      "Evalset: [Train : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1578,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.126,  }]\n",
      "Training on Total Epoch: 661, Round: 661\n",
      "Evalset: [Train : Metrics { logloss:0.1205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1575,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1257,  }]\n",
      "Training on Total Epoch: 662, Round: 662\n",
      "Evalset: [Train : Metrics { logloss:0.1204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1575,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1255,  }]\n",
      "Training on Total Epoch: 663, Round: 663\n",
      "Evalset: [Train : Metrics { logloss:0.1202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1575,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1253,  }]\n",
      "Training on Total Epoch: 664, Round: 664\n",
      "Evalset: [Train : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1574,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1252,  }]\n",
      "Training on Total Epoch: 665, Round: 665\n",
      "Evalset: [Train : Metrics { logloss:0.1198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1573,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1251,  }]\n",
      "Training on Total Epoch: 666, Round: 666\n",
      "Evalset: [Train : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1571,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1249,  }]\n",
      "Training on Total Epoch: 667, Round: 667\n",
      "Evalset: [Train : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1569,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1248,  }]\n",
      "Training on Total Epoch: 668, Round: 668\n",
      "Evalset: [Train : Metrics { logloss:0.1191,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1567,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1247,  }]\n",
      "Training on Total Epoch: 669, Round: 669\n",
      "Evalset: [Train : Metrics { logloss:0.1189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1566,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1245,  }]\n",
      "Training on Total Epoch: 670, Round: 670\n",
      "Evalset: [Train : Metrics { logloss:0.1187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1564,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1244,  }]\n",
      "Training on Total Epoch: 671, Round: 671\n",
      "Evalset: [Train : Metrics { logloss:0.1186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1564,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1243,  }]\n",
      "Training on Total Epoch: 672, Round: 672\n",
      "Evalset: [Train : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1563,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1241,  }]\n",
      "Training on Total Epoch: 673, Round: 673\n",
      "Evalset: [Train : Metrics { logloss:0.1182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1561,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1238,  }]\n",
      "Training on Total Epoch: 674, Round: 674\n",
      "Evalset: [Train : Metrics { logloss:0.118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.156,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1237,  }]\n",
      "Training on Total Epoch: 675, Round: 675\n",
      "Evalset: [Train : Metrics { logloss:0.1178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1559,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1235,  }]\n",
      "Training on Total Epoch: 676, Round: 676\n",
      "Evalset: [Train : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1558,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1235,  }]\n",
      "Training on Total Epoch: 677, Round: 677\n",
      "Evalset: [Train : Metrics { logloss:0.1174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1558,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1234,  }]\n",
      "Training on Total Epoch: 678, Round: 678\n",
      "Evalset: [Train : Metrics { logloss:0.1172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1557,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1234,  }]\n",
      "Training on Total Epoch: 679, Round: 679\n",
      "Evalset: [Train : Metrics { logloss:0.117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1557,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1233,  }]\n",
      "Training on Total Epoch: 680, Round: 680\n",
      "Evalset: [Train : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1555,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.123,  }]\n",
      "Training on Total Epoch: 681, Round: 681\n",
      "Evalset: [Train : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1554,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1229,  }]\n",
      "Training on Total Epoch: 682, Round: 682\n",
      "Evalset: [Train : Metrics { logloss:0.1165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1552,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1228,  }]\n",
      "Training on Total Epoch: 683, Round: 683\n",
      "Evalset: [Train : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.155,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1226,  }]\n",
      "Training on Total Epoch: 684, Round: 684\n",
      "Evalset: [Train : Metrics { logloss:0.1161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1549,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1224,  }]\n",
      "Training on Total Epoch: 685, Round: 685\n",
      "Evalset: [Train : Metrics { logloss:0.1159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1549,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1224,  }]\n",
      "Training on Total Epoch: 686, Round: 686\n",
      "Evalset: [Train : Metrics { logloss:0.1157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1548,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1223,  }]\n",
      "Training on Total Epoch: 687, Round: 687\n",
      "Evalset: [Train : Metrics { logloss:0.1155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1546,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1221,  }]\n",
      "Training on Total Epoch: 688, Round: 688\n",
      "Evalset: [Train : Metrics { logloss:0.1153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1546,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.122,  }]\n",
      "Training on Total Epoch: 689, Round: 689\n",
      "Evalset: [Train : Metrics { logloss:0.1152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1544,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1218,  }]\n",
      "Training on Total Epoch: 690, Round: 690\n",
      "Evalset: [Train : Metrics { logloss:0.115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1543,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1217,  }]\n",
      "Training on Total Epoch: 691, Round: 691\n",
      "Evalset: [Train : Metrics { logloss:0.1148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1542,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1215,  }]\n",
      "Training on Total Epoch: 692, Round: 692\n",
      "Evalset: [Train : Metrics { logloss:0.1146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1541,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1214,  }]\n",
      "Training on Total Epoch: 693, Round: 693\n",
      "Evalset: [Train : Metrics { logloss:0.1144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1538,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1212,  }]\n",
      "Training on Total Epoch: 694, Round: 694\n",
      "Evalset: [Train : Metrics { logloss:0.1142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1536,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1211,  }]\n",
      "Training on Total Epoch: 695, Round: 695\n",
      "Evalset: [Train : Metrics { logloss:0.1141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1535,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.121,  }]\n",
      "Training on Total Epoch: 696, Round: 696\n",
      "Evalset: [Train : Metrics { logloss:0.1139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1533,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1209,  }]\n",
      "Training on Total Epoch: 697, Round: 697\n",
      "Evalset: [Train : Metrics { logloss:0.1137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1532,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1208,  }]\n",
      "Training on Total Epoch: 698, Round: 698\n",
      "Evalset: [Train : Metrics { logloss:0.1135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.153,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1206,  }]\n",
      "Training on Total Epoch: 699, Round: 699\n",
      "Evalset: [Train : Metrics { logloss:0.1134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1529,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1205,  }]\n",
      "Training on Total Epoch: 700, Round: 700\n",
      "Evalset: [Train : Metrics { logloss:0.1132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1529,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1204,  }]\n",
      "Training on Total Epoch: 701, Round: 701\n",
      "Evalset: [Train : Metrics { logloss:0.113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1528,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1203,  }]\n",
      "Training on Total Epoch: 702, Round: 702\n",
      "Evalset: [Train : Metrics { logloss:0.1129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1529,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1202,  }]\n",
      "Training on Total Epoch: 703, Round: 703\n",
      "Evalset: [Train : Metrics { logloss:0.1127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1527,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1201,  }]\n",
      "Training on Total Epoch: 704, Round: 704\n",
      "Evalset: [Train : Metrics { logloss:0.1125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1526,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.12,  }]\n",
      "Training on Total Epoch: 705, Round: 705\n",
      "Evalset: [Train : Metrics { logloss:0.1123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1527,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.12,  }]\n",
      "Training on Total Epoch: 706, Round: 706\n",
      "Evalset: [Train : Metrics { logloss:0.1122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1527,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.12,  }]\n",
      "Training on Total Epoch: 707, Round: 707\n",
      "Evalset: [Train : Metrics { logloss:0.112,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1527,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1199,  }]\n",
      "Training on Total Epoch: 708, Round: 708\n",
      "Evalset: [Train : Metrics { logloss:0.1118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1526,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1196,  }]\n",
      "Training on Total Epoch: 709, Round: 709\n",
      "Evalset: [Train : Metrics { logloss:0.1116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1525,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1195,  }]\n",
      "Training on Total Epoch: 710, Round: 710\n",
      "Evalset: [Train : Metrics { logloss:0.1114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1524,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1193,  }]\n",
      "Training on Total Epoch: 711, Round: 711\n",
      "Evalset: [Train : Metrics { logloss:0.1113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1521,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1192,  }]\n",
      "Training on Total Epoch: 712, Round: 712\n",
      "Evalset: [Train : Metrics { logloss:0.1111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1516,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.119,  }]\n",
      "Training on Total Epoch: 713, Round: 713\n",
      "Evalset: [Train : Metrics { logloss:0.1109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1514,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1187,  }]\n",
      "Training on Total Epoch: 714, Round: 714\n",
      "Evalset: [Train : Metrics { logloss:0.1108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1512,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1185,  }]\n",
      "Training on Total Epoch: 715, Round: 715\n",
      "Evalset: [Train : Metrics { logloss:0.1106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1511,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1184,  }]\n",
      "Training on Total Epoch: 716, Round: 716\n",
      "Evalset: [Train : Metrics { logloss:0.1104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1509,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1183,  }]\n",
      "Training on Total Epoch: 717, Round: 717\n",
      "Evalset: [Train : Metrics { logloss:0.1102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1508,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1182,  }]\n",
      "Training on Total Epoch: 718, Round: 718\n",
      "Evalset: [Train : Metrics { logloss:0.1101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1507,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1181,  }]\n",
      "Training on Total Epoch: 719, Round: 719\n",
      "Evalset: [Train : Metrics { logloss:0.1099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1181,  }]\n",
      "Training on Total Epoch: 720, Round: 720\n",
      "Evalset: [Train : Metrics { logloss:0.1098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1181,  }]\n",
      "Training on Total Epoch: 721, Round: 721\n",
      "Evalset: [Train : Metrics { logloss:0.1096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1181,  }]\n",
      "Training on Total Epoch: 722, Round: 722\n",
      "Evalset: [Train : Metrics { logloss:0.1094,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1504,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1178,  }]\n",
      "Training on Total Epoch: 723, Round: 723\n",
      "Evalset: [Train : Metrics { logloss:0.1093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1503,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1176,  }]\n",
      "Training on Total Epoch: 724, Round: 724\n",
      "Evalset: [Train : Metrics { logloss:0.1091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1501,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1176,  }]\n",
      "Training on Total Epoch: 725, Round: 725\n",
      "Evalset: [Train : Metrics { logloss:0.1089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1499,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1174,  }]\n",
      "Training on Total Epoch: 726, Round: 726\n",
      "Evalset: [Train : Metrics { logloss:0.1088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1172,  }]\n",
      "Training on Total Epoch: 727, Round: 727\n",
      "Evalset: [Train : Metrics { logloss:0.1086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1499,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1172,  }]\n",
      "Training on Total Epoch: 728, Round: 728\n",
      "Evalset: [Train : Metrics { logloss:0.1084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.15,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.117,  }]\n",
      "Training on Total Epoch: 729, Round: 729\n",
      "Evalset: [Train : Metrics { logloss:0.1083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1502,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.117,  }]\n",
      "Training on Total Epoch: 730, Round: 730\n",
      "Evalset: [Train : Metrics { logloss:0.1081,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1502,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.117,  }]\n",
      "Training on Total Epoch: 731, Round: 731\n",
      "Evalset: [Train : Metrics { logloss:0.108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1501,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1168,  }]\n",
      "Training on Total Epoch: 732, Round: 732\n",
      "Evalset: [Train : Metrics { logloss:0.1078,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1167,  }]\n",
      "Training on Total Epoch: 733, Round: 733\n",
      "Evalset: [Train : Metrics { logloss:0.1076,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1166,  }]\n",
      "Training on Total Epoch: 734, Round: 734\n",
      "Evalset: [Train : Metrics { logloss:0.1075,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1495,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1164,  }]\n",
      "Training on Total Epoch: 735, Round: 735\n",
      "Evalset: [Train : Metrics { logloss:0.1073,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1494,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1163,  }]\n",
      "Training on Total Epoch: 736, Round: 736\n",
      "Evalset: [Train : Metrics { logloss:0.1071,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1493,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1162,  }]\n",
      "Training on Total Epoch: 737, Round: 737\n",
      "Evalset: [Train : Metrics { logloss:0.107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1492,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1161,  }]\n",
      "Training on Total Epoch: 738, Round: 738\n",
      "Evalset: [Train : Metrics { logloss:0.1068,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.149,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1159,  }]\n",
      "Training on Total Epoch: 739, Round: 739\n",
      "Evalset: [Train : Metrics { logloss:0.1067,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.149,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1158,  }]\n",
      "Training on Total Epoch: 740, Round: 740\n",
      "Evalset: [Train : Metrics { logloss:0.1065,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1489,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1158,  }]\n",
      "Training on Total Epoch: 741, Round: 741\n",
      "Evalset: [Train : Metrics { logloss:0.1064,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1488,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1157,  }]\n",
      "Training on Total Epoch: 742, Round: 742\n",
      "Evalset: [Train : Metrics { logloss:0.1062,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1487,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1155,  }]\n",
      "Training on Total Epoch: 743, Round: 743\n",
      "Evalset: [Train : Metrics { logloss:0.106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1486,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1153,  }]\n",
      "Training on Total Epoch: 744, Round: 744\n",
      "Evalset: [Train : Metrics { logloss:0.1059,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1484,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1153,  }]\n",
      "Training on Total Epoch: 745, Round: 745\n",
      "Evalset: [Train : Metrics { logloss:0.1057,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1482,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1152,  }]\n",
      "Training on Total Epoch: 746, Round: 746\n",
      "Evalset: [Train : Metrics { logloss:0.1056,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1482,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.115,  }]\n",
      "Training on Total Epoch: 747, Round: 747\n",
      "Evalset: [Train : Metrics { logloss:0.1054,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1481,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1148,  }]\n",
      "Training on Total Epoch: 748, Round: 748\n",
      "Evalset: [Train : Metrics { logloss:0.1053,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1147,  }]\n",
      "Training on Total Epoch: 749, Round: 749\n",
      "Evalset: [Train : Metrics { logloss:0.1051,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1147,  }]\n",
      "Training on Total Epoch: 750, Round: 750\n",
      "Evalset: [Train : Metrics { logloss:0.105,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1482,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1147,  }]\n",
      "Training on Total Epoch: 751, Round: 751\n",
      "Evalset: [Train : Metrics { logloss:0.1048,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1481,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1146,  }]\n",
      "Training on Total Epoch: 752, Round: 752\n",
      "Evalset: [Train : Metrics { logloss:0.1047,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1481,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1145,  }]\n",
      "Training on Total Epoch: 753, Round: 753\n",
      "Evalset: [Train : Metrics { logloss:0.1045,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1143,  }]\n",
      "Training on Total Epoch: 754, Round: 754\n",
      "Evalset: [Train : Metrics { logloss:0.1044,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1142,  }]\n",
      "Training on Total Epoch: 755, Round: 755\n",
      "Evalset: [Train : Metrics { logloss:0.1042,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1478,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1141,  }]\n",
      "Training on Total Epoch: 756, Round: 756\n",
      "Evalset: [Train : Metrics { logloss:0.1041,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1476,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1141,  }]\n",
      "Training on Total Epoch: 757, Round: 757\n",
      "Evalset: [Train : Metrics { logloss:0.1039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1473,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.114,  }]\n",
      "Training on Total Epoch: 758, Round: 758\n",
      "Evalset: [Train : Metrics { logloss:0.1038,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1471,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1138,  }]\n",
      "Training on Total Epoch: 759, Round: 759\n",
      "Evalset: [Train : Metrics { logloss:0.1036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1468,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1136,  }]\n",
      "Training on Total Epoch: 760, Round: 760\n",
      "Evalset: [Train : Metrics { logloss:0.1035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1467,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1134,  }]\n",
      "Training on Total Epoch: 761, Round: 761\n",
      "Evalset: [Train : Metrics { logloss:0.1033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1466,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1133,  }]\n",
      "Training on Total Epoch: 762, Round: 762\n",
      "Evalset: [Train : Metrics { logloss:0.1032,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1466,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1133,  }]\n",
      "Training on Total Epoch: 763, Round: 763\n",
      "Evalset: [Train : Metrics { logloss:0.103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1467,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1133,  }]\n",
      "Training on Total Epoch: 764, Round: 764\n",
      "Evalset: [Train : Metrics { logloss:0.1029,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1467,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1133,  }]\n",
      "Training on Total Epoch: 765, Round: 765\n",
      "Evalset: [Train : Metrics { logloss:0.1027,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1466,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1132,  }]\n",
      "Training on Total Epoch: 766, Round: 766\n",
      "Evalset: [Train : Metrics { logloss:0.1026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1466,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1131,  }]\n",
      "Training on Total Epoch: 767, Round: 767\n",
      "Evalset: [Train : Metrics { logloss:0.1024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1463,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.113,  }]\n",
      "Training on Total Epoch: 768, Round: 768\n",
      "Evalset: [Train : Metrics { logloss:0.1023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1462,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1129,  }]\n",
      "Training on Total Epoch: 769, Round: 769\n",
      "Evalset: [Train : Metrics { logloss:0.1021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1463,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1127,  }]\n",
      "Training on Total Epoch: 770, Round: 770\n",
      "Evalset: [Train : Metrics { logloss:0.102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1461,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1125,  }]\n",
      "Training on Total Epoch: 771, Round: 771\n",
      "Evalset: [Train : Metrics { logloss:0.1019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1457,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1123,  }]\n",
      "Training on Total Epoch: 772, Round: 772\n",
      "Evalset: [Train : Metrics { logloss:0.1017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1455,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1122,  }]\n",
      "Training on Total Epoch: 773, Round: 773\n",
      "Evalset: [Train : Metrics { logloss:0.1015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1453,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1122,  }]\n",
      "Training on Total Epoch: 774, Round: 774\n",
      "Evalset: [Train : Metrics { logloss:0.1014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1453,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1121,  }]\n",
      "Training on Total Epoch: 775, Round: 775\n",
      "Evalset: [Train : Metrics { logloss:0.1013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1121,  }]\n",
      "Training on Total Epoch: 776, Round: 776\n",
      "Evalset: [Train : Metrics { logloss:0.1011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.112,  }]\n",
      "Training on Total Epoch: 777, Round: 777\n",
      "Evalset: [Train : Metrics { logloss:0.101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.112,  }]\n",
      "Training on Total Epoch: 778, Round: 778\n",
      "Evalset: [Train : Metrics { logloss:0.1008,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1453,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1118,  }]\n",
      "Training on Total Epoch: 779, Round: 779\n",
      "Evalset: [Train : Metrics { logloss:0.1007,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1453,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1117,  }]\n",
      "Training on Total Epoch: 780, Round: 780\n",
      "Evalset: [Train : Metrics { logloss:0.1006,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1452,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1114,  }]\n",
      "Training on Total Epoch: 781, Round: 781\n",
      "Evalset: [Train : Metrics { logloss:0.1004,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1448,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1113,  }]\n",
      "Training on Total Epoch: 782, Round: 782\n",
      "Evalset: [Train : Metrics { logloss:0.1003,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1445,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1111,  }]\n",
      "Training on Total Epoch: 783, Round: 783\n",
      "Evalset: [Train : Metrics { logloss:0.1002,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1445,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1111,  }]\n",
      "Training on Total Epoch: 784, Round: 784\n",
      "Evalset: [Train : Metrics { logloss:0.1,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1445,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.111,  }]\n",
      "Training on Total Epoch: 785, Round: 785\n",
      "Evalset: [Train : Metrics { logloss:0.0998,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1446,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1111,  }]\n",
      "Training on Total Epoch: 786, Round: 786\n",
      "Evalset: [Train : Metrics { logloss:0.0997,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1445,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.111,  }]\n",
      "Training on Total Epoch: 787, Round: 787\n",
      "Evalset: [Train : Metrics { logloss:0.0996,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1445,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1109,  }]\n",
      "Training on Total Epoch: 788, Round: 788\n",
      "Evalset: [Train : Metrics { logloss:0.0994,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1444,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1109,  }]\n",
      "Training on Total Epoch: 789, Round: 789\n",
      "Evalset: [Train : Metrics { logloss:0.0993,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1443,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1108,  }]\n",
      "Training on Total Epoch: 790, Round: 790\n",
      "Evalset: [Train : Metrics { logloss:0.0992,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1443,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1107,  }]\n",
      "Training on Total Epoch: 791, Round: 791\n",
      "Evalset: [Train : Metrics { logloss:0.099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1442,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1106,  }]\n",
      "Training on Total Epoch: 792, Round: 792\n",
      "Evalset: [Train : Metrics { logloss:0.0989,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1441,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1105,  }]\n",
      "Training on Total Epoch: 793, Round: 793\n",
      "Evalset: [Train : Metrics { logloss:0.0987,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1439,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1104,  }]\n",
      "Training on Total Epoch: 794, Round: 794\n",
      "Evalset: [Train : Metrics { logloss:0.0986,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1439,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1102,  }]\n",
      "Training on Total Epoch: 795, Round: 795\n",
      "Evalset: [Train : Metrics { logloss:0.0985,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1437,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1101,  }]\n",
      "Training on Total Epoch: 796, Round: 796\n",
      "Evalset: [Train : Metrics { logloss:0.0983,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1437,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.11,  }]\n",
      "Training on Total Epoch: 797, Round: 797\n",
      "Evalset: [Train : Metrics { logloss:0.0982,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1434,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1099,  }]\n",
      "Training on Total Epoch: 798, Round: 798\n",
      "Evalset: [Train : Metrics { logloss:0.0981,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1098,  }]\n",
      "Training on Total Epoch: 799, Round: 799\n",
      "Evalset: [Train : Metrics { logloss:0.0979,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1432,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1096,  }]\n",
      "Training on Total Epoch: 800, Round: 800\n",
      "Evalset: [Train : Metrics { logloss:0.0978,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1434,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1095,  }]\n",
      "Training on Total Epoch: 801, Round: 801\n",
      "Evalset: [Train : Metrics { logloss:0.0977,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1436,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1095,  }]\n",
      "Training on Total Epoch: 802, Round: 802\n",
      "Evalset: [Train : Metrics { logloss:0.0975,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1434,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1094,  }]\n",
      "Training on Total Epoch: 803, Round: 803\n",
      "Evalset: [Train : Metrics { logloss:0.0974,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1094,  }]\n",
      "Training on Total Epoch: 804, Round: 804\n",
      "Evalset: [Train : Metrics { logloss:0.0973,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1432,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1094,  }]\n",
      "Training on Total Epoch: 805, Round: 805\n",
      "Evalset: [Train : Metrics { logloss:0.0971,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1432,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1094,  }]\n",
      "Training on Total Epoch: 806, Round: 806\n",
      "Evalset: [Train : Metrics { logloss:0.097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1431,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1093,  }]\n",
      "Training on Total Epoch: 807, Round: 807\n",
      "Evalset: [Train : Metrics { logloss:0.0969,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.143,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1092,  }]\n",
      "Training on Total Epoch: 808, Round: 808\n",
      "Evalset: [Train : Metrics { logloss:0.0967,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.143,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1091,  }]\n",
      "Training on Total Epoch: 809, Round: 809\n",
      "Evalset: [Train : Metrics { logloss:0.0966,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.143,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.109,  }]\n",
      "Training on Total Epoch: 810, Round: 810\n",
      "Evalset: [Train : Metrics { logloss:0.0965,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1428,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1089,  }]\n",
      "Training on Total Epoch: 811, Round: 811\n",
      "Evalset: [Train : Metrics { logloss:0.0963,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1425,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1087,  }]\n",
      "Training on Total Epoch: 812, Round: 812\n",
      "Evalset: [Train : Metrics { logloss:0.0962,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1424,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1086,  }]\n",
      "Training on Total Epoch: 813, Round: 813\n",
      "Evalset: [Train : Metrics { logloss:0.0961,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1423,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1085,  }]\n",
      "Training on Total Epoch: 814, Round: 814\n",
      "Evalset: [Train : Metrics { logloss:0.096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.142,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1084,  }]\n",
      "Training on Total Epoch: 815, Round: 815\n",
      "Evalset: [Train : Metrics { logloss:0.0958,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1417,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1083,  }]\n",
      "Training on Total Epoch: 816, Round: 816\n",
      "Evalset: [Train : Metrics { logloss:0.0957,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1083,  }]\n",
      "Training on Total Epoch: 817, Round: 817\n",
      "Evalset: [Train : Metrics { logloss:0.0956,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1418,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1083,  }]\n",
      "Training on Total Epoch: 818, Round: 818\n",
      "Evalset: [Train : Metrics { logloss:0.0954,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1418,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1082,  }]\n",
      "Training on Total Epoch: 819, Round: 819\n",
      "Evalset: [Train : Metrics { logloss:0.0953,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1417,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1081,  }]\n",
      "Training on Total Epoch: 820, Round: 820\n",
      "Evalset: [Train : Metrics { logloss:0.0952,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1079,  }]\n",
      "Training on Total Epoch: 821, Round: 821\n",
      "Evalset: [Train : Metrics { logloss:0.0951,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1078,  }]\n",
      "Training on Total Epoch: 822, Round: 822\n",
      "Evalset: [Train : Metrics { logloss:0.0949,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1077,  }]\n",
      "Training on Total Epoch: 823, Round: 823\n",
      "Evalset: [Train : Metrics { logloss:0.0948,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1076,  }]\n",
      "Training on Total Epoch: 824, Round: 824\n",
      "Evalset: [Train : Metrics { logloss:0.0947,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1415,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1076,  }]\n",
      "Training on Total Epoch: 825, Round: 825\n",
      "Evalset: [Train : Metrics { logloss:0.0945,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1075,  }]\n",
      "Training on Total Epoch: 826, Round: 826\n",
      "Evalset: [Train : Metrics { logloss:0.0944,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1414,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1074,  }]\n",
      "Training on Total Epoch: 827, Round: 827\n",
      "Evalset: [Train : Metrics { logloss:0.0943,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1413,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1074,  }]\n",
      "Training on Total Epoch: 828, Round: 828\n",
      "Evalset: [Train : Metrics { logloss:0.0942,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1412,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1074,  }]\n",
      "Training on Total Epoch: 829, Round: 829\n",
      "Evalset: [Train : Metrics { logloss:0.094,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.141,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1074,  }]\n",
      "Training on Total Epoch: 830, Round: 830\n",
      "Evalset: [Train : Metrics { logloss:0.0939,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.141,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1074,  }]\n",
      "Training on Total Epoch: 831, Round: 831\n",
      "Evalset: [Train : Metrics { logloss:0.0938,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1408,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1073,  }]\n",
      "Training on Total Epoch: 832, Round: 832\n",
      "Evalset: [Train : Metrics { logloss:0.0937,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1406,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1071,  }]\n",
      "Training on Total Epoch: 833, Round: 833\n",
      "Evalset: [Train : Metrics { logloss:0.0936,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1405,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1068,  }]\n",
      "Training on Total Epoch: 834, Round: 834\n",
      "Evalset: [Train : Metrics { logloss:0.0934,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1406,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1066,  }]\n",
      "Training on Total Epoch: 835, Round: 835\n",
      "Evalset: [Train : Metrics { logloss:0.0933,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1408,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1065,  }]\n",
      "Training on Total Epoch: 836, Round: 836\n",
      "Evalset: [Train : Metrics { logloss:0.0932,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1065,  }]\n",
      "Training on Total Epoch: 837, Round: 837\n",
      "Evalset: [Train : Metrics { logloss:0.093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1066,  }]\n",
      "Training on Total Epoch: 838, Round: 838\n",
      "Evalset: [Train : Metrics { logloss:0.0929,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1067,  }]\n",
      "Training on Total Epoch: 839, Round: 839\n",
      "Evalset: [Train : Metrics { logloss:0.0928,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1411,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1067,  }]\n",
      "Training on Total Epoch: 840, Round: 840\n",
      "Evalset: [Train : Metrics { logloss:0.0927,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1066,  }]\n",
      "Training on Total Epoch: 841, Round: 841\n",
      "Evalset: [Train : Metrics { logloss:0.0926,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1407,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1064,  }]\n",
      "Training on Total Epoch: 842, Round: 842\n",
      "Evalset: [Train : Metrics { logloss:0.0925,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1407,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1063,  }]\n",
      "Training on Total Epoch: 843, Round: 843\n",
      "Evalset: [Train : Metrics { logloss:0.0923,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1404,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1061,  }]\n",
      "Training on Total Epoch: 844, Round: 844\n",
      "Evalset: [Train : Metrics { logloss:0.0922,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1402,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1061,  }]\n",
      "Training on Total Epoch: 845, Round: 845\n",
      "Evalset: [Train : Metrics { logloss:0.0921,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1403,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1061,  }]\n",
      "Training on Total Epoch: 846, Round: 846\n",
      "Evalset: [Train : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1403,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.106,  }]\n",
      "Training on Total Epoch: 847, Round: 847\n",
      "Evalset: [Train : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1402,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.106,  }]\n",
      "Training on Total Epoch: 848, Round: 848\n",
      "Evalset: [Train : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.14,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1058,  }]\n",
      "Training on Total Epoch: 849, Round: 849\n",
      "Evalset: [Train : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1399,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1057,  }]\n",
      "Training on Total Epoch: 850, Round: 850\n",
      "Evalset: [Train : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1398,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1057,  }]\n",
      "Training on Total Epoch: 851, Round: 851\n",
      "Evalset: [Train : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1398,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1055,  }]\n",
      "Training on Total Epoch: 852, Round: 852\n",
      "Evalset: [Train : Metrics { logloss:0.0912,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1395,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1055,  }]\n",
      "Training on Total Epoch: 853, Round: 853\n",
      "Evalset: [Train : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1394,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1054,  }]\n",
      "Training on Total Epoch: 854, Round: 854\n",
      "Evalset: [Train : Metrics { logloss:0.091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1395,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1053,  }]\n",
      "Training on Total Epoch: 855, Round: 855\n",
      "Evalset: [Train : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1395,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1052,  }]\n",
      "Training on Total Epoch: 856, Round: 856\n",
      "Evalset: [Train : Metrics { logloss:0.0908,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1395,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1051,  }]\n",
      "Training on Total Epoch: 857, Round: 857\n",
      "Evalset: [Train : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1395,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1049,  }]\n",
      "Training on Total Epoch: 858, Round: 858\n",
      "Evalset: [Train : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1394,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1049,  }]\n",
      "Training on Total Epoch: 859, Round: 859\n",
      "Evalset: [Train : Metrics { logloss:0.0904,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1394,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1049,  }]\n",
      "Training on Total Epoch: 860, Round: 860\n",
      "Evalset: [Train : Metrics { logloss:0.0903,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1394,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1048,  }]\n",
      "Training on Total Epoch: 861, Round: 861\n",
      "Evalset: [Train : Metrics { logloss:0.0902,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1394,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1048,  }]\n",
      "Training on Total Epoch: 862, Round: 862\n",
      "Evalset: [Train : Metrics { logloss:0.0901,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1393,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1048,  }]\n",
      "Training on Total Epoch: 863, Round: 863\n",
      "Evalset: [Train : Metrics { logloss:0.09,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1392,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1047,  }]\n",
      "Training on Total Epoch: 864, Round: 864\n",
      "Evalset: [Train : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.139,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1046,  }]\n",
      "Training on Total Epoch: 865, Round: 865\n",
      "Evalset: [Train : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1389,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1045,  }]\n",
      "Training on Total Epoch: 866, Round: 866\n",
      "Evalset: [Train : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1388,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1044,  }]\n",
      "Training on Total Epoch: 867, Round: 867\n",
      "Evalset: [Train : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1387,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1043,  }]\n",
      "Training on Total Epoch: 868, Round: 868\n",
      "Evalset: [Train : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1386,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1044,  }]\n",
      "Training on Total Epoch: 869, Round: 869\n",
      "Evalset: [Train : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1043,  }]\n",
      "Training on Total Epoch: 870, Round: 870\n",
      "Evalset: [Train : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1382,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1042,  }]\n",
      "Training on Total Epoch: 871, Round: 871\n",
      "Evalset: [Train : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1381,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1042,  }]\n",
      "Training on Total Epoch: 872, Round: 872\n",
      "Evalset: [Train : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.138,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1042,  }]\n",
      "Training on Total Epoch: 873, Round: 873\n",
      "Evalset: [Train : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.138,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1041,  }]\n",
      "Training on Total Epoch: 874, Round: 874\n",
      "Evalset: [Train : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1381,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.104,  }]\n",
      "Training on Total Epoch: 875, Round: 875\n",
      "Evalset: [Train : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1383,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.104,  }]\n",
      "Training on Total Epoch: 876, Round: 876\n",
      "Evalset: [Train : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1383,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1038,  }]\n",
      "Training on Total Epoch: 877, Round: 877\n",
      "Evalset: [Train : Metrics { logloss:0.0883,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 878, Round: 878\n",
      "Evalset: [Train : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1383,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 879, Round: 879\n",
      "Evalset: [Train : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1382,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 880, Round: 880\n",
      "Evalset: [Train : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1382,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 881, Round: 881\n",
      "Evalset: [Train : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1379,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1035,  }]\n",
      "Training on Total Epoch: 882, Round: 882\n",
      "Evalset: [Train : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1034,  }]\n",
      "Training on Total Epoch: 883, Round: 883\n",
      "Evalset: [Train : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1375,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1033,  }]\n",
      "Training on Total Epoch: 884, Round: 884\n",
      "Evalset: [Train : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1374,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1031,  }]\n",
      "Training on Total Epoch: 885, Round: 885\n",
      "Evalset: [Train : Metrics { logloss:0.0875,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1375,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.103,  }]\n",
      "Training on Total Epoch: 886, Round: 886\n",
      "Evalset: [Train : Metrics { logloss:0.0873,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1375,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.103,  }]\n",
      "Training on Total Epoch: 887, Round: 887\n",
      "Evalset: [Train : Metrics { logloss:0.0872,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1375,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.103,  }]\n",
      "Training on Total Epoch: 888, Round: 888\n",
      "Evalset: [Train : Metrics { logloss:0.0871,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1031,  }]\n",
      "Training on Total Epoch: 889, Round: 889\n",
      "Evalset: [Train : Metrics { logloss:0.087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1375,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1029,  }]\n",
      "Training on Total Epoch: 890, Round: 890\n",
      "Evalset: [Train : Metrics { logloss:0.0869,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1374,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1029,  }]\n",
      "Training on Total Epoch: 891, Round: 891\n",
      "Evalset: [Train : Metrics { logloss:0.0868,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1372,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 892, Round: 892\n",
      "Evalset: [Train : Metrics { logloss:0.0867,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1371,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 893, Round: 893\n",
      "Evalset: [Train : Metrics { logloss:0.0866,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1372,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1028,  }]\n",
      "Training on Total Epoch: 894, Round: 894\n",
      "Evalset: [Train : Metrics { logloss:0.0865,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1371,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 895, Round: 895\n",
      "Evalset: [Train : Metrics { logloss:0.0864,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1369,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 896, Round: 896\n",
      "Evalset: [Train : Metrics { logloss:0.0863,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1369,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1025,  }]\n",
      "Training on Total Epoch: 897, Round: 897\n",
      "Evalset: [Train : Metrics { logloss:0.0861,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1369,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1024,  }]\n",
      "Training on Total Epoch: 898, Round: 898\n",
      "Evalset: [Train : Metrics { logloss:0.086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1367,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1023,  }]\n",
      "Training on Total Epoch: 899, Round: 899\n",
      "Evalset: [Train : Metrics { logloss:0.0859,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1366,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1023,  }]\n",
      "Training on Total Epoch: 900, Round: 900\n",
      "Evalset: [Train : Metrics { logloss:0.0858,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1022,  }]\n",
      "Training on Total Epoch: 901, Round: 901\n",
      "Evalset: [Train : Metrics { logloss:0.0857,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1021,  }]\n",
      "Training on Total Epoch: 902, Round: 902\n",
      "Evalset: [Train : Metrics { logloss:0.0856,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1366,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1021,  }]\n",
      "Training on Total Epoch: 903, Round: 903\n",
      "Evalset: [Train : Metrics { logloss:0.0855,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1367,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1021,  }]\n",
      "Training on Total Epoch: 904, Round: 904\n",
      "Evalset: [Train : Metrics { logloss:0.0854,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1367,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1021,  }]\n",
      "Training on Total Epoch: 905, Round: 905\n",
      "Evalset: [Train : Metrics { logloss:0.0853,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1367,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1021,  }]\n",
      "Training on Total Epoch: 906, Round: 906\n",
      "Evalset: [Train : Metrics { logloss:0.0852,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.102,  }]\n",
      "Training on Total Epoch: 907, Round: 907\n",
      "Evalset: [Train : Metrics { logloss:0.0851,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1364,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1019,  }]\n",
      "Training on Total Epoch: 908, Round: 908\n",
      "Evalset: [Train : Metrics { logloss:0.085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1364,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1018,  }]\n",
      "Training on Total Epoch: 909, Round: 909\n",
      "Evalset: [Train : Metrics { logloss:0.0849,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1362,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1016,  }]\n",
      "Training on Total Epoch: 910, Round: 910\n",
      "Evalset: [Train : Metrics { logloss:0.0848,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1361,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1014,  }]\n",
      "Training on Total Epoch: 911, Round: 911\n",
      "Evalset: [Train : Metrics { logloss:0.0847,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.136,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1014,  }]\n",
      "Training on Total Epoch: 912, Round: 912\n",
      "Evalset: [Train : Metrics { logloss:0.0845,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.136,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1014,  }]\n",
      "Training on Total Epoch: 913, Round: 913\n",
      "Evalset: [Train : Metrics { logloss:0.0844,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.136,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1013,  }]\n",
      "Training on Total Epoch: 914, Round: 914\n",
      "Evalset: [Train : Metrics { logloss:0.0843,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.136,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1014,  }]\n",
      "Training on Total Epoch: 915, Round: 915\n",
      "Evalset: [Train : Metrics { logloss:0.0842,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1013,  }]\n",
      "Training on Total Epoch: 916, Round: 916\n",
      "Evalset: [Train : Metrics { logloss:0.0841,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1012,  }]\n",
      "Training on Total Epoch: 917, Round: 917\n",
      "Evalset: [Train : Metrics { logloss:0.084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1011,  }]\n",
      "Training on Total Epoch: 918, Round: 918\n",
      "Evalset: [Train : Metrics { logloss:0.0839,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1012,  }]\n",
      "Training on Total Epoch: 919, Round: 919\n",
      "Evalset: [Train : Metrics { logloss:0.0838,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1012,  }]\n",
      "Training on Total Epoch: 920, Round: 920\n",
      "Evalset: [Train : Metrics { logloss:0.0837,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1011,  }]\n",
      "Training on Total Epoch: 921, Round: 921\n",
      "Evalset: [Train : Metrics { logloss:0.0836,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.101,  }]\n",
      "Training on Total Epoch: 922, Round: 922\n",
      "Evalset: [Train : Metrics { logloss:0.0835,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1009,  }]\n",
      "Training on Total Epoch: 923, Round: 923\n",
      "Evalset: [Train : Metrics { logloss:0.0834,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1009,  }]\n",
      "Training on Total Epoch: 924, Round: 924\n",
      "Evalset: [Train : Metrics { logloss:0.0833,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1007,  }]\n",
      "Training on Total Epoch: 925, Round: 925\n",
      "Evalset: [Train : Metrics { logloss:0.0832,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1005,  }]\n",
      "Training on Total Epoch: 926, Round: 926\n",
      "Evalset: [Train : Metrics { logloss:0.0831,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1004,  }]\n",
      "Training on Total Epoch: 927, Round: 927\n",
      "Evalset: [Train : Metrics { logloss:0.083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1003,  }]\n",
      "Training on Total Epoch: 928, Round: 928\n",
      "Evalset: [Train : Metrics { logloss:0.0829,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1003,  }]\n",
      "Training on Total Epoch: 929, Round: 929\n",
      "Evalset: [Train : Metrics { logloss:0.0828,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1003,  }]\n",
      "Training on Total Epoch: 930, Round: 930\n",
      "Evalset: [Train : Metrics { logloss:0.0827,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1004,  }]\n",
      "Training on Total Epoch: 931, Round: 931\n",
      "Evalset: [Train : Metrics { logloss:0.0826,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1004,  }]\n",
      "Training on Total Epoch: 932, Round: 932\n",
      "Evalset: [Train : Metrics { logloss:0.0825,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1005,  }]\n",
      "Training on Total Epoch: 933, Round: 933\n",
      "Evalset: [Train : Metrics { logloss:0.0824,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1004,  }]\n",
      "Training on Total Epoch: 934, Round: 934\n",
      "Evalset: [Train : Metrics { logloss:0.0823,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1003,  }]\n",
      "Training on Total Epoch: 935, Round: 935\n",
      "Evalset: [Train : Metrics { logloss:0.0822,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1001,  }]\n",
      "Training on Total Epoch: 936, Round: 936\n",
      "Evalset: [Train : Metrics { logloss:0.0821,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1,  }]\n",
      "Training on Total Epoch: 937, Round: 937\n",
      "Evalset: [Train : Metrics { logloss:0.082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0999,  }]\n",
      "Training on Total Epoch: 938, Round: 938\n",
      "Evalset: [Train : Metrics { logloss:0.0819,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1,  }]\n",
      "Training on Total Epoch: 939, Round: 939\n",
      "Evalset: [Train : Metrics { logloss:0.0818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1001,  }]\n",
      "Training on Total Epoch: 940, Round: 940\n",
      "Evalset: [Train : Metrics { logloss:0.0817,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1,  }]\n",
      "Training on Total Epoch: 941, Round: 941\n",
      "Evalset: [Train : Metrics { logloss:0.0816,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0998,  }]\n",
      "Training on Total Epoch: 942, Round: 942\n",
      "Evalset: [Train : Metrics { logloss:0.0815,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0996,  }]\n",
      "Training on Total Epoch: 943, Round: 943\n",
      "Evalset: [Train : Metrics { logloss:0.0814,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0996,  }]\n",
      "Training on Total Epoch: 944, Round: 944\n",
      "Evalset: [Train : Metrics { logloss:0.0813,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0995,  }]\n",
      "Training on Total Epoch: 945, Round: 945\n",
      "Evalset: [Train : Metrics { logloss:0.0812,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0995,  }]\n",
      "Training on Total Epoch: 946, Round: 946\n",
      "Evalset: [Train : Metrics { logloss:0.0811,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0994,  }]\n",
      "Training on Total Epoch: 947, Round: 947\n",
      "Evalset: [Train : Metrics { logloss:0.0811,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0992,  }]\n",
      "Training on Total Epoch: 948, Round: 948\n",
      "Evalset: [Train : Metrics { logloss:0.081,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0992,  }]\n",
      "Training on Total Epoch: 949, Round: 949\n",
      "Evalset: [Train : Metrics { logloss:0.0808,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0993,  }]\n",
      "Training on Total Epoch: 950, Round: 950\n",
      "Evalset: [Train : Metrics { logloss:0.0807,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1343,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0993,  }]\n",
      "Training on Total Epoch: 951, Round: 951\n",
      "Evalset: [Train : Metrics { logloss:0.0806,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1342,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0993,  }]\n",
      "Training on Total Epoch: 952, Round: 952\n",
      "Evalset: [Train : Metrics { logloss:0.0805,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0994,  }]\n",
      "Training on Total Epoch: 953, Round: 953\n",
      "Evalset: [Train : Metrics { logloss:0.0804,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0993,  }]\n",
      "Training on Total Epoch: 954, Round: 954\n",
      "Evalset: [Train : Metrics { logloss:0.0803,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0993,  }]\n",
      "Training on Total Epoch: 955, Round: 955\n",
      "Evalset: [Train : Metrics { logloss:0.0802,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0993,  }]\n",
      "Training on Total Epoch: 956, Round: 956\n",
      "Evalset: [Train : Metrics { logloss:0.0802,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0992,  }]\n",
      "Training on Total Epoch: 957, Round: 957\n",
      "Evalset: [Train : Metrics { logloss:0.08,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0991,  }]\n",
      "Training on Total Epoch: 958, Round: 958\n",
      "Evalset: [Train : Metrics { logloss:0.0799,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.099,  }]\n",
      "Training on Total Epoch: 959, Round: 959\n",
      "Evalset: [Train : Metrics { logloss:0.0798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.099,  }]\n",
      "Training on Total Epoch: 960, Round: 960\n",
      "Evalset: [Train : Metrics { logloss:0.0797,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0989,  }]\n",
      "Training on Total Epoch: 961, Round: 961\n",
      "Evalset: [Train : Metrics { logloss:0.0797,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0987,  }]\n",
      "Training on Total Epoch: 962, Round: 962\n",
      "Evalset: [Train : Metrics { logloss:0.0796,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0987,  }]\n",
      "Training on Total Epoch: 963, Round: 963\n",
      "Evalset: [Train : Metrics { logloss:0.0795,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0985,  }]\n",
      "Training on Total Epoch: 964, Round: 964\n",
      "Evalset: [Train : Metrics { logloss:0.0794,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0985,  }]\n",
      "Training on Total Epoch: 965, Round: 965\n",
      "Evalset: [Train : Metrics { logloss:0.0793,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0986,  }]\n",
      "Training on Total Epoch: 966, Round: 966\n",
      "Evalset: [Train : Metrics { logloss:0.0792,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0986,  }]\n",
      "Training on Total Epoch: 967, Round: 967\n",
      "Evalset: [Train : Metrics { logloss:0.0791,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0985,  }]\n",
      "Training on Total Epoch: 968, Round: 968\n",
      "Evalset: [Train : Metrics { logloss:0.079,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0985,  }]\n",
      "Training on Total Epoch: 969, Round: 969\n",
      "Evalset: [Train : Metrics { logloss:0.0789,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0984,  }]\n",
      "Training on Total Epoch: 970, Round: 970\n",
      "Evalset: [Train : Metrics { logloss:0.0788,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0984,  }]\n",
      "Training on Total Epoch: 971, Round: 971\n",
      "Evalset: [Train : Metrics { logloss:0.0787,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0984,  }]\n",
      "Training on Total Epoch: 972, Round: 972\n",
      "Evalset: [Train : Metrics { logloss:0.0786,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0982,  }]\n",
      "Training on Total Epoch: 973, Round: 973\n",
      "Evalset: [Train : Metrics { logloss:0.0785,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0982,  }]\n",
      "Training on Total Epoch: 974, Round: 974\n",
      "Evalset: [Train : Metrics { logloss:0.0784,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0981,  }]\n",
      "Training on Total Epoch: 975, Round: 975\n",
      "Evalset: [Train : Metrics { logloss:0.0783,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0982,  }]\n",
      "Training on Total Epoch: 976, Round: 976\n",
      "Evalset: [Train : Metrics { logloss:0.0783,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0981,  }]\n",
      "Training on Total Epoch: 977, Round: 977\n",
      "Evalset: [Train : Metrics { logloss:0.0782,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.098,  }]\n",
      "Training on Total Epoch: 978, Round: 978\n",
      "Evalset: [Train : Metrics { logloss:0.0781,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0978,  }]\n",
      "Training on Total Epoch: 979, Round: 979\n",
      "Evalset: [Train : Metrics { logloss:0.078,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0978,  }]\n",
      "Training on Total Epoch: 980, Round: 980\n",
      "Evalset: [Train : Metrics { logloss:0.0779,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0978,  }]\n",
      "Training on Total Epoch: 981, Round: 981\n",
      "Evalset: [Train : Metrics { logloss:0.0778,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0979,  }]\n",
      "Training on Total Epoch: 982, Round: 982\n",
      "Evalset: [Train : Metrics { logloss:0.0777,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0979,  }]\n",
      "Training on Total Epoch: 983, Round: 983\n",
      "Evalset: [Train : Metrics { logloss:0.0776,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0978,  }]\n",
      "Training on Total Epoch: 984, Round: 984\n",
      "Evalset: [Train : Metrics { logloss:0.0775,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0977,  }]\n",
      "Training on Total Epoch: 985, Round: 985\n",
      "Evalset: [Train : Metrics { logloss:0.0774,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0977,  }]\n",
      "Training on Total Epoch: 986, Round: 986\n",
      "Evalset: [Train : Metrics { logloss:0.0773,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0976,  }]\n",
      "Training on Total Epoch: 987, Round: 987\n",
      "Evalset: [Train : Metrics { logloss:0.0772,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0976,  }]\n",
      "Training on Total Epoch: 988, Round: 988\n",
      "Evalset: [Train : Metrics { logloss:0.0772,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0976,  }]\n",
      "Training on Total Epoch: 989, Round: 989\n",
      "Evalset: [Train : Metrics { logloss:0.0771,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0975,  }]\n",
      "Training on Total Epoch: 990, Round: 990\n",
      "Evalset: [Train : Metrics { logloss:0.077,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0975,  }]\n",
      "Training on Total Epoch: 991, Round: 991\n",
      "Evalset: [Train : Metrics { logloss:0.0769,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0974,  }]\n",
      "Training on Total Epoch: 992, Round: 992\n",
      "Evalset: [Train : Metrics { logloss:0.0768,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0975,  }]\n",
      "Training on Total Epoch: 993, Round: 993\n",
      "Evalset: [Train : Metrics { logloss:0.0767,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0976,  }]\n",
      "Training on Total Epoch: 994, Round: 994\n",
      "Evalset: [Train : Metrics { logloss:0.0766,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0974,  }]\n",
      "Training on Total Epoch: 995, Round: 995\n",
      "Evalset: [Train : Metrics { logloss:0.0765,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0973,  }]\n",
      "Training on Total Epoch: 996, Round: 996\n",
      "Evalset: [Train : Metrics { logloss:0.0765,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0973,  }]\n",
      "Training on Total Epoch: 997, Round: 997\n",
      "Evalset: [Train : Metrics { logloss:0.0764,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0972,  }]\n",
      "Training on Total Epoch: 998, Round: 998\n",
      "Evalset: [Train : Metrics { logloss:0.0763,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0973,  }]\n",
      "Training on Total Epoch: 999, Round: 999\n",
      "Evalset: [Train : Metrics { logloss:0.0762,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0972,  }]\n",
      "Training on Total Epoch: 1000, Round: 1000\n",
      "Evalset: [Train : Metrics { logloss:0.0761,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0971,  }]\n",
      "Training on Total Epoch: 1001, Round: 1001\n",
      "Evalset: [Train : Metrics { logloss:0.076,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0969,  }]\n",
      "Training on Total Epoch: 1002, Round: 1002\n",
      "Evalset: [Train : Metrics { logloss:0.0759,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0969,  }]\n",
      "Training on Total Epoch: 1003, Round: 1003\n",
      "Evalset: [Train : Metrics { logloss:0.0758,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0969,  }]\n",
      "Training on Total Epoch: 1004, Round: 1004\n",
      "Evalset: [Train : Metrics { logloss:0.0758,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0969,  }]\n",
      "Training on Total Epoch: 1005, Round: 1005\n",
      "Evalset: [Train : Metrics { logloss:0.0757,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0969,  }]\n",
      "Training on Total Epoch: 1006, Round: 1006\n",
      "Evalset: [Train : Metrics { logloss:0.0756,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0968,  }]\n",
      "Training on Total Epoch: 1007, Round: 1007\n",
      "Evalset: [Train : Metrics { logloss:0.0755,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1008, Round: 1008\n",
      "Evalset: [Train : Metrics { logloss:0.0754,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1009, Round: 1009\n",
      "Evalset: [Train : Metrics { logloss:0.0753,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0967,  }]\n",
      "Training on Total Epoch: 1010, Round: 1010\n",
      "Evalset: [Train : Metrics { logloss:0.0752,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1011, Round: 1011\n",
      "Evalset: [Train : Metrics { logloss:0.0751,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1012, Round: 1012\n",
      "Evalset: [Train : Metrics { logloss:0.075,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0965,  }]\n",
      "Training on Total Epoch: 1013, Round: 1013\n",
      "Evalset: [Train : Metrics { logloss:0.0749,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0964,  }]\n",
      "Training on Total Epoch: 1014, Round: 1014\n",
      "Evalset: [Train : Metrics { logloss:0.0749,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0962,  }]\n",
      "Training on Total Epoch: 1015, Round: 1015\n",
      "Evalset: [Train : Metrics { logloss:0.0748,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0961,  }]\n",
      "Training on Total Epoch: 1016, Round: 1016\n",
      "Evalset: [Train : Metrics { logloss:0.0747,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0961,  }]\n",
      "Training on Total Epoch: 1017, Round: 1017\n",
      "Evalset: [Train : Metrics { logloss:0.0746,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0962,  }]\n",
      "Training on Total Epoch: 1018, Round: 1018\n",
      "Evalset: [Train : Metrics { logloss:0.0745,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0962,  }]\n",
      "Training on Total Epoch: 1019, Round: 1019\n",
      "Evalset: [Train : Metrics { logloss:0.0744,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0962,  }]\n",
      "Training on Total Epoch: 1020, Round: 1020\n",
      "Evalset: [Train : Metrics { logloss:0.0743,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0961,  }]\n",
      "Training on Total Epoch: 1021, Round: 1021\n",
      "Evalset: [Train : Metrics { logloss:0.0743,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0961,  }]\n",
      "Training on Total Epoch: 1022, Round: 1022\n",
      "Evalset: [Train : Metrics { logloss:0.0742,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0961,  }]\n",
      "Training on Total Epoch: 1023, Round: 1023\n",
      "Evalset: [Train : Metrics { logloss:0.0741,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0961,  }]\n",
      "Training on Total Epoch: 1024, Round: 1024\n",
      "Evalset: [Train : Metrics { logloss:0.074,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0961,  }]\n",
      "Training on Total Epoch: 1025, Round: 1025\n",
      "Evalset: [Train : Metrics { logloss:0.0739,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.096,  }]\n",
      "Training on Total Epoch: 1026, Round: 1026\n",
      "Evalset: [Train : Metrics { logloss:0.0738,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0959,  }]\n",
      "Training on Total Epoch: 1027, Round: 1027\n",
      "Evalset: [Train : Metrics { logloss:0.0737,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0958,  }]\n",
      "Training on Total Epoch: 1028, Round: 1028\n",
      "Evalset: [Train : Metrics { logloss:0.0737,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0956,  }]\n",
      "Training on Total Epoch: 1029, Round: 1029\n",
      "Evalset: [Train : Metrics { logloss:0.0736,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0956,  }]\n",
      "Training on Total Epoch: 1030, Round: 1030\n",
      "Evalset: [Train : Metrics { logloss:0.0735,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0956,  }]\n",
      "Training on Total Epoch: 1031, Round: 1031\n",
      "Evalset: [Train : Metrics { logloss:0.0734,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0956,  }]\n",
      "Training on Total Epoch: 1032, Round: 1032\n",
      "Evalset: [Train : Metrics { logloss:0.0733,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0957,  }]\n",
      "Training on Total Epoch: 1033, Round: 1033\n",
      "Evalset: [Train : Metrics { logloss:0.0732,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0957,  }]\n",
      "Training on Total Epoch: 1034, Round: 1034\n",
      "Evalset: [Train : Metrics { logloss:0.0731,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0956,  }]\n",
      "Training on Total Epoch: 1035, Round: 1035\n",
      "Evalset: [Train : Metrics { logloss:0.0731,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0955,  }]\n",
      "Training on Total Epoch: 1036, Round: 1036\n",
      "Evalset: [Train : Metrics { logloss:0.073,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0954,  }]\n",
      "Training on Total Epoch: 1037, Round: 1037\n",
      "Evalset: [Train : Metrics { logloss:0.0729,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0954,  }]\n",
      "Training on Total Epoch: 1038, Round: 1038\n",
      "Evalset: [Train : Metrics { logloss:0.0728,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0953,  }]\n",
      "Training on Total Epoch: 1039, Round: 1039\n",
      "Evalset: [Train : Metrics { logloss:0.0727,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0954,  }]\n",
      "Training on Total Epoch: 1040, Round: 1040\n",
      "Evalset: [Train : Metrics { logloss:0.0727,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1041, Round: 1041\n",
      "Evalset: [Train : Metrics { logloss:0.0726,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1042, Round: 1042\n",
      "Evalset: [Train : Metrics { logloss:0.0725,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1043, Round: 1043\n",
      "Evalset: [Train : Metrics { logloss:0.0724,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1044, Round: 1044\n",
      "Evalset: [Train : Metrics { logloss:0.0724,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1045, Round: 1045\n",
      "Evalset: [Train : Metrics { logloss:0.0723,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1046, Round: 1046\n",
      "Evalset: [Train : Metrics { logloss:0.0722,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1047, Round: 1047\n",
      "Evalset: [Train : Metrics { logloss:0.0721,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1048, Round: 1048\n",
      "Evalset: [Train : Metrics { logloss:0.072,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1049, Round: 1049\n",
      "Evalset: [Train : Metrics { logloss:0.0719,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1050, Round: 1050\n",
      "Evalset: [Train : Metrics { logloss:0.0718,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0951,  }]\n",
      "Training on Total Epoch: 1051, Round: 1051\n",
      "Evalset: [Train : Metrics { logloss:0.0718,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1052, Round: 1052\n",
      "Evalset: [Train : Metrics { logloss:0.0717,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1053, Round: 1053\n",
      "Evalset: [Train : Metrics { logloss:0.0716,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0949,  }]\n",
      "Training on Total Epoch: 1054, Round: 1054\n",
      "Evalset: [Train : Metrics { logloss:0.0715,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0947,  }]\n",
      "Training on Total Epoch: 1055, Round: 1055\n",
      "Evalset: [Train : Metrics { logloss:0.0714,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0946,  }]\n",
      "Training on Total Epoch: 1056, Round: 1056\n",
      "Evalset: [Train : Metrics { logloss:0.0714,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0944,  }]\n",
      "Training on Total Epoch: 1057, Round: 1057\n",
      "Evalset: [Train : Metrics { logloss:0.0713,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0944,  }]\n",
      "Training on Total Epoch: 1058, Round: 1058\n",
      "Evalset: [Train : Metrics { logloss:0.0712,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0946,  }]\n",
      "Training on Total Epoch: 1059, Round: 1059\n",
      "Evalset: [Train : Metrics { logloss:0.0711,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0946,  }]\n",
      "Training on Total Epoch: 1060, Round: 1060\n",
      "Evalset: [Train : Metrics { logloss:0.071,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0945,  }]\n",
      "Training on Total Epoch: 1061, Round: 1061\n",
      "Evalset: [Train : Metrics { logloss:0.071,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0945,  }]\n",
      "Training on Total Epoch: 1062, Round: 1062\n",
      "Evalset: [Train : Metrics { logloss:0.0709,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0944,  }]\n",
      "Training on Total Epoch: 1063, Round: 1063\n",
      "Evalset: [Train : Metrics { logloss:0.0708,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1064, Round: 1064\n",
      "Evalset: [Train : Metrics { logloss:0.0707,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1065, Round: 1065\n",
      "Evalset: [Train : Metrics { logloss:0.0707,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1066, Round: 1066\n",
      "Evalset: [Train : Metrics { logloss:0.0706,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1067, Round: 1067\n",
      "Evalset: [Train : Metrics { logloss:0.0705,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0943,  }]\n",
      "Training on Total Epoch: 1068, Round: 1068\n",
      "Evalset: [Train : Metrics { logloss:0.0704,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0944,  }]\n",
      "Training on Total Epoch: 1069, Round: 1069\n",
      "Evalset: [Train : Metrics { logloss:0.0703,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1070, Round: 1070\n",
      "Evalset: [Train : Metrics { logloss:0.0702,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1071, Round: 1071\n",
      "Evalset: [Train : Metrics { logloss:0.0702,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1072, Round: 1072\n",
      "Evalset: [Train : Metrics { logloss:0.0701,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1073, Round: 1073\n",
      "Evalset: [Train : Metrics { logloss:0.07,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1074, Round: 1074\n",
      "Evalset: [Train : Metrics { logloss:0.07,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1075, Round: 1075\n",
      "Evalset: [Train : Metrics { logloss:0.0699,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1076, Round: 1076\n",
      "Evalset: [Train : Metrics { logloss:0.0698,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0942,  }]\n",
      "Training on Total Epoch: 1077, Round: 1077\n",
      "Evalset: [Train : Metrics { logloss:0.0697,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1078, Round: 1078\n",
      "Evalset: [Train : Metrics { logloss:0.0696,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1079, Round: 1079\n",
      "Evalset: [Train : Metrics { logloss:0.0696,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1080, Round: 1080\n",
      "Evalset: [Train : Metrics { logloss:0.0695,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.094,  }]\n",
      "Training on Total Epoch: 1081, Round: 1081\n",
      "Evalset: [Train : Metrics { logloss:0.0694,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0939,  }]\n",
      "Training on Total Epoch: 1082, Round: 1082\n",
      "Evalset: [Train : Metrics { logloss:0.0693,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0938,  }]\n",
      "Training on Total Epoch: 1083, Round: 1083\n",
      "Evalset: [Train : Metrics { logloss:0.0693,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0937,  }]\n",
      "Training on Total Epoch: 1084, Round: 1084\n",
      "Evalset: [Train : Metrics { logloss:0.0692,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0936,  }]\n",
      "Training on Total Epoch: 1085, Round: 1085\n",
      "Evalset: [Train : Metrics { logloss:0.0691,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0936,  }]\n",
      "Training on Total Epoch: 1086, Round: 1086\n",
      "Evalset: [Train : Metrics { logloss:0.069,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0937,  }]\n",
      "Training on Total Epoch: 1087, Round: 1087\n",
      "Evalset: [Train : Metrics { logloss:0.0689,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0937,  }]\n",
      "Training on Total Epoch: 1088, Round: 1088\n",
      "Evalset: [Train : Metrics { logloss:0.0689,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0936,  }]\n",
      "Training on Total Epoch: 1089, Round: 1089\n",
      "Evalset: [Train : Metrics { logloss:0.0688,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0937,  }]\n",
      "Training on Total Epoch: 1090, Round: 1090\n",
      "Evalset: [Train : Metrics { logloss:0.0687,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0935,  }]\n",
      "Training on Total Epoch: 1091, Round: 1091\n",
      "Evalset: [Train : Metrics { logloss:0.0686,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1092, Round: 1092\n",
      "Evalset: [Train : Metrics { logloss:0.0686,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1093, Round: 1093\n",
      "Evalset: [Train : Metrics { logloss:0.0685,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1094, Round: 1094\n",
      "Evalset: [Train : Metrics { logloss:0.0684,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0935,  }]\n",
      "Training on Total Epoch: 1095, Round: 1095\n",
      "Evalset: [Train : Metrics { logloss:0.0683,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0935,  }]\n",
      "Training on Total Epoch: 1096, Round: 1096\n",
      "Evalset: [Train : Metrics { logloss:0.0683,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1097, Round: 1097\n",
      "Evalset: [Train : Metrics { logloss:0.0682,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0933,  }]\n",
      "Training on Total Epoch: 1098, Round: 1098\n",
      "Evalset: [Train : Metrics { logloss:0.0681,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0932,  }]\n",
      "Training on Total Epoch: 1099, Round: 1099\n",
      "Evalset: [Train : Metrics { logloss:0.068,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0932,  }]\n",
      "Training on Total Epoch: 1100, Round: 1100\n",
      "Evalset: [Train : Metrics { logloss:0.068,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0932,  }]\n",
      "Training on Total Epoch: 1101, Round: 1101\n",
      "Evalset: [Train : Metrics { logloss:0.0679,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0932,  }]\n",
      "Training on Total Epoch: 1102, Round: 1102\n",
      "Evalset: [Train : Metrics { logloss:0.0678,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0931,  }]\n",
      "Training on Total Epoch: 1103, Round: 1103\n",
      "Evalset: [Train : Metrics { logloss:0.0677,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.093,  }]\n",
      "Training on Total Epoch: 1104, Round: 1104\n",
      "Evalset: [Train : Metrics { logloss:0.0677,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0929,  }]\n",
      "Training on Total Epoch: 1105, Round: 1105\n",
      "Evalset: [Train : Metrics { logloss:0.0676,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0928,  }]\n",
      "Training on Total Epoch: 1106, Round: 1106\n",
      "Evalset: [Train : Metrics { logloss:0.0675,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0927,  }]\n",
      "Training on Total Epoch: 1107, Round: 1107\n",
      "Evalset: [Train : Metrics { logloss:0.0675,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0927,  }]\n",
      "Training on Total Epoch: 1108, Round: 1108\n",
      "Evalset: [Train : Metrics { logloss:0.0674,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0927,  }]\n",
      "Training on Total Epoch: 1109, Round: 1109\n",
      "Evalset: [Train : Metrics { logloss:0.0673,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0926,  }]\n",
      "Training on Total Epoch: 1110, Round: 1110\n",
      "Evalset: [Train : Metrics { logloss:0.0672,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0926,  }]\n",
      "Training on Total Epoch: 1111, Round: 1111\n",
      "Evalset: [Train : Metrics { logloss:0.0672,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0926,  }]\n",
      "Training on Total Epoch: 1112, Round: 1112\n",
      "Evalset: [Train : Metrics { logloss:0.0671,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0927,  }]\n",
      "Training on Total Epoch: 1113, Round: 1113\n",
      "Evalset: [Train : Metrics { logloss:0.067,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0928,  }]\n",
      "Training on Total Epoch: 1114, Round: 1114\n",
      "Evalset: [Train : Metrics { logloss:0.0669,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0927,  }]\n",
      "Training on Total Epoch: 1115, Round: 1115\n",
      "Evalset: [Train : Metrics { logloss:0.0669,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0926,  }]\n",
      "Training on Total Epoch: 1116, Round: 1116\n",
      "Evalset: [Train : Metrics { logloss:0.0668,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0925,  }]\n",
      "Training on Total Epoch: 1117, Round: 1117\n",
      "Evalset: [Train : Metrics { logloss:0.0667,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0924,  }]\n",
      "Training on Total Epoch: 1118, Round: 1118\n",
      "Evalset: [Train : Metrics { logloss:0.0666,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1119, Round: 1119\n",
      "Evalset: [Train : Metrics { logloss:0.0666,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1120, Round: 1120\n",
      "Evalset: [Train : Metrics { logloss:0.0665,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1121, Round: 1121\n",
      "Evalset: [Train : Metrics { logloss:0.0664,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1122, Round: 1122\n",
      "Evalset: [Train : Metrics { logloss:0.0664,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1123, Round: 1123\n",
      "Evalset: [Train : Metrics { logloss:0.0663,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1124, Round: 1124\n",
      "Evalset: [Train : Metrics { logloss:0.0662,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1125, Round: 1125\n",
      "Evalset: [Train : Metrics { logloss:0.0661,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.092,  }]\n",
      "Training on Total Epoch: 1126, Round: 1126\n",
      "Evalset: [Train : Metrics { logloss:0.0661,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1127, Round: 1127\n",
      "Evalset: [Train : Metrics { logloss:0.066,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1128, Round: 1128\n",
      "Evalset: [Train : Metrics { logloss:0.0659,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1129, Round: 1129\n",
      "Evalset: [Train : Metrics { logloss:0.0659,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1130, Round: 1130\n",
      "Evalset: [Train : Metrics { logloss:0.0658,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1131, Round: 1131\n",
      "Evalset: [Train : Metrics { logloss:0.0657,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.092,  }]\n",
      "Training on Total Epoch: 1132, Round: 1132\n",
      "Evalset: [Train : Metrics { logloss:0.0656,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0919,  }]\n",
      "Training on Total Epoch: 1133, Round: 1133\n",
      "Evalset: [Train : Metrics { logloss:0.0656,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0919,  }]\n",
      "Training on Total Epoch: 1134, Round: 1134\n",
      "Evalset: [Train : Metrics { logloss:0.0655,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1135, Round: 1135\n",
      "Evalset: [Train : Metrics { logloss:0.0654,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1136, Round: 1136\n",
      "Evalset: [Train : Metrics { logloss:0.0653,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0919,  }]\n",
      "Training on Total Epoch: 1137, Round: 1137\n",
      "Evalset: [Train : Metrics { logloss:0.0653,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1138, Round: 1138\n",
      "Evalset: [Train : Metrics { logloss:0.0652,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1139, Round: 1139\n",
      "Evalset: [Train : Metrics { logloss:0.0651,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0917,  }]\n",
      "Training on Total Epoch: 1140, Round: 1140\n",
      "Evalset: [Train : Metrics { logloss:0.0651,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0916,  }]\n",
      "Training on Total Epoch: 1141, Round: 1141\n",
      "Evalset: [Train : Metrics { logloss:0.065,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1142, Round: 1142\n",
      "Evalset: [Train : Metrics { logloss:0.0649,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1143, Round: 1143\n",
      "Evalset: [Train : Metrics { logloss:0.0649,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1144, Round: 1144\n",
      "Evalset: [Train : Metrics { logloss:0.0648,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.127,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0916,  }]\n",
      "Training on Total Epoch: 1145, Round: 1145\n",
      "Evalset: [Train : Metrics { logloss:0.0647,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0915,  }]\n",
      "Training on Total Epoch: 1146, Round: 1146\n",
      "Evalset: [Train : Metrics { logloss:0.0646,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.127,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1147, Round: 1147\n",
      "Evalset: [Train : Metrics { logloss:0.0646,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1148, Round: 1148\n",
      "Evalset: [Train : Metrics { logloss:0.0645,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1149, Round: 1149\n",
      "Evalset: [Train : Metrics { logloss:0.0644,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1150, Round: 1150\n",
      "Evalset: [Train : Metrics { logloss:0.0644,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1151, Round: 1151\n",
      "Evalset: [Train : Metrics { logloss:0.0643,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0915,  }]\n",
      "Training on Total Epoch: 1152, Round: 1152\n",
      "Evalset: [Train : Metrics { logloss:0.0642,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.127,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0915,  }]\n",
      "Training on Total Epoch: 1153, Round: 1153\n",
      "Evalset: [Train : Metrics { logloss:0.0642,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0916,  }]\n",
      "Training on Total Epoch: 1154, Round: 1154\n",
      "Evalset: [Train : Metrics { logloss:0.0641,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0916,  }]\n",
      "Training on Total Epoch: 1155, Round: 1155\n",
      "Evalset: [Train : Metrics { logloss:0.064,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0915,  }]\n",
      "Training on Total Epoch: 1156, Round: 1156\n",
      "Evalset: [Train : Metrics { logloss:0.064,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1157, Round: 1157\n",
      "Evalset: [Train : Metrics { logloss:0.0639,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1158, Round: 1158\n",
      "Evalset: [Train : Metrics { logloss:0.0638,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0913,  }]\n",
      "Training on Total Epoch: 1159, Round: 1159\n",
      "Evalset: [Train : Metrics { logloss:0.0638,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0913,  }]\n",
      "Training on Total Epoch: 1160, Round: 1160\n",
      "Evalset: [Train : Metrics { logloss:0.0637,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0913,  }]\n",
      "Training on Total Epoch: 1161, Round: 1161\n",
      "Evalset: [Train : Metrics { logloss:0.0636,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0912,  }]\n",
      "Training on Total Epoch: 1162, Round: 1162\n",
      "Evalset: [Train : Metrics { logloss:0.0635,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0911,  }]\n",
      "Training on Total Epoch: 1163, Round: 1163\n",
      "Evalset: [Train : Metrics { logloss:0.0635,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.091,  }]\n",
      "Training on Total Epoch: 1164, Round: 1164\n",
      "Evalset: [Train : Metrics { logloss:0.0634,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0909,  }]\n",
      "Training on Total Epoch: 1165, Round: 1165\n",
      "Evalset: [Train : Metrics { logloss:0.0634,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1166, Round: 1166\n",
      "Evalset: [Train : Metrics { logloss:0.0633,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1167, Round: 1167\n",
      "Evalset: [Train : Metrics { logloss:0.0632,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0909,  }]\n",
      "Training on Total Epoch: 1168, Round: 1168\n",
      "Evalset: [Train : Metrics { logloss:0.0632,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0909,  }]\n",
      "Training on Total Epoch: 1169, Round: 1169\n",
      "Evalset: [Train : Metrics { logloss:0.0631,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1170, Round: 1170\n",
      "Evalset: [Train : Metrics { logloss:0.063,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1171, Round: 1171\n",
      "Evalset: [Train : Metrics { logloss:0.0629,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0909,  }]\n",
      "Training on Total Epoch: 1172, Round: 1172\n",
      "Evalset: [Train : Metrics { logloss:0.0629,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.091,  }]\n",
      "Training on Total Epoch: 1173, Round: 1173\n",
      "Evalset: [Train : Metrics { logloss:0.0628,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0911,  }]\n",
      "Training on Total Epoch: 1174, Round: 1174\n",
      "Evalset: [Train : Metrics { logloss:0.0628,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0911,  }]\n",
      "Training on Total Epoch: 1175, Round: 1175\n",
      "Evalset: [Train : Metrics { logloss:0.0627,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.091,  }]\n",
      "Training on Total Epoch: 1176, Round: 1176\n",
      "Evalset: [Train : Metrics { logloss:0.0626,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0909,  }]\n",
      "Training on Total Epoch: 1177, Round: 1177\n",
      "Evalset: [Train : Metrics { logloss:0.0625,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1178, Round: 1178\n",
      "Evalset: [Train : Metrics { logloss:0.0625,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1179, Round: 1179\n",
      "Evalset: [Train : Metrics { logloss:0.0624,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1180, Round: 1180\n",
      "Evalset: [Train : Metrics { logloss:0.0623,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0907,  }]\n",
      "Training on Total Epoch: 1181, Round: 1181\n",
      "Evalset: [Train : Metrics { logloss:0.0623,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1182, Round: 1182\n",
      "Evalset: [Train : Metrics { logloss:0.0622,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1183, Round: 1183\n",
      "Evalset: [Train : Metrics { logloss:0.0622,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1184, Round: 1184\n",
      "Evalset: [Train : Metrics { logloss:0.0621,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0907,  }]\n",
      "Training on Total Epoch: 1185, Round: 1185\n",
      "Evalset: [Train : Metrics { logloss:0.062,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1186, Round: 1186\n",
      "Evalset: [Train : Metrics { logloss:0.062,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1187, Round: 1187\n",
      "Evalset: [Train : Metrics { logloss:0.0619,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1188, Round: 1188\n",
      "Evalset: [Train : Metrics { logloss:0.0618,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1189, Round: 1189\n",
      "Evalset: [Train : Metrics { logloss:0.0618,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1190, Round: 1190\n",
      "Evalset: [Train : Metrics { logloss:0.0617,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0907,  }]\n",
      "Training on Total Epoch: 1191, Round: 1191\n",
      "Evalset: [Train : Metrics { logloss:0.0616,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0907,  }]\n",
      "Training on Total Epoch: 1192, Round: 1192\n",
      "Evalset: [Train : Metrics { logloss:0.0616,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1193, Round: 1193\n",
      "Evalset: [Train : Metrics { logloss:0.0615,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0905,  }]\n",
      "Training on Total Epoch: 1194, Round: 1194\n",
      "Evalset: [Train : Metrics { logloss:0.0614,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0905,  }]\n",
      "Training on Total Epoch: 1195, Round: 1195\n",
      "Evalset: [Train : Metrics { logloss:0.0614,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0905,  }]\n",
      "Training on Total Epoch: 1196, Round: 1196\n",
      "Evalset: [Train : Metrics { logloss:0.0613,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0904,  }]\n",
      "Training on Total Epoch: 1197, Round: 1197\n",
      "Evalset: [Train : Metrics { logloss:0.0612,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1198, Round: 1198\n",
      "Evalset: [Train : Metrics { logloss:0.0612,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1199, Round: 1199\n",
      "Evalset: [Train : Metrics { logloss:0.0611,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1200, Round: 1200\n",
      "Evalset: [Train : Metrics { logloss:0.061,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1201, Round: 1201\n",
      "Evalset: [Train : Metrics { logloss:0.061,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1202, Round: 1202\n",
      "Evalset: [Train : Metrics { logloss:0.0609,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0902,  }]\n",
      "Training on Total Epoch: 1203, Round: 1203\n",
      "Evalset: [Train : Metrics { logloss:0.0609,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0902,  }]\n",
      "Training on Total Epoch: 1204, Round: 1204\n",
      "Evalset: [Train : Metrics { logloss:0.0608,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0901,  }]\n",
      "Training on Total Epoch: 1205, Round: 1205\n",
      "Evalset: [Train : Metrics { logloss:0.0607,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0901,  }]\n",
      "Training on Total Epoch: 1206, Round: 1206\n",
      "Evalset: [Train : Metrics { logloss:0.0607,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.09,  }]\n",
      "Training on Total Epoch: 1207, Round: 1207\n",
      "Evalset: [Train : Metrics { logloss:0.0606,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0901,  }]\n",
      "Training on Total Epoch: 1208, Round: 1208\n",
      "Evalset: [Train : Metrics { logloss:0.0605,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1209, Round: 1209\n",
      "Evalset: [Train : Metrics { logloss:0.0605,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1210, Round: 1210\n",
      "Evalset: [Train : Metrics { logloss:0.0604,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1211, Round: 1211\n",
      "Evalset: [Train : Metrics { logloss:0.0603,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1212, Round: 1212\n",
      "Evalset: [Train : Metrics { logloss:0.0603,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1213, Round: 1213\n",
      "Evalset: [Train : Metrics { logloss:0.0602,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0904,  }]\n",
      "Training on Total Epoch: 1214, Round: 1214\n",
      "Evalset: [Train : Metrics { logloss:0.0602,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0903,  }]\n",
      "Training on Total Epoch: 1215, Round: 1215\n",
      "Evalset: [Train : Metrics { logloss:0.0601,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.09,  }]\n",
      "Training on Total Epoch: 1216, Round: 1216\n",
      "Evalset: [Train : Metrics { logloss:0.06,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.09,  }]\n",
      "Training on Total Epoch: 1217, Round: 1217\n",
      "Evalset: [Train : Metrics { logloss:0.06,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1218, Round: 1218\n",
      "Evalset: [Train : Metrics { logloss:0.0599,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1219, Round: 1219\n",
      "Evalset: [Train : Metrics { logloss:0.0598,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1220, Round: 1220\n",
      "Evalset: [Train : Metrics { logloss:0.0598,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1221, Round: 1221\n",
      "Evalset: [Train : Metrics { logloss:0.0597,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.09,  }]\n",
      "Training on Total Epoch: 1222, Round: 1222\n",
      "Evalset: [Train : Metrics { logloss:0.0597,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.09,  }]\n",
      "Training on Total Epoch: 1223, Round: 1223\n",
      "Evalset: [Train : Metrics { logloss:0.0596,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.09,  }]\n",
      "Training on Total Epoch: 1224, Round: 1224\n",
      "Evalset: [Train : Metrics { logloss:0.0595,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1225, Round: 1225\n",
      "Evalset: [Train : Metrics { logloss:0.0595,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1226, Round: 1226\n",
      "Evalset: [Train : Metrics { logloss:0.0594,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1227, Round: 1227\n",
      "Evalset: [Train : Metrics { logloss:0.0593,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0896,  }]\n",
      "Training on Total Epoch: 1228, Round: 1228\n",
      "Evalset: [Train : Metrics { logloss:0.0593,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0897,  }]\n",
      "Training on Total Epoch: 1229, Round: 1229\n",
      "Evalset: [Train : Metrics { logloss:0.0592,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0896,  }]\n",
      "Training on Total Epoch: 1230, Round: 1230\n",
      "Evalset: [Train : Metrics { logloss:0.0592,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0895,  }]\n",
      "Training on Total Epoch: 1231, Round: 1231\n",
      "Evalset: [Train : Metrics { logloss:0.0591,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0896,  }]\n",
      "Training on Total Epoch: 1232, Round: 1232\n",
      "Evalset: [Train : Metrics { logloss:0.059,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0895,  }]\n",
      "Training on Total Epoch: 1233, Round: 1233\n",
      "Evalset: [Train : Metrics { logloss:0.059,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0895,  }]\n",
      "Training on Total Epoch: 1234, Round: 1234\n",
      "Evalset: [Train : Metrics { logloss:0.0589,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0893,  }]\n",
      "Training on Total Epoch: 1235, Round: 1235\n",
      "Evalset: [Train : Metrics { logloss:0.0589,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1236, Round: 1236\n",
      "Evalset: [Train : Metrics { logloss:0.0588,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1237, Round: 1237\n",
      "Evalset: [Train : Metrics { logloss:0.0588,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1238, Round: 1238\n",
      "Evalset: [Train : Metrics { logloss:0.0587,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0893,  }]\n",
      "Training on Total Epoch: 1239, Round: 1239\n",
      "Evalset: [Train : Metrics { logloss:0.0586,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0893,  }]\n",
      "Training on Total Epoch: 1240, Round: 1240\n",
      "Evalset: [Train : Metrics { logloss:0.0586,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0892,  }]\n",
      "Training on Total Epoch: 1241, Round: 1241\n",
      "Evalset: [Train : Metrics { logloss:0.0585,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1242, Round: 1242\n",
      "Evalset: [Train : Metrics { logloss:0.0585,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0892,  }]\n",
      "Training on Total Epoch: 1243, Round: 1243\n",
      "Evalset: [Train : Metrics { logloss:0.0584,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1244, Round: 1244\n",
      "Evalset: [Train : Metrics { logloss:0.0583,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1245, Round: 1245\n",
      "Evalset: [Train : Metrics { logloss:0.0583,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1246, Round: 1246\n",
      "Evalset: [Train : Metrics { logloss:0.0582,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1247, Round: 1247\n",
      "Evalset: [Train : Metrics { logloss:0.0582,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.089,  }]\n",
      "Training on Total Epoch: 1248, Round: 1248\n",
      "Evalset: [Train : Metrics { logloss:0.0581,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1249, Round: 1249\n",
      "Evalset: [Train : Metrics { logloss:0.058,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1250, Round: 1250\n",
      "Evalset: [Train : Metrics { logloss:0.058,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1251, Round: 1251\n",
      "Evalset: [Train : Metrics { logloss:0.0579,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1252, Round: 1252\n",
      "Evalset: [Train : Metrics { logloss:0.0579,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0892,  }]\n",
      "Training on Total Epoch: 1253, Round: 1253\n",
      "Evalset: [Train : Metrics { logloss:0.0578,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1254, Round: 1254\n",
      "Evalset: [Train : Metrics { logloss:0.0577,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1255, Round: 1255\n",
      "Evalset: [Train : Metrics { logloss:0.0577,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1256, Round: 1256\n",
      "Evalset: [Train : Metrics { logloss:0.0576,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0892,  }]\n",
      "Training on Total Epoch: 1257, Round: 1257\n",
      "Evalset: [Train : Metrics { logloss:0.0576,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1258, Round: 1258\n",
      "Evalset: [Train : Metrics { logloss:0.0575,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.089,  }]\n",
      "Training on Total Epoch: 1259, Round: 1259\n",
      "Evalset: [Train : Metrics { logloss:0.0574,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1260, Round: 1260\n",
      "Evalset: [Train : Metrics { logloss:0.0574,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1261, Round: 1261\n",
      "Evalset: [Train : Metrics { logloss:0.0573,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1262, Round: 1262\n",
      "Evalset: [Train : Metrics { logloss:0.0573,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1263, Round: 1263\n",
      "Evalset: [Train : Metrics { logloss:0.0572,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1264, Round: 1264\n",
      "Evalset: [Train : Metrics { logloss:0.0571,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1265, Round: 1265\n",
      "Evalset: [Train : Metrics { logloss:0.0571,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1266, Round: 1266\n",
      "Evalset: [Train : Metrics { logloss:0.057,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1267, Round: 1267\n",
      "Evalset: [Train : Metrics { logloss:0.057,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.089,  }]\n",
      "Training on Total Epoch: 1268, Round: 1268\n",
      "Evalset: [Train : Metrics { logloss:0.0569,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1269, Round: 1269\n",
      "Evalset: [Train : Metrics { logloss:0.0568,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1270, Round: 1270\n",
      "Evalset: [Train : Metrics { logloss:0.0568,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1271, Round: 1271\n",
      "Evalset: [Train : Metrics { logloss:0.0567,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1272, Round: 1272\n",
      "Evalset: [Train : Metrics { logloss:0.0567,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1273, Round: 1273\n",
      "Evalset: [Train : Metrics { logloss:0.0566,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1274, Round: 1274\n",
      "Evalset: [Train : Metrics { logloss:0.0566,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1275, Round: 1275\n",
      "Evalset: [Train : Metrics { logloss:0.0565,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1276, Round: 1276\n",
      "Evalset: [Train : Metrics { logloss:0.0564,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1277, Round: 1277\n",
      "Evalset: [Train : Metrics { logloss:0.0564,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1278, Round: 1278\n",
      "Evalset: [Train : Metrics { logloss:0.0563,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1279, Round: 1279\n",
      "Evalset: [Train : Metrics { logloss:0.0563,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1280, Round: 1280\n",
      "Evalset: [Train : Metrics { logloss:0.0562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1281, Round: 1281\n",
      "Evalset: [Train : Metrics { logloss:0.0562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1282, Round: 1282\n",
      "Evalset: [Train : Metrics { logloss:0.0561,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1283, Round: 1283\n",
      "Evalset: [Train : Metrics { logloss:0.056,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1284, Round: 1284\n",
      "Evalset: [Train : Metrics { logloss:0.056,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1285, Round: 1285\n",
      "Evalset: [Train : Metrics { logloss:0.0559,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0884,  }]\n",
      "Training on Total Epoch: 1286, Round: 1286\n",
      "Evalset: [Train : Metrics { logloss:0.0559,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0884,  }]\n",
      "Training on Total Epoch: 1287, Round: 1287\n",
      "Evalset: [Train : Metrics { logloss:0.0558,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1288, Round: 1288\n",
      "Evalset: [Train : Metrics { logloss:0.0558,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1289, Round: 1289\n",
      "Evalset: [Train : Metrics { logloss:0.0557,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1290, Round: 1290\n",
      "Evalset: [Train : Metrics { logloss:0.0557,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0883,  }]\n",
      "Training on Total Epoch: 1291, Round: 1291\n",
      "Evalset: [Train : Metrics { logloss:0.0556,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1292, Round: 1292\n",
      "Evalset: [Train : Metrics { logloss:0.0555,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1293, Round: 1293\n",
      "Evalset: [Train : Metrics { logloss:0.0555,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1294, Round: 1294\n",
      "Evalset: [Train : Metrics { logloss:0.0554,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0883,  }]\n",
      "Training on Total Epoch: 1295, Round: 1295\n",
      "Evalset: [Train : Metrics { logloss:0.0554,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0884,  }]\n",
      "Training on Total Epoch: 1296, Round: 1296\n",
      "Evalset: [Train : Metrics { logloss:0.0553,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1297, Round: 1297\n",
      "Evalset: [Train : Metrics { logloss:0.0553,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1298, Round: 1298\n",
      "Evalset: [Train : Metrics { logloss:0.0552,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1299, Round: 1299\n",
      "Evalset: [Train : Metrics { logloss:0.0552,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1300, Round: 1300\n",
      "Evalset: [Train : Metrics { logloss:0.0551,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1301, Round: 1301\n",
      "Evalset: [Train : Metrics { logloss:0.055,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1302, Round: 1302\n",
      "Evalset: [Train : Metrics { logloss:0.055,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0884,  }]\n",
      "Training on Total Epoch: 1303, Round: 1303\n",
      "Evalset: [Train : Metrics { logloss:0.0549,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0884,  }]\n",
      "Training on Total Epoch: 1304, Round: 1304\n",
      "Evalset: [Train : Metrics { logloss:0.0549,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1305, Round: 1305\n",
      "Evalset: [Train : Metrics { logloss:0.0548,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1306, Round: 1306\n",
      "Evalset: [Train : Metrics { logloss:0.0548,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1307, Round: 1307\n",
      "Evalset: [Train : Metrics { logloss:0.0547,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0883,  }]\n",
      "Training on Total Epoch: 1308, Round: 1308\n",
      "Evalset: [Train : Metrics { logloss:0.0547,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1309, Round: 1309\n",
      "Evalset: [Train : Metrics { logloss:0.0546,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1310, Round: 1310\n",
      "Evalset: [Train : Metrics { logloss:0.0545,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1311, Round: 1311\n",
      "Evalset: [Train : Metrics { logloss:0.0545,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1312, Round: 1312\n",
      "Evalset: [Train : Metrics { logloss:0.0544,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1313, Round: 1313\n",
      "Evalset: [Train : Metrics { logloss:0.0544,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.088,  }]\n",
      "Training on Total Epoch: 1314, Round: 1314\n",
      "Evalset: [Train : Metrics { logloss:0.0543,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1315, Round: 1315\n",
      "Evalset: [Train : Metrics { logloss:0.0543,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1316, Round: 1316\n",
      "Evalset: [Train : Metrics { logloss:0.0542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1317, Round: 1317\n",
      "Evalset: [Train : Metrics { logloss:0.0542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1318, Round: 1318\n",
      "Evalset: [Train : Metrics { logloss:0.0541,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1319, Round: 1319\n",
      "Evalset: [Train : Metrics { logloss:0.0541,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1320, Round: 1320\n",
      "Evalset: [Train : Metrics { logloss:0.054,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1321, Round: 1321\n",
      "Evalset: [Train : Metrics { logloss:0.054,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1322, Round: 1322\n",
      "Evalset: [Train : Metrics { logloss:0.0539,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0883,  }]\n",
      "Training on Total Epoch: 1323, Round: 1323\n",
      "Evalset: [Train : Metrics { logloss:0.0539,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1324, Round: 1324\n",
      "Evalset: [Train : Metrics { logloss:0.0538,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0881,  }]\n",
      "Training on Total Epoch: 1325, Round: 1325\n",
      "Evalset: [Train : Metrics { logloss:0.0538,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0879,  }]\n",
      "Training on Total Epoch: 1326, Round: 1326\n",
      "Evalset: [Train : Metrics { logloss:0.0537,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0878,  }]\n",
      "Training on Total Epoch: 1327, Round: 1327\n",
      "Evalset: [Train : Metrics { logloss:0.0536,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0878,  }]\n",
      "Training on Total Epoch: 1328, Round: 1328\n",
      "Evalset: [Train : Metrics { logloss:0.0536,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.088,  }]\n",
      "Training on Total Epoch: 1329, Round: 1329\n",
      "Evalset: [Train : Metrics { logloss:0.0535,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1330, Round: 1330\n",
      "Evalset: [Train : Metrics { logloss:0.0535,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1331, Round: 1331\n",
      "Evalset: [Train : Metrics { logloss:0.0534,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0879,  }]\n",
      "Training on Total Epoch: 1332, Round: 1332\n",
      "Evalset: [Train : Metrics { logloss:0.0534,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0878,  }]\n",
      "Training on Total Epoch: 1333, Round: 1333\n",
      "Evalset: [Train : Metrics { logloss:0.0533,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0878,  }]\n",
      "Training on Total Epoch: 1334, Round: 1334\n",
      "Evalset: [Train : Metrics { logloss:0.0533,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0878,  }]\n",
      "Training on Total Epoch: 1335, Round: 1335\n",
      "Evalset: [Train : Metrics { logloss:0.0532,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0879,  }]\n",
      "Training on Total Epoch: 1336, Round: 1336\n",
      "Evalset: [Train : Metrics { logloss:0.0532,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.088,  }]\n",
      "Training on Total Epoch: 1337, Round: 1337\n",
      "Evalset: [Train : Metrics { logloss:0.0531,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.088,  }]\n",
      "Training on Total Epoch: 1338, Round: 1338\n",
      "Evalset: [Train : Metrics { logloss:0.0531,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.088,  }]\n",
      "Training on Total Epoch: 1339, Round: 1339\n",
      "Evalset: [Train : Metrics { logloss:0.053,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0879,  }]\n",
      "Training on Total Epoch: 1340, Round: 1340\n",
      "Evalset: [Train : Metrics { logloss:0.0529,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0878,  }]\n",
      "Training on Total Epoch: 1341, Round: 1341\n",
      "Evalset: [Train : Metrics { logloss:0.0529,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0877,  }]\n",
      "Training on Total Epoch: 1342, Round: 1342\n",
      "Evalset: [Train : Metrics { logloss:0.0528,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0877,  }]\n",
      "Training on Total Epoch: 1343, Round: 1343\n",
      "Evalset: [Train : Metrics { logloss:0.0528,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0877,  }]\n",
      "Training on Total Epoch: 1344, Round: 1344\n",
      "Evalset: [Train : Metrics { logloss:0.0527,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0876,  }]\n",
      "Training on Total Epoch: 1345, Round: 1345\n",
      "Evalset: [Train : Metrics { logloss:0.0527,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0875,  }]\n",
      "Training on Total Epoch: 1346, Round: 1346\n",
      "Evalset: [Train : Metrics { logloss:0.0526,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0875,  }]\n",
      "Training on Total Epoch: 1347, Round: 1347\n",
      "Evalset: [Train : Metrics { logloss:0.0526,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0875,  }]\n",
      "Training on Total Epoch: 1348, Round: 1348\n",
      "Evalset: [Train : Metrics { logloss:0.0525,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0875,  }]\n",
      "Training on Total Epoch: 1349, Round: 1349\n",
      "Evalset: [Train : Metrics { logloss:0.0525,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0875,  }]\n",
      "Training on Total Epoch: 1350, Round: 1350\n",
      "Evalset: [Train : Metrics { logloss:0.0524,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0874,  }]\n",
      "Training on Total Epoch: 1351, Round: 1351\n",
      "Evalset: [Train : Metrics { logloss:0.0524,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0873,  }]\n",
      "Training on Total Epoch: 1352, Round: 1352\n",
      "Evalset: [Train : Metrics { logloss:0.0523,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0874,  }]\n",
      "Training on Total Epoch: 1353, Round: 1353\n",
      "Evalset: [Train : Metrics { logloss:0.0523,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0874,  }]\n",
      "Training on Total Epoch: 1354, Round: 1354\n",
      "Evalset: [Train : Metrics { logloss:0.0522,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0875,  }]\n",
      "Training on Total Epoch: 1355, Round: 1355\n",
      "Evalset: [Train : Metrics { logloss:0.0522,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0874,  }]\n",
      "Training on Total Epoch: 1356, Round: 1356\n",
      "Evalset: [Train : Metrics { logloss:0.0521,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0875,  }]\n",
      "Training on Total Epoch: 1357, Round: 1357\n",
      "Evalset: [Train : Metrics { logloss:0.0521,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0874,  }]\n",
      "Training on Total Epoch: 1358, Round: 1358\n",
      "Evalset: [Train : Metrics { logloss:0.052,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1359, Round: 1359\n",
      "Evalset: [Train : Metrics { logloss:0.052,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1360, Round: 1360\n",
      "Evalset: [Train : Metrics { logloss:0.0519,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1361, Round: 1361\n",
      "Evalset: [Train : Metrics { logloss:0.0519,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1362, Round: 1362\n",
      "Evalset: [Train : Metrics { logloss:0.0518,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0873,  }]\n",
      "Training on Total Epoch: 1363, Round: 1363\n",
      "Evalset: [Train : Metrics { logloss:0.0518,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1364, Round: 1364\n",
      "Evalset: [Train : Metrics { logloss:0.0517,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1365, Round: 1365\n",
      "Evalset: [Train : Metrics { logloss:0.0517,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0873,  }]\n",
      "Training on Total Epoch: 1366, Round: 1366\n",
      "Evalset: [Train : Metrics { logloss:0.0516,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1367, Round: 1367\n",
      "Evalset: [Train : Metrics { logloss:0.0516,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1368, Round: 1368\n",
      "Evalset: [Train : Metrics { logloss:0.0515,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1369, Round: 1369\n",
      "Evalset: [Train : Metrics { logloss:0.0515,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1370, Round: 1370\n",
      "Evalset: [Train : Metrics { logloss:0.0514,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1371, Round: 1371\n",
      "Evalset: [Train : Metrics { logloss:0.0514,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0873,  }]\n",
      "Training on Total Epoch: 1372, Round: 1372\n",
      "Evalset: [Train : Metrics { logloss:0.0513,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1373, Round: 1373\n",
      "Evalset: [Train : Metrics { logloss:0.0513,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1374, Round: 1374\n",
      "Evalset: [Train : Metrics { logloss:0.0513,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1375, Round: 1375\n",
      "Evalset: [Train : Metrics { logloss:0.0512,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1376, Round: 1376\n",
      "Evalset: [Train : Metrics { logloss:0.0511,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0873,  }]\n",
      "Training on Total Epoch: 1377, Round: 1377\n",
      "Evalset: [Train : Metrics { logloss:0.0511,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0873,  }]\n",
      "Training on Total Epoch: 1378, Round: 1378\n",
      "Evalset: [Train : Metrics { logloss:0.051,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1379, Round: 1379\n",
      "Evalset: [Train : Metrics { logloss:0.051,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1380, Round: 1380\n",
      "Evalset: [Train : Metrics { logloss:0.0509,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1381, Round: 1381\n",
      "Evalset: [Train : Metrics { logloss:0.0509,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1382, Round: 1382\n",
      "Evalset: [Train : Metrics { logloss:0.0508,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1383, Round: 1383\n",
      "Evalset: [Train : Metrics { logloss:0.0508,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1384, Round: 1384\n",
      "Evalset: [Train : Metrics { logloss:0.0507,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 1385, Round: 1385\n",
      "Evalset: [Train : Metrics { logloss:0.0507,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 1386, Round: 1386\n",
      "Evalset: [Train : Metrics { logloss:0.0506,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 1387, Round: 1387\n",
      "Evalset: [Train : Metrics { logloss:0.0506,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1388, Round: 1388\n",
      "Evalset: [Train : Metrics { logloss:0.0505,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1389, Round: 1389\n",
      "Evalset: [Train : Metrics { logloss:0.0505,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 1390, Round: 1390\n",
      "Evalset: [Train : Metrics { logloss:0.0504,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 1391, Round: 1391\n",
      "Evalset: [Train : Metrics { logloss:0.0504,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 1392, Round: 1392\n",
      "Evalset: [Train : Metrics { logloss:0.0503,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 1393, Round: 1393\n",
      "Evalset: [Train : Metrics { logloss:0.0503,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 1394, Round: 1394\n",
      "Evalset: [Train : Metrics { logloss:0.0502,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 1395, Round: 1395\n",
      "Evalset: [Train : Metrics { logloss:0.0502,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 1396, Round: 1396\n",
      "Evalset: [Train : Metrics { logloss:0.0501,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 1397, Round: 1397\n",
      "Evalset: [Train : Metrics { logloss:0.0501,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1398, Round: 1398\n",
      "Evalset: [Train : Metrics { logloss:0.0501,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 1399, Round: 1399\n",
      "Evalset: [Train : Metrics { logloss:0.05,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1400, Round: 1400\n",
      "Evalset: [Train : Metrics { logloss:0.0499,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1401, Round: 1401\n",
      "Evalset: [Train : Metrics { logloss:0.0499,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 1402, Round: 1402\n",
      "Evalset: [Train : Metrics { logloss:0.0498,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 1403, Round: 1403\n",
      "Evalset: [Train : Metrics { logloss:0.0498,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 1404, Round: 1404\n",
      "Evalset: [Train : Metrics { logloss:0.0498,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 1405, Round: 1405\n",
      "Evalset: [Train : Metrics { logloss:0.0497,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1406, Round: 1406\n",
      "Evalset: [Train : Metrics { logloss:0.0497,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 1407, Round: 1407\n",
      "Evalset: [Train : Metrics { logloss:0.0496,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1408, Round: 1408\n",
      "Evalset: [Train : Metrics { logloss:0.0496,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 1409, Round: 1409\n",
      "Evalset: [Train : Metrics { logloss:0.0495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1410, Round: 1410\n",
      "Evalset: [Train : Metrics { logloss:0.0495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1411, Round: 1411\n",
      "Evalset: [Train : Metrics { logloss:0.0494,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1412, Round: 1412\n",
      "Evalset: [Train : Metrics { logloss:0.0494,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1413, Round: 1413\n",
      "Evalset: [Train : Metrics { logloss:0.0493,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1414, Round: 1414\n",
      "Evalset: [Train : Metrics { logloss:0.0493,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 1415, Round: 1415\n",
      "Evalset: [Train : Metrics { logloss:0.0492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 1416, Round: 1416\n",
      "Evalset: [Train : Metrics { logloss:0.0492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1417, Round: 1417\n",
      "Evalset: [Train : Metrics { logloss:0.0491,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 1418, Round: 1418\n",
      "Evalset: [Train : Metrics { logloss:0.0491,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 1419, Round: 1419\n",
      "Evalset: [Train : Metrics { logloss:0.049,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 1420, Round: 1420\n",
      "Evalset: [Train : Metrics { logloss:0.049,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1421, Round: 1421\n",
      "Evalset: [Train : Metrics { logloss:0.049,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1422, Round: 1422\n",
      "Evalset: [Train : Metrics { logloss:0.0489,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1423, Round: 1423\n",
      "Evalset: [Train : Metrics { logloss:0.0489,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1424, Round: 1424\n",
      "Evalset: [Train : Metrics { logloss:0.0488,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1425, Round: 1425\n",
      "Evalset: [Train : Metrics { logloss:0.0488,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1426, Round: 1426\n",
      "Evalset: [Train : Metrics { logloss:0.0487,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1427, Round: 1427\n",
      "Evalset: [Train : Metrics { logloss:0.0487,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1428, Round: 1428\n",
      "Evalset: [Train : Metrics { logloss:0.0486,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 1429, Round: 1429\n",
      "Evalset: [Train : Metrics { logloss:0.0486,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 1430, Round: 1430\n",
      "Evalset: [Train : Metrics { logloss:0.0485,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1431, Round: 1431\n",
      "Evalset: [Train : Metrics { logloss:0.0485,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1432, Round: 1432\n",
      "Evalset: [Train : Metrics { logloss:0.0484,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1433, Round: 1433\n",
      "Evalset: [Train : Metrics { logloss:0.0484,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1434, Round: 1434\n",
      "Evalset: [Train : Metrics { logloss:0.0483,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1435, Round: 1435\n",
      "Evalset: [Train : Metrics { logloss:0.0483,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1436, Round: 1436\n",
      "Evalset: [Train : Metrics { logloss:0.0483,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1437, Round: 1437\n",
      "Evalset: [Train : Metrics { logloss:0.0482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 1438, Round: 1438\n",
      "Evalset: [Train : Metrics { logloss:0.0482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1439, Round: 1439\n",
      "Evalset: [Train : Metrics { logloss:0.0481,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1440, Round: 1440\n",
      "Evalset: [Train : Metrics { logloss:0.0481,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1441, Round: 1441\n",
      "Evalset: [Train : Metrics { logloss:0.048,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1442, Round: 1442\n",
      "Evalset: [Train : Metrics { logloss:0.048,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1443, Round: 1443\n",
      "Evalset: [Train : Metrics { logloss:0.0479,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1444, Round: 1444\n",
      "Evalset: [Train : Metrics { logloss:0.0479,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1445, Round: 1445\n",
      "Evalset: [Train : Metrics { logloss:0.0478,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1446, Round: 1446\n",
      "Evalset: [Train : Metrics { logloss:0.0478,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1447, Round: 1447\n",
      "Evalset: [Train : Metrics { logloss:0.0478,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 1448, Round: 1448\n",
      "Evalset: [Train : Metrics { logloss:0.0477,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1449, Round: 1449\n",
      "Evalset: [Train : Metrics { logloss:0.0477,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1450, Round: 1450\n",
      "Evalset: [Train : Metrics { logloss:0.0476,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1451, Round: 1451\n",
      "Evalset: [Train : Metrics { logloss:0.0476,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1452, Round: 1452\n",
      "Evalset: [Train : Metrics { logloss:0.0475,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1453, Round: 1453\n",
      "Evalset: [Train : Metrics { logloss:0.0475,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1454, Round: 1454\n",
      "Evalset: [Train : Metrics { logloss:0.0474,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1455, Round: 1455\n",
      "Evalset: [Train : Metrics { logloss:0.0474,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1456, Round: 1456\n",
      "Evalset: [Train : Metrics { logloss:0.0473,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1457, Round: 1457\n",
      "Evalset: [Train : Metrics { logloss:0.0473,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1458, Round: 1458\n",
      "Evalset: [Train : Metrics { logloss:0.0472,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1459, Round: 1459\n",
      "Evalset: [Train : Metrics { logloss:0.0472,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1460, Round: 1460\n",
      "Evalset: [Train : Metrics { logloss:0.0472,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1461, Round: 1461\n",
      "Evalset: [Train : Metrics { logloss:0.0471,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1462, Round: 1462\n",
      "Evalset: [Train : Metrics { logloss:0.0471,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1463, Round: 1463\n",
      "Evalset: [Train : Metrics { logloss:0.047,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1464, Round: 1464\n",
      "Evalset: [Train : Metrics { logloss:0.047,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1465, Round: 1465\n",
      "Evalset: [Train : Metrics { logloss:0.0469,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1466, Round: 1466\n",
      "Evalset: [Train : Metrics { logloss:0.0469,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1467, Round: 1467\n",
      "Evalset: [Train : Metrics { logloss:0.0469,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1468, Round: 1468\n",
      "Evalset: [Train : Metrics { logloss:0.0468,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1469, Round: 1469\n",
      "Evalset: [Train : Metrics { logloss:0.0468,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1470, Round: 1470\n",
      "Evalset: [Train : Metrics { logloss:0.0467,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1471, Round: 1471\n",
      "Evalset: [Train : Metrics { logloss:0.0467,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1472, Round: 1472\n",
      "Evalset: [Train : Metrics { logloss:0.0467,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1473, Round: 1473\n",
      "Evalset: [Train : Metrics { logloss:0.0466,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1474, Round: 1474\n",
      "Evalset: [Train : Metrics { logloss:0.0466,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1475, Round: 1475\n",
      "Evalset: [Train : Metrics { logloss:0.0465,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1476, Round: 1476\n",
      "Evalset: [Train : Metrics { logloss:0.0465,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1477, Round: 1477\n",
      "Evalset: [Train : Metrics { logloss:0.0464,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1478, Round: 1478\n",
      "Evalset: [Train : Metrics { logloss:0.0464,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1479, Round: 1479\n",
      "Evalset: [Train : Metrics { logloss:0.0463,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1480, Round: 1480\n",
      "Evalset: [Train : Metrics { logloss:0.0463,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1481, Round: 1481\n",
      "Evalset: [Train : Metrics { logloss:0.0462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1482, Round: 1482\n",
      "Evalset: [Train : Metrics { logloss:0.0462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1483, Round: 1483\n",
      "Evalset: [Train : Metrics { logloss:0.0462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1484, Round: 1484\n",
      "Evalset: [Train : Metrics { logloss:0.0461,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1485, Round: 1485\n",
      "Evalset: [Train : Metrics { logloss:0.0461,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1486, Round: 1486\n",
      "Evalset: [Train : Metrics { logloss:0.046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1487, Round: 1487\n",
      "Evalset: [Train : Metrics { logloss:0.046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1488, Round: 1488\n",
      "Evalset: [Train : Metrics { logloss:0.046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1489, Round: 1489\n",
      "Evalset: [Train : Metrics { logloss:0.0459,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1490, Round: 1490\n",
      "Evalset: [Train : Metrics { logloss:0.0459,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1491, Round: 1491\n",
      "Evalset: [Train : Metrics { logloss:0.0458,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1492, Round: 1492\n",
      "Evalset: [Train : Metrics { logloss:0.0458,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1493, Round: 1493\n",
      "Evalset: [Train : Metrics { logloss:0.0457,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1494, Round: 1494\n",
      "Evalset: [Train : Metrics { logloss:0.0457,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1495, Round: 1495\n",
      "Evalset: [Train : Metrics { logloss:0.0457,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1496, Round: 1496\n",
      "Evalset: [Train : Metrics { logloss:0.0456,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1497, Round: 1497\n",
      "Evalset: [Train : Metrics { logloss:0.0456,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1498, Round: 1498\n",
      "Evalset: [Train : Metrics { logloss:0.0455,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1499, Round: 1499\n",
      "Evalset: [Train : Metrics { logloss:0.0455,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1500, Round: 1500\n",
      "Evalset: [Train : Metrics { logloss:0.0455,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1501, Round: 1501\n",
      "Evalset: [Train : Metrics { logloss:0.0454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1502, Round: 1502\n",
      "Evalset: [Train : Metrics { logloss:0.0454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1503, Round: 1503\n",
      "Evalset: [Train : Metrics { logloss:0.0453,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1504, Round: 1504\n",
      "Evalset: [Train : Metrics { logloss:0.0453,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1505, Round: 1505\n",
      "Evalset: [Train : Metrics { logloss:0.0452,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1506, Round: 1506\n",
      "Evalset: [Train : Metrics { logloss:0.0452,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1507, Round: 1507\n",
      "Evalset: [Train : Metrics { logloss:0.0452,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1508, Round: 1508\n",
      "Evalset: [Train : Metrics { logloss:0.0451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1509, Round: 1509\n",
      "Evalset: [Train : Metrics { logloss:0.0451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1510, Round: 1510\n",
      "Evalset: [Train : Metrics { logloss:0.045,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1511, Round: 1511\n",
      "Evalset: [Train : Metrics { logloss:0.045,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1512, Round: 1512\n",
      "Evalset: [Train : Metrics { logloss:0.0449,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1513, Round: 1513\n",
      "Evalset: [Train : Metrics { logloss:0.0449,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1514, Round: 1514\n",
      "Evalset: [Train : Metrics { logloss:0.0449,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1515, Round: 1515\n",
      "Evalset: [Train : Metrics { logloss:0.0448,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1516, Round: 1516\n",
      "Evalset: [Train : Metrics { logloss:0.0448,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1517, Round: 1517\n",
      "Evalset: [Train : Metrics { logloss:0.0447,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1518, Round: 1518\n",
      "Evalset: [Train : Metrics { logloss:0.0447,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1519, Round: 1519\n",
      "Evalset: [Train : Metrics { logloss:0.0447,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1520, Round: 1520\n",
      "Evalset: [Train : Metrics { logloss:0.0446,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1521, Round: 1521\n",
      "Evalset: [Train : Metrics { logloss:0.0446,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1522, Round: 1522\n",
      "Evalset: [Train : Metrics { logloss:0.0445,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1523, Round: 1523\n",
      "Evalset: [Train : Metrics { logloss:0.0445,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1524, Round: 1524\n",
      "Evalset: [Train : Metrics { logloss:0.0444,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1525, Round: 1525\n",
      "Evalset: [Train : Metrics { logloss:0.0444,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1526, Round: 1526\n",
      "Evalset: [Train : Metrics { logloss:0.0444,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1527, Round: 1527\n",
      "Evalset: [Train : Metrics { logloss:0.0443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1528, Round: 1528\n",
      "Evalset: [Train : Metrics { logloss:0.0443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1529, Round: 1529\n",
      "Evalset: [Train : Metrics { logloss:0.0443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1530, Round: 1530\n",
      "Evalset: [Train : Metrics { logloss:0.0442,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1531, Round: 1531\n",
      "Evalset: [Train : Metrics { logloss:0.0442,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1532, Round: 1532\n",
      "Evalset: [Train : Metrics { logloss:0.0441,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1533, Round: 1533\n",
      "Evalset: [Train : Metrics { logloss:0.0441,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1534, Round: 1534\n",
      "Evalset: [Train : Metrics { logloss:0.044,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1535, Round: 1535\n",
      "Evalset: [Train : Metrics { logloss:0.044,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1536, Round: 1536\n",
      "Evalset: [Train : Metrics { logloss:0.044,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1537, Round: 1537\n",
      "Evalset: [Train : Metrics { logloss:0.0439,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1538, Round: 1538\n",
      "Evalset: [Train : Metrics { logloss:0.0439,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1539, Round: 1539\n",
      "Evalset: [Train : Metrics { logloss:0.0438,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1540, Round: 1540\n",
      "Evalset: [Train : Metrics { logloss:0.0438,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1541, Round: 1541\n",
      "Evalset: [Train : Metrics { logloss:0.0437,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1542, Round: 1542\n",
      "Evalset: [Train : Metrics { logloss:0.0437,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1543, Round: 1543\n",
      "Evalset: [Train : Metrics { logloss:0.0437,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1544, Round: 1544\n",
      "Evalset: [Train : Metrics { logloss:0.0436,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1545, Round: 1545\n",
      "Evalset: [Train : Metrics { logloss:0.0436,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1546, Round: 1546\n",
      "Evalset: [Train : Metrics { logloss:0.0436,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1547, Round: 1547\n",
      "Evalset: [Train : Metrics { logloss:0.0435,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1548, Round: 1548\n",
      "Evalset: [Train : Metrics { logloss:0.0435,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1549, Round: 1549\n",
      "Evalset: [Train : Metrics { logloss:0.0434,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1550, Round: 1550\n",
      "Evalset: [Train : Metrics { logloss:0.0434,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1551, Round: 1551\n",
      "Evalset: [Train : Metrics { logloss:0.0434,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1552, Round: 1552\n",
      "Evalset: [Train : Metrics { logloss:0.0433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1553, Round: 1553\n",
      "Evalset: [Train : Metrics { logloss:0.0433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1554, Round: 1554\n",
      "Evalset: [Train : Metrics { logloss:0.0432,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1555, Round: 1555\n",
      "Evalset: [Train : Metrics { logloss:0.0432,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1556, Round: 1556\n",
      "Evalset: [Train : Metrics { logloss:0.0432,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1557, Round: 1557\n",
      "Evalset: [Train : Metrics { logloss:0.0431,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1558, Round: 1558\n",
      "Evalset: [Train : Metrics { logloss:0.0431,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1559, Round: 1559\n",
      "Evalset: [Train : Metrics { logloss:0.043,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1560, Round: 1560\n",
      "Evalset: [Train : Metrics { logloss:0.043,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1561, Round: 1561\n",
      "Evalset: [Train : Metrics { logloss:0.043,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1562, Round: 1562\n",
      "Evalset: [Train : Metrics { logloss:0.0429,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1563, Round: 1563\n",
      "Evalset: [Train : Metrics { logloss:0.0429,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1564, Round: 1564\n",
      "Evalset: [Train : Metrics { logloss:0.0429,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1565, Round: 1565\n",
      "Evalset: [Train : Metrics { logloss:0.0428,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1566, Round: 1566\n",
      "Evalset: [Train : Metrics { logloss:0.0428,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1567, Round: 1567\n",
      "Evalset: [Train : Metrics { logloss:0.0427,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1568, Round: 1568\n",
      "Evalset: [Train : Metrics { logloss:0.0427,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1569, Round: 1569\n",
      "Evalset: [Train : Metrics { logloss:0.0427,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1570, Round: 1570\n",
      "Evalset: [Train : Metrics { logloss:0.0426,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1571, Round: 1571\n",
      "Evalset: [Train : Metrics { logloss:0.0426,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1572, Round: 1572\n",
      "Evalset: [Train : Metrics { logloss:0.0425,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1573, Round: 1573\n",
      "Evalset: [Train : Metrics { logloss:0.0425,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1574, Round: 1574\n",
      "Evalset: [Train : Metrics { logloss:0.0425,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1575, Round: 1575\n",
      "Evalset: [Train : Metrics { logloss:0.0424,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1576, Round: 1576\n",
      "Evalset: [Train : Metrics { logloss:0.0424,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1577, Round: 1577\n",
      "Evalset: [Train : Metrics { logloss:0.0423,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1578, Round: 1578\n",
      "Evalset: [Train : Metrics { logloss:0.0423,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1579, Round: 1579\n",
      "Evalset: [Train : Metrics { logloss:0.0423,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1580, Round: 1580\n",
      "Evalset: [Train : Metrics { logloss:0.0422,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1581, Round: 1581\n",
      "Evalset: [Train : Metrics { logloss:0.0422,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1582, Round: 1582\n",
      "Evalset: [Train : Metrics { logloss:0.0422,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1583, Round: 1583\n",
      "Evalset: [Train : Metrics { logloss:0.0421,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1584, Round: 1584\n",
      "Evalset: [Train : Metrics { logloss:0.0421,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1585, Round: 1585\n",
      "Evalset: [Train : Metrics { logloss:0.042,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1586, Round: 1586\n",
      "Evalset: [Train : Metrics { logloss:0.042,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1587, Round: 1587\n",
      "Evalset: [Train : Metrics { logloss:0.042,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1588, Round: 1588\n",
      "Evalset: [Train : Metrics { logloss:0.0419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1589, Round: 1589\n",
      "Evalset: [Train : Metrics { logloss:0.0419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1590, Round: 1590\n",
      "Evalset: [Train : Metrics { logloss:0.0419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1591, Round: 1591\n",
      "Evalset: [Train : Metrics { logloss:0.0418,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1592, Round: 1592\n",
      "Evalset: [Train : Metrics { logloss:0.0418,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1593, Round: 1593\n",
      "Evalset: [Train : Metrics { logloss:0.0417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1594, Round: 1594\n",
      "Evalset: [Train : Metrics { logloss:0.0417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1595, Round: 1595\n",
      "Evalset: [Train : Metrics { logloss:0.0417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1596, Round: 1596\n",
      "Evalset: [Train : Metrics { logloss:0.0416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1597, Round: 1597\n",
      "Evalset: [Train : Metrics { logloss:0.0416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1598, Round: 1598\n",
      "Evalset: [Train : Metrics { logloss:0.0416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1599, Round: 1599\n",
      "Evalset: [Train : Metrics { logloss:0.0415,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1600, Round: 1600\n",
      "Evalset: [Train : Metrics { logloss:0.0415,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1601, Round: 1601\n",
      "Evalset: [Train : Metrics { logloss:0.0415,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1602, Round: 1602\n",
      "Evalset: [Train : Metrics { logloss:0.0414,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1603, Round: 1603\n",
      "Evalset: [Train : Metrics { logloss:0.0414,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1604, Round: 1604\n",
      "Evalset: [Train : Metrics { logloss:0.0413,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1605, Round: 1605\n",
      "Evalset: [Train : Metrics { logloss:0.0413,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1606, Round: 1606\n",
      "Evalset: [Train : Metrics { logloss:0.0413,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1607, Round: 1607\n",
      "Evalset: [Train : Metrics { logloss:0.0412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1608, Round: 1608\n",
      "Evalset: [Train : Metrics { logloss:0.0412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1609, Round: 1609\n",
      "Evalset: [Train : Metrics { logloss:0.0412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1610, Round: 1610\n",
      "Evalset: [Train : Metrics { logloss:0.0411,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1611, Round: 1611\n",
      "Evalset: [Train : Metrics { logloss:0.0411,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1612, Round: 1612\n",
      "Evalset: [Train : Metrics { logloss:0.041,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1613, Round: 1613\n",
      "Evalset: [Train : Metrics { logloss:0.041,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1614, Round: 1614\n",
      "Evalset: [Train : Metrics { logloss:0.0409,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1615, Round: 1615\n",
      "Evalset: [Train : Metrics { logloss:0.0409,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1616, Round: 1616\n",
      "Evalset: [Train : Metrics { logloss:0.0409,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1617, Round: 1617\n",
      "Evalset: [Train : Metrics { logloss:0.0409,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1618, Round: 1618\n",
      "Evalset: [Train : Metrics { logloss:0.0408,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1619, Round: 1619\n",
      "Evalset: [Train : Metrics { logloss:0.0408,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1620, Round: 1620\n",
      "Evalset: [Train : Metrics { logloss:0.0407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1621, Round: 1621\n",
      "Evalset: [Train : Metrics { logloss:0.0407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1622, Round: 1622\n",
      "Evalset: [Train : Metrics { logloss:0.0407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1623, Round: 1623\n",
      "Evalset: [Train : Metrics { logloss:0.0406,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1624, Round: 1624\n",
      "Evalset: [Train : Metrics { logloss:0.0406,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1625, Round: 1625\n",
      "Evalset: [Train : Metrics { logloss:0.0406,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1626, Round: 1626\n",
      "Evalset: [Train : Metrics { logloss:0.0405,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1627, Round: 1627\n",
      "Evalset: [Train : Metrics { logloss:0.0405,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1628, Round: 1628\n",
      "Evalset: [Train : Metrics { logloss:0.0405,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1629, Round: 1629\n",
      "Evalset: [Train : Metrics { logloss:0.0404,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1630, Round: 1630\n",
      "Evalset: [Train : Metrics { logloss:0.0404,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1631, Round: 1631\n",
      "Evalset: [Train : Metrics { logloss:0.0403,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1632, Round: 1632\n",
      "Evalset: [Train : Metrics { logloss:0.0403,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1633, Round: 1633\n",
      "Evalset: [Train : Metrics { logloss:0.0403,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1634, Round: 1634\n",
      "Evalset: [Train : Metrics { logloss:0.0402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1635, Round: 1635\n",
      "Evalset: [Train : Metrics { logloss:0.0402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1636, Round: 1636\n",
      "Evalset: [Train : Metrics { logloss:0.0402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1637, Round: 1637\n",
      "Evalset: [Train : Metrics { logloss:0.0401,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1638, Round: 1638\n",
      "Evalset: [Train : Metrics { logloss:0.0401,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1639, Round: 1639\n",
      "Evalset: [Train : Metrics { logloss:0.0401,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1640, Round: 1640\n",
      "Evalset: [Train : Metrics { logloss:0.04,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1641, Round: 1641\n",
      "Evalset: [Train : Metrics { logloss:0.04,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1642, Round: 1642\n",
      "Evalset: [Train : Metrics { logloss:0.0399,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1643, Round: 1643\n",
      "Evalset: [Train : Metrics { logloss:0.0399,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1644, Round: 1644\n",
      "Evalset: [Train : Metrics { logloss:0.0399,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1645, Round: 1645\n",
      "Evalset: [Train : Metrics { logloss:0.0398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1646, Round: 1646\n",
      "Evalset: [Train : Metrics { logloss:0.0398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1647, Round: 1647\n",
      "Evalset: [Train : Metrics { logloss:0.0398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1648, Round: 1648\n",
      "Evalset: [Train : Metrics { logloss:0.0397,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1649, Round: 1649\n",
      "Evalset: [Train : Metrics { logloss:0.0397,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1650, Round: 1650\n",
      "Evalset: [Train : Metrics { logloss:0.0397,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1651, Round: 1651\n",
      "Evalset: [Train : Metrics { logloss:0.0396,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1652, Round: 1652\n",
      "Evalset: [Train : Metrics { logloss:0.0396,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1653, Round: 1653\n",
      "Evalset: [Train : Metrics { logloss:0.0396,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1654, Round: 1654\n",
      "Evalset: [Train : Metrics { logloss:0.0395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1655, Round: 1655\n",
      "Evalset: [Train : Metrics { logloss:0.0395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1656, Round: 1656\n",
      "Evalset: [Train : Metrics { logloss:0.0395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1657, Round: 1657\n",
      "Evalset: [Train : Metrics { logloss:0.0394,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1658, Round: 1658\n",
      "Evalset: [Train : Metrics { logloss:0.0394,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1659, Round: 1659\n",
      "Evalset: [Train : Metrics { logloss:0.0394,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1660, Round: 1660\n",
      "Evalset: [Train : Metrics { logloss:0.0393,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1661, Round: 1661\n",
      "Evalset: [Train : Metrics { logloss:0.0393,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1662, Round: 1662\n",
      "Evalset: [Train : Metrics { logloss:0.0393,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1663, Round: 1663\n",
      "Evalset: [Train : Metrics { logloss:0.0392,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1664, Round: 1664\n",
      "Evalset: [Train : Metrics { logloss:0.0392,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1665, Round: 1665\n",
      "Evalset: [Train : Metrics { logloss:0.0391,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1666, Round: 1666\n",
      "Evalset: [Train : Metrics { logloss:0.0391,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1667, Round: 1667\n",
      "Evalset: [Train : Metrics { logloss:0.0391,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1668, Round: 1668\n",
      "Evalset: [Train : Metrics { logloss:0.039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1669, Round: 1669\n",
      "Evalset: [Train : Metrics { logloss:0.039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1670, Round: 1670\n",
      "Evalset: [Train : Metrics { logloss:0.039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1671, Round: 1671\n",
      "Evalset: [Train : Metrics { logloss:0.0389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1672, Round: 1672\n",
      "Evalset: [Train : Metrics { logloss:0.0389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1673, Round: 1673\n",
      "Evalset: [Train : Metrics { logloss:0.0389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1674, Round: 1674\n",
      "Evalset: [Train : Metrics { logloss:0.0389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1675, Round: 1675\n",
      "Evalset: [Train : Metrics { logloss:0.0388,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1676, Round: 1676\n",
      "Evalset: [Train : Metrics { logloss:0.0388,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1677, Round: 1677\n",
      "Evalset: [Train : Metrics { logloss:0.0387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1678, Round: 1678\n",
      "Evalset: [Train : Metrics { logloss:0.0387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1679, Round: 1679\n",
      "Evalset: [Train : Metrics { logloss:0.0387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1680, Round: 1680\n",
      "Evalset: [Train : Metrics { logloss:0.0386,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1681, Round: 1681\n",
      "Evalset: [Train : Metrics { logloss:0.0386,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1682, Round: 1682\n",
      "Evalset: [Train : Metrics { logloss:0.0386,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1683, Round: 1683\n",
      "Evalset: [Train : Metrics { logloss:0.0385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1684, Round: 1684\n",
      "Evalset: [Train : Metrics { logloss:0.0385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1685, Round: 1685\n",
      "Evalset: [Train : Metrics { logloss:0.0385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1686, Round: 1686\n",
      "Evalset: [Train : Metrics { logloss:0.0384,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1687, Round: 1687\n",
      "Evalset: [Train : Metrics { logloss:0.0384,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1688, Round: 1688\n",
      "Evalset: [Train : Metrics { logloss:0.0384,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1689, Round: 1689\n",
      "Evalset: [Train : Metrics { logloss:0.0383,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1690, Round: 1690\n",
      "Evalset: [Train : Metrics { logloss:0.0383,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1691, Round: 1691\n",
      "Evalset: [Train : Metrics { logloss:0.0383,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1692, Round: 1692\n",
      "Evalset: [Train : Metrics { logloss:0.0382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1693, Round: 1693\n",
      "Evalset: [Train : Metrics { logloss:0.0382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1694, Round: 1694\n",
      "Evalset: [Train : Metrics { logloss:0.0382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1695, Round: 1695\n",
      "Evalset: [Train : Metrics { logloss:0.0381,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1696, Round: 1696\n",
      "Evalset: [Train : Metrics { logloss:0.0381,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1697, Round: 1697\n",
      "Evalset: [Train : Metrics { logloss:0.0381,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1698, Round: 1698\n",
      "Evalset: [Train : Metrics { logloss:0.038,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1699, Round: 1699\n",
      "Evalset: [Train : Metrics { logloss:0.038,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1700, Round: 1700\n",
      "Evalset: [Train : Metrics { logloss:0.038,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1701, Round: 1701\n",
      "Evalset: [Train : Metrics { logloss:0.0379,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1702, Round: 1702\n",
      "Evalset: [Train : Metrics { logloss:0.0379,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1703, Round: 1703\n",
      "Evalset: [Train : Metrics { logloss:0.0379,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1704, Round: 1704\n",
      "Evalset: [Train : Metrics { logloss:0.0378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1705, Round: 1705\n",
      "Evalset: [Train : Metrics { logloss:0.0378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1706, Round: 1706\n",
      "Evalset: [Train : Metrics { logloss:0.0378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1707, Round: 1707\n",
      "Evalset: [Train : Metrics { logloss:0.0377,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1708, Round: 1708\n",
      "Evalset: [Train : Metrics { logloss:0.0377,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1709, Round: 1709\n",
      "Evalset: [Train : Metrics { logloss:0.0377,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1710, Round: 1710\n",
      "Evalset: [Train : Metrics { logloss:0.0376,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1711, Round: 1711\n",
      "Evalset: [Train : Metrics { logloss:0.0376,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1712, Round: 1712\n",
      "Evalset: [Train : Metrics { logloss:0.0376,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1713, Round: 1713\n",
      "Evalset: [Train : Metrics { logloss:0.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1714, Round: 1714\n",
      "Evalset: [Train : Metrics { logloss:0.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1715, Round: 1715\n",
      "Evalset: [Train : Metrics { logloss:0.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1716, Round: 1716\n",
      "Evalset: [Train : Metrics { logloss:0.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1717, Round: 1717\n",
      "Evalset: [Train : Metrics { logloss:0.0374,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1718, Round: 1718\n",
      "Evalset: [Train : Metrics { logloss:0.0374,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1719, Round: 1719\n",
      "Evalset: [Train : Metrics { logloss:0.0374,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1720, Round: 1720\n",
      "Evalset: [Train : Metrics { logloss:0.0373,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1721, Round: 1721\n",
      "Evalset: [Train : Metrics { logloss:0.0373,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1722, Round: 1722\n",
      "Evalset: [Train : Metrics { logloss:0.0373,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1723, Round: 1723\n",
      "Evalset: [Train : Metrics { logloss:0.0372,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1724, Round: 1724\n",
      "Evalset: [Train : Metrics { logloss:0.0372,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1725, Round: 1725\n",
      "Evalset: [Train : Metrics { logloss:0.0372,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1726, Round: 1726\n",
      "Evalset: [Train : Metrics { logloss:0.0371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1727, Round: 1727\n",
      "Evalset: [Train : Metrics { logloss:0.0371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1728, Round: 1728\n",
      "Evalset: [Train : Metrics { logloss:0.0371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1729, Round: 1729\n",
      "Evalset: [Train : Metrics { logloss:0.037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1730, Round: 1730\n",
      "Evalset: [Train : Metrics { logloss:0.037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1731, Round: 1731\n",
      "Evalset: [Train : Metrics { logloss:0.037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1732, Round: 1732\n",
      "Evalset: [Train : Metrics { logloss:0.0369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1733, Round: 1733\n",
      "Evalset: [Train : Metrics { logloss:0.0369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1734, Round: 1734\n",
      "Evalset: [Train : Metrics { logloss:0.0369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1735, Round: 1735\n",
      "Evalset: [Train : Metrics { logloss:0.0369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1736, Round: 1736\n",
      "Evalset: [Train : Metrics { logloss:0.0368,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1737, Round: 1737\n",
      "Evalset: [Train : Metrics { logloss:0.0368,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1738, Round: 1738\n",
      "Evalset: [Train : Metrics { logloss:0.0367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1739, Round: 1739\n",
      "Evalset: [Train : Metrics { logloss:0.0367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1740, Round: 1740\n",
      "Evalset: [Train : Metrics { logloss:0.0367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1741, Round: 1741\n",
      "Evalset: [Train : Metrics { logloss:0.0367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1742, Round: 1742\n",
      "Evalset: [Train : Metrics { logloss:0.0366,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1743, Round: 1743\n",
      "Evalset: [Train : Metrics { logloss:0.0366,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1744, Round: 1744\n",
      "Evalset: [Train : Metrics { logloss:0.0366,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1745, Round: 1745\n",
      "Evalset: [Train : Metrics { logloss:0.0365,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1746, Round: 1746\n",
      "Evalset: [Train : Metrics { logloss:0.0365,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1747, Round: 1747\n",
      "Evalset: [Train : Metrics { logloss:0.0365,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1748, Round: 1748\n",
      "Evalset: [Train : Metrics { logloss:0.0364,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1749, Round: 1749\n",
      "Evalset: [Train : Metrics { logloss:0.0364,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1750, Round: 1750\n",
      "Evalset: [Train : Metrics { logloss:0.0364,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1751, Round: 1751\n",
      "Evalset: [Train : Metrics { logloss:0.0363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1752, Round: 1752\n",
      "Evalset: [Train : Metrics { logloss:0.0363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1753, Round: 1753\n",
      "Evalset: [Train : Metrics { logloss:0.0363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1754, Round: 1754\n",
      "Evalset: [Train : Metrics { logloss:0.0363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1755, Round: 1755\n",
      "Evalset: [Train : Metrics { logloss:0.0362,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1756, Round: 1756\n",
      "Evalset: [Train : Metrics { logloss:0.0362,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1757, Round: 1757\n",
      "Evalset: [Train : Metrics { logloss:0.0362,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1758, Round: 1758\n",
      "Evalset: [Train : Metrics { logloss:0.0361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1759, Round: 1759\n",
      "Evalset: [Train : Metrics { logloss:0.0361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1760, Round: 1760\n",
      "Evalset: [Train : Metrics { logloss:0.0361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1761, Round: 1761\n",
      "Evalset: [Train : Metrics { logloss:0.036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1762, Round: 1762\n",
      "Evalset: [Train : Metrics { logloss:0.036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1763, Round: 1763\n",
      "Evalset: [Train : Metrics { logloss:0.036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1764, Round: 1764\n",
      "Evalset: [Train : Metrics { logloss:0.0359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1765, Round: 1765\n",
      "Evalset: [Train : Metrics { logloss:0.0359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1766, Round: 1766\n",
      "Evalset: [Train : Metrics { logloss:0.0359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1767, Round: 1767\n",
      "Evalset: [Train : Metrics { logloss:0.0359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1768, Round: 1768\n",
      "Evalset: [Train : Metrics { logloss:0.0358,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1769, Round: 1769\n",
      "Evalset: [Train : Metrics { logloss:0.0358,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1770, Round: 1770\n",
      "Evalset: [Train : Metrics { logloss:0.0358,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1771, Round: 1771\n",
      "Evalset: [Train : Metrics { logloss:0.0357,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1772, Round: 1772\n",
      "Evalset: [Train : Metrics { logloss:0.0357,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1773, Round: 1773\n",
      "Evalset: [Train : Metrics { logloss:0.0357,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1774, Round: 1774\n",
      "Evalset: [Train : Metrics { logloss:0.0357,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1775, Round: 1775\n",
      "Evalset: [Train : Metrics { logloss:0.0356,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1776, Round: 1776\n",
      "Evalset: [Train : Metrics { logloss:0.0356,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1777, Round: 1777\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1778, Round: 1778\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1779, Round: 1779\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1780, Round: 1780\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1781, Round: 1781\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1782, Round: 1782\n",
      "Evalset: [Train : Metrics { logloss:0.0354,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1783, Round: 1783\n",
      "Evalset: [Train : Metrics { logloss:0.0354,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1784, Round: 1784\n",
      "Evalset: [Train : Metrics { logloss:0.0353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1785, Round: 1785\n",
      "Evalset: [Train : Metrics { logloss:0.0353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1786, Round: 1786\n",
      "Evalset: [Train : Metrics { logloss:0.0353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1787, Round: 1787\n",
      "Evalset: [Train : Metrics { logloss:0.0353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1788, Round: 1788\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1789, Round: 1789\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1790, Round: 1790\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1791, Round: 1791\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1792, Round: 1792\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1793, Round: 1793\n",
      "Evalset: [Train : Metrics { logloss:0.0351,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1794, Round: 1794\n",
      "Evalset: [Train : Metrics { logloss:0.035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1795, Round: 1795\n",
      "Evalset: [Train : Metrics { logloss:0.035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1796, Round: 1796\n",
      "Evalset: [Train : Metrics { logloss:0.035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1797, Round: 1797\n",
      "Evalset: [Train : Metrics { logloss:0.035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1798, Round: 1798\n",
      "Evalset: [Train : Metrics { logloss:0.035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1799, Round: 1799\n",
      "Evalset: [Train : Metrics { logloss:0.0349,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1800, Round: 1800\n",
      "Evalset: [Train : Metrics { logloss:0.0349,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1801, Round: 1801\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1802, Round: 1802\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1803, Round: 1803\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1804, Round: 1804\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1805, Round: 1805\n",
      "Evalset: [Train : Metrics { logloss:0.0347,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1806, Round: 1806\n",
      "Evalset: [Train : Metrics { logloss:0.0347,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1807, Round: 1807\n",
      "Evalset: [Train : Metrics { logloss:0.0347,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1808, Round: 1808\n",
      "Evalset: [Train : Metrics { logloss:0.0346,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1809, Round: 1809\n",
      "Evalset: [Train : Metrics { logloss:0.0346,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1810, Round: 1810\n",
      "Evalset: [Train : Metrics { logloss:0.0346,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1811, Round: 1811\n",
      "Evalset: [Train : Metrics { logloss:0.0345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1812, Round: 1812\n",
      "Evalset: [Train : Metrics { logloss:0.0345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1813, Round: 1813\n",
      "Evalset: [Train : Metrics { logloss:0.0345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1814, Round: 1814\n",
      "Evalset: [Train : Metrics { logloss:0.0345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1815, Round: 1815\n",
      "Evalset: [Train : Metrics { logloss:0.0344,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1816, Round: 1816\n",
      "Evalset: [Train : Metrics { logloss:0.0344,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1817, Round: 1817\n",
      "Evalset: [Train : Metrics { logloss:0.0344,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1818, Round: 1818\n",
      "Evalset: [Train : Metrics { logloss:0.0343,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1819, Round: 1819\n",
      "Evalset: [Train : Metrics { logloss:0.0343,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1820, Round: 1820\n",
      "Evalset: [Train : Metrics { logloss:0.0343,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1821, Round: 1821\n",
      "Evalset: [Train : Metrics { logloss:0.0343,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1822, Round: 1822\n",
      "Evalset: [Train : Metrics { logloss:0.0342,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1823, Round: 1823\n",
      "Evalset: [Train : Metrics { logloss:0.0342,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1824, Round: 1824\n",
      "Evalset: [Train : Metrics { logloss:0.0342,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1825, Round: 1825\n",
      "Evalset: [Train : Metrics { logloss:0.0341,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1826, Round: 1826\n",
      "Evalset: [Train : Metrics { logloss:0.0341,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1827, Round: 1827\n",
      "Evalset: [Train : Metrics { logloss:0.0341,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1828, Round: 1828\n",
      "Evalset: [Train : Metrics { logloss:0.034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1829, Round: 1829\n",
      "Evalset: [Train : Metrics { logloss:0.034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1830, Round: 1830\n",
      "Evalset: [Train : Metrics { logloss:0.034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1831, Round: 1831\n",
      "Evalset: [Train : Metrics { logloss:0.034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1832, Round: 1832\n",
      "Evalset: [Train : Metrics { logloss:0.0339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1833, Round: 1833\n",
      "Evalset: [Train : Metrics { logloss:0.0339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1834, Round: 1834\n",
      "Evalset: [Train : Metrics { logloss:0.0339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1835, Round: 1835\n",
      "Evalset: [Train : Metrics { logloss:0.0338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1836, Round: 1836\n",
      "Evalset: [Train : Metrics { logloss:0.0338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1837, Round: 1837\n",
      "Evalset: [Train : Metrics { logloss:0.0338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1838, Round: 1838\n",
      "Evalset: [Train : Metrics { logloss:0.0338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1839, Round: 1839\n",
      "Evalset: [Train : Metrics { logloss:0.0337,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1840, Round: 1840\n",
      "Evalset: [Train : Metrics { logloss:0.0337,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1841, Round: 1841\n",
      "Evalset: [Train : Metrics { logloss:0.0337,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1842, Round: 1842\n",
      "Evalset: [Train : Metrics { logloss:0.0336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1843, Round: 1843\n",
      "Evalset: [Train : Metrics { logloss:0.0336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1844, Round: 1844\n",
      "Evalset: [Train : Metrics { logloss:0.0336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1845, Round: 1845\n",
      "Evalset: [Train : Metrics { logloss:0.0336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1846, Round: 1846\n",
      "Evalset: [Train : Metrics { logloss:0.0335,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1847, Round: 1847\n",
      "Evalset: [Train : Metrics { logloss:0.0335,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1848, Round: 1848\n",
      "Evalset: [Train : Metrics { logloss:0.0335,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1849, Round: 1849\n",
      "Evalset: [Train : Metrics { logloss:0.0334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1850, Round: 1850\n",
      "Evalset: [Train : Metrics { logloss:0.0334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1851, Round: 1851\n",
      "Evalset: [Train : Metrics { logloss:0.0334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1852, Round: 1852\n",
      "Evalset: [Train : Metrics { logloss:0.0334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1853, Round: 1853\n",
      "Evalset: [Train : Metrics { logloss:0.0333,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1854, Round: 1854\n",
      "Evalset: [Train : Metrics { logloss:0.0333,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1855, Round: 1855\n",
      "Evalset: [Train : Metrics { logloss:0.0333,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1856, Round: 1856\n",
      "Evalset: [Train : Metrics { logloss:0.0333,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1857, Round: 1857\n",
      "Evalset: [Train : Metrics { logloss:0.0332,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1858, Round: 1858\n",
      "Evalset: [Train : Metrics { logloss:0.0332,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1859, Round: 1859\n",
      "Evalset: [Train : Metrics { logloss:0.0332,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1860, Round: 1860\n",
      "Evalset: [Train : Metrics { logloss:0.0331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1861, Round: 1861\n",
      "Evalset: [Train : Metrics { logloss:0.0331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1862, Round: 1862\n",
      "Evalset: [Train : Metrics { logloss:0.0331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1863, Round: 1863\n",
      "Evalset: [Train : Metrics { logloss:0.0331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1864, Round: 1864\n",
      "Evalset: [Train : Metrics { logloss:0.033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1865, Round: 1865\n",
      "Evalset: [Train : Metrics { logloss:0.033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1866, Round: 1866\n",
      "Evalset: [Train : Metrics { logloss:0.033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1867, Round: 1867\n",
      "Evalset: [Train : Metrics { logloss:0.033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1868, Round: 1868\n",
      "Evalset: [Train : Metrics { logloss:0.0329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1869, Round: 1869\n",
      "Evalset: [Train : Metrics { logloss:0.0329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1870, Round: 1870\n",
      "Evalset: [Train : Metrics { logloss:0.0329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1871, Round: 1871\n",
      "Evalset: [Train : Metrics { logloss:0.0328,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1872, Round: 1872\n",
      "Evalset: [Train : Metrics { logloss:0.0328,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1873, Round: 1873\n",
      "Evalset: [Train : Metrics { logloss:0.0328,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1874, Round: 1874\n",
      "Evalset: [Train : Metrics { logloss:0.0327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1875, Round: 1875\n",
      "Evalset: [Train : Metrics { logloss:0.0327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1876, Round: 1876\n",
      "Evalset: [Train : Metrics { logloss:0.0327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1877, Round: 1877\n",
      "Evalset: [Train : Metrics { logloss:0.0327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1878, Round: 1878\n",
      "Evalset: [Train : Metrics { logloss:0.0326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1879, Round: 1879\n",
      "Evalset: [Train : Metrics { logloss:0.0326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1880, Round: 1880\n",
      "Evalset: [Train : Metrics { logloss:0.0326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1881, Round: 1881\n",
      "Evalset: [Train : Metrics { logloss:0.0326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1882, Round: 1882\n",
      "Evalset: [Train : Metrics { logloss:0.0326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1883, Round: 1883\n",
      "Evalset: [Train : Metrics { logloss:0.0325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1884, Round: 1884\n",
      "Evalset: [Train : Metrics { logloss:0.0325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1885, Round: 1885\n",
      "Evalset: [Train : Metrics { logloss:0.0325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1886, Round: 1886\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1887, Round: 1887\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1888, Round: 1888\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1889, Round: 1889\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1890, Round: 1890\n",
      "Evalset: [Train : Metrics { logloss:0.0323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1891, Round: 1891\n",
      "Evalset: [Train : Metrics { logloss:0.0323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1892, Round: 1892\n",
      "Evalset: [Train : Metrics { logloss:0.0323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1893, Round: 1893\n",
      "Evalset: [Train : Metrics { logloss:0.0322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1894, Round: 1894\n",
      "Evalset: [Train : Metrics { logloss:0.0322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1895, Round: 1895\n",
      "Evalset: [Train : Metrics { logloss:0.0322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1896, Round: 1896\n",
      "Evalset: [Train : Metrics { logloss:0.0322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1897, Round: 1897\n",
      "Evalset: [Train : Metrics { logloss:0.0321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1898, Round: 1898\n",
      "Evalset: [Train : Metrics { logloss:0.0321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1899, Round: 1899\n",
      "Evalset: [Train : Metrics { logloss:0.0321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1900, Round: 1900\n",
      "Evalset: [Train : Metrics { logloss:0.0321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1901, Round: 1901\n",
      "Evalset: [Train : Metrics { logloss:0.032,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1902, Round: 1902\n",
      "Evalset: [Train : Metrics { logloss:0.032,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1903, Round: 1903\n",
      "Evalset: [Train : Metrics { logloss:0.032,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1904, Round: 1904\n",
      "Evalset: [Train : Metrics { logloss:0.0319,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1905, Round: 1905\n",
      "Evalset: [Train : Metrics { logloss:0.0319,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1906, Round: 1906\n",
      "Evalset: [Train : Metrics { logloss:0.0319,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1907, Round: 1907\n",
      "Evalset: [Train : Metrics { logloss:0.0319,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1908, Round: 1908\n",
      "Evalset: [Train : Metrics { logloss:0.0318,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1909, Round: 1909\n",
      "Evalset: [Train : Metrics { logloss:0.0318,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1910, Round: 1910\n",
      "Evalset: [Train : Metrics { logloss:0.0318,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1911, Round: 1911\n",
      "Evalset: [Train : Metrics { logloss:0.0318,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1912, Round: 1912\n",
      "Evalset: [Train : Metrics { logloss:0.0317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1913, Round: 1913\n",
      "Evalset: [Train : Metrics { logloss:0.0317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1914, Round: 1914\n",
      "Evalset: [Train : Metrics { logloss:0.0317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1915, Round: 1915\n",
      "Evalset: [Train : Metrics { logloss:0.0317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1916, Round: 1916\n",
      "Evalset: [Train : Metrics { logloss:0.0316,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1917, Round: 1917\n",
      "Evalset: [Train : Metrics { logloss:0.0316,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1918, Round: 1918\n",
      "Evalset: [Train : Metrics { logloss:0.0316,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1919, Round: 1919\n",
      "Evalset: [Train : Metrics { logloss:0.0315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1920, Round: 1920\n",
      "Evalset: [Train : Metrics { logloss:0.0315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1921, Round: 1921\n",
      "Evalset: [Train : Metrics { logloss:0.0315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1922, Round: 1922\n",
      "Evalset: [Train : Metrics { logloss:0.0315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1923, Round: 1923\n",
      "Evalset: [Train : Metrics { logloss:0.0315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1924, Round: 1924\n",
      "Evalset: [Train : Metrics { logloss:0.0314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1925, Round: 1925\n",
      "Evalset: [Train : Metrics { logloss:0.0314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1926, Round: 1926\n",
      "Evalset: [Train : Metrics { logloss:0.0314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1927, Round: 1927\n",
      "Evalset: [Train : Metrics { logloss:0.0314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1928, Round: 1928\n",
      "Evalset: [Train : Metrics { logloss:0.0313,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0831,  }]\n",
      "Training on Total Epoch: 1929, Round: 1929\n",
      "Evalset: [Train : Metrics { logloss:0.0313,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0831,  }]\n",
      "Training on Total Epoch: 1930, Round: 1930\n",
      "Evalset: [Train : Metrics { logloss:0.0313,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1931, Round: 1931\n",
      "Evalset: [Train : Metrics { logloss:0.0313,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1932, Round: 1932\n",
      "Evalset: [Train : Metrics { logloss:0.0312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1933, Round: 1933\n",
      "Evalset: [Train : Metrics { logloss:0.0312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1934, Round: 1934\n",
      "Evalset: [Train : Metrics { logloss:0.0312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1935, Round: 1935\n",
      "Evalset: [Train : Metrics { logloss:0.0311,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1936, Round: 1936\n",
      "Evalset: [Train : Metrics { logloss:0.0311,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1937, Round: 1937\n",
      "Evalset: [Train : Metrics { logloss:0.0311,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1938, Round: 1938\n",
      "Evalset: [Train : Metrics { logloss:0.0311,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1939, Round: 1939\n",
      "Evalset: [Train : Metrics { logloss:0.031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1940, Round: 1940\n",
      "Evalset: [Train : Metrics { logloss:0.031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1941, Round: 1941\n",
      "Evalset: [Train : Metrics { logloss:0.031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1942, Round: 1942\n",
      "Evalset: [Train : Metrics { logloss:0.031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1943, Round: 1943\n",
      "Evalset: [Train : Metrics { logloss:0.0309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1944, Round: 1944\n",
      "Evalset: [Train : Metrics { logloss:0.0309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1945, Round: 1945\n",
      "Evalset: [Train : Metrics { logloss:0.0309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1946, Round: 1946\n",
      "Evalset: [Train : Metrics { logloss:0.0309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 1947, Round: 1947\n",
      "Evalset: [Train : Metrics { logloss:0.0308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1948, Round: 1948\n",
      "Evalset: [Train : Metrics { logloss:0.0308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1949, Round: 1949\n",
      "Evalset: [Train : Metrics { logloss:0.0308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1950, Round: 1950\n",
      "Evalset: [Train : Metrics { logloss:0.0308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1951, Round: 1951\n",
      "Evalset: [Train : Metrics { logloss:0.0307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1952, Round: 1952\n",
      "Evalset: [Train : Metrics { logloss:0.0307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1953, Round: 1953\n",
      "Evalset: [Train : Metrics { logloss:0.0307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1954, Round: 1954\n",
      "Evalset: [Train : Metrics { logloss:0.0307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1955, Round: 1955\n",
      "Evalset: [Train : Metrics { logloss:0.0306,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1956, Round: 1956\n",
      "Evalset: [Train : Metrics { logloss:0.0306,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1957, Round: 1957\n",
      "Evalset: [Train : Metrics { logloss:0.0306,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1958, Round: 1958\n",
      "Evalset: [Train : Metrics { logloss:0.0306,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 1959, Round: 1959\n",
      "Evalset: [Train : Metrics { logloss:0.0305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 1960, Round: 1960\n",
      "Evalset: [Train : Metrics { logloss:0.0305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0831,  }]\n",
      "Training on Total Epoch: 1961, Round: 1961\n",
      "Evalset: [Train : Metrics { logloss:0.0305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1962, Round: 1962\n",
      "Evalset: [Train : Metrics { logloss:0.0305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1963, Round: 1963\n",
      "Evalset: [Train : Metrics { logloss:0.0304,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1964, Round: 1964\n",
      "Evalset: [Train : Metrics { logloss:0.0304,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1965, Round: 1965\n",
      "Evalset: [Train : Metrics { logloss:0.0304,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1966, Round: 1966\n",
      "Evalset: [Train : Metrics { logloss:0.0304,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 1967, Round: 1967\n",
      "Evalset: [Train : Metrics { logloss:0.0303,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1968, Round: 1968\n",
      "Evalset: [Train : Metrics { logloss:0.0303,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1969, Round: 1969\n",
      "Evalset: [Train : Metrics { logloss:0.0303,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1970, Round: 1970\n",
      "Evalset: [Train : Metrics { logloss:0.0303,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1971, Round: 1971\n",
      "Evalset: [Train : Metrics { logloss:0.0302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1972, Round: 1972\n",
      "Evalset: [Train : Metrics { logloss:0.0302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1973, Round: 1973\n",
      "Evalset: [Train : Metrics { logloss:0.0302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1974, Round: 1974\n",
      "Evalset: [Train : Metrics { logloss:0.0302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1975, Round: 1975\n",
      "Evalset: [Train : Metrics { logloss:0.0301,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1976, Round: 1976\n",
      "Evalset: [Train : Metrics { logloss:0.0301,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1977, Round: 1977\n",
      "Evalset: [Train : Metrics { logloss:0.0301,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1978, Round: 1978\n",
      "Evalset: [Train : Metrics { logloss:0.0301,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1979, Round: 1979\n",
      "Evalset: [Train : Metrics { logloss:0.03,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1980, Round: 1980\n",
      "Evalset: [Train : Metrics { logloss:0.03,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1981, Round: 1981\n",
      "Evalset: [Train : Metrics { logloss:0.03,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1982, Round: 1982\n",
      "Evalset: [Train : Metrics { logloss:0.03,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1983, Round: 1983\n",
      "Evalset: [Train : Metrics { logloss:0.03,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1984, Round: 1984\n",
      "Evalset: [Train : Metrics { logloss:0.0299,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1985, Round: 1985\n",
      "Evalset: [Train : Metrics { logloss:0.0299,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1986, Round: 1986\n",
      "Evalset: [Train : Metrics { logloss:0.0299,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1987, Round: 1987\n",
      "Evalset: [Train : Metrics { logloss:0.0298,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1988, Round: 1988\n",
      "Evalset: [Train : Metrics { logloss:0.0298,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1989, Round: 1989\n",
      "Evalset: [Train : Metrics { logloss:0.0298,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1990, Round: 1990\n",
      "Evalset: [Train : Metrics { logloss:0.0298,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1991, Round: 1991\n",
      "Evalset: [Train : Metrics { logloss:0.0297,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1992, Round: 1992\n",
      "Evalset: [Train : Metrics { logloss:0.0297,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1993, Round: 1993\n",
      "Evalset: [Train : Metrics { logloss:0.0297,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1994, Round: 1994\n",
      "Evalset: [Train : Metrics { logloss:0.0297,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1995, Round: 1995\n",
      "Evalset: [Train : Metrics { logloss:0.0296,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1996, Round: 1996\n",
      "Evalset: [Train : Metrics { logloss:0.0296,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1997, Round: 1997\n",
      "Evalset: [Train : Metrics { logloss:0.0296,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1998, Round: 1998\n",
      "Evalset: [Train : Metrics { logloss:0.0296,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1999, Round: 1999\n",
      "Evalset: [Train : Metrics { logloss:0.0295,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2000, Round: 2000\n",
      "Evalset: [Train : Metrics { logloss:0.0295,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2001, Round: 2001\n",
      "Evalset: [Train : Metrics { logloss:0.0295,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2002, Round: 2002\n",
      "Evalset: [Train : Metrics { logloss:0.0295,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2003, Round: 2003\n",
      "Evalset: [Train : Metrics { logloss:0.0294,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2004, Round: 2004\n",
      "Evalset: [Train : Metrics { logloss:0.0294,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2005, Round: 2005\n",
      "Evalset: [Train : Metrics { logloss:0.0294,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2006, Round: 2006\n",
      "Evalset: [Train : Metrics { logloss:0.0294,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2007, Round: 2007\n",
      "Evalset: [Train : Metrics { logloss:0.0294,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2008, Round: 2008\n",
      "Evalset: [Train : Metrics { logloss:0.0293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2009, Round: 2009\n",
      "Evalset: [Train : Metrics { logloss:0.0293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2010, Round: 2010\n",
      "Evalset: [Train : Metrics { logloss:0.0293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2011, Round: 2011\n",
      "Evalset: [Train : Metrics { logloss:0.0293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2012, Round: 2012\n",
      "Evalset: [Train : Metrics { logloss:0.0292,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2013, Round: 2013\n",
      "Evalset: [Train : Metrics { logloss:0.0292,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2014, Round: 2014\n",
      "Evalset: [Train : Metrics { logloss:0.0292,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2015, Round: 2015\n",
      "Evalset: [Train : Metrics { logloss:0.0292,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2016, Round: 2016\n",
      "Evalset: [Train : Metrics { logloss:0.0292,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2017, Round: 2017\n",
      "Evalset: [Train : Metrics { logloss:0.0291,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2018, Round: 2018\n",
      "Evalset: [Train : Metrics { logloss:0.0291,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2019, Round: 2019\n",
      "Evalset: [Train : Metrics { logloss:0.0291,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2020, Round: 2020\n",
      "Evalset: [Train : Metrics { logloss:0.029,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2021, Round: 2021\n",
      "Evalset: [Train : Metrics { logloss:0.029,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2022, Round: 2022\n",
      "Evalset: [Train : Metrics { logloss:0.029,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2023, Round: 2023\n",
      "Evalset: [Train : Metrics { logloss:0.029,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2024, Round: 2024\n",
      "Evalset: [Train : Metrics { logloss:0.0289,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2025, Round: 2025\n",
      "Evalset: [Train : Metrics { logloss:0.0289,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2026, Round: 2026\n",
      "Evalset: [Train : Metrics { logloss:0.0289,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2027, Round: 2027\n",
      "Evalset: [Train : Metrics { logloss:0.0289,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2028, Round: 2028\n",
      "Evalset: [Train : Metrics { logloss:0.0288,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2029, Round: 2029\n",
      "Evalset: [Train : Metrics { logloss:0.0288,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2030, Round: 2030\n",
      "Evalset: [Train : Metrics { logloss:0.0288,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2031, Round: 2031\n",
      "Evalset: [Train : Metrics { logloss:0.0288,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2032, Round: 2032\n",
      "Evalset: [Train : Metrics { logloss:0.0288,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2033, Round: 2033\n",
      "Evalset: [Train : Metrics { logloss:0.0287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2034, Round: 2034\n",
      "Evalset: [Train : Metrics { logloss:0.0287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2035, Round: 2035\n",
      "Evalset: [Train : Metrics { logloss:0.0287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2036, Round: 2036\n",
      "Evalset: [Train : Metrics { logloss:0.0287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2037, Round: 2037\n",
      "Evalset: [Train : Metrics { logloss:0.0287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2038, Round: 2038\n",
      "Evalset: [Train : Metrics { logloss:0.0286,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2039, Round: 2039\n",
      "Evalset: [Train : Metrics { logloss:0.0286,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2040, Round: 2040\n",
      "Evalset: [Train : Metrics { logloss:0.0286,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2041, Round: 2041\n",
      "Evalset: [Train : Metrics { logloss:0.0286,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2042, Round: 2042\n",
      "Evalset: [Train : Metrics { logloss:0.0285,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2043, Round: 2043\n",
      "Evalset: [Train : Metrics { logloss:0.0285,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2044, Round: 2044\n",
      "Evalset: [Train : Metrics { logloss:0.0285,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2045, Round: 2045\n",
      "Evalset: [Train : Metrics { logloss:0.0285,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2046, Round: 2046\n",
      "Evalset: [Train : Metrics { logloss:0.0284,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2047, Round: 2047\n",
      "Evalset: [Train : Metrics { logloss:0.0284,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2048, Round: 2048\n",
      "Evalset: [Train : Metrics { logloss:0.0284,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2049, Round: 2049\n",
      "Evalset: [Train : Metrics { logloss:0.0284,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2050, Round: 2050\n",
      "Evalset: [Train : Metrics { logloss:0.0283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2051, Round: 2051\n",
      "Evalset: [Train : Metrics { logloss:0.0283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2052, Round: 2052\n",
      "Evalset: [Train : Metrics { logloss:0.0283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2053, Round: 2053\n",
      "Evalset: [Train : Metrics { logloss:0.0283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2054, Round: 2054\n",
      "Evalset: [Train : Metrics { logloss:0.0282,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2055, Round: 2055\n",
      "Evalset: [Train : Metrics { logloss:0.0282,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2056, Round: 2056\n",
      "Evalset: [Train : Metrics { logloss:0.0282,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2057, Round: 2057\n",
      "Evalset: [Train : Metrics { logloss:0.0282,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2058, Round: 2058\n",
      "Evalset: [Train : Metrics { logloss:0.0282,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2059, Round: 2059\n",
      "Evalset: [Train : Metrics { logloss:0.0281,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2060, Round: 2060\n",
      "Evalset: [Train : Metrics { logloss:0.0281,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2061, Round: 2061\n",
      "Evalset: [Train : Metrics { logloss:0.0281,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2062, Round: 2062\n",
      "Evalset: [Train : Metrics { logloss:0.0281,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2063, Round: 2063\n",
      "Evalset: [Train : Metrics { logloss:0.0281,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2064, Round: 2064\n",
      "Evalset: [Train : Metrics { logloss:0.028,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2065, Round: 2065\n",
      "Evalset: [Train : Metrics { logloss:0.028,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2066, Round: 2066\n",
      "Evalset: [Train : Metrics { logloss:0.028,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2067, Round: 2067\n",
      "Evalset: [Train : Metrics { logloss:0.0279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2068, Round: 2068\n",
      "Evalset: [Train : Metrics { logloss:0.0279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2069, Round: 2069\n",
      "Evalset: [Train : Metrics { logloss:0.0279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2070, Round: 2070\n",
      "Evalset: [Train : Metrics { logloss:0.0279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2071, Round: 2071\n",
      "Evalset: [Train : Metrics { logloss:0.0278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2072, Round: 2072\n",
      "Evalset: [Train : Metrics { logloss:0.0278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2073, Round: 2073\n",
      "Evalset: [Train : Metrics { logloss:0.0278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2074, Round: 2074\n",
      "Evalset: [Train : Metrics { logloss:0.0278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2075, Round: 2075\n",
      "Evalset: [Train : Metrics { logloss:0.0278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2076, Round: 2076\n",
      "Evalset: [Train : Metrics { logloss:0.0278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0831,  }]\n",
      "Training on Total Epoch: 2077, Round: 2077\n",
      "Evalset: [Train : Metrics { logloss:0.0277,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.083,  }]\n",
      "Training on Total Epoch: 2078, Round: 2078\n",
      "Evalset: [Train : Metrics { logloss:0.0277,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2079, Round: 2079\n",
      "Evalset: [Train : Metrics { logloss:0.0277,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2080, Round: 2080\n",
      "Evalset: [Train : Metrics { logloss:0.0276,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2081, Round: 2081\n",
      "Evalset: [Train : Metrics { logloss:0.0276,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2082, Round: 2082\n",
      "Evalset: [Train : Metrics { logloss:0.0276,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2083, Round: 2083\n",
      "Evalset: [Train : Metrics { logloss:0.0276,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2084, Round: 2084\n",
      "Evalset: [Train : Metrics { logloss:0.0276,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2085, Round: 2085\n",
      "Evalset: [Train : Metrics { logloss:0.0275,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2086, Round: 2086\n",
      "Evalset: [Train : Metrics { logloss:0.0275,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2087, Round: 2087\n",
      "Evalset: [Train : Metrics { logloss:0.0275,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2088, Round: 2088\n",
      "Evalset: [Train : Metrics { logloss:0.0275,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2089, Round: 2089\n",
      "Evalset: [Train : Metrics { logloss:0.0274,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2090, Round: 2090\n",
      "Evalset: [Train : Metrics { logloss:0.0274,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2091, Round: 2091\n",
      "Evalset: [Train : Metrics { logloss:0.0274,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2092, Round: 2092\n",
      "Evalset: [Train : Metrics { logloss:0.0274,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2093, Round: 2093\n",
      "Evalset: [Train : Metrics { logloss:0.0274,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2094, Round: 2094\n",
      "Evalset: [Train : Metrics { logloss:0.0273,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2095, Round: 2095\n",
      "Evalset: [Train : Metrics { logloss:0.0273,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2096, Round: 2096\n",
      "Evalset: [Train : Metrics { logloss:0.0273,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2097, Round: 2097\n",
      "Evalset: [Train : Metrics { logloss:0.0273,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2098, Round: 2098\n",
      "Evalset: [Train : Metrics { logloss:0.0272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2099, Round: 2099\n",
      "Evalset: [Train : Metrics { logloss:0.0272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2100, Round: 2100\n",
      "Evalset: [Train : Metrics { logloss:0.0272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2101, Round: 2101\n",
      "Evalset: [Train : Metrics { logloss:0.0272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2102, Round: 2102\n",
      "Evalset: [Train : Metrics { logloss:0.0272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2103, Round: 2103\n",
      "Evalset: [Train : Metrics { logloss:0.0271,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2104, Round: 2104\n",
      "Evalset: [Train : Metrics { logloss:0.0271,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2105, Round: 2105\n",
      "Evalset: [Train : Metrics { logloss:0.0271,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2106, Round: 2106\n",
      "Evalset: [Train : Metrics { logloss:0.0271,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2107, Round: 2107\n",
      "Evalset: [Train : Metrics { logloss:0.0271,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2108, Round: 2108\n",
      "Evalset: [Train : Metrics { logloss:0.027,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2109, Round: 2109\n",
      "Evalset: [Train : Metrics { logloss:0.027,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2110, Round: 2110\n",
      "Evalset: [Train : Metrics { logloss:0.027,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2111, Round: 2111\n",
      "Evalset: [Train : Metrics { logloss:0.027,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2112, Round: 2112\n",
      "Evalset: [Train : Metrics { logloss:0.0269,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2113, Round: 2113\n",
      "Evalset: [Train : Metrics { logloss:0.0269,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2114, Round: 2114\n",
      "Evalset: [Train : Metrics { logloss:0.0269,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2115, Round: 2115\n",
      "Evalset: [Train : Metrics { logloss:0.0269,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2116, Round: 2116\n",
      "Evalset: [Train : Metrics { logloss:0.0269,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2117, Round: 2117\n",
      "Evalset: [Train : Metrics { logloss:0.0268,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2118, Round: 2118\n",
      "Evalset: [Train : Metrics { logloss:0.0268,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2119, Round: 2119\n",
      "Evalset: [Train : Metrics { logloss:0.0268,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2120, Round: 2120\n",
      "Evalset: [Train : Metrics { logloss:0.0268,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2121, Round: 2121\n",
      "Evalset: [Train : Metrics { logloss:0.0268,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2122, Round: 2122\n",
      "Evalset: [Train : Metrics { logloss:0.0267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2123, Round: 2123\n",
      "Evalset: [Train : Metrics { logloss:0.0267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2124, Round: 2124\n",
      "Evalset: [Train : Metrics { logloss:0.0267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2125, Round: 2125\n",
      "Evalset: [Train : Metrics { logloss:0.0267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2126, Round: 2126\n",
      "Evalset: [Train : Metrics { logloss:0.0266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2127, Round: 2127\n",
      "Evalset: [Train : Metrics { logloss:0.0266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2128, Round: 2128\n",
      "Evalset: [Train : Metrics { logloss:0.0266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2129, Round: 2129\n",
      "Evalset: [Train : Metrics { logloss:0.0266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2130, Round: 2130\n",
      "Evalset: [Train : Metrics { logloss:0.0266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2131, Round: 2131\n",
      "Evalset: [Train : Metrics { logloss:0.0266,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2132, Round: 2132\n",
      "Evalset: [Train : Metrics { logloss:0.0265,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2133, Round: 2133\n",
      "Evalset: [Train : Metrics { logloss:0.0265,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2134, Round: 2134\n",
      "Evalset: [Train : Metrics { logloss:0.0265,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2135, Round: 2135\n",
      "Evalset: [Train : Metrics { logloss:0.0264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2136, Round: 2136\n",
      "Evalset: [Train : Metrics { logloss:0.0264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2137, Round: 2137\n",
      "Evalset: [Train : Metrics { logloss:0.0264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2138, Round: 2138\n",
      "Evalset: [Train : Metrics { logloss:0.0264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2139, Round: 2139\n",
      "Evalset: [Train : Metrics { logloss:0.0264,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2140, Round: 2140\n",
      "Evalset: [Train : Metrics { logloss:0.0263,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2141, Round: 2141\n",
      "Evalset: [Train : Metrics { logloss:0.0263,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2142, Round: 2142\n",
      "Evalset: [Train : Metrics { logloss:0.0263,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2143, Round: 2143\n",
      "Evalset: [Train : Metrics { logloss:0.0263,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2144, Round: 2144\n",
      "Evalset: [Train : Metrics { logloss:0.0262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2145, Round: 2145\n",
      "Evalset: [Train : Metrics { logloss:0.0262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2146, Round: 2146\n",
      "Evalset: [Train : Metrics { logloss:0.0262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2147, Round: 2147\n",
      "Evalset: [Train : Metrics { logloss:0.0262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2148, Round: 2148\n",
      "Evalset: [Train : Metrics { logloss:0.0262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2149, Round: 2149\n",
      "Evalset: [Train : Metrics { logloss:0.0261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2150, Round: 2150\n",
      "Evalset: [Train : Metrics { logloss:0.0261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2151, Round: 2151\n",
      "Evalset: [Train : Metrics { logloss:0.0261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2152, Round: 2152\n",
      "Evalset: [Train : Metrics { logloss:0.0261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2153, Round: 2153\n",
      "Evalset: [Train : Metrics { logloss:0.0261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2154, Round: 2154\n",
      "Evalset: [Train : Metrics { logloss:0.026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2155, Round: 2155\n",
      "Evalset: [Train : Metrics { logloss:0.026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2156, Round: 2156\n",
      "Evalset: [Train : Metrics { logloss:0.026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2157, Round: 2157\n",
      "Evalset: [Train : Metrics { logloss:0.026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2158, Round: 2158\n",
      "Evalset: [Train : Metrics { logloss:0.026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2159, Round: 2159\n",
      "Evalset: [Train : Metrics { logloss:0.026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2160, Round: 2160\n",
      "Evalset: [Train : Metrics { logloss:0.0259,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2161, Round: 2161\n",
      "Evalset: [Train : Metrics { logloss:0.0259,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2162, Round: 2162\n",
      "Evalset: [Train : Metrics { logloss:0.0259,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2163, Round: 2163\n",
      "Evalset: [Train : Metrics { logloss:0.0259,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2164, Round: 2164\n",
      "Evalset: [Train : Metrics { logloss:0.0258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2165, Round: 2165\n",
      "Evalset: [Train : Metrics { logloss:0.0258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2166, Round: 2166\n",
      "Evalset: [Train : Metrics { logloss:0.0258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2167, Round: 2167\n",
      "Evalset: [Train : Metrics { logloss:0.0258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2168, Round: 2168\n",
      "Evalset: [Train : Metrics { logloss:0.0258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2169, Round: 2169\n",
      "Evalset: [Train : Metrics { logloss:0.0257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2170, Round: 2170\n",
      "Evalset: [Train : Metrics { logloss:0.0257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2171, Round: 2171\n",
      "Evalset: [Train : Metrics { logloss:0.0257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2172, Round: 2172\n",
      "Evalset: [Train : Metrics { logloss:0.0257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2173, Round: 2173\n",
      "Evalset: [Train : Metrics { logloss:0.0257,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2174, Round: 2174\n",
      "Evalset: [Train : Metrics { logloss:0.0256,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2175, Round: 2175\n",
      "Evalset: [Train : Metrics { logloss:0.0256,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2176, Round: 2176\n",
      "Evalset: [Train : Metrics { logloss:0.0256,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2177, Round: 2177\n",
      "Evalset: [Train : Metrics { logloss:0.0256,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2178, Round: 2178\n",
      "Evalset: [Train : Metrics { logloss:0.0255,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2179, Round: 2179\n",
      "Evalset: [Train : Metrics { logloss:0.0255,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2180, Round: 2180\n",
      "Evalset: [Train : Metrics { logloss:0.0255,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2181, Round: 2181\n",
      "Evalset: [Train : Metrics { logloss:0.0255,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2182, Round: 2182\n",
      "Evalset: [Train : Metrics { logloss:0.0255,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2183, Round: 2183\n",
      "Evalset: [Train : Metrics { logloss:0.0254,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2184, Round: 2184\n",
      "Evalset: [Train : Metrics { logloss:0.0254,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2185, Round: 2185\n",
      "Evalset: [Train : Metrics { logloss:0.0254,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2186, Round: 2186\n",
      "Evalset: [Train : Metrics { logloss:0.0254,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2187, Round: 2187\n",
      "Evalset: [Train : Metrics { logloss:0.0254,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2188, Round: 2188\n",
      "Evalset: [Train : Metrics { logloss:0.0253,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2189, Round: 2189\n",
      "Evalset: [Train : Metrics { logloss:0.0253,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2190, Round: 2190\n",
      "Evalset: [Train : Metrics { logloss:0.0253,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2191, Round: 2191\n",
      "Evalset: [Train : Metrics { logloss:0.0253,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2192, Round: 2192\n",
      "Evalset: [Train : Metrics { logloss:0.0252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2193, Round: 2193\n",
      "Evalset: [Train : Metrics { logloss:0.0252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2194, Round: 2194\n",
      "Evalset: [Train : Metrics { logloss:0.0252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2195, Round: 2195\n",
      "Evalset: [Train : Metrics { logloss:0.0252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2196, Round: 2196\n",
      "Evalset: [Train : Metrics { logloss:0.0252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2197, Round: 2197\n",
      "Evalset: [Train : Metrics { logloss:0.0252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2198, Round: 2198\n",
      "Evalset: [Train : Metrics { logloss:0.0251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2199, Round: 2199\n",
      "Evalset: [Train : Metrics { logloss:0.0251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2200, Round: 2200\n",
      "Evalset: [Train : Metrics { logloss:0.0251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2201, Round: 2201\n",
      "Evalset: [Train : Metrics { logloss:0.0251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2202, Round: 2202\n",
      "Evalset: [Train : Metrics { logloss:0.0251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2203, Round: 2203\n",
      "Evalset: [Train : Metrics { logloss:0.025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2204, Round: 2204\n",
      "Evalset: [Train : Metrics { logloss:0.025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2205, Round: 2205\n",
      "Evalset: [Train : Metrics { logloss:0.025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2206, Round: 2206\n",
      "Evalset: [Train : Metrics { logloss:0.025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2207, Round: 2207\n",
      "Evalset: [Train : Metrics { logloss:0.025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2208, Round: 2208\n",
      "Evalset: [Train : Metrics { logloss:0.025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2209, Round: 2209\n",
      "Evalset: [Train : Metrics { logloss:0.0249,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0831,  }]\n",
      "Training on Total Epoch: 2210, Round: 2210\n",
      "Evalset: [Train : Metrics { logloss:0.0249,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2211, Round: 2211\n",
      "Evalset: [Train : Metrics { logloss:0.0249,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2212, Round: 2212\n",
      "Evalset: [Train : Metrics { logloss:0.0249,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2213, Round: 2213\n",
      "Evalset: [Train : Metrics { logloss:0.0248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2214, Round: 2214\n",
      "Evalset: [Train : Metrics { logloss:0.0248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2215, Round: 2215\n",
      "Evalset: [Train : Metrics { logloss:0.0248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2216, Round: 2216\n",
      "Evalset: [Train : Metrics { logloss:0.0248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2217, Round: 2217\n",
      "Evalset: [Train : Metrics { logloss:0.0247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2218, Round: 2218\n",
      "Evalset: [Train : Metrics { logloss:0.0247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2219, Round: 2219\n",
      "Evalset: [Train : Metrics { logloss:0.0247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2220, Round: 2220\n",
      "Evalset: [Train : Metrics { logloss:0.0247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2221, Round: 2221\n",
      "Evalset: [Train : Metrics { logloss:0.0247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2222, Round: 2222\n",
      "Evalset: [Train : Metrics { logloss:0.0246,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2223, Round: 2223\n",
      "Evalset: [Train : Metrics { logloss:0.0246,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2224, Round: 2224\n",
      "Evalset: [Train : Metrics { logloss:0.0246,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2225, Round: 2225\n",
      "Evalset: [Train : Metrics { logloss:0.0246,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2226, Round: 2226\n",
      "Evalset: [Train : Metrics { logloss:0.0246,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2227, Round: 2227\n",
      "Evalset: [Train : Metrics { logloss:0.0245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2228, Round: 2228\n",
      "Evalset: [Train : Metrics { logloss:0.0245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2229, Round: 2229\n",
      "Evalset: [Train : Metrics { logloss:0.0245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2230, Round: 2230\n",
      "Evalset: [Train : Metrics { logloss:0.0245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2231, Round: 2231\n",
      "Evalset: [Train : Metrics { logloss:0.0245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2232, Round: 2232\n",
      "Evalset: [Train : Metrics { logloss:0.0245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2233, Round: 2233\n",
      "Evalset: [Train : Metrics { logloss:0.0244,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2234, Round: 2234\n",
      "Evalset: [Train : Metrics { logloss:0.0244,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2235, Round: 2235\n",
      "Evalset: [Train : Metrics { logloss:0.0244,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2236, Round: 2236\n",
      "Evalset: [Train : Metrics { logloss:0.0244,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2237, Round: 2237\n",
      "Evalset: [Train : Metrics { logloss:0.0244,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2238, Round: 2238\n",
      "Evalset: [Train : Metrics { logloss:0.0243,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2239, Round: 2239\n",
      "Evalset: [Train : Metrics { logloss:0.0243,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2240, Round: 2240\n",
      "Evalset: [Train : Metrics { logloss:0.0243,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2241, Round: 2241\n",
      "Evalset: [Train : Metrics { logloss:0.0243,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2242, Round: 2242\n",
      "Evalset: [Train : Metrics { logloss:0.0242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2243, Round: 2243\n",
      "Evalset: [Train : Metrics { logloss:0.0242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2244, Round: 2244\n",
      "Evalset: [Train : Metrics { logloss:0.0242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2245, Round: 2245\n",
      "Evalset: [Train : Metrics { logloss:0.0242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2246, Round: 2246\n",
      "Evalset: [Train : Metrics { logloss:0.0242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2247, Round: 2247\n",
      "Evalset: [Train : Metrics { logloss:0.0241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2248, Round: 2248\n",
      "Evalset: [Train : Metrics { logloss:0.0241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2249, Round: 2249\n",
      "Evalset: [Train : Metrics { logloss:0.0241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2250, Round: 2250\n",
      "Evalset: [Train : Metrics { logloss:0.0241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2251, Round: 2251\n",
      "Evalset: [Train : Metrics { logloss:0.0241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2252, Round: 2252\n",
      "Evalset: [Train : Metrics { logloss:0.0241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2253, Round: 2253\n",
      "Evalset: [Train : Metrics { logloss:0.024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2254, Round: 2254\n",
      "Evalset: [Train : Metrics { logloss:0.024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2255, Round: 2255\n",
      "Evalset: [Train : Metrics { logloss:0.024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2256, Round: 2256\n",
      "Evalset: [Train : Metrics { logloss:0.024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2257, Round: 2257\n",
      "Evalset: [Train : Metrics { logloss:0.024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2258, Round: 2258\n",
      "Evalset: [Train : Metrics { logloss:0.0239,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2259, Round: 2259\n",
      "Evalset: [Train : Metrics { logloss:0.0239,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2260, Round: 2260\n",
      "Evalset: [Train : Metrics { logloss:0.0239,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2261, Round: 2261\n",
      "Evalset: [Train : Metrics { logloss:0.0239,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2262, Round: 2262\n",
      "Evalset: [Train : Metrics { logloss:0.0239,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2263, Round: 2263\n",
      "Evalset: [Train : Metrics { logloss:0.0238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2264, Round: 2264\n",
      "Evalset: [Train : Metrics { logloss:0.0238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2265, Round: 2265\n",
      "Evalset: [Train : Metrics { logloss:0.0238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2266, Round: 2266\n",
      "Evalset: [Train : Metrics { logloss:0.0238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2267, Round: 2267\n",
      "Evalset: [Train : Metrics { logloss:0.0238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2268, Round: 2268\n",
      "Evalset: [Train : Metrics { logloss:0.0238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2269, Round: 2269\n",
      "Evalset: [Train : Metrics { logloss:0.0237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2270, Round: 2270\n",
      "Evalset: [Train : Metrics { logloss:0.0237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2271, Round: 2271\n",
      "Evalset: [Train : Metrics { logloss:0.0237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2272, Round: 2272\n",
      "Evalset: [Train : Metrics { logloss:0.0237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2273, Round: 2273\n",
      "Evalset: [Train : Metrics { logloss:0.0237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2274, Round: 2274\n",
      "Evalset: [Train : Metrics { logloss:0.0236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2275, Round: 2275\n",
      "Evalset: [Train : Metrics { logloss:0.0236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2276, Round: 2276\n",
      "Evalset: [Train : Metrics { logloss:0.0236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2277, Round: 2277\n",
      "Evalset: [Train : Metrics { logloss:0.0236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2278, Round: 2278\n",
      "Evalset: [Train : Metrics { logloss:0.0236,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2279, Round: 2279\n",
      "Evalset: [Train : Metrics { logloss:0.0235,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2280, Round: 2280\n",
      "Evalset: [Train : Metrics { logloss:0.0235,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2281, Round: 2281\n",
      "Evalset: [Train : Metrics { logloss:0.0235,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2282, Round: 2282\n",
      "Evalset: [Train : Metrics { logloss:0.0235,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2283, Round: 2283\n",
      "Evalset: [Train : Metrics { logloss:0.0235,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2284, Round: 2284\n",
      "Evalset: [Train : Metrics { logloss:0.0234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2285, Round: 2285\n",
      "Evalset: [Train : Metrics { logloss:0.0234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2286, Round: 2286\n",
      "Evalset: [Train : Metrics { logloss:0.0234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2287, Round: 2287\n",
      "Evalset: [Train : Metrics { logloss:0.0234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2288, Round: 2288\n",
      "Evalset: [Train : Metrics { logloss:0.0234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2289, Round: 2289\n",
      "Evalset: [Train : Metrics { logloss:0.0234,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2290, Round: 2290\n",
      "Evalset: [Train : Metrics { logloss:0.0233,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2291, Round: 2291\n",
      "Evalset: [Train : Metrics { logloss:0.0233,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2292, Round: 2292\n",
      "Evalset: [Train : Metrics { logloss:0.0233,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2293, Round: 2293\n",
      "Evalset: [Train : Metrics { logloss:0.0233,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2294, Round: 2294\n",
      "Evalset: [Train : Metrics { logloss:0.0233,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2295, Round: 2295\n",
      "Evalset: [Train : Metrics { logloss:0.0232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2296, Round: 2296\n",
      "Evalset: [Train : Metrics { logloss:0.0232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2297, Round: 2297\n",
      "Evalset: [Train : Metrics { logloss:0.0232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2298, Round: 2298\n",
      "Evalset: [Train : Metrics { logloss:0.0232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2299, Round: 2299\n",
      "Evalset: [Train : Metrics { logloss:0.0232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2300, Round: 2300\n",
      "Evalset: [Train : Metrics { logloss:0.0232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2301, Round: 2301\n",
      "Evalset: [Train : Metrics { logloss:0.0231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2302, Round: 2302\n",
      "Evalset: [Train : Metrics { logloss:0.0231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2303, Round: 2303\n",
      "Evalset: [Train : Metrics { logloss:0.0231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2304, Round: 2304\n",
      "Evalset: [Train : Metrics { logloss:0.0231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2305, Round: 2305\n",
      "Evalset: [Train : Metrics { logloss:0.0231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2306, Round: 2306\n",
      "Evalset: [Train : Metrics { logloss:0.023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2307, Round: 2307\n",
      "Evalset: [Train : Metrics { logloss:0.023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2308, Round: 2308\n",
      "Evalset: [Train : Metrics { logloss:0.023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2309, Round: 2309\n",
      "Evalset: [Train : Metrics { logloss:0.023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2310, Round: 2310\n",
      "Evalset: [Train : Metrics { logloss:0.023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2311, Round: 2311\n",
      "Evalset: [Train : Metrics { logloss:0.023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2312, Round: 2312\n",
      "Evalset: [Train : Metrics { logloss:0.023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2313, Round: 2313\n",
      "Evalset: [Train : Metrics { logloss:0.0229,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2314, Round: 2314\n",
      "Evalset: [Train : Metrics { logloss:0.0229,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2315, Round: 2315\n",
      "Evalset: [Train : Metrics { logloss:0.0229,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2316, Round: 2316\n",
      "Evalset: [Train : Metrics { logloss:0.0229,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2317, Round: 2317\n",
      "Evalset: [Train : Metrics { logloss:0.0228,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2318, Round: 2318\n",
      "Evalset: [Train : Metrics { logloss:0.0228,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2319, Round: 2319\n",
      "Evalset: [Train : Metrics { logloss:0.0228,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2320, Round: 2320\n",
      "Evalset: [Train : Metrics { logloss:0.0228,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2321, Round: 2321\n",
      "Evalset: [Train : Metrics { logloss:0.0228,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2322, Round: 2322\n",
      "Evalset: [Train : Metrics { logloss:0.0227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2323, Round: 2323\n",
      "Evalset: [Train : Metrics { logloss:0.0227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2324, Round: 2324\n",
      "Evalset: [Train : Metrics { logloss:0.0227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2325, Round: 2325\n",
      "Evalset: [Train : Metrics { logloss:0.0227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2326, Round: 2326\n",
      "Evalset: [Train : Metrics { logloss:0.0227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2327, Round: 2327\n",
      "Evalset: [Train : Metrics { logloss:0.0227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2328, Round: 2328\n",
      "Evalset: [Train : Metrics { logloss:0.0226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2329, Round: 2329\n",
      "Evalset: [Train : Metrics { logloss:0.0226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2330, Round: 2330\n",
      "Evalset: [Train : Metrics { logloss:0.0226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2331, Round: 2331\n",
      "Evalset: [Train : Metrics { logloss:0.0226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2332, Round: 2332\n",
      "Evalset: [Train : Metrics { logloss:0.0226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2333, Round: 2333\n",
      "Evalset: [Train : Metrics { logloss:0.0226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2334, Round: 2334\n",
      "Evalset: [Train : Metrics { logloss:0.0225,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2335, Round: 2335\n",
      "Evalset: [Train : Metrics { logloss:0.0225,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2336, Round: 2336\n",
      "Evalset: [Train : Metrics { logloss:0.0225,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2337, Round: 2337\n",
      "Evalset: [Train : Metrics { logloss:0.0225,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2338, Round: 2338\n",
      "Evalset: [Train : Metrics { logloss:0.0225,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2339, Round: 2339\n",
      "Evalset: [Train : Metrics { logloss:0.0224,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2340, Round: 2340\n",
      "Evalset: [Train : Metrics { logloss:0.0224,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2341, Round: 2341\n",
      "Evalset: [Train : Metrics { logloss:0.0224,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2342, Round: 2342\n",
      "Evalset: [Train : Metrics { logloss:0.0224,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2343, Round: 2343\n",
      "Evalset: [Train : Metrics { logloss:0.0224,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2344, Round: 2344\n",
      "Evalset: [Train : Metrics { logloss:0.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2345, Round: 2345\n",
      "Evalset: [Train : Metrics { logloss:0.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2346, Round: 2346\n",
      "Evalset: [Train : Metrics { logloss:0.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2347, Round: 2347\n",
      "Evalset: [Train : Metrics { logloss:0.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2348, Round: 2348\n",
      "Evalset: [Train : Metrics { logloss:0.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2349, Round: 2349\n",
      "Evalset: [Train : Metrics { logloss:0.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2350, Round: 2350\n",
      "Evalset: [Train : Metrics { logloss:0.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2351, Round: 2351\n",
      "Evalset: [Train : Metrics { logloss:0.0222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2352, Round: 2352\n",
      "Evalset: [Train : Metrics { logloss:0.0222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2353, Round: 2353\n",
      "Evalset: [Train : Metrics { logloss:0.0222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2354, Round: 2354\n",
      "Evalset: [Train : Metrics { logloss:0.0222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2355, Round: 2355\n",
      "Evalset: [Train : Metrics { logloss:0.0222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2356, Round: 2356\n",
      "Evalset: [Train : Metrics { logloss:0.0221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2357, Round: 2357\n",
      "Evalset: [Train : Metrics { logloss:0.0221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2358, Round: 2358\n",
      "Evalset: [Train : Metrics { logloss:0.0221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2359, Round: 2359\n",
      "Evalset: [Train : Metrics { logloss:0.0221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2360, Round: 2360\n",
      "Evalset: [Train : Metrics { logloss:0.0221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2361, Round: 2361\n",
      "Evalset: [Train : Metrics { logloss:0.022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2362, Round: 2362\n",
      "Evalset: [Train : Metrics { logloss:0.022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0832,  }]\n",
      "Training on Total Epoch: 2363, Round: 2363\n",
      "Evalset: [Train : Metrics { logloss:0.022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0831,  }]\n",
      "Training on Total Epoch: 2364, Round: 2364\n",
      "Evalset: [Train : Metrics { logloss:0.022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 2365, Round: 2365\n",
      "Evalset: [Train : Metrics { logloss:0.022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2366, Round: 2366\n",
      "Evalset: [Train : Metrics { logloss:0.022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2367, Round: 2367\n",
      "Evalset: [Train : Metrics { logloss:0.0219,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2368, Round: 2368\n",
      "Evalset: [Train : Metrics { logloss:0.0219,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2369, Round: 2369\n",
      "Evalset: [Train : Metrics { logloss:0.0219,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2370, Round: 2370\n",
      "Evalset: [Train : Metrics { logloss:0.0219,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2371, Round: 2371\n",
      "Evalset: [Train : Metrics { logloss:0.0219,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2372, Round: 2372\n",
      "Evalset: [Train : Metrics { logloss:0.0219,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2373, Round: 2373\n",
      "Evalset: [Train : Metrics { logloss:0.0218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2374, Round: 2374\n",
      "Evalset: [Train : Metrics { logloss:0.0218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2375, Round: 2375\n",
      "Evalset: [Train : Metrics { logloss:0.0218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2376, Round: 2376\n",
      "Evalset: [Train : Metrics { logloss:0.0218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2377, Round: 2377\n",
      "Evalset: [Train : Metrics { logloss:0.0218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2378, Round: 2378\n",
      "Evalset: [Train : Metrics { logloss:0.0218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2379, Round: 2379\n",
      "Evalset: [Train : Metrics { logloss:0.0217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2380, Round: 2380\n",
      "Evalset: [Train : Metrics { logloss:0.0217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2381, Round: 2381\n",
      "Evalset: [Train : Metrics { logloss:0.0217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2382, Round: 2382\n",
      "Evalset: [Train : Metrics { logloss:0.0217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2383, Round: 2383\n",
      "Evalset: [Train : Metrics { logloss:0.0217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2384, Round: 2384\n",
      "Evalset: [Train : Metrics { logloss:0.0217,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2385, Round: 2385\n",
      "Evalset: [Train : Metrics { logloss:0.0216,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2386, Round: 2386\n",
      "Evalset: [Train : Metrics { logloss:0.0216,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2387, Round: 2387\n",
      "Evalset: [Train : Metrics { logloss:0.0216,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2388, Round: 2388\n",
      "Evalset: [Train : Metrics { logloss:0.0216,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2389, Round: 2389\n",
      "Evalset: [Train : Metrics { logloss:0.0216,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2390, Round: 2390\n",
      "Evalset: [Train : Metrics { logloss:0.0216,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2391, Round: 2391\n",
      "Evalset: [Train : Metrics { logloss:0.0215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2392, Round: 2392\n",
      "Evalset: [Train : Metrics { logloss:0.0215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2393, Round: 2393\n",
      "Evalset: [Train : Metrics { logloss:0.0215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2394, Round: 2394\n",
      "Evalset: [Train : Metrics { logloss:0.0215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2395, Round: 2395\n",
      "Evalset: [Train : Metrics { logloss:0.0215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2396, Round: 2396\n",
      "Evalset: [Train : Metrics { logloss:0.0214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2397, Round: 2397\n",
      "Evalset: [Train : Metrics { logloss:0.0214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2398, Round: 2398\n",
      "Evalset: [Train : Metrics { logloss:0.0214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2399, Round: 2399\n",
      "Evalset: [Train : Metrics { logloss:0.0214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2400, Round: 2400\n",
      "Evalset: [Train : Metrics { logloss:0.0214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2401, Round: 2401\n",
      "Evalset: [Train : Metrics { logloss:0.0214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2402, Round: 2402\n",
      "Evalset: [Train : Metrics { logloss:0.0214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 2403, Round: 2403\n",
      "Evalset: [Train : Metrics { logloss:0.0213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 2404, Round: 2404\n",
      "Evalset: [Train : Metrics { logloss:0.0213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2405, Round: 2405\n",
      "Evalset: [Train : Metrics { logloss:0.0213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2406, Round: 2406\n",
      "Evalset: [Train : Metrics { logloss:0.0213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2407, Round: 2407\n",
      "Evalset: [Train : Metrics { logloss:0.0213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2408, Round: 2408\n",
      "Evalset: [Train : Metrics { logloss:0.0212,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2409, Round: 2409\n",
      "Evalset: [Train : Metrics { logloss:0.0212,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2410, Round: 2410\n",
      "Evalset: [Train : Metrics { logloss:0.0212,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2411, Round: 2411\n",
      "Evalset: [Train : Metrics { logloss:0.0212,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2412, Round: 2412\n",
      "Evalset: [Train : Metrics { logloss:0.0212,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2413, Round: 2413\n",
      "Evalset: [Train : Metrics { logloss:0.0212,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2414, Round: 2414\n",
      "Evalset: [Train : Metrics { logloss:0.0211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2415, Round: 2415\n",
      "Evalset: [Train : Metrics { logloss:0.0211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2416, Round: 2416\n",
      "Evalset: [Train : Metrics { logloss:0.0211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2417, Round: 2417\n",
      "Evalset: [Train : Metrics { logloss:0.0211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2418, Round: 2418\n",
      "Evalset: [Train : Metrics { logloss:0.0211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1266,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2419, Round: 2419\n",
      "Evalset: [Train : Metrics { logloss:0.0211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2420, Round: 2420\n",
      "Evalset: [Train : Metrics { logloss:0.021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2421, Round: 2421\n",
      "Evalset: [Train : Metrics { logloss:0.021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2422, Round: 2422\n",
      "Evalset: [Train : Metrics { logloss:0.021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2423, Round: 2423\n",
      "Evalset: [Train : Metrics { logloss:0.021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2424, Round: 2424\n",
      "Evalset: [Train : Metrics { logloss:0.021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2425, Round: 2425\n",
      "Evalset: [Train : Metrics { logloss:0.021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2426, Round: 2426\n",
      "Evalset: [Train : Metrics { logloss:0.0209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2427, Round: 2427\n",
      "Evalset: [Train : Metrics { logloss:0.0209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1266,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2428, Round: 2428\n",
      "Evalset: [Train : Metrics { logloss:0.0209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2429, Round: 2429\n",
      "Evalset: [Train : Metrics { logloss:0.0209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.127,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2430, Round: 2430\n",
      "Evalset: [Train : Metrics { logloss:0.0209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2431, Round: 2431\n",
      "Evalset: [Train : Metrics { logloss:0.0209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2432, Round: 2432\n",
      "Evalset: [Train : Metrics { logloss:0.0209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2433, Round: 2433\n",
      "Evalset: [Train : Metrics { logloss:0.0208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2434, Round: 2434\n",
      "Evalset: [Train : Metrics { logloss:0.0208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2435, Round: 2435\n",
      "Evalset: [Train : Metrics { logloss:0.0208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2436, Round: 2436\n",
      "Evalset: [Train : Metrics { logloss:0.0208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2437, Round: 2437\n",
      "Evalset: [Train : Metrics { logloss:0.0208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2438, Round: 2438\n",
      "Evalset: [Train : Metrics { logloss:0.0207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2439, Round: 2439\n",
      "Evalset: [Train : Metrics { logloss:0.0207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2440, Round: 2440\n",
      "Evalset: [Train : Metrics { logloss:0.0207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2441, Round: 2441\n",
      "Evalset: [Train : Metrics { logloss:0.0207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2442, Round: 2442\n",
      "Evalset: [Train : Metrics { logloss:0.0207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1266,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2443, Round: 2443\n",
      "Evalset: [Train : Metrics { logloss:0.0207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2444, Round: 2444\n",
      "Evalset: [Train : Metrics { logloss:0.0207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2445, Round: 2445\n",
      "Evalset: [Train : Metrics { logloss:0.0206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2446, Round: 2446\n",
      "Evalset: [Train : Metrics { logloss:0.0206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2447, Round: 2447\n",
      "Evalset: [Train : Metrics { logloss:0.0206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1266,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2448, Round: 2448\n",
      "Evalset: [Train : Metrics { logloss:0.0206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2449, Round: 2449\n",
      "Evalset: [Train : Metrics { logloss:0.0206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2450, Round: 2450\n",
      "Evalset: [Train : Metrics { logloss:0.0206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2451, Round: 2451\n",
      "Evalset: [Train : Metrics { logloss:0.0205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2452, Round: 2452\n",
      "Evalset: [Train : Metrics { logloss:0.0205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2453, Round: 2453\n",
      "Evalset: [Train : Metrics { logloss:0.0205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2454, Round: 2454\n",
      "Evalset: [Train : Metrics { logloss:0.0205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2455, Round: 2455\n",
      "Evalset: [Train : Metrics { logloss:0.0205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2456, Round: 2456\n",
      "Evalset: [Train : Metrics { logloss:0.0204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2457, Round: 2457\n",
      "Evalset: [Train : Metrics { logloss:0.0204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2458, Round: 2458\n",
      "Evalset: [Train : Metrics { logloss:0.0204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2459, Round: 2459\n",
      "Evalset: [Train : Metrics { logloss:0.0204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.127,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2460, Round: 2460\n",
      "Evalset: [Train : Metrics { logloss:0.0204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2461, Round: 2461\n",
      "Evalset: [Train : Metrics { logloss:0.0204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2462, Round: 2462\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2463, Round: 2463\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2464, Round: 2464\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2465, Round: 2465\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2466, Round: 2466\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2467, Round: 2467\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2468, Round: 2468\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2469, Round: 2469\n",
      "Evalset: [Train : Metrics { logloss:0.0203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2470, Round: 2470\n",
      "Evalset: [Train : Metrics { logloss:0.0202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2471, Round: 2471\n",
      "Evalset: [Train : Metrics { logloss:0.0202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2472, Round: 2472\n",
      "Evalset: [Train : Metrics { logloss:0.0202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2473, Round: 2473\n",
      "Evalset: [Train : Metrics { logloss:0.0202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2474, Round: 2474\n",
      "Evalset: [Train : Metrics { logloss:0.0201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2475, Round: 2475\n",
      "Evalset: [Train : Metrics { logloss:0.0201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2476, Round: 2476\n",
      "Evalset: [Train : Metrics { logloss:0.0201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2477, Round: 2477\n",
      "Evalset: [Train : Metrics { logloss:0.0201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2478, Round: 2478\n",
      "Evalset: [Train : Metrics { logloss:0.0201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2479, Round: 2479\n",
      "Evalset: [Train : Metrics { logloss:0.0201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2480, Round: 2480\n",
      "Evalset: [Train : Metrics { logloss:0.0201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2481, Round: 2481\n",
      "Evalset: [Train : Metrics { logloss:0.02,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2482, Round: 2482\n",
      "Evalset: [Train : Metrics { logloss:0.02,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2483, Round: 2483\n",
      "Evalset: [Train : Metrics { logloss:0.02,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2484, Round: 2484\n",
      "Evalset: [Train : Metrics { logloss:0.02,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2485, Round: 2485\n",
      "Evalset: [Train : Metrics { logloss:0.02,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2486, Round: 2486\n",
      "Evalset: [Train : Metrics { logloss:0.02,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2487, Round: 2487\n",
      "Evalset: [Train : Metrics { logloss:0.0199,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2488, Round: 2488\n",
      "Evalset: [Train : Metrics { logloss:0.0199,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2489, Round: 2489\n",
      "Evalset: [Train : Metrics { logloss:0.0199,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2490, Round: 2490\n",
      "Evalset: [Train : Metrics { logloss:0.0199,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2491, Round: 2491\n",
      "Evalset: [Train : Metrics { logloss:0.0199,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2492, Round: 2492\n",
      "Evalset: [Train : Metrics { logloss:0.0199,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2493, Round: 2493\n",
      "Evalset: [Train : Metrics { logloss:0.0198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2494, Round: 2494\n",
      "Evalset: [Train : Metrics { logloss:0.0198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2495, Round: 2495\n",
      "Evalset: [Train : Metrics { logloss:0.0198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2496, Round: 2496\n",
      "Evalset: [Train : Metrics { logloss:0.0198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2497, Round: 2497\n",
      "Evalset: [Train : Metrics { logloss:0.0198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2498, Round: 2498\n",
      "Evalset: [Train : Metrics { logloss:0.0198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2499, Round: 2499\n",
      "Evalset: [Train : Metrics { logloss:0.0198,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2500, Round: 2500\n",
      "Evalset: [Train : Metrics { logloss:0.0197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2501, Round: 2501\n",
      "Evalset: [Train : Metrics { logloss:0.0197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2502, Round: 2502\n",
      "Evalset: [Train : Metrics { logloss:0.0197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2503, Round: 2503\n",
      "Evalset: [Train : Metrics { logloss:0.0197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2504, Round: 2504\n",
      "Evalset: [Train : Metrics { logloss:0.0197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2505, Round: 2505\n",
      "Evalset: [Train : Metrics { logloss:0.0197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2506, Round: 2506\n",
      "Evalset: [Train : Metrics { logloss:0.0196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2507, Round: 2507\n",
      "Evalset: [Train : Metrics { logloss:0.0196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2508, Round: 2508\n",
      "Evalset: [Train : Metrics { logloss:0.0196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2509, Round: 2509\n",
      "Evalset: [Train : Metrics { logloss:0.0196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2510, Round: 2510\n",
      "Evalset: [Train : Metrics { logloss:0.0196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2511, Round: 2511\n",
      "Evalset: [Train : Metrics { logloss:0.0196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2512, Round: 2512\n",
      "Evalset: [Train : Metrics { logloss:0.0196,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 2513, Round: 2513\n",
      "Evalset: [Train : Metrics { logloss:0.0195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2514, Round: 2514\n",
      "Evalset: [Train : Metrics { logloss:0.0195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2515, Round: 2515\n",
      "Evalset: [Train : Metrics { logloss:0.0195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2516, Round: 2516\n",
      "Evalset: [Train : Metrics { logloss:0.0195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2517, Round: 2517\n",
      "Evalset: [Train : Metrics { logloss:0.0195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2518, Round: 2518\n",
      "Evalset: [Train : Metrics { logloss:0.0195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2519, Round: 2519\n",
      "Evalset: [Train : Metrics { logloss:0.0194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2520, Round: 2520\n",
      "Evalset: [Train : Metrics { logloss:0.0194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2521, Round: 2521\n",
      "Evalset: [Train : Metrics { logloss:0.0194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2522, Round: 2522\n",
      "Evalset: [Train : Metrics { logloss:0.0194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2523, Round: 2523\n",
      "Evalset: [Train : Metrics { logloss:0.0194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2524, Round: 2524\n",
      "Evalset: [Train : Metrics { logloss:0.0194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2525, Round: 2525\n",
      "Evalset: [Train : Metrics { logloss:0.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2526, Round: 2526\n",
      "Evalset: [Train : Metrics { logloss:0.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2527, Round: 2527\n",
      "Evalset: [Train : Metrics { logloss:0.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2528, Round: 2528\n",
      "Evalset: [Train : Metrics { logloss:0.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2529, Round: 2529\n",
      "Evalset: [Train : Metrics { logloss:0.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2530, Round: 2530\n",
      "Evalset: [Train : Metrics { logloss:0.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2531, Round: 2531\n",
      "Evalset: [Train : Metrics { logloss:0.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2532, Round: 2532\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2533, Round: 2533\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2534, Round: 2534\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2535, Round: 2535\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2536, Round: 2536\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2537, Round: 2537\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2538, Round: 2538\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2539, Round: 2539\n",
      "Evalset: [Train : Metrics { logloss:0.0192,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 2540, Round: 2540\n",
      "Evalset: [Train : Metrics { logloss:0.0191,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 2541, Round: 2541\n",
      "Evalset: [Train : Metrics { logloss:0.0191,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 2542, Round: 2542\n",
      "Evalset: [Train : Metrics { logloss:0.0191,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2543, Round: 2543\n",
      "Evalset: [Train : Metrics { logloss:0.0191,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2544, Round: 2544\n",
      "Evalset: [Train : Metrics { logloss:0.0191,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2545, Round: 2545\n",
      "Evalset: [Train : Metrics { logloss:0.019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2546, Round: 2546\n",
      "Evalset: [Train : Metrics { logloss:0.019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 2547, Round: 2547\n",
      "Evalset: [Train : Metrics { logloss:0.019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2548, Round: 2548\n",
      "Evalset: [Train : Metrics { logloss:0.019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2549, Round: 2549\n",
      "Evalset: [Train : Metrics { logloss:0.019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2550, Round: 2550\n",
      "Evalset: [Train : Metrics { logloss:0.019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2551, Round: 2551\n",
      "Evalset: [Train : Metrics { logloss:0.0189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2552, Round: 2552\n",
      "Evalset: [Train : Metrics { logloss:0.0189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2553, Round: 2553\n",
      "Evalset: [Train : Metrics { logloss:0.0189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2554, Round: 2554\n",
      "Evalset: [Train : Metrics { logloss:0.0189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2555, Round: 2555\n",
      "Evalset: [Train : Metrics { logloss:0.0189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1284,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2556, Round: 2556\n",
      "Evalset: [Train : Metrics { logloss:0.0189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2557, Round: 2557\n",
      "Evalset: [Train : Metrics { logloss:0.0189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2558, Round: 2558\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2559, Round: 2559\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2560, Round: 2560\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2561, Round: 2561\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2562, Round: 2562\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2563, Round: 2563\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2564, Round: 2564\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2565, Round: 2565\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2566, Round: 2566\n",
      "Evalset: [Train : Metrics { logloss:0.0188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2567, Round: 2567\n",
      "Evalset: [Train : Metrics { logloss:0.0187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2568, Round: 2568\n",
      "Evalset: [Train : Metrics { logloss:0.0187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2569, Round: 2569\n",
      "Evalset: [Train : Metrics { logloss:0.0187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2570, Round: 2570\n",
      "Evalset: [Train : Metrics { logloss:0.0187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2571, Round: 2571\n",
      "Evalset: [Train : Metrics { logloss:0.0187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2572, Round: 2572\n",
      "Evalset: [Train : Metrics { logloss:0.0186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2573, Round: 2573\n",
      "Evalset: [Train : Metrics { logloss:0.0186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2574, Round: 2574\n",
      "Evalset: [Train : Metrics { logloss:0.0186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2575, Round: 2575\n",
      "Evalset: [Train : Metrics { logloss:0.0186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1284,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2576, Round: 2576\n",
      "Evalset: [Train : Metrics { logloss:0.0186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2577, Round: 2577\n",
      "Evalset: [Train : Metrics { logloss:0.0186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 2578, Round: 2578\n",
      "Evalset: [Train : Metrics { logloss:0.0186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2579, Round: 2579\n",
      "Evalset: [Train : Metrics { logloss:0.0185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0842,  }]\n",
      "Training on Total Epoch: 2580, Round: 2580\n",
      "Evalset: [Train : Metrics { logloss:0.0185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2581, Round: 2581\n",
      "Evalset: [Train : Metrics { logloss:0.0185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2582, Round: 2582\n",
      "Evalset: [Train : Metrics { logloss:0.0185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2583, Round: 2583\n",
      "Evalset: [Train : Metrics { logloss:0.0185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2584, Round: 2584\n",
      "Evalset: [Train : Metrics { logloss:0.0185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2585, Round: 2585\n",
      "Evalset: [Train : Metrics { logloss:0.0185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2586, Round: 2586\n",
      "Evalset: [Train : Metrics { logloss:0.0184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2587, Round: 2587\n",
      "Evalset: [Train : Metrics { logloss:0.0184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2588, Round: 2588\n",
      "Evalset: [Train : Metrics { logloss:0.0184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2589, Round: 2589\n",
      "Evalset: [Train : Metrics { logloss:0.0184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2590, Round: 2590\n",
      "Evalset: [Train : Metrics { logloss:0.0184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2591, Round: 2591\n",
      "Evalset: [Train : Metrics { logloss:0.0184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2592, Round: 2592\n",
      "Evalset: [Train : Metrics { logloss:0.0184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2593, Round: 2593\n",
      "Evalset: [Train : Metrics { logloss:0.0183,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2594, Round: 2594\n",
      "Evalset: [Train : Metrics { logloss:0.0183,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2595, Round: 2595\n",
      "Evalset: [Train : Metrics { logloss:0.0183,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2596, Round: 2596\n",
      "Evalset: [Train : Metrics { logloss:0.0183,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2597, Round: 2597\n",
      "Evalset: [Train : Metrics { logloss:0.0183,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1284,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2598, Round: 2598\n",
      "Evalset: [Train : Metrics { logloss:0.0183,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1284,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2599, Round: 2599\n",
      "Evalset: [Train : Metrics { logloss:0.0182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2600, Round: 2600\n",
      "Evalset: [Train : Metrics { logloss:0.0182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1284,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2601, Round: 2601\n",
      "Evalset: [Train : Metrics { logloss:0.0182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2602, Round: 2602\n",
      "Evalset: [Train : Metrics { logloss:0.0182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2603, Round: 2603\n",
      "Evalset: [Train : Metrics { logloss:0.0182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2604, Round: 2604\n",
      "Evalset: [Train : Metrics { logloss:0.0182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2605, Round: 2605\n",
      "Evalset: [Train : Metrics { logloss:0.0182,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2606, Round: 2606\n",
      "Evalset: [Train : Metrics { logloss:0.0181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2607, Round: 2607\n",
      "Evalset: [Train : Metrics { logloss:0.0181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2608, Round: 2608\n",
      "Evalset: [Train : Metrics { logloss:0.0181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2609, Round: 2609\n",
      "Evalset: [Train : Metrics { logloss:0.0181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2610, Round: 2610\n",
      "Evalset: [Train : Metrics { logloss:0.0181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2611, Round: 2611\n",
      "Evalset: [Train : Metrics { logloss:0.0181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2612, Round: 2612\n",
      "Evalset: [Train : Metrics { logloss:0.0181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2613, Round: 2613\n",
      "Evalset: [Train : Metrics { logloss:0.018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2614, Round: 2614\n",
      "Evalset: [Train : Metrics { logloss:0.018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2615, Round: 2615\n",
      "Evalset: [Train : Metrics { logloss:0.018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2616, Round: 2616\n",
      "Evalset: [Train : Metrics { logloss:0.018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2617, Round: 2617\n",
      "Evalset: [Train : Metrics { logloss:0.018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2618, Round: 2618\n",
      "Evalset: [Train : Metrics { logloss:0.018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2619, Round: 2619\n",
      "Evalset: [Train : Metrics { logloss:0.018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2620, Round: 2620\n",
      "Evalset: [Train : Metrics { logloss:0.0179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2621, Round: 2621\n",
      "Evalset: [Train : Metrics { logloss:0.0179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2622, Round: 2622\n",
      "Evalset: [Train : Metrics { logloss:0.0179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2623, Round: 2623\n",
      "Evalset: [Train : Metrics { logloss:0.0179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2624, Round: 2624\n",
      "Evalset: [Train : Metrics { logloss:0.0179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2625, Round: 2625\n",
      "Evalset: [Train : Metrics { logloss:0.0179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2626, Round: 2626\n",
      "Evalset: [Train : Metrics { logloss:0.0179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2627, Round: 2627\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2628, Round: 2628\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2629, Round: 2629\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2630, Round: 2630\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2631, Round: 2631\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2632, Round: 2632\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2633, Round: 2633\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2634, Round: 2634\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2635, Round: 2635\n",
      "Evalset: [Train : Metrics { logloss:0.0178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2636, Round: 2636\n",
      "Evalset: [Train : Metrics { logloss:0.0177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2637, Round: 2637\n",
      "Evalset: [Train : Metrics { logloss:0.0177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2638, Round: 2638\n",
      "Evalset: [Train : Metrics { logloss:0.0177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2639, Round: 2639\n",
      "Evalset: [Train : Metrics { logloss:0.0177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2640, Round: 2640\n",
      "Evalset: [Train : Metrics { logloss:0.0177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2641, Round: 2641\n",
      "Evalset: [Train : Metrics { logloss:0.0177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2642, Round: 2642\n",
      "Evalset: [Train : Metrics { logloss:0.0176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2643, Round: 2643\n",
      "Evalset: [Train : Metrics { logloss:0.0176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2644, Round: 2644\n",
      "Evalset: [Train : Metrics { logloss:0.0176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2645, Round: 2645\n",
      "Evalset: [Train : Metrics { logloss:0.0176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2646, Round: 2646\n",
      "Evalset: [Train : Metrics { logloss:0.0176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 2647, Round: 2647\n",
      "Evalset: [Train : Metrics { logloss:0.0176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2648, Round: 2648\n",
      "Evalset: [Train : Metrics { logloss:0.0176,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2649, Round: 2649\n",
      "Evalset: [Train : Metrics { logloss:0.0175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2650, Round: 2650\n",
      "Evalset: [Train : Metrics { logloss:0.0175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2651, Round: 2651\n",
      "Evalset: [Train : Metrics { logloss:0.0175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2652, Round: 2652\n",
      "Evalset: [Train : Metrics { logloss:0.0175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2653, Round: 2653\n",
      "Evalset: [Train : Metrics { logloss:0.0175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2654, Round: 2654\n",
      "Evalset: [Train : Metrics { logloss:0.0175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2655, Round: 2655\n",
      "Evalset: [Train : Metrics { logloss:0.0175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2656, Round: 2656\n",
      "Evalset: [Train : Metrics { logloss:0.0174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2657, Round: 2657\n",
      "Evalset: [Train : Metrics { logloss:0.0174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2658, Round: 2658\n",
      "Evalset: [Train : Metrics { logloss:0.0174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2659, Round: 2659\n",
      "Evalset: [Train : Metrics { logloss:0.0174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2660, Round: 2660\n",
      "Evalset: [Train : Metrics { logloss:0.0174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2661, Round: 2661\n",
      "Evalset: [Train : Metrics { logloss:0.0174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2662, Round: 2662\n",
      "Evalset: [Train : Metrics { logloss:0.0174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2663, Round: 2663\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2664, Round: 2664\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2665, Round: 2665\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2666, Round: 2666\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2667, Round: 2667\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2668, Round: 2668\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2669, Round: 2669\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2670, Round: 2670\n",
      "Evalset: [Train : Metrics { logloss:0.0173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2671, Round: 2671\n",
      "Evalset: [Train : Metrics { logloss:0.0172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2672, Round: 2672\n",
      "Evalset: [Train : Metrics { logloss:0.0172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2673, Round: 2673\n",
      "Evalset: [Train : Metrics { logloss:0.0172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2674, Round: 2674\n",
      "Evalset: [Train : Metrics { logloss:0.0172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2675, Round: 2675\n",
      "Evalset: [Train : Metrics { logloss:0.0172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2676, Round: 2676\n",
      "Evalset: [Train : Metrics { logloss:0.0172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2677, Round: 2677\n",
      "Evalset: [Train : Metrics { logloss:0.0172,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2678, Round: 2678\n",
      "Evalset: [Train : Metrics { logloss:0.0171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2679, Round: 2679\n",
      "Evalset: [Train : Metrics { logloss:0.0171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2680, Round: 2680\n",
      "Evalset: [Train : Metrics { logloss:0.0171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2681, Round: 2681\n",
      "Evalset: [Train : Metrics { logloss:0.0171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2682, Round: 2682\n",
      "Evalset: [Train : Metrics { logloss:0.0171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2683, Round: 2683\n",
      "Evalset: [Train : Metrics { logloss:0.0171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2684, Round: 2684\n",
      "Evalset: [Train : Metrics { logloss:0.0171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2685, Round: 2685\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2686, Round: 2686\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2687, Round: 2687\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2688, Round: 2688\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2689, Round: 2689\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2690, Round: 2690\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2691, Round: 2691\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2692, Round: 2692\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2693, Round: 2693\n",
      "Evalset: [Train : Metrics { logloss:0.017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 2694, Round: 2694\n",
      "Evalset: [Train : Metrics { logloss:0.0169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2695, Round: 2695\n",
      "Evalset: [Train : Metrics { logloss:0.0169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2696, Round: 2696\n",
      "Evalset: [Train : Metrics { logloss:0.0169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2697, Round: 2697\n",
      "Evalset: [Train : Metrics { logloss:0.0169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2698, Round: 2698\n",
      "Evalset: [Train : Metrics { logloss:0.0169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2699, Round: 2699\n",
      "Evalset: [Train : Metrics { logloss:0.0169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2700, Round: 2700\n",
      "Evalset: [Train : Metrics { logloss:0.0169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2701, Round: 2701\n",
      "Evalset: [Train : Metrics { logloss:0.0168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2702, Round: 2702\n",
      "Evalset: [Train : Metrics { logloss:0.0168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2703, Round: 2703\n",
      "Evalset: [Train : Metrics { logloss:0.0168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2704, Round: 2704\n",
      "Evalset: [Train : Metrics { logloss:0.0168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2705, Round: 2705\n",
      "Evalset: [Train : Metrics { logloss:0.0168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2706, Round: 2706\n",
      "Evalset: [Train : Metrics { logloss:0.0168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2707, Round: 2707\n",
      "Evalset: [Train : Metrics { logloss:0.0168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2708, Round: 2708\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2709, Round: 2709\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2710, Round: 2710\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2711, Round: 2711\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2712, Round: 2712\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2713, Round: 2713\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2714, Round: 2714\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2715, Round: 2715\n",
      "Evalset: [Train : Metrics { logloss:0.0167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2716, Round: 2716\n",
      "Evalset: [Train : Metrics { logloss:0.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2717, Round: 2717\n",
      "Evalset: [Train : Metrics { logloss:0.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2718, Round: 2718\n",
      "Evalset: [Train : Metrics { logloss:0.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2719, Round: 2719\n",
      "Evalset: [Train : Metrics { logloss:0.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2720, Round: 2720\n",
      "Evalset: [Train : Metrics { logloss:0.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2721, Round: 2721\n",
      "Evalset: [Train : Metrics { logloss:0.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2722, Round: 2722\n",
      "Evalset: [Train : Metrics { logloss:0.0166,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2723, Round: 2723\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2724, Round: 2724\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2725, Round: 2725\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2726, Round: 2726\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2727, Round: 2727\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2728, Round: 2728\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2729, Round: 2729\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2730, Round: 2730\n",
      "Evalset: [Train : Metrics { logloss:0.0165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2731, Round: 2731\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2732, Round: 2732\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2733, Round: 2733\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2734, Round: 2734\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2735, Round: 2735\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2736, Round: 2736\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2737, Round: 2737\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2738, Round: 2738\n",
      "Evalset: [Train : Metrics { logloss:0.0164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2739, Round: 2739\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2740, Round: 2740\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2741, Round: 2741\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2742, Round: 2742\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2743, Round: 2743\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1299,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2744, Round: 2744\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2745, Round: 2745\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2746, Round: 2746\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2747, Round: 2747\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2748, Round: 2748\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2749, Round: 2749\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2750, Round: 2750\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2751, Round: 2751\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2752, Round: 2752\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2753, Round: 2753\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 2754, Round: 2754\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 2755, Round: 2755\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 2756, Round: 2756\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2757, Round: 2757\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2758, Round: 2758\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2759, Round: 2759\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2760, Round: 2760\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2761, Round: 2761\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2762, Round: 2762\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2763, Round: 2763\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2764, Round: 2764\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2765, Round: 2765\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2766, Round: 2766\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2767, Round: 2767\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2768, Round: 2768\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2769, Round: 2769\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2770, Round: 2770\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2771, Round: 2771\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2772, Round: 2772\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2773, Round: 2773\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2774, Round: 2774\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2775, Round: 2775\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2776, Round: 2776\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2777, Round: 2777\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2778, Round: 2778\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2779, Round: 2779\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2780, Round: 2780\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2781, Round: 2781\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2782, Round: 2782\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2783, Round: 2783\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2784, Round: 2784\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2785, Round: 2785\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2786, Round: 2786\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2787, Round: 2787\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2788, Round: 2788\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2789, Round: 2789\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1306,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2790, Round: 2790\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2791, Round: 2791\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2792, Round: 2792\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2793, Round: 2793\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2794, Round: 2794\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2795, Round: 2795\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2796, Round: 2796\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2797, Round: 2797\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2798, Round: 2798\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2799, Round: 2799\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2800, Round: 2800\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2801, Round: 2801\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2802, Round: 2802\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2803, Round: 2803\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2804, Round: 2804\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2805, Round: 2805\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2806, Round: 2806\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2807, Round: 2807\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2808, Round: 2808\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2809, Round: 2809\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2810, Round: 2810\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2811, Round: 2811\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2812, Round: 2812\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2813, Round: 2813\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2814, Round: 2814\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2815, Round: 2815\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2816, Round: 2816\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2817, Round: 2817\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2818, Round: 2818\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2819, Round: 2819\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2820, Round: 2820\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2821, Round: 2821\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2822, Round: 2822\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2823, Round: 2823\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2824, Round: 2824\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2825, Round: 2825\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2826, Round: 2826\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2827, Round: 2827\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2828, Round: 2828\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2829, Round: 2829\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2830, Round: 2830\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2831, Round: 2831\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2832, Round: 2832\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 2833, Round: 2833\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 2834, Round: 2834\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2835, Round: 2835\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2836, Round: 2836\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2837, Round: 2837\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2838, Round: 2838\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2839, Round: 2839\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2840, Round: 2840\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2841, Round: 2841\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2842, Round: 2842\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2843, Round: 2843\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2844, Round: 2844\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2845, Round: 2845\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2846, Round: 2846\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2847, Round: 2847\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2848, Round: 2848\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2849, Round: 2849\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2850, Round: 2850\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1316,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2851, Round: 2851\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 2852, Round: 2852\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2853, Round: 2853\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2854, Round: 2854\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2855, Round: 2855\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2856, Round: 2856\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2857, Round: 2857\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2858, Round: 2858\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2859, Round: 2859\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2860, Round: 2860\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2861, Round: 2861\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2862, Round: 2862\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2863, Round: 2863\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2864, Round: 2864\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2865, Round: 2865\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2866, Round: 2866\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2867, Round: 2867\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2868, Round: 2868\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2869, Round: 2869\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1316,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2870, Round: 2870\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1316,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2871, Round: 2871\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2872, Round: 2872\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2873, Round: 2873\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2874, Round: 2874\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2875, Round: 2875\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2876, Round: 2876\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2877, Round: 2877\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2878, Round: 2878\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2879, Round: 2879\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1316,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2880, Round: 2880\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2881, Round: 2881\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2882, Round: 2882\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2883, Round: 2883\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1316,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2884, Round: 2884\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2885, Round: 2885\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2886, Round: 2886\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2887, Round: 2887\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2888, Round: 2888\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2889, Round: 2889\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2890, Round: 2890\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2891, Round: 2891\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2892, Round: 2892\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2893, Round: 2893\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2894, Round: 2894\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2895, Round: 2895\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2896, Round: 2896\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2897, Round: 2897\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2898, Round: 2898\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2899, Round: 2899\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2900, Round: 2900\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2901, Round: 2901\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2902, Round: 2902\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2903, Round: 2903\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2904, Round: 2904\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2905, Round: 2905\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2906, Round: 2906\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2907, Round: 2907\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2908, Round: 2908\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2909, Round: 2909\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2910, Round: 2910\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2911, Round: 2911\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2912, Round: 2912\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2913, Round: 2913\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2914, Round: 2914\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2915, Round: 2915\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2916, Round: 2916\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1327,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2917, Round: 2917\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1327,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2918, Round: 2918\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2919, Round: 2919\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2920, Round: 2920\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2921, Round: 2921\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2922, Round: 2922\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2923, Round: 2923\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2924, Round: 2924\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 2925, Round: 2925\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2926, Round: 2926\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2927, Round: 2927\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2928, Round: 2928\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2929, Round: 2929\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2930, Round: 2930\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2931, Round: 2931\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2932, Round: 2932\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2933, Round: 2933\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2934, Round: 2934\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2935, Round: 2935\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2936, Round: 2936\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2937, Round: 2937\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2938, Round: 2938\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2939, Round: 2939\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2940, Round: 2940\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1327,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2941, Round: 2941\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2942, Round: 2942\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2943, Round: 2943\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 2944, Round: 2944\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2945, Round: 2945\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2946, Round: 2946\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2947, Round: 2947\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1327,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2948, Round: 2948\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2949, Round: 2949\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2950, Round: 2950\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2951, Round: 2951\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2952, Round: 2952\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2953, Round: 2953\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2954, Round: 2954\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2955, Round: 2955\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2956, Round: 2956\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2957, Round: 2957\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2958, Round: 2958\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2959, Round: 2959\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2960, Round: 2960\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2961, Round: 2961\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2962, Round: 2962\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2963, Round: 2963\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2964, Round: 2964\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2965, Round: 2965\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 2966, Round: 2966\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2967, Round: 2967\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 2968, Round: 2968\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 2969, Round: 2969\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2970, Round: 2970\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2971, Round: 2971\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2972, Round: 2972\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2973, Round: 2973\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2974, Round: 2974\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2975, Round: 2975\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2976, Round: 2976\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2977, Round: 2977\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2978, Round: 2978\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 2979, Round: 2979\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2980, Round: 2980\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2981, Round: 2981\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 2982, Round: 2982\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2983, Round: 2983\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2984, Round: 2984\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2985, Round: 2985\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2986, Round: 2986\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2987, Round: 2987\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 2988, Round: 2988\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2989, Round: 2989\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2990, Round: 2990\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2991, Round: 2991\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 2992, Round: 2992\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 2993, Round: 2993\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2994, Round: 2994\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 2995, Round: 2995\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2996, Round: 2996\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 2997, Round: 2997\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 2998, Round: 2998\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 2999, Round: 2999\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3000, Round: 3000\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3001, Round: 3001\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3002, Round: 3002\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3003, Round: 3003\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3004, Round: 3004\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3005, Round: 3005\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 3006, Round: 3006\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 3007, Round: 3007\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 3008, Round: 3008\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3009, Round: 3009\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3010, Round: 3010\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1332,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3011, Round: 3011\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3012, Round: 3012\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3013, Round: 3013\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3014, Round: 3014\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3015, Round: 3015\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3016, Round: 3016\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3017, Round: 3017\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 3018, Round: 3018\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 3019, Round: 3019\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3020, Round: 3020\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.134,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3021, Round: 3021\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3022, Round: 3022\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3023, Round: 3023\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3024, Round: 3024\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3025, Round: 3025\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 3026, Round: 3026\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3027, Round: 3027\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3028, Round: 3028\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3029, Round: 3029\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 3030, Round: 3030\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 3031, Round: 3031\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.134,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 3032, Round: 3032\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 3033, Round: 3033\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1343,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3034, Round: 3034\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3035, Round: 3035\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3036, Round: 3036\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1343,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3037, Round: 3037\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3038, Round: 3038\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1343,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3039, Round: 3039\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3040, Round: 3040\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.134,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3041, Round: 3041\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 3042, Round: 3042\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 3043, Round: 3043\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3044, Round: 3044\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3045, Round: 3045\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 3046, Round: 3046\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3047, Round: 3047\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1342,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3048, Round: 3048\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1343,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3049, Round: 3049\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3050, Round: 3050\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3051, Round: 3051\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3052, Round: 3052\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3053, Round: 3053\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3054, Round: 3054\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3055, Round: 3055\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3056, Round: 3056\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3057, Round: 3057\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3058, Round: 3058\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.134,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3059, Round: 3059\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3060, Round: 3060\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3061, Round: 3061\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3062, Round: 3062\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3063, Round: 3063\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3064, Round: 3064\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3065, Round: 3065\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3066, Round: 3066\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3067, Round: 3067\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3068, Round: 3068\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3069, Round: 3069\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3070, Round: 3070\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3071, Round: 3071\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3072, Round: 3072\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 3073, Round: 3073\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3074, Round: 3074\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3075, Round: 3075\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3076, Round: 3076\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3077, Round: 3077\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3078, Round: 3078\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1344,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3079, Round: 3079\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3080, Round: 3080\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3081, Round: 3081\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 3082, Round: 3082\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3083, Round: 3083\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 3084, Round: 3084\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3085, Round: 3085\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3086, Round: 3086\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3087, Round: 3087\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3088, Round: 3088\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3089, Round: 3089\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3090, Round: 3090\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3091, Round: 3091\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3092, Round: 3092\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3093, Round: 3093\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3094, Round: 3094\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3095, Round: 3095\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3096, Round: 3096\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3097, Round: 3097\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3098, Round: 3098\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3099, Round: 3099\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 3100, Round: 3100\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 3101, Round: 3101\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 3102, Round: 3102\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3103, Round: 3103\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3104, Round: 3104\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3105, Round: 3105\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3106, Round: 3106\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3107, Round: 3107\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3108, Round: 3108\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3109, Round: 3109\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 3110, Round: 3110\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3111, Round: 3111\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3112, Round: 3112\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3113, Round: 3113\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3114, Round: 3114\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3115, Round: 3115\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3116, Round: 3116\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3117, Round: 3117\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3118, Round: 3118\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3119, Round: 3119\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3120, Round: 3120\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 3121, Round: 3121\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3122, Round: 3122\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3123, Round: 3123\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3124, Round: 3124\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3125, Round: 3125\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3126, Round: 3126\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3127, Round: 3127\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3128, Round: 3128\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3129, Round: 3129\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3130, Round: 3130\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3131, Round: 3131\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3132, Round: 3132\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3133, Round: 3133\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3134, Round: 3134\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3135, Round: 3135\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3136, Round: 3136\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3137, Round: 3137\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3138, Round: 3138\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 3139, Round: 3139\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 3140, Round: 3140\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 3141, Round: 3141\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3142, Round: 3142\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3143, Round: 3143\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3144, Round: 3144\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3145, Round: 3145\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3146, Round: 3146\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3147, Round: 3147\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3148, Round: 3148\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3149, Round: 3149\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3150, Round: 3150\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3151, Round: 3151\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3152, Round: 3152\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 3153, Round: 3153\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 3154, Round: 3154\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3155, Round: 3155\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 3156, Round: 3156\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 3157, Round: 3157\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 3158, Round: 3158\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 3159, Round: 3159\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3160, Round: 3160\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3161, Round: 3161\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3162, Round: 3162\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1361,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 3163, Round: 3163\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0863,  }]\n",
      "Training on Total Epoch: 3164, Round: 3164\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3165, Round: 3165\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3166, Round: 3166\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 3167, Round: 3167\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1356,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 3168, Round: 3168\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 3169, Round: 3169\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 3170, Round: 3170\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 3171, Round: 3171\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN Simple Interf Evaluator(name = Eval_1, task = classification, has trained n_epoch = 3172, n_step = 15860)."
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Evaluate the model - Benchmark Model 1 - 2 Layers, Small Model\n",
    "# \n",
    "\n",
    "model1 = Model_1(backend=backend, device=device, autograd=False)\n",
    "crit1 = MultiCrossEntropy(eps = 1e-10, raw_logits=False, backend=backend, device=device, autograd=False)\n",
    "optm1 = AdamW(model1.parameters(), lr = 2e-4, eps = 1e-10, backend=backend, device=device, autograd=False)\n",
    "eval1 = Evaluator(\"Eval_1\", task = \"classification\", module=model1, criterion=crit1, optimizer=optm1)\n",
    "\n",
    "# Start to train the model\n",
    "eval1.fit(\n",
    "    X = train_feature, y = train_target,\n",
    "    epoches = 5000,\n",
    "    batch_size = 768,\n",
    "    shuffle = True,\n",
    "    random_state = None,\n",
    "    one_hot = True,\n",
    "    verbosity = 1,\n",
    "    evalper = 1,\n",
    "    evalset = {\n",
    "        \"Train\": (train_feature, train_target),\n",
    "        \"Valid\": (valid_feature, valid_target),\n",
    "        \"Test\":  (test_feature, test_target)\n",
    "    },\n",
    "    evalmetrics = [\"logloss\"],\n",
    "    early_stop = 5,\n",
    "    early_stop_logic = \"most\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Config: {Benchmark Evaluation: Model1, (64, 32, 10)}\n",
      "ACC    : 0.975979\n",
      "PREC   : 0.976448\n",
      "RECALL : 0.975652\n",
      "F1     : 0.975806\n",
      "CONFUSION MATRIX:\n",
      "         0       1       2       3    4       5       6       7       8       9\n",
      "0  0.9837  0.0000  0.0000  0.0000  0.0  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "1  0.0000  0.9268  0.0000  0.0000  0.0  0.0000  0.0000  0.0000  0.0081  0.0000\n",
      "2  0.0000  0.0180  0.9910  0.0000  0.0  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "3  0.0000  0.0000  0.0083  0.9833  0.0  0.0417  0.0000  0.0000  0.0000  0.0083\n",
      "4  0.0086  0.0000  0.0000  0.0000  1.0  0.0000  0.0086  0.0000  0.0000  0.0000\n",
      "5  0.0000  0.0000  0.0000  0.0081  0.0  0.9593  0.0000  0.0081  0.0000  0.0000\n",
      "6  0.0000  0.0000  0.0000  0.0000  0.0  0.0000  0.9907  0.0000  0.0000  0.0000\n",
      "7  0.0000  0.0000  0.0000  0.0000  0.0  0.0000  0.0000  0.9903  0.0000  0.0000\n",
      "8  0.0000  0.0421  0.0000  0.0105  0.0  0.0000  0.0000  0.0000  0.9684  0.0211\n",
      "9  0.0097  0.0291  0.0000  0.0000  0.0  0.0000  0.0000  0.0000  0.0194  0.9709\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the model - Benchmark Model 1 - 2 Layers, Small Model\n",
    "# \n",
    "\n",
    "# Print the results for the test-set\n",
    "eval1.eval()\n",
    "pred, acc, prec, recall, f1, cfm = eval_pipeline(eval1, test_feature, test_target)\n",
    "print(\"Model Config: {Benchmark Evaluation: Model1, (64, 32, 10)}\")\n",
    "print(\"ACC    :\", round(acc, 6))\n",
    "print(\"PREC   :\", round(prec, 6))\n",
    "print(\"RECALL :\", round(recall, 6))\n",
    "print(\"F1     :\", round(f1, 6))\n",
    "print(\"CONFUSION MATRIX:\\n\", pd.DataFrame(cfm.to_numpy_array().round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1.2 Results from the 2nd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Total Epoch: 0, Round: 0\n",
      "Training on Total Epoch: 1, Round: 1\n",
      "Training on Total Epoch: 2, Round: 2\n",
      "Evalset: [Train : Metrics { logloss:2.3085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3052,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3069,  }]\n",
      "Training on Total Epoch: 3, Round: 3\n",
      "Evalset: [Train : Metrics { logloss:2.3075,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3049,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3061,  }]\n",
      "Training on Total Epoch: 4, Round: 4\n",
      "Evalset: [Train : Metrics { logloss:2.3066,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3047,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3054,  }]\n",
      "Training on Total Epoch: 5, Round: 5\n",
      "Evalset: [Train : Metrics { logloss:2.3059,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3046,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3048,  }]\n",
      "Training on Total Epoch: 6, Round: 6\n",
      "Evalset: [Train : Metrics { logloss:2.3052,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3045,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3043,  }]\n",
      "Training on Total Epoch: 7, Round: 7\n",
      "Evalset: [Train : Metrics { logloss:2.3046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3045,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3039,  }]\n",
      "Training on Total Epoch: 8, Round: 8\n",
      "Evalset: [Train : Metrics { logloss:2.3041,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3045,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3036,  }]\n",
      "Training on Total Epoch: 9, Round: 9\n",
      "Evalset: [Train : Metrics { logloss:2.3037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3045,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3034,  }]\n",
      "Training on Total Epoch: 10, Round: 10\n",
      "Evalset: [Train : Metrics { logloss:2.3033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3046,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3032,  }]\n",
      "Training on Total Epoch: 11, Round: 11\n",
      "Evalset: [Train : Metrics { logloss:2.3031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3046,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3031,  }]\n",
      "Training on Total Epoch: 12, Round: 12\n",
      "Evalset: [Train : Metrics { logloss:2.3028,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3047,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 13, Round: 13\n",
      "Evalset: [Train : Metrics { logloss:2.3026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3048,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 14, Round: 14\n",
      "Evalset: [Train : Metrics { logloss:2.3025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3049,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 15, Round: 15\n",
      "Evalset: [Train : Metrics { logloss:2.3024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.305,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 16, Round: 16\n",
      "Evalset: [Train : Metrics { logloss:2.3023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3052,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3029,  }]\n",
      "Training on Total Epoch: 17, Round: 17\n",
      "Evalset: [Train : Metrics { logloss:2.3022,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3053,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3029,  }]\n",
      "Training on Total Epoch: 18, Round: 18\n",
      "Evalset: [Train : Metrics { logloss:2.3021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3054,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3029,  }]\n",
      "Training on Total Epoch: 19, Round: 19\n",
      "Evalset: [Train : Metrics { logloss:2.3021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3055,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 20, Round: 20\n",
      "Evalset: [Train : Metrics { logloss:2.3021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3056,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3029,  }]\n",
      "Training on Total Epoch: 21, Round: 21\n",
      "Evalset: [Train : Metrics { logloss:2.3021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3057,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 22, Round: 22\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3058,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 23, Round: 23\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3059,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3031,  }]\n",
      "Training on Total Epoch: 24, Round: 24\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3059,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3031,  }]\n",
      "Training on Total Epoch: 25, Round: 25\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3058,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3032,  }]\n",
      "Training on Total Epoch: 26, Round: 26\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3058,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3032,  }]\n",
      "Training on Total Epoch: 27, Round: 27\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3058,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3032,  }]\n",
      "Training on Total Epoch: 28, Round: 28\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3057,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3033,  }]\n",
      "Training on Total Epoch: 29, Round: 29\n",
      "Evalset: [Train : Metrics { logloss:2.302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3057,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3033,  }]\n",
      "Training on Total Epoch: 30, Round: 30\n",
      "Evalset: [Train : Metrics { logloss:2.3019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3057,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3033,  }]\n",
      "Training on Total Epoch: 31, Round: 31\n",
      "Evalset: [Train : Metrics { logloss:2.3019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3056,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3033,  }]\n",
      "Training on Total Epoch: 32, Round: 32\n",
      "Evalset: [Train : Metrics { logloss:2.3019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3057,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3033,  }]\n",
      "Training on Total Epoch: 33, Round: 33\n",
      "Evalset: [Train : Metrics { logloss:2.3019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3057,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3033,  }]\n",
      "Training on Total Epoch: 34, Round: 34\n",
      "Evalset: [Train : Metrics { logloss:2.3019,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3056,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3033,  }]\n",
      "Training on Total Epoch: 35, Round: 35\n",
      "Evalset: [Train : Metrics { logloss:2.3018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3055,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3032,  }]\n",
      "Training on Total Epoch: 36, Round: 36\n",
      "Evalset: [Train : Metrics { logloss:2.3018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3054,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3031,  }]\n",
      "Training on Total Epoch: 37, Round: 37\n",
      "Evalset: [Train : Metrics { logloss:2.3017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3054,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3031,  }]\n",
      "Training on Total Epoch: 38, Round: 38\n",
      "Evalset: [Train : Metrics { logloss:2.3016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3054,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.303,  }]\n",
      "Training on Total Epoch: 39, Round: 39\n",
      "Evalset: [Train : Metrics { logloss:2.3015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3052,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3029,  }]\n",
      "Training on Total Epoch: 40, Round: 40\n",
      "Evalset: [Train : Metrics { logloss:2.3013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.305,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3028,  }]\n",
      "Training on Total Epoch: 41, Round: 41\n",
      "Evalset: [Train : Metrics { logloss:2.3011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3047,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3025,  }]\n",
      "Training on Total Epoch: 42, Round: 42\n",
      "Evalset: [Train : Metrics { logloss:2.3008,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3043,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3022,  }]\n",
      "Training on Total Epoch: 43, Round: 43\n",
      "Evalset: [Train : Metrics { logloss:2.3005,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3039,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3018,  }]\n",
      "Training on Total Epoch: 44, Round: 44\n",
      "Evalset: [Train : Metrics { logloss:2.3,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3034,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3013,  }]\n",
      "Training on Total Epoch: 45, Round: 45\n",
      "Evalset: [Train : Metrics { logloss:2.2995,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3029,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3007,  }]\n",
      "Training on Total Epoch: 46, Round: 46\n",
      "Evalset: [Train : Metrics { logloss:2.2989,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3023,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.3001,  }]\n",
      "Training on Total Epoch: 47, Round: 47\n",
      "Evalset: [Train : Metrics { logloss:2.2982,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3016,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2993,  }]\n",
      "Training on Total Epoch: 48, Round: 48\n",
      "Evalset: [Train : Metrics { logloss:2.2974,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.3007,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2984,  }]\n",
      "Training on Total Epoch: 49, Round: 49\n",
      "Evalset: [Train : Metrics { logloss:2.2965,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2997,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2974,  }]\n",
      "Training on Total Epoch: 50, Round: 50\n",
      "Evalset: [Train : Metrics { logloss:2.2955,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2985,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2962,  }]\n",
      "Training on Total Epoch: 51, Round: 51\n",
      "Evalset: [Train : Metrics { logloss:2.2944,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2973,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.295,  }]\n",
      "Training on Total Epoch: 52, Round: 52\n",
      "Evalset: [Train : Metrics { logloss:2.2932,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.296,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2937,  }]\n",
      "Training on Total Epoch: 53, Round: 53\n",
      "Evalset: [Train : Metrics { logloss:2.2919,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2945,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2923,  }]\n",
      "Training on Total Epoch: 54, Round: 54\n",
      "Evalset: [Train : Metrics { logloss:2.2906,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2929,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2909,  }]\n",
      "Training on Total Epoch: 55, Round: 55\n",
      "Evalset: [Train : Metrics { logloss:2.2891,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2912,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2893,  }]\n",
      "Training on Total Epoch: 56, Round: 56\n",
      "Evalset: [Train : Metrics { logloss:2.2874,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2894,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2876,  }]\n",
      "Training on Total Epoch: 57, Round: 57\n",
      "Evalset: [Train : Metrics { logloss:2.2857,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2875,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2859,  }]\n",
      "Training on Total Epoch: 58, Round: 58\n",
      "Evalset: [Train : Metrics { logloss:2.2839,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2854,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.284,  }]\n",
      "Training on Total Epoch: 59, Round: 59\n",
      "Evalset: [Train : Metrics { logloss:2.2819,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2833,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.282,  }]\n",
      "Training on Total Epoch: 60, Round: 60\n",
      "Evalset: [Train : Metrics { logloss:2.2798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2812,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.28,  }]\n",
      "Training on Total Epoch: 61, Round: 61\n",
      "Evalset: [Train : Metrics { logloss:2.2776,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2789,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2777,  }]\n",
      "Training on Total Epoch: 62, Round: 62\n",
      "Evalset: [Train : Metrics { logloss:2.2752,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2765,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2754,  }]\n",
      "Training on Total Epoch: 63, Round: 63\n",
      "Evalset: [Train : Metrics { logloss:2.2727,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.274,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2729,  }]\n",
      "Training on Total Epoch: 64, Round: 64\n",
      "Evalset: [Train : Metrics { logloss:2.2701,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2713,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2703,  }]\n",
      "Training on Total Epoch: 65, Round: 65\n",
      "Evalset: [Train : Metrics { logloss:2.2674,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2684,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2676,  }]\n",
      "Training on Total Epoch: 66, Round: 66\n",
      "Evalset: [Train : Metrics { logloss:2.2645,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2655,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2647,  }]\n",
      "Training on Total Epoch: 67, Round: 67\n",
      "Evalset: [Train : Metrics { logloss:2.2615,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2625,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2617,  }]\n",
      "Training on Total Epoch: 68, Round: 68\n",
      "Evalset: [Train : Metrics { logloss:2.2584,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2593,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2585,  }]\n",
      "Training on Total Epoch: 69, Round: 69\n",
      "Evalset: [Train : Metrics { logloss:2.2551,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2559,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2552,  }]\n",
      "Training on Total Epoch: 70, Round: 70\n",
      "Evalset: [Train : Metrics { logloss:2.2517,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2525,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2517,  }]\n",
      "Training on Total Epoch: 71, Round: 71\n",
      "Evalset: [Train : Metrics { logloss:2.2482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.249,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2481,  }]\n",
      "Training on Total Epoch: 72, Round: 72\n",
      "Evalset: [Train : Metrics { logloss:2.2445,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2453,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2444,  }]\n",
      "Training on Total Epoch: 73, Round: 73\n",
      "Evalset: [Train : Metrics { logloss:2.2407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2416,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2405,  }]\n",
      "Training on Total Epoch: 74, Round: 74\n",
      "Evalset: [Train : Metrics { logloss:2.2367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2377,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2365,  }]\n",
      "Training on Total Epoch: 75, Round: 75\n",
      "Evalset: [Train : Metrics { logloss:2.2327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2337,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2324,  }]\n",
      "Training on Total Epoch: 76, Round: 76\n",
      "Evalset: [Train : Metrics { logloss:2.2285,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2295,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2281,  }]\n",
      "Training on Total Epoch: 77, Round: 77\n",
      "Evalset: [Train : Metrics { logloss:2.2242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2252,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2237,  }]\n",
      "Training on Total Epoch: 78, Round: 78\n",
      "Evalset: [Train : Metrics { logloss:2.2197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2208,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2192,  }]\n",
      "Training on Total Epoch: 79, Round: 79\n",
      "Evalset: [Train : Metrics { logloss:2.2151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2163,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2146,  }]\n",
      "Training on Total Epoch: 80, Round: 80\n",
      "Evalset: [Train : Metrics { logloss:2.2104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2118,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2098,  }]\n",
      "Training on Total Epoch: 81, Round: 81\n",
      "Evalset: [Train : Metrics { logloss:2.2056,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.207,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.205,  }]\n",
      "Training on Total Epoch: 82, Round: 82\n",
      "Evalset: [Train : Metrics { logloss:2.2007,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.2021,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.2,  }]\n",
      "Training on Total Epoch: 83, Round: 83\n",
      "Evalset: [Train : Metrics { logloss:2.1957,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1971,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1949,  }]\n",
      "Training on Total Epoch: 84, Round: 84\n",
      "Evalset: [Train : Metrics { logloss:2.1905,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1921,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1896,  }]\n",
      "Training on Total Epoch: 85, Round: 85\n",
      "Evalset: [Train : Metrics { logloss:2.1852,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1868,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1842,  }]\n",
      "Training on Total Epoch: 86, Round: 86\n",
      "Evalset: [Train : Metrics { logloss:2.1798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1815,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1787,  }]\n",
      "Training on Total Epoch: 87, Round: 87\n",
      "Evalset: [Train : Metrics { logloss:2.1743,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1759,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.173,  }]\n",
      "Training on Total Epoch: 88, Round: 88\n",
      "Evalset: [Train : Metrics { logloss:2.1687,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1703,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1673,  }]\n",
      "Training on Total Epoch: 89, Round: 89\n",
      "Evalset: [Train : Metrics { logloss:2.1629,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1646,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1615,  }]\n",
      "Training on Total Epoch: 90, Round: 90\n",
      "Evalset: [Train : Metrics { logloss:2.1571,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1588,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1555,  }]\n",
      "Training on Total Epoch: 91, Round: 91\n",
      "Evalset: [Train : Metrics { logloss:2.1511,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1528,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1493,  }]\n",
      "Training on Total Epoch: 92, Round: 92\n",
      "Evalset: [Train : Metrics { logloss:2.1451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1465,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.143,  }]\n",
      "Training on Total Epoch: 93, Round: 93\n",
      "Evalset: [Train : Metrics { logloss:2.1389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1402,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1366,  }]\n",
      "Training on Total Epoch: 94, Round: 94\n",
      "Evalset: [Train : Metrics { logloss:2.1326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.13,  }]\n",
      "Training on Total Epoch: 95, Round: 95\n",
      "Evalset: [Train : Metrics { logloss:2.1262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1234,  }]\n",
      "Training on Total Epoch: 96, Round: 96\n",
      "Evalset: [Train : Metrics { logloss:2.1197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1206,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1167,  }]\n",
      "Training on Total Epoch: 97, Round: 97\n",
      "Evalset: [Train : Metrics { logloss:2.1131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.114,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.11,  }]\n",
      "Training on Total Epoch: 98, Round: 98\n",
      "Evalset: [Train : Metrics { logloss:2.1065,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1074,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.1032,  }]\n",
      "Training on Total Epoch: 99, Round: 99\n",
      "Evalset: [Train : Metrics { logloss:2.0998,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.1007,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0963,  }]\n",
      "Training on Total Epoch: 100, Round: 100\n",
      "Evalset: [Train : Metrics { logloss:2.093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0938,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0894,  }]\n",
      "Training on Total Epoch: 101, Round: 101\n",
      "Evalset: [Train : Metrics { logloss:2.0862,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0869,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0823,  }]\n",
      "Training on Total Epoch: 102, Round: 102\n",
      "Evalset: [Train : Metrics { logloss:2.0793,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0799,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0752,  }]\n",
      "Training on Total Epoch: 103, Round: 103\n",
      "Evalset: [Train : Metrics { logloss:2.0723,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0727,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.068,  }]\n",
      "Training on Total Epoch: 104, Round: 104\n",
      "Evalset: [Train : Metrics { logloss:2.0653,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0655,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0607,  }]\n",
      "Training on Total Epoch: 105, Round: 105\n",
      "Evalset: [Train : Metrics { logloss:2.0582,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0582,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0534,  }]\n",
      "Training on Total Epoch: 106, Round: 106\n",
      "Evalset: [Train : Metrics { logloss:2.0511,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0509,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0461,  }]\n",
      "Training on Total Epoch: 107, Round: 107\n",
      "Evalset: [Train : Metrics { logloss:2.0439,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0436,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0387,  }]\n",
      "Training on Total Epoch: 108, Round: 108\n",
      "Evalset: [Train : Metrics { logloss:2.0367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0363,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0312,  }]\n",
      "Training on Total Epoch: 109, Round: 109\n",
      "Evalset: [Train : Metrics { logloss:2.0295,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0289,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0237,  }]\n",
      "Training on Total Epoch: 110, Round: 110\n",
      "Evalset: [Train : Metrics { logloss:2.0223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0217,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0163,  }]\n",
      "Training on Total Epoch: 111, Round: 111\n",
      "Evalset: [Train : Metrics { logloss:2.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.0143,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0088,  }]\n",
      "Training on Total Epoch: 112, Round: 112\n",
      "Evalset: [Train : Metrics { logloss:2.0077,  }]\n",
      "Evalset: [Valid : Metrics { logloss:2.007,  }]\n",
      "Evalset: [Test : Metrics { logloss:2.0013,  }]\n",
      "Training on Total Epoch: 113, Round: 113\n",
      "Evalset: [Train : Metrics { logloss:2.0005,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9997,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9939,  }]\n",
      "Training on Total Epoch: 114, Round: 114\n",
      "Evalset: [Train : Metrics { logloss:1.9932,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9923,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9864,  }]\n",
      "Training on Total Epoch: 115, Round: 115\n",
      "Evalset: [Train : Metrics { logloss:1.9859,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9849,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9788,  }]\n",
      "Training on Total Epoch: 116, Round: 116\n",
      "Evalset: [Train : Metrics { logloss:1.9785,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9774,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9713,  }]\n",
      "Training on Total Epoch: 117, Round: 117\n",
      "Evalset: [Train : Metrics { logloss:1.9712,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9699,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9637,  }]\n",
      "Training on Total Epoch: 118, Round: 118\n",
      "Evalset: [Train : Metrics { logloss:1.9639,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9625,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9561,  }]\n",
      "Training on Total Epoch: 119, Round: 119\n",
      "Evalset: [Train : Metrics { logloss:1.9565,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9552,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9486,  }]\n",
      "Training on Total Epoch: 120, Round: 120\n",
      "Evalset: [Train : Metrics { logloss:1.9492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9479,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9411,  }]\n",
      "Training on Total Epoch: 121, Round: 121\n",
      "Evalset: [Train : Metrics { logloss:1.9419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9406,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9337,  }]\n",
      "Training on Total Epoch: 122, Round: 122\n",
      "Evalset: [Train : Metrics { logloss:1.9346,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9332,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9262,  }]\n",
      "Training on Total Epoch: 123, Round: 123\n",
      "Evalset: [Train : Metrics { logloss:1.9273,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9257,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9186,  }]\n",
      "Training on Total Epoch: 124, Round: 124\n",
      "Evalset: [Train : Metrics { logloss:1.92,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9183,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9112,  }]\n",
      "Training on Total Epoch: 125, Round: 125\n",
      "Evalset: [Train : Metrics { logloss:1.9127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9109,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.9037,  }]\n",
      "Training on Total Epoch: 126, Round: 126\n",
      "Evalset: [Train : Metrics { logloss:1.9053,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.9034,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8961,  }]\n",
      "Training on Total Epoch: 127, Round: 127\n",
      "Evalset: [Train : Metrics { logloss:1.898,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.896,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8885,  }]\n",
      "Training on Total Epoch: 128, Round: 128\n",
      "Evalset: [Train : Metrics { logloss:1.8907,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8886,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.881,  }]\n",
      "Training on Total Epoch: 129, Round: 129\n",
      "Evalset: [Train : Metrics { logloss:1.8834,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8812,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8734,  }]\n",
      "Training on Total Epoch: 130, Round: 130\n",
      "Evalset: [Train : Metrics { logloss:1.8762,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8739,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.866,  }]\n",
      "Training on Total Epoch: 131, Round: 131\n",
      "Evalset: [Train : Metrics { logloss:1.869,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8666,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8586,  }]\n",
      "Training on Total Epoch: 132, Round: 132\n",
      "Evalset: [Train : Metrics { logloss:1.8618,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8594,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8512,  }]\n",
      "Training on Total Epoch: 133, Round: 133\n",
      "Evalset: [Train : Metrics { logloss:1.8546,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8521,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8439,  }]\n",
      "Training on Total Epoch: 134, Round: 134\n",
      "Evalset: [Train : Metrics { logloss:1.8474,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.845,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8365,  }]\n",
      "Training on Total Epoch: 135, Round: 135\n",
      "Evalset: [Train : Metrics { logloss:1.8402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8377,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8291,  }]\n",
      "Training on Total Epoch: 136, Round: 136\n",
      "Evalset: [Train : Metrics { logloss:1.833,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8303,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8216,  }]\n",
      "Training on Total Epoch: 137, Round: 137\n",
      "Evalset: [Train : Metrics { logloss:1.8259,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.823,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8142,  }]\n",
      "Training on Total Epoch: 138, Round: 138\n",
      "Evalset: [Train : Metrics { logloss:1.8187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8156,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.8068,  }]\n",
      "Training on Total Epoch: 139, Round: 139\n",
      "Evalset: [Train : Metrics { logloss:1.8116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8084,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7995,  }]\n",
      "Training on Total Epoch: 140, Round: 140\n",
      "Evalset: [Train : Metrics { logloss:1.8046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.8015,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7923,  }]\n",
      "Training on Total Epoch: 141, Round: 141\n",
      "Evalset: [Train : Metrics { logloss:1.7976,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7945,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7851,  }]\n",
      "Training on Total Epoch: 142, Round: 142\n",
      "Evalset: [Train : Metrics { logloss:1.7906,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7874,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7778,  }]\n",
      "Training on Total Epoch: 143, Round: 143\n",
      "Evalset: [Train : Metrics { logloss:1.7835,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7801,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7706,  }]\n",
      "Training on Total Epoch: 144, Round: 144\n",
      "Evalset: [Train : Metrics { logloss:1.7764,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7727,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7632,  }]\n",
      "Training on Total Epoch: 145, Round: 145\n",
      "Evalset: [Train : Metrics { logloss:1.7694,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7654,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7559,  }]\n",
      "Training on Total Epoch: 146, Round: 146\n",
      "Evalset: [Train : Metrics { logloss:1.7623,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7582,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7486,  }]\n",
      "Training on Total Epoch: 147, Round: 147\n",
      "Evalset: [Train : Metrics { logloss:1.7552,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.751,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7413,  }]\n",
      "Training on Total Epoch: 148, Round: 148\n",
      "Evalset: [Train : Metrics { logloss:1.7482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7438,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.734,  }]\n",
      "Training on Total Epoch: 149, Round: 149\n",
      "Evalset: [Train : Metrics { logloss:1.7411,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7367,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7268,  }]\n",
      "Training on Total Epoch: 150, Round: 150\n",
      "Evalset: [Train : Metrics { logloss:1.7339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7293,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7194,  }]\n",
      "Training on Total Epoch: 151, Round: 151\n",
      "Evalset: [Train : Metrics { logloss:1.7267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7217,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7119,  }]\n",
      "Training on Total Epoch: 152, Round: 152\n",
      "Evalset: [Train : Metrics { logloss:1.7194,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7143,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.7045,  }]\n",
      "Training on Total Epoch: 153, Round: 153\n",
      "Evalset: [Train : Metrics { logloss:1.7123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7072,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6971,  }]\n",
      "Training on Total Epoch: 154, Round: 154\n",
      "Evalset: [Train : Metrics { logloss:1.7052,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.7,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6898,  }]\n",
      "Training on Total Epoch: 155, Round: 155\n",
      "Evalset: [Train : Metrics { logloss:1.698,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6928,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6824,  }]\n",
      "Training on Total Epoch: 156, Round: 156\n",
      "Evalset: [Train : Metrics { logloss:1.6908,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6854,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.675,  }]\n",
      "Training on Total Epoch: 157, Round: 157\n",
      "Evalset: [Train : Metrics { logloss:1.6837,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.678,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6677,  }]\n",
      "Training on Total Epoch: 158, Round: 158\n",
      "Evalset: [Train : Metrics { logloss:1.6766,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.671,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6605,  }]\n",
      "Training on Total Epoch: 159, Round: 159\n",
      "Evalset: [Train : Metrics { logloss:1.6696,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6639,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6533,  }]\n",
      "Training on Total Epoch: 160, Round: 160\n",
      "Evalset: [Train : Metrics { logloss:1.6626,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6568,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.646,  }]\n",
      "Training on Total Epoch: 161, Round: 161\n",
      "Evalset: [Train : Metrics { logloss:1.6556,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6498,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6389,  }]\n",
      "Training on Total Epoch: 162, Round: 162\n",
      "Evalset: [Train : Metrics { logloss:1.6488,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.643,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.632,  }]\n",
      "Training on Total Epoch: 163, Round: 163\n",
      "Evalset: [Train : Metrics { logloss:1.642,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6362,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6252,  }]\n",
      "Training on Total Epoch: 164, Round: 164\n",
      "Evalset: [Train : Metrics { logloss:1.6353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6295,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6183,  }]\n",
      "Training on Total Epoch: 165, Round: 165\n",
      "Evalset: [Train : Metrics { logloss:1.6286,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6228,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6115,  }]\n",
      "Training on Total Epoch: 166, Round: 166\n",
      "Evalset: [Train : Metrics { logloss:1.622,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6161,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.6048,  }]\n",
      "Training on Total Epoch: 167, Round: 167\n",
      "Evalset: [Train : Metrics { logloss:1.6154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6094,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5981,  }]\n",
      "Training on Total Epoch: 168, Round: 168\n",
      "Evalset: [Train : Metrics { logloss:1.6089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.6027,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5914,  }]\n",
      "Training on Total Epoch: 169, Round: 169\n",
      "Evalset: [Train : Metrics { logloss:1.6024,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.596,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5848,  }]\n",
      "Training on Total Epoch: 170, Round: 170\n",
      "Evalset: [Train : Metrics { logloss:1.596,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5895,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5783,  }]\n",
      "Training on Total Epoch: 171, Round: 171\n",
      "Evalset: [Train : Metrics { logloss:1.5896,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5832,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5719,  }]\n",
      "Training on Total Epoch: 172, Round: 172\n",
      "Evalset: [Train : Metrics { logloss:1.5833,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.577,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5656,  }]\n",
      "Training on Total Epoch: 173, Round: 173\n",
      "Evalset: [Train : Metrics { logloss:1.5771,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5709,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5593,  }]\n",
      "Training on Total Epoch: 174, Round: 174\n",
      "Evalset: [Train : Metrics { logloss:1.5708,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5646,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.553,  }]\n",
      "Training on Total Epoch: 175, Round: 175\n",
      "Evalset: [Train : Metrics { logloss:1.5646,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5584,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5467,  }]\n",
      "Training on Total Epoch: 176, Round: 176\n",
      "Evalset: [Train : Metrics { logloss:1.5584,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5522,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5404,  }]\n",
      "Training on Total Epoch: 177, Round: 177\n",
      "Evalset: [Train : Metrics { logloss:1.5523,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5462,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5343,  }]\n",
      "Training on Total Epoch: 178, Round: 178\n",
      "Evalset: [Train : Metrics { logloss:1.5461,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.54,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5281,  }]\n",
      "Training on Total Epoch: 179, Round: 179\n",
      "Evalset: [Train : Metrics { logloss:1.54,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5338,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5219,  }]\n",
      "Training on Total Epoch: 180, Round: 180\n",
      "Evalset: [Train : Metrics { logloss:1.5339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5275,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5157,  }]\n",
      "Training on Total Epoch: 181, Round: 181\n",
      "Evalset: [Train : Metrics { logloss:1.5279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5214,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5097,  }]\n",
      "Training on Total Epoch: 182, Round: 182\n",
      "Evalset: [Train : Metrics { logloss:1.5218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5153,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.5036,  }]\n",
      "Training on Total Epoch: 183, Round: 183\n",
      "Evalset: [Train : Metrics { logloss:1.5158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5094,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4975,  }]\n",
      "Training on Total Epoch: 184, Round: 184\n",
      "Evalset: [Train : Metrics { logloss:1.5098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.5034,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4915,  }]\n",
      "Training on Total Epoch: 185, Round: 185\n",
      "Evalset: [Train : Metrics { logloss:1.5038,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4974,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4855,  }]\n",
      "Training on Total Epoch: 186, Round: 186\n",
      "Evalset: [Train : Metrics { logloss:1.4978,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4915,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4796,  }]\n",
      "Training on Total Epoch: 187, Round: 187\n",
      "Evalset: [Train : Metrics { logloss:1.4918,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4853,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4735,  }]\n",
      "Training on Total Epoch: 188, Round: 188\n",
      "Evalset: [Train : Metrics { logloss:1.4858,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4793,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4675,  }]\n",
      "Training on Total Epoch: 189, Round: 189\n",
      "Evalset: [Train : Metrics { logloss:1.4798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4733,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4616,  }]\n",
      "Training on Total Epoch: 190, Round: 190\n",
      "Evalset: [Train : Metrics { logloss:1.4739,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4675,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4556,  }]\n",
      "Training on Total Epoch: 191, Round: 191\n",
      "Evalset: [Train : Metrics { logloss:1.4679,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4616,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4497,  }]\n",
      "Training on Total Epoch: 192, Round: 192\n",
      "Evalset: [Train : Metrics { logloss:1.462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4557,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4438,  }]\n",
      "Training on Total Epoch: 193, Round: 193\n",
      "Evalset: [Train : Metrics { logloss:1.4561,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4498,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4379,  }]\n",
      "Training on Total Epoch: 194, Round: 194\n",
      "Evalset: [Train : Metrics { logloss:1.4502,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.444,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4321,  }]\n",
      "Training on Total Epoch: 195, Round: 195\n",
      "Evalset: [Train : Metrics { logloss:1.4443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4382,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4262,  }]\n",
      "Training on Total Epoch: 196, Round: 196\n",
      "Evalset: [Train : Metrics { logloss:1.4384,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4323,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4203,  }]\n",
      "Training on Total Epoch: 197, Round: 197\n",
      "Evalset: [Train : Metrics { logloss:1.4325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4264,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4144,  }]\n",
      "Training on Total Epoch: 198, Round: 198\n",
      "Evalset: [Train : Metrics { logloss:1.4267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4207,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4086,  }]\n",
      "Training on Total Epoch: 199, Round: 199\n",
      "Evalset: [Train : Metrics { logloss:1.4209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.415,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.4028,  }]\n",
      "Training on Total Epoch: 200, Round: 200\n",
      "Evalset: [Train : Metrics { logloss:1.4149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4091,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3969,  }]\n",
      "Training on Total Epoch: 201, Round: 201\n",
      "Evalset: [Train : Metrics { logloss:1.409,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.4032,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3909,  }]\n",
      "Training on Total Epoch: 202, Round: 202\n",
      "Evalset: [Train : Metrics { logloss:1.4031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3972,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.385,  }]\n",
      "Training on Total Epoch: 203, Round: 203\n",
      "Evalset: [Train : Metrics { logloss:1.3972,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3912,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3791,  }]\n",
      "Training on Total Epoch: 204, Round: 204\n",
      "Evalset: [Train : Metrics { logloss:1.3914,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3853,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3732,  }]\n",
      "Training on Total Epoch: 205, Round: 205\n",
      "Evalset: [Train : Metrics { logloss:1.3856,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3795,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3675,  }]\n",
      "Training on Total Epoch: 206, Round: 206\n",
      "Evalset: [Train : Metrics { logloss:1.3798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3737,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3616,  }]\n",
      "Training on Total Epoch: 207, Round: 207\n",
      "Evalset: [Train : Metrics { logloss:1.374,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3679,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3558,  }]\n",
      "Training on Total Epoch: 208, Round: 208\n",
      "Evalset: [Train : Metrics { logloss:1.3682,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3622,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3501,  }]\n",
      "Training on Total Epoch: 209, Round: 209\n",
      "Evalset: [Train : Metrics { logloss:1.3624,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3566,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3443,  }]\n",
      "Training on Total Epoch: 210, Round: 210\n",
      "Evalset: [Train : Metrics { logloss:1.3566,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3509,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3385,  }]\n",
      "Training on Total Epoch: 211, Round: 211\n",
      "Evalset: [Train : Metrics { logloss:1.3508,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.345,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3326,  }]\n",
      "Training on Total Epoch: 212, Round: 212\n",
      "Evalset: [Train : Metrics { logloss:1.3451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3394,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3268,  }]\n",
      "Training on Total Epoch: 213, Round: 213\n",
      "Evalset: [Train : Metrics { logloss:1.3393,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3337,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3211,  }]\n",
      "Training on Total Epoch: 214, Round: 214\n",
      "Evalset: [Train : Metrics { logloss:1.3336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.328,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3154,  }]\n",
      "Training on Total Epoch: 215, Round: 215\n",
      "Evalset: [Train : Metrics { logloss:1.3278,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3225,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.3097,  }]\n",
      "Training on Total Epoch: 216, Round: 216\n",
      "Evalset: [Train : Metrics { logloss:1.3221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3168,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.304,  }]\n",
      "Training on Total Epoch: 217, Round: 217\n",
      "Evalset: [Train : Metrics { logloss:1.3165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3116,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2984,  }]\n",
      "Training on Total Epoch: 218, Round: 218\n",
      "Evalset: [Train : Metrics { logloss:1.3109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3062,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2928,  }]\n",
      "Training on Total Epoch: 219, Round: 219\n",
      "Evalset: [Train : Metrics { logloss:1.3051,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.3003,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.287,  }]\n",
      "Training on Total Epoch: 220, Round: 220\n",
      "Evalset: [Train : Metrics { logloss:1.2993,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2943,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2811,  }]\n",
      "Training on Total Epoch: 221, Round: 221\n",
      "Evalset: [Train : Metrics { logloss:1.2936,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2885,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2754,  }]\n",
      "Training on Total Epoch: 222, Round: 222\n",
      "Evalset: [Train : Metrics { logloss:1.2879,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2829,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2696,  }]\n",
      "Training on Total Epoch: 223, Round: 223\n",
      "Evalset: [Train : Metrics { logloss:1.2823,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2773,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2639,  }]\n",
      "Training on Total Epoch: 224, Round: 224\n",
      "Evalset: [Train : Metrics { logloss:1.2767,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2719,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2584,  }]\n",
      "Training on Total Epoch: 225, Round: 225\n",
      "Evalset: [Train : Metrics { logloss:1.2712,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2667,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2529,  }]\n",
      "Training on Total Epoch: 226, Round: 226\n",
      "Evalset: [Train : Metrics { logloss:1.2657,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2616,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2474,  }]\n",
      "Training on Total Epoch: 227, Round: 227\n",
      "Evalset: [Train : Metrics { logloss:1.2601,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2563,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2418,  }]\n",
      "Training on Total Epoch: 228, Round: 228\n",
      "Evalset: [Train : Metrics { logloss:1.2545,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2506,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2361,  }]\n",
      "Training on Total Epoch: 229, Round: 229\n",
      "Evalset: [Train : Metrics { logloss:1.2489,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2451,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2304,  }]\n",
      "Training on Total Epoch: 230, Round: 230\n",
      "Evalset: [Train : Metrics { logloss:1.2433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2398,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2249,  }]\n",
      "Training on Total Epoch: 231, Round: 231\n",
      "Evalset: [Train : Metrics { logloss:1.2378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2344,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2193,  }]\n",
      "Training on Total Epoch: 232, Round: 232\n",
      "Evalset: [Train : Metrics { logloss:1.2323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2289,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2138,  }]\n",
      "Training on Total Epoch: 233, Round: 233\n",
      "Evalset: [Train : Metrics { logloss:1.2269,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2236,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.2084,  }]\n",
      "Training on Total Epoch: 234, Round: 234\n",
      "Evalset: [Train : Metrics { logloss:1.2215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2183,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.203,  }]\n",
      "Training on Total Epoch: 235, Round: 235\n",
      "Evalset: [Train : Metrics { logloss:1.2161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.213,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1977,  }]\n",
      "Training on Total Epoch: 236, Round: 236\n",
      "Evalset: [Train : Metrics { logloss:1.2108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2078,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1924,  }]\n",
      "Training on Total Epoch: 237, Round: 237\n",
      "Evalset: [Train : Metrics { logloss:1.2055,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.2029,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1872,  }]\n",
      "Training on Total Epoch: 238, Round: 238\n",
      "Evalset: [Train : Metrics { logloss:1.2002,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.198,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.182,  }]\n",
      "Training on Total Epoch: 239, Round: 239\n",
      "Evalset: [Train : Metrics { logloss:1.1949,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1929,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1767,  }]\n",
      "Training on Total Epoch: 240, Round: 240\n",
      "Evalset: [Train : Metrics { logloss:1.1897,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1877,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1714,  }]\n",
      "Training on Total Epoch: 241, Round: 241\n",
      "Evalset: [Train : Metrics { logloss:1.1844,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1823,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1661,  }]\n",
      "Training on Total Epoch: 242, Round: 242\n",
      "Evalset: [Train : Metrics { logloss:1.1792,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1773,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1609,  }]\n",
      "Training on Total Epoch: 243, Round: 243\n",
      "Evalset: [Train : Metrics { logloss:1.1741,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1724,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1558,  }]\n",
      "Training on Total Epoch: 244, Round: 244\n",
      "Evalset: [Train : Metrics { logloss:1.169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1675,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1508,  }]\n",
      "Training on Total Epoch: 245, Round: 245\n",
      "Evalset: [Train : Metrics { logloss:1.1639,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1624,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1457,  }]\n",
      "Training on Total Epoch: 246, Round: 246\n",
      "Evalset: [Train : Metrics { logloss:1.1588,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1574,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1407,  }]\n",
      "Training on Total Epoch: 247, Round: 247\n",
      "Evalset: [Train : Metrics { logloss:1.1538,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1523,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1356,  }]\n",
      "Training on Total Epoch: 248, Round: 248\n",
      "Evalset: [Train : Metrics { logloss:1.1487,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1473,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1306,  }]\n",
      "Training on Total Epoch: 249, Round: 249\n",
      "Evalset: [Train : Metrics { logloss:1.1436,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1421,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1255,  }]\n",
      "Training on Total Epoch: 250, Round: 250\n",
      "Evalset: [Train : Metrics { logloss:1.1386,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1372,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1204,  }]\n",
      "Training on Total Epoch: 251, Round: 251\n",
      "Evalset: [Train : Metrics { logloss:1.1336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1155,  }]\n",
      "Training on Total Epoch: 252, Round: 252\n",
      "Evalset: [Train : Metrics { logloss:1.1287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1105,  }]\n",
      "Training on Total Epoch: 253, Round: 253\n",
      "Evalset: [Train : Metrics { logloss:1.1237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1056,  }]\n",
      "Training on Total Epoch: 254, Round: 254\n",
      "Evalset: [Train : Metrics { logloss:1.1187,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.1007,  }]\n",
      "Training on Total Epoch: 255, Round: 255\n",
      "Evalset: [Train : Metrics { logloss:1.1137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1135,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0956,  }]\n",
      "Training on Total Epoch: 256, Round: 256\n",
      "Evalset: [Train : Metrics { logloss:1.1086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1084,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0906,  }]\n",
      "Training on Total Epoch: 257, Round: 257\n",
      "Evalset: [Train : Metrics { logloss:1.1036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.1035,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0857,  }]\n",
      "Training on Total Epoch: 258, Round: 258\n",
      "Evalset: [Train : Metrics { logloss:1.0987,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0986,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0808,  }]\n",
      "Training on Total Epoch: 259, Round: 259\n",
      "Evalset: [Train : Metrics { logloss:1.0939,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0938,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.076,  }]\n",
      "Training on Total Epoch: 260, Round: 260\n",
      "Evalset: [Train : Metrics { logloss:1.0891,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0713,  }]\n",
      "Training on Total Epoch: 261, Round: 261\n",
      "Evalset: [Train : Metrics { logloss:1.0843,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0847,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0666,  }]\n",
      "Training on Total Epoch: 262, Round: 262\n",
      "Evalset: [Train : Metrics { logloss:1.0796,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0802,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0619,  }]\n",
      "Training on Total Epoch: 263, Round: 263\n",
      "Evalset: [Train : Metrics { logloss:1.0749,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0754,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0572,  }]\n",
      "Training on Total Epoch: 264, Round: 264\n",
      "Evalset: [Train : Metrics { logloss:1.0702,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0707,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0525,  }]\n",
      "Training on Total Epoch: 265, Round: 265\n",
      "Evalset: [Train : Metrics { logloss:1.0655,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.066,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0479,  }]\n",
      "Training on Total Epoch: 266, Round: 266\n",
      "Evalset: [Train : Metrics { logloss:1.0608,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0614,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0433,  }]\n",
      "Training on Total Epoch: 267, Round: 267\n",
      "Evalset: [Train : Metrics { logloss:1.0561,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0569,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0386,  }]\n",
      "Training on Total Epoch: 268, Round: 268\n",
      "Evalset: [Train : Metrics { logloss:1.0514,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0522,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.034,  }]\n",
      "Training on Total Epoch: 269, Round: 269\n",
      "Evalset: [Train : Metrics { logloss:1.0468,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0475,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0293,  }]\n",
      "Training on Total Epoch: 270, Round: 270\n",
      "Evalset: [Train : Metrics { logloss:1.0421,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0428,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0247,  }]\n",
      "Training on Total Epoch: 271, Round: 271\n",
      "Evalset: [Train : Metrics { logloss:1.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0382,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0201,  }]\n",
      "Training on Total Epoch: 272, Round: 272\n",
      "Evalset: [Train : Metrics { logloss:1.0329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0338,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0156,  }]\n",
      "Training on Total Epoch: 273, Round: 273\n",
      "Evalset: [Train : Metrics { logloss:1.0283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0293,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0111,  }]\n",
      "Training on Total Epoch: 274, Round: 274\n",
      "Evalset: [Train : Metrics { logloss:1.0238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0248,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0066,  }]\n",
      "Training on Total Epoch: 275, Round: 275\n",
      "Evalset: [Train : Metrics { logloss:1.0193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0206,  }]\n",
      "Evalset: [Test : Metrics { logloss:1.0021,  }]\n",
      "Training on Total Epoch: 276, Round: 276\n",
      "Evalset: [Train : Metrics { logloss:1.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9976,  }]\n",
      "Training on Total Epoch: 277, Round: 277\n",
      "Evalset: [Train : Metrics { logloss:1.0103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9932,  }]\n",
      "Training on Total Epoch: 278, Round: 278\n",
      "Evalset: [Train : Metrics { logloss:1.0058,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0076,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9887,  }]\n",
      "Training on Total Epoch: 279, Round: 279\n",
      "Evalset: [Train : Metrics { logloss:1.0013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:1.0029,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9842,  }]\n",
      "Training on Total Epoch: 280, Round: 280\n",
      "Evalset: [Train : Metrics { logloss:0.9969,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9983,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9798,  }]\n",
      "Training on Total Epoch: 281, Round: 281\n",
      "Evalset: [Train : Metrics { logloss:0.9924,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9939,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9753,  }]\n",
      "Training on Total Epoch: 282, Round: 282\n",
      "Evalset: [Train : Metrics { logloss:0.988,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9709,  }]\n",
      "Training on Total Epoch: 283, Round: 283\n",
      "Evalset: [Train : Metrics { logloss:0.9836,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9855,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9665,  }]\n",
      "Training on Total Epoch: 284, Round: 284\n",
      "Evalset: [Train : Metrics { logloss:0.9792,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9813,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9622,  }]\n",
      "Training on Total Epoch: 285, Round: 285\n",
      "Evalset: [Train : Metrics { logloss:0.9749,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9774,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9579,  }]\n",
      "Training on Total Epoch: 286, Round: 286\n",
      "Evalset: [Train : Metrics { logloss:0.9707,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9735,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9537,  }]\n",
      "Training on Total Epoch: 287, Round: 287\n",
      "Evalset: [Train : Metrics { logloss:0.9664,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9694,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9495,  }]\n",
      "Training on Total Epoch: 288, Round: 288\n",
      "Evalset: [Train : Metrics { logloss:0.9622,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9651,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9452,  }]\n",
      "Training on Total Epoch: 289, Round: 289\n",
      "Evalset: [Train : Metrics { logloss:0.958,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.961,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.941,  }]\n",
      "Training on Total Epoch: 290, Round: 290\n",
      "Evalset: [Train : Metrics { logloss:0.9537,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9567,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9368,  }]\n",
      "Training on Total Epoch: 291, Round: 291\n",
      "Evalset: [Train : Metrics { logloss:0.9495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9526,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9326,  }]\n",
      "Training on Total Epoch: 292, Round: 292\n",
      "Evalset: [Train : Metrics { logloss:0.9452,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9483,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9284,  }]\n",
      "Training on Total Epoch: 293, Round: 293\n",
      "Evalset: [Train : Metrics { logloss:0.941,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9443,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9242,  }]\n",
      "Training on Total Epoch: 294, Round: 294\n",
      "Evalset: [Train : Metrics { logloss:0.9369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9402,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9201,  }]\n",
      "Training on Total Epoch: 295, Round: 295\n",
      "Evalset: [Train : Metrics { logloss:0.9329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9362,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.916,  }]\n",
      "Training on Total Epoch: 296, Round: 296\n",
      "Evalset: [Train : Metrics { logloss:0.9288,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9119,  }]\n",
      "Training on Total Epoch: 297, Round: 297\n",
      "Evalset: [Train : Metrics { logloss:0.9248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9079,  }]\n",
      "Training on Total Epoch: 298, Round: 298\n",
      "Evalset: [Train : Metrics { logloss:0.9208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.924,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9039,  }]\n",
      "Training on Total Epoch: 299, Round: 299\n",
      "Evalset: [Train : Metrics { logloss:0.9168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.92,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.9,  }]\n",
      "Training on Total Epoch: 300, Round: 300\n",
      "Evalset: [Train : Metrics { logloss:0.9129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8961,  }]\n",
      "Training on Total Epoch: 301, Round: 301\n",
      "Evalset: [Train : Metrics { logloss:0.9089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8922,  }]\n",
      "Training on Total Epoch: 302, Round: 302\n",
      "Evalset: [Train : Metrics { logloss:0.905,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9087,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8882,  }]\n",
      "Training on Total Epoch: 303, Round: 303\n",
      "Evalset: [Train : Metrics { logloss:0.9011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9054,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8844,  }]\n",
      "Training on Total Epoch: 304, Round: 304\n",
      "Evalset: [Train : Metrics { logloss:0.8973,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.9019,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8805,  }]\n",
      "Training on Total Epoch: 305, Round: 305\n",
      "Evalset: [Train : Metrics { logloss:0.8934,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8983,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8767,  }]\n",
      "Training on Total Epoch: 306, Round: 306\n",
      "Evalset: [Train : Metrics { logloss:0.8896,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8946,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8729,  }]\n",
      "Training on Total Epoch: 307, Round: 307\n",
      "Evalset: [Train : Metrics { logloss:0.8857,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8691,  }]\n",
      "Training on Total Epoch: 308, Round: 308\n",
      "Evalset: [Train : Metrics { logloss:0.8819,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8865,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8653,  }]\n",
      "Training on Total Epoch: 309, Round: 309\n",
      "Evalset: [Train : Metrics { logloss:0.8782,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8829,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8615,  }]\n",
      "Training on Total Epoch: 310, Round: 310\n",
      "Evalset: [Train : Metrics { logloss:0.8744,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8793,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8579,  }]\n",
      "Training on Total Epoch: 311, Round: 311\n",
      "Evalset: [Train : Metrics { logloss:0.8708,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8759,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8543,  }]\n",
      "Training on Total Epoch: 312, Round: 312\n",
      "Evalset: [Train : Metrics { logloss:0.8672,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8725,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8507,  }]\n",
      "Training on Total Epoch: 313, Round: 313\n",
      "Evalset: [Train : Metrics { logloss:0.8636,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8691,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8471,  }]\n",
      "Training on Total Epoch: 314, Round: 314\n",
      "Evalset: [Train : Metrics { logloss:0.86,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8657,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8436,  }]\n",
      "Training on Total Epoch: 315, Round: 315\n",
      "Evalset: [Train : Metrics { logloss:0.8564,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8621,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.84,  }]\n",
      "Training on Total Epoch: 316, Round: 316\n",
      "Evalset: [Train : Metrics { logloss:0.8527,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8364,  }]\n",
      "Training on Total Epoch: 317, Round: 317\n",
      "Evalset: [Train : Metrics { logloss:0.8491,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8551,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.833,  }]\n",
      "Training on Total Epoch: 318, Round: 318\n",
      "Evalset: [Train : Metrics { logloss:0.8456,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8515,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8295,  }]\n",
      "Training on Total Epoch: 319, Round: 319\n",
      "Evalset: [Train : Metrics { logloss:0.842,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8479,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.826,  }]\n",
      "Training on Total Epoch: 320, Round: 320\n",
      "Evalset: [Train : Metrics { logloss:0.8385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8444,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8224,  }]\n",
      "Training on Total Epoch: 321, Round: 321\n",
      "Evalset: [Train : Metrics { logloss:0.835,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.841,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.819,  }]\n",
      "Training on Total Epoch: 322, Round: 322\n",
      "Evalset: [Train : Metrics { logloss:0.8316,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8378,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8156,  }]\n",
      "Training on Total Epoch: 323, Round: 323\n",
      "Evalset: [Train : Metrics { logloss:0.8282,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8346,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8121,  }]\n",
      "Training on Total Epoch: 324, Round: 324\n",
      "Evalset: [Train : Metrics { logloss:0.8248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8087,  }]\n",
      "Training on Total Epoch: 325, Round: 325\n",
      "Evalset: [Train : Metrics { logloss:0.8214,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8054,  }]\n",
      "Training on Total Epoch: 326, Round: 326\n",
      "Evalset: [Train : Metrics { logloss:0.818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.8021,  }]\n",
      "Training on Total Epoch: 327, Round: 327\n",
      "Evalset: [Train : Metrics { logloss:0.8146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7987,  }]\n",
      "Training on Total Epoch: 328, Round: 328\n",
      "Evalset: [Train : Metrics { logloss:0.8111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8181,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7953,  }]\n",
      "Training on Total Epoch: 329, Round: 329\n",
      "Evalset: [Train : Metrics { logloss:0.8077,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.792,  }]\n",
      "Training on Total Epoch: 330, Round: 330\n",
      "Evalset: [Train : Metrics { logloss:0.8044,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8116,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7888,  }]\n",
      "Training on Total Epoch: 331, Round: 331\n",
      "Evalset: [Train : Metrics { logloss:0.8011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8084,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7856,  }]\n",
      "Training on Total Epoch: 332, Round: 332\n",
      "Evalset: [Train : Metrics { logloss:0.7978,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8052,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7823,  }]\n",
      "Training on Total Epoch: 333, Round: 333\n",
      "Evalset: [Train : Metrics { logloss:0.7945,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.8021,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7791,  }]\n",
      "Training on Total Epoch: 334, Round: 334\n",
      "Evalset: [Train : Metrics { logloss:0.7913,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7991,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7759,  }]\n",
      "Training on Total Epoch: 335, Round: 335\n",
      "Evalset: [Train : Metrics { logloss:0.788,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7959,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7727,  }]\n",
      "Training on Total Epoch: 336, Round: 336\n",
      "Evalset: [Train : Metrics { logloss:0.7848,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7929,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7695,  }]\n",
      "Training on Total Epoch: 337, Round: 337\n",
      "Evalset: [Train : Metrics { logloss:0.7816,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7899,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7663,  }]\n",
      "Training on Total Epoch: 338, Round: 338\n",
      "Evalset: [Train : Metrics { logloss:0.7784,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7868,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7632,  }]\n",
      "Training on Total Epoch: 339, Round: 339\n",
      "Evalset: [Train : Metrics { logloss:0.7753,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7836,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7601,  }]\n",
      "Training on Total Epoch: 340, Round: 340\n",
      "Evalset: [Train : Metrics { logloss:0.7722,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7805,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.757,  }]\n",
      "Training on Total Epoch: 341, Round: 341\n",
      "Evalset: [Train : Metrics { logloss:0.769,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7773,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7539,  }]\n",
      "Training on Total Epoch: 342, Round: 342\n",
      "Evalset: [Train : Metrics { logloss:0.7659,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7741,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7508,  }]\n",
      "Training on Total Epoch: 343, Round: 343\n",
      "Evalset: [Train : Metrics { logloss:0.7627,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7708,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7476,  }]\n",
      "Training on Total Epoch: 344, Round: 344\n",
      "Evalset: [Train : Metrics { logloss:0.7596,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7676,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7445,  }]\n",
      "Training on Total Epoch: 345, Round: 345\n",
      "Evalset: [Train : Metrics { logloss:0.7565,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7647,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7415,  }]\n",
      "Training on Total Epoch: 346, Round: 346\n",
      "Evalset: [Train : Metrics { logloss:0.7535,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.762,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7386,  }]\n",
      "Training on Total Epoch: 347, Round: 347\n",
      "Evalset: [Train : Metrics { logloss:0.7504,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7589,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7356,  }]\n",
      "Training on Total Epoch: 348, Round: 348\n",
      "Evalset: [Train : Metrics { logloss:0.7473,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7561,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7326,  }]\n",
      "Training on Total Epoch: 349, Round: 349\n",
      "Evalset: [Train : Metrics { logloss:0.7442,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7533,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7296,  }]\n",
      "Training on Total Epoch: 350, Round: 350\n",
      "Evalset: [Train : Metrics { logloss:0.7412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7503,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7266,  }]\n",
      "Training on Total Epoch: 351, Round: 351\n",
      "Evalset: [Train : Metrics { logloss:0.7382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7474,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7237,  }]\n",
      "Training on Total Epoch: 352, Round: 352\n",
      "Evalset: [Train : Metrics { logloss:0.7352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7446,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7206,  }]\n",
      "Training on Total Epoch: 353, Round: 353\n",
      "Evalset: [Train : Metrics { logloss:0.7322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7417,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7177,  }]\n",
      "Training on Total Epoch: 354, Round: 354\n",
      "Evalset: [Train : Metrics { logloss:0.7292,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7388,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7147,  }]\n",
      "Training on Total Epoch: 355, Round: 355\n",
      "Evalset: [Train : Metrics { logloss:0.7262,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7118,  }]\n",
      "Training on Total Epoch: 356, Round: 356\n",
      "Evalset: [Train : Metrics { logloss:0.7233,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.733,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7089,  }]\n",
      "Training on Total Epoch: 357, Round: 357\n",
      "Evalset: [Train : Metrics { logloss:0.7204,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.706,  }]\n",
      "Training on Total Epoch: 358, Round: 358\n",
      "Evalset: [Train : Metrics { logloss:0.7174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7032,  }]\n",
      "Training on Total Epoch: 359, Round: 359\n",
      "Evalset: [Train : Metrics { logloss:0.7145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.7003,  }]\n",
      "Training on Total Epoch: 360, Round: 360\n",
      "Evalset: [Train : Metrics { logloss:0.7115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6975,  }]\n",
      "Training on Total Epoch: 361, Round: 361\n",
      "Evalset: [Train : Metrics { logloss:0.7087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7187,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6946,  }]\n",
      "Training on Total Epoch: 362, Round: 362\n",
      "Evalset: [Train : Metrics { logloss:0.7058,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7159,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6918,  }]\n",
      "Training on Total Epoch: 363, Round: 363\n",
      "Evalset: [Train : Metrics { logloss:0.7029,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6889,  }]\n",
      "Training on Total Epoch: 364, Round: 364\n",
      "Evalset: [Train : Metrics { logloss:0.7,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7104,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.686,  }]\n",
      "Training on Total Epoch: 365, Round: 365\n",
      "Evalset: [Train : Metrics { logloss:0.6971,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7078,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6833,  }]\n",
      "Training on Total Epoch: 366, Round: 366\n",
      "Evalset: [Train : Metrics { logloss:0.6942,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7053,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6805,  }]\n",
      "Training on Total Epoch: 367, Round: 367\n",
      "Evalset: [Train : Metrics { logloss:0.6914,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7027,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6778,  }]\n",
      "Training on Total Epoch: 368, Round: 368\n",
      "Evalset: [Train : Metrics { logloss:0.6886,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.7001,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6751,  }]\n",
      "Training on Total Epoch: 369, Round: 369\n",
      "Evalset: [Train : Metrics { logloss:0.6858,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6973,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6724,  }]\n",
      "Training on Total Epoch: 370, Round: 370\n",
      "Evalset: [Train : Metrics { logloss:0.683,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6947,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6696,  }]\n",
      "Training on Total Epoch: 371, Round: 371\n",
      "Evalset: [Train : Metrics { logloss:0.6802,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.692,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6668,  }]\n",
      "Training on Total Epoch: 372, Round: 372\n",
      "Evalset: [Train : Metrics { logloss:0.6774,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6641,  }]\n",
      "Training on Total Epoch: 373, Round: 373\n",
      "Evalset: [Train : Metrics { logloss:0.6746,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6864,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6613,  }]\n",
      "Training on Total Epoch: 374, Round: 374\n",
      "Evalset: [Train : Metrics { logloss:0.6718,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6837,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6586,  }]\n",
      "Training on Total Epoch: 375, Round: 375\n",
      "Evalset: [Train : Metrics { logloss:0.6691,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6811,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6559,  }]\n",
      "Training on Total Epoch: 376, Round: 376\n",
      "Evalset: [Train : Metrics { logloss:0.6663,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6783,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6531,  }]\n",
      "Training on Total Epoch: 377, Round: 377\n",
      "Evalset: [Train : Metrics { logloss:0.6635,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6755,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6504,  }]\n",
      "Training on Total Epoch: 378, Round: 378\n",
      "Evalset: [Train : Metrics { logloss:0.6608,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6727,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6478,  }]\n",
      "Training on Total Epoch: 379, Round: 379\n",
      "Evalset: [Train : Metrics { logloss:0.6581,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6702,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6451,  }]\n",
      "Training on Total Epoch: 380, Round: 380\n",
      "Evalset: [Train : Metrics { logloss:0.6555,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6677,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6425,  }]\n",
      "Training on Total Epoch: 381, Round: 381\n",
      "Evalset: [Train : Metrics { logloss:0.6528,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6652,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.64,  }]\n",
      "Training on Total Epoch: 382, Round: 382\n",
      "Evalset: [Train : Metrics { logloss:0.6502,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6628,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6375,  }]\n",
      "Training on Total Epoch: 383, Round: 383\n",
      "Evalset: [Train : Metrics { logloss:0.6476,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6603,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.635,  }]\n",
      "Training on Total Epoch: 384, Round: 384\n",
      "Evalset: [Train : Metrics { logloss:0.6451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6578,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6324,  }]\n",
      "Training on Total Epoch: 385, Round: 385\n",
      "Evalset: [Train : Metrics { logloss:0.6425,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6553,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6299,  }]\n",
      "Training on Total Epoch: 386, Round: 386\n",
      "Evalset: [Train : Metrics { logloss:0.6399,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6529,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6274,  }]\n",
      "Training on Total Epoch: 387, Round: 387\n",
      "Evalset: [Train : Metrics { logloss:0.6375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6249,  }]\n",
      "Training on Total Epoch: 388, Round: 388\n",
      "Evalset: [Train : Metrics { logloss:0.6349,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6479,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6223,  }]\n",
      "Training on Total Epoch: 389, Round: 389\n",
      "Evalset: [Train : Metrics { logloss:0.6323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6198,  }]\n",
      "Training on Total Epoch: 390, Round: 390\n",
      "Evalset: [Train : Metrics { logloss:0.6297,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6428,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6174,  }]\n",
      "Training on Total Epoch: 391, Round: 391\n",
      "Evalset: [Train : Metrics { logloss:0.6272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6404,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.615,  }]\n",
      "Training on Total Epoch: 392, Round: 392\n",
      "Evalset: [Train : Metrics { logloss:0.6247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.638,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6127,  }]\n",
      "Training on Total Epoch: 393, Round: 393\n",
      "Evalset: [Train : Metrics { logloss:0.6223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6104,  }]\n",
      "Training on Total Epoch: 394, Round: 394\n",
      "Evalset: [Train : Metrics { logloss:0.6199,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.608,  }]\n",
      "Training on Total Epoch: 395, Round: 395\n",
      "Evalset: [Train : Metrics { logloss:0.6175,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6056,  }]\n",
      "Training on Total Epoch: 396, Round: 396\n",
      "Evalset: [Train : Metrics { logloss:0.6151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6032,  }]\n",
      "Training on Total Epoch: 397, Round: 397\n",
      "Evalset: [Train : Metrics { logloss:0.6127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.6008,  }]\n",
      "Training on Total Epoch: 398, Round: 398\n",
      "Evalset: [Train : Metrics { logloss:0.6102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5984,  }]\n",
      "Training on Total Epoch: 399, Round: 399\n",
      "Evalset: [Train : Metrics { logloss:0.6077,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5961,  }]\n",
      "Training on Total Epoch: 400, Round: 400\n",
      "Evalset: [Train : Metrics { logloss:0.6053,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5938,  }]\n",
      "Training on Total Epoch: 401, Round: 401\n",
      "Evalset: [Train : Metrics { logloss:0.603,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.617,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5915,  }]\n",
      "Training on Total Epoch: 402, Round: 402\n",
      "Evalset: [Train : Metrics { logloss:0.6006,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6147,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5892,  }]\n",
      "Training on Total Epoch: 403, Round: 403\n",
      "Evalset: [Train : Metrics { logloss:0.5982,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5869,  }]\n",
      "Training on Total Epoch: 404, Round: 404\n",
      "Evalset: [Train : Metrics { logloss:0.5958,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6102,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5847,  }]\n",
      "Training on Total Epoch: 405, Round: 405\n",
      "Evalset: [Train : Metrics { logloss:0.5935,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6079,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5824,  }]\n",
      "Training on Total Epoch: 406, Round: 406\n",
      "Evalset: [Train : Metrics { logloss:0.5911,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6057,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5801,  }]\n",
      "Training on Total Epoch: 407, Round: 407\n",
      "Evalset: [Train : Metrics { logloss:0.5888,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6036,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5778,  }]\n",
      "Training on Total Epoch: 408, Round: 408\n",
      "Evalset: [Train : Metrics { logloss:0.5865,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.6016,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5756,  }]\n",
      "Training on Total Epoch: 409, Round: 409\n",
      "Evalset: [Train : Metrics { logloss:0.5843,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5995,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5734,  }]\n",
      "Training on Total Epoch: 410, Round: 410\n",
      "Evalset: [Train : Metrics { logloss:0.582,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5972,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5712,  }]\n",
      "Training on Total Epoch: 411, Round: 411\n",
      "Evalset: [Train : Metrics { logloss:0.5797,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5949,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.569,  }]\n",
      "Training on Total Epoch: 412, Round: 412\n",
      "Evalset: [Train : Metrics { logloss:0.5775,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5928,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5668,  }]\n",
      "Training on Total Epoch: 413, Round: 413\n",
      "Evalset: [Train : Metrics { logloss:0.5752,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5646,  }]\n",
      "Training on Total Epoch: 414, Round: 414\n",
      "Evalset: [Train : Metrics { logloss:0.5729,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5625,  }]\n",
      "Training on Total Epoch: 415, Round: 415\n",
      "Evalset: [Train : Metrics { logloss:0.5707,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5864,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5603,  }]\n",
      "Training on Total Epoch: 416, Round: 416\n",
      "Evalset: [Train : Metrics { logloss:0.5685,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5844,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5581,  }]\n",
      "Training on Total Epoch: 417, Round: 417\n",
      "Evalset: [Train : Metrics { logloss:0.5663,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5822,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5559,  }]\n",
      "Training on Total Epoch: 418, Round: 418\n",
      "Evalset: [Train : Metrics { logloss:0.5641,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5799,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5538,  }]\n",
      "Training on Total Epoch: 419, Round: 419\n",
      "Evalset: [Train : Metrics { logloss:0.5619,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5778,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5518,  }]\n",
      "Training on Total Epoch: 420, Round: 420\n",
      "Evalset: [Train : Metrics { logloss:0.5598,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5758,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5497,  }]\n",
      "Training on Total Epoch: 421, Round: 421\n",
      "Evalset: [Train : Metrics { logloss:0.5577,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5736,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5477,  }]\n",
      "Training on Total Epoch: 422, Round: 422\n",
      "Evalset: [Train : Metrics { logloss:0.5556,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5457,  }]\n",
      "Training on Total Epoch: 423, Round: 423\n",
      "Evalset: [Train : Metrics { logloss:0.5536,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5696,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5437,  }]\n",
      "Training on Total Epoch: 424, Round: 424\n",
      "Evalset: [Train : Metrics { logloss:0.5515,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5678,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5417,  }]\n",
      "Training on Total Epoch: 425, Round: 425\n",
      "Evalset: [Train : Metrics { logloss:0.5495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5662,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5397,  }]\n",
      "Training on Total Epoch: 426, Round: 426\n",
      "Evalset: [Train : Metrics { logloss:0.5475,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5643,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5377,  }]\n",
      "Training on Total Epoch: 427, Round: 427\n",
      "Evalset: [Train : Metrics { logloss:0.5454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5623,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5357,  }]\n",
      "Training on Total Epoch: 428, Round: 428\n",
      "Evalset: [Train : Metrics { logloss:0.5433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5603,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5337,  }]\n",
      "Training on Total Epoch: 429, Round: 429\n",
      "Evalset: [Train : Metrics { logloss:0.5412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5317,  }]\n",
      "Training on Total Epoch: 430, Round: 430\n",
      "Evalset: [Train : Metrics { logloss:0.5391,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5567,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5297,  }]\n",
      "Training on Total Epoch: 431, Round: 431\n",
      "Evalset: [Train : Metrics { logloss:0.537,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5547,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5277,  }]\n",
      "Training on Total Epoch: 432, Round: 432\n",
      "Evalset: [Train : Metrics { logloss:0.535,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5527,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5256,  }]\n",
      "Training on Total Epoch: 433, Round: 433\n",
      "Evalset: [Train : Metrics { logloss:0.533,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5507,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5237,  }]\n",
      "Training on Total Epoch: 434, Round: 434\n",
      "Evalset: [Train : Metrics { logloss:0.531,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5486,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5217,  }]\n",
      "Training on Total Epoch: 435, Round: 435\n",
      "Evalset: [Train : Metrics { logloss:0.529,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5464,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5198,  }]\n",
      "Training on Total Epoch: 436, Round: 436\n",
      "Evalset: [Train : Metrics { logloss:0.527,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5441,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5179,  }]\n",
      "Training on Total Epoch: 437, Round: 437\n",
      "Evalset: [Train : Metrics { logloss:0.5251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.542,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.516,  }]\n",
      "Training on Total Epoch: 438, Round: 438\n",
      "Evalset: [Train : Metrics { logloss:0.5231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5401,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5141,  }]\n",
      "Training on Total Epoch: 439, Round: 439\n",
      "Evalset: [Train : Metrics { logloss:0.521,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5122,  }]\n",
      "Training on Total Epoch: 440, Round: 440\n",
      "Evalset: [Train : Metrics { logloss:0.5191,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5368,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5104,  }]\n",
      "Training on Total Epoch: 441, Round: 441\n",
      "Evalset: [Train : Metrics { logloss:0.5171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5085,  }]\n",
      "Training on Total Epoch: 442, Round: 442\n",
      "Evalset: [Train : Metrics { logloss:0.5151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5066,  }]\n",
      "Training on Total Epoch: 443, Round: 443\n",
      "Evalset: [Train : Metrics { logloss:0.5132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5048,  }]\n",
      "Training on Total Epoch: 444, Round: 444\n",
      "Evalset: [Train : Metrics { logloss:0.5113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.5029,  }]\n",
      "Training on Total Epoch: 445, Round: 445\n",
      "Evalset: [Train : Metrics { logloss:0.5093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.501,  }]\n",
      "Training on Total Epoch: 446, Round: 446\n",
      "Evalset: [Train : Metrics { logloss:0.5074,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4991,  }]\n",
      "Training on Total Epoch: 447, Round: 447\n",
      "Evalset: [Train : Metrics { logloss:0.5055,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4971,  }]\n",
      "Training on Total Epoch: 448, Round: 448\n",
      "Evalset: [Train : Metrics { logloss:0.5037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4952,  }]\n",
      "Training on Total Epoch: 449, Round: 449\n",
      "Evalset: [Train : Metrics { logloss:0.5018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5202,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4934,  }]\n",
      "Training on Total Epoch: 450, Round: 450\n",
      "Evalset: [Train : Metrics { logloss:0.4999,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5188,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4916,  }]\n",
      "Training on Total Epoch: 451, Round: 451\n",
      "Evalset: [Train : Metrics { logloss:0.4981,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4899,  }]\n",
      "Training on Total Epoch: 452, Round: 452\n",
      "Evalset: [Train : Metrics { logloss:0.4963,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4883,  }]\n",
      "Training on Total Epoch: 453, Round: 453\n",
      "Evalset: [Train : Metrics { logloss:0.4944,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4866,  }]\n",
      "Training on Total Epoch: 454, Round: 454\n",
      "Evalset: [Train : Metrics { logloss:0.4925,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.513,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4849,  }]\n",
      "Training on Total Epoch: 455, Round: 455\n",
      "Evalset: [Train : Metrics { logloss:0.4906,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5109,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4831,  }]\n",
      "Training on Total Epoch: 456, Round: 456\n",
      "Evalset: [Train : Metrics { logloss:0.4887,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5086,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4813,  }]\n",
      "Training on Total Epoch: 457, Round: 457\n",
      "Evalset: [Train : Metrics { logloss:0.4869,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5067,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4795,  }]\n",
      "Training on Total Epoch: 458, Round: 458\n",
      "Evalset: [Train : Metrics { logloss:0.4851,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.505,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4778,  }]\n",
      "Training on Total Epoch: 459, Round: 459\n",
      "Evalset: [Train : Metrics { logloss:0.4833,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5032,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4762,  }]\n",
      "Training on Total Epoch: 460, Round: 460\n",
      "Evalset: [Train : Metrics { logloss:0.4815,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.5014,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4745,  }]\n",
      "Training on Total Epoch: 461, Round: 461\n",
      "Evalset: [Train : Metrics { logloss:0.4798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4996,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4728,  }]\n",
      "Training on Total Epoch: 462, Round: 462\n",
      "Evalset: [Train : Metrics { logloss:0.478,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4979,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4711,  }]\n",
      "Training on Total Epoch: 463, Round: 463\n",
      "Evalset: [Train : Metrics { logloss:0.4763,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4963,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4693,  }]\n",
      "Training on Total Epoch: 464, Round: 464\n",
      "Evalset: [Train : Metrics { logloss:0.4746,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4948,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4676,  }]\n",
      "Training on Total Epoch: 465, Round: 465\n",
      "Evalset: [Train : Metrics { logloss:0.4729,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4933,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.466,  }]\n",
      "Training on Total Epoch: 466, Round: 466\n",
      "Evalset: [Train : Metrics { logloss:0.4712,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4644,  }]\n",
      "Training on Total Epoch: 467, Round: 467\n",
      "Evalset: [Train : Metrics { logloss:0.4696,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4902,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4628,  }]\n",
      "Training on Total Epoch: 468, Round: 468\n",
      "Evalset: [Train : Metrics { logloss:0.4679,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4613,  }]\n",
      "Training on Total Epoch: 469, Round: 469\n",
      "Evalset: [Train : Metrics { logloss:0.4662,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4871,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4597,  }]\n",
      "Training on Total Epoch: 470, Round: 470\n",
      "Evalset: [Train : Metrics { logloss:0.4646,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4855,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4583,  }]\n",
      "Training on Total Epoch: 471, Round: 471\n",
      "Evalset: [Train : Metrics { logloss:0.4629,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4839,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4567,  }]\n",
      "Training on Total Epoch: 472, Round: 472\n",
      "Evalset: [Train : Metrics { logloss:0.4612,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4822,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4551,  }]\n",
      "Training on Total Epoch: 473, Round: 473\n",
      "Evalset: [Train : Metrics { logloss:0.4596,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4806,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4535,  }]\n",
      "Training on Total Epoch: 474, Round: 474\n",
      "Evalset: [Train : Metrics { logloss:0.4579,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4789,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4519,  }]\n",
      "Training on Total Epoch: 475, Round: 475\n",
      "Evalset: [Train : Metrics { logloss:0.4563,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4771,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4503,  }]\n",
      "Training on Total Epoch: 476, Round: 476\n",
      "Evalset: [Train : Metrics { logloss:0.4546,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4754,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4486,  }]\n",
      "Training on Total Epoch: 477, Round: 477\n",
      "Evalset: [Train : Metrics { logloss:0.4529,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4739,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.447,  }]\n",
      "Training on Total Epoch: 478, Round: 478\n",
      "Evalset: [Train : Metrics { logloss:0.4513,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4726,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4455,  }]\n",
      "Training on Total Epoch: 479, Round: 479\n",
      "Evalset: [Train : Metrics { logloss:0.4497,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4713,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.444,  }]\n",
      "Training on Total Epoch: 480, Round: 480\n",
      "Evalset: [Train : Metrics { logloss:0.4481,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4699,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4425,  }]\n",
      "Training on Total Epoch: 481, Round: 481\n",
      "Evalset: [Train : Metrics { logloss:0.4465,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4685,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4409,  }]\n",
      "Training on Total Epoch: 482, Round: 482\n",
      "Evalset: [Train : Metrics { logloss:0.4449,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.467,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4394,  }]\n",
      "Training on Total Epoch: 483, Round: 483\n",
      "Evalset: [Train : Metrics { logloss:0.4433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4654,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4377,  }]\n",
      "Training on Total Epoch: 484, Round: 484\n",
      "Evalset: [Train : Metrics { logloss:0.4418,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4637,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4362,  }]\n",
      "Training on Total Epoch: 485, Round: 485\n",
      "Evalset: [Train : Metrics { logloss:0.4402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4621,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4347,  }]\n",
      "Training on Total Epoch: 486, Round: 486\n",
      "Evalset: [Train : Metrics { logloss:0.4387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4605,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4332,  }]\n",
      "Training on Total Epoch: 487, Round: 487\n",
      "Evalset: [Train : Metrics { logloss:0.4372,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4591,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4317,  }]\n",
      "Training on Total Epoch: 488, Round: 488\n",
      "Evalset: [Train : Metrics { logloss:0.4357,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4573,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4302,  }]\n",
      "Training on Total Epoch: 489, Round: 489\n",
      "Evalset: [Train : Metrics { logloss:0.4342,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4554,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4286,  }]\n",
      "Training on Total Epoch: 490, Round: 490\n",
      "Evalset: [Train : Metrics { logloss:0.4328,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4539,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4272,  }]\n",
      "Training on Total Epoch: 491, Round: 491\n",
      "Evalset: [Train : Metrics { logloss:0.4313,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4526,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4258,  }]\n",
      "Training on Total Epoch: 492, Round: 492\n",
      "Evalset: [Train : Metrics { logloss:0.4298,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4512,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4244,  }]\n",
      "Training on Total Epoch: 493, Round: 493\n",
      "Evalset: [Train : Metrics { logloss:0.4283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4231,  }]\n",
      "Training on Total Epoch: 494, Round: 494\n",
      "Evalset: [Train : Metrics { logloss:0.4267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4485,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4217,  }]\n",
      "Training on Total Epoch: 495, Round: 495\n",
      "Evalset: [Train : Metrics { logloss:0.4252,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4471,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4203,  }]\n",
      "Training on Total Epoch: 496, Round: 496\n",
      "Evalset: [Train : Metrics { logloss:0.4237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4457,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4188,  }]\n",
      "Training on Total Epoch: 497, Round: 497\n",
      "Evalset: [Train : Metrics { logloss:0.4222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4444,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4175,  }]\n",
      "Training on Total Epoch: 498, Round: 498\n",
      "Evalset: [Train : Metrics { logloss:0.4208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4432,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4162,  }]\n",
      "Training on Total Epoch: 499, Round: 499\n",
      "Evalset: [Train : Metrics { logloss:0.4193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.442,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4148,  }]\n",
      "Training on Total Epoch: 500, Round: 500\n",
      "Evalset: [Train : Metrics { logloss:0.4179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4407,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4134,  }]\n",
      "Training on Total Epoch: 501, Round: 501\n",
      "Evalset: [Train : Metrics { logloss:0.4164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4395,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.412,  }]\n",
      "Training on Total Epoch: 502, Round: 502\n",
      "Evalset: [Train : Metrics { logloss:0.415,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.438,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4106,  }]\n",
      "Training on Total Epoch: 503, Round: 503\n",
      "Evalset: [Train : Metrics { logloss:0.4136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4364,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4092,  }]\n",
      "Training on Total Epoch: 504, Round: 504\n",
      "Evalset: [Train : Metrics { logloss:0.4121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4078,  }]\n",
      "Training on Total Epoch: 505, Round: 505\n",
      "Evalset: [Train : Metrics { logloss:0.4107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4063,  }]\n",
      "Training on Total Epoch: 506, Round: 506\n",
      "Evalset: [Train : Metrics { logloss:0.4093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.405,  }]\n",
      "Training on Total Epoch: 507, Round: 507\n",
      "Evalset: [Train : Metrics { logloss:0.4079,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4037,  }]\n",
      "Training on Total Epoch: 508, Round: 508\n",
      "Evalset: [Train : Metrics { logloss:0.4066,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4024,  }]\n",
      "Training on Total Epoch: 509, Round: 509\n",
      "Evalset: [Train : Metrics { logloss:0.4052,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4281,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.4012,  }]\n",
      "Training on Total Epoch: 510, Round: 510\n",
      "Evalset: [Train : Metrics { logloss:0.4039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3999,  }]\n",
      "Training on Total Epoch: 511, Round: 511\n",
      "Evalset: [Train : Metrics { logloss:0.4025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3987,  }]\n",
      "Training on Total Epoch: 512, Round: 512\n",
      "Evalset: [Train : Metrics { logloss:0.4012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3975,  }]\n",
      "Training on Total Epoch: 513, Round: 513\n",
      "Evalset: [Train : Metrics { logloss:0.3998,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3962,  }]\n",
      "Training on Total Epoch: 514, Round: 514\n",
      "Evalset: [Train : Metrics { logloss:0.3985,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.395,  }]\n",
      "Training on Total Epoch: 515, Round: 515\n",
      "Evalset: [Train : Metrics { logloss:0.3972,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.421,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3938,  }]\n",
      "Training on Total Epoch: 516, Round: 516\n",
      "Evalset: [Train : Metrics { logloss:0.3958,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4198,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3926,  }]\n",
      "Training on Total Epoch: 517, Round: 517\n",
      "Evalset: [Train : Metrics { logloss:0.3945,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3914,  }]\n",
      "Training on Total Epoch: 518, Round: 518\n",
      "Evalset: [Train : Metrics { logloss:0.3933,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.417,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3901,  }]\n",
      "Training on Total Epoch: 519, Round: 519\n",
      "Evalset: [Train : Metrics { logloss:0.392,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4157,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3889,  }]\n",
      "Training on Total Epoch: 520, Round: 520\n",
      "Evalset: [Train : Metrics { logloss:0.3907,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4146,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3877,  }]\n",
      "Training on Total Epoch: 521, Round: 521\n",
      "Evalset: [Train : Metrics { logloss:0.3894,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4134,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3865,  }]\n",
      "Training on Total Epoch: 522, Round: 522\n",
      "Evalset: [Train : Metrics { logloss:0.3881,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3852,  }]\n",
      "Training on Total Epoch: 523, Round: 523\n",
      "Evalset: [Train : Metrics { logloss:0.3869,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4113,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.384,  }]\n",
      "Training on Total Epoch: 524, Round: 524\n",
      "Evalset: [Train : Metrics { logloss:0.3856,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4102,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3828,  }]\n",
      "Training on Total Epoch: 525, Round: 525\n",
      "Evalset: [Train : Metrics { logloss:0.3843,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3815,  }]\n",
      "Training on Total Epoch: 526, Round: 526\n",
      "Evalset: [Train : Metrics { logloss:0.383,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4078,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3803,  }]\n",
      "Training on Total Epoch: 527, Round: 527\n",
      "Evalset: [Train : Metrics { logloss:0.3818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4067,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3792,  }]\n",
      "Training on Total Epoch: 528, Round: 528\n",
      "Evalset: [Train : Metrics { logloss:0.3806,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4056,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.378,  }]\n",
      "Training on Total Epoch: 529, Round: 529\n",
      "Evalset: [Train : Metrics { logloss:0.3793,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4044,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3769,  }]\n",
      "Training on Total Epoch: 530, Round: 530\n",
      "Evalset: [Train : Metrics { logloss:0.3781,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4032,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3758,  }]\n",
      "Training on Total Epoch: 531, Round: 531\n",
      "Evalset: [Train : Metrics { logloss:0.3769,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4021,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3748,  }]\n",
      "Training on Total Epoch: 532, Round: 532\n",
      "Evalset: [Train : Metrics { logloss:0.3757,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.4009,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3738,  }]\n",
      "Training on Total Epoch: 533, Round: 533\n",
      "Evalset: [Train : Metrics { logloss:0.3745,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3997,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3726,  }]\n",
      "Training on Total Epoch: 534, Round: 534\n",
      "Evalset: [Train : Metrics { logloss:0.3733,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3985,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3714,  }]\n",
      "Training on Total Epoch: 535, Round: 535\n",
      "Evalset: [Train : Metrics { logloss:0.372,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3972,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3702,  }]\n",
      "Training on Total Epoch: 536, Round: 536\n",
      "Evalset: [Train : Metrics { logloss:0.3708,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3961,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.369,  }]\n",
      "Training on Total Epoch: 537, Round: 537\n",
      "Evalset: [Train : Metrics { logloss:0.3695,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3949,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3679,  }]\n",
      "Training on Total Epoch: 538, Round: 538\n",
      "Evalset: [Train : Metrics { logloss:0.3683,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3936,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3667,  }]\n",
      "Training on Total Epoch: 539, Round: 539\n",
      "Evalset: [Train : Metrics { logloss:0.3671,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3923,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3655,  }]\n",
      "Training on Total Epoch: 540, Round: 540\n",
      "Evalset: [Train : Metrics { logloss:0.3659,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.391,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3643,  }]\n",
      "Training on Total Epoch: 541, Round: 541\n",
      "Evalset: [Train : Metrics { logloss:0.3647,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.363,  }]\n",
      "Training on Total Epoch: 542, Round: 542\n",
      "Evalset: [Train : Metrics { logloss:0.3635,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3619,  }]\n",
      "Training on Total Epoch: 543, Round: 543\n",
      "Evalset: [Train : Metrics { logloss:0.3623,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3608,  }]\n",
      "Training on Total Epoch: 544, Round: 544\n",
      "Evalset: [Train : Metrics { logloss:0.3611,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.387,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3597,  }]\n",
      "Training on Total Epoch: 545, Round: 545\n",
      "Evalset: [Train : Metrics { logloss:0.3599,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3862,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3587,  }]\n",
      "Training on Total Epoch: 546, Round: 546\n",
      "Evalset: [Train : Metrics { logloss:0.3587,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3853,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3575,  }]\n",
      "Training on Total Epoch: 547, Round: 547\n",
      "Evalset: [Train : Metrics { logloss:0.3576,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3843,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3564,  }]\n",
      "Training on Total Epoch: 548, Round: 548\n",
      "Evalset: [Train : Metrics { logloss:0.3565,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3833,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3553,  }]\n",
      "Training on Total Epoch: 549, Round: 549\n",
      "Evalset: [Train : Metrics { logloss:0.3554,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.382,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3542,  }]\n",
      "Training on Total Epoch: 550, Round: 550\n",
      "Evalset: [Train : Metrics { logloss:0.3543,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3809,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3531,  }]\n",
      "Training on Total Epoch: 551, Round: 551\n",
      "Evalset: [Train : Metrics { logloss:0.3532,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3799,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.352,  }]\n",
      "Training on Total Epoch: 552, Round: 552\n",
      "Evalset: [Train : Metrics { logloss:0.3521,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3788,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.351,  }]\n",
      "Training on Total Epoch: 553, Round: 553\n",
      "Evalset: [Train : Metrics { logloss:0.3509,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3777,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.35,  }]\n",
      "Training on Total Epoch: 554, Round: 554\n",
      "Evalset: [Train : Metrics { logloss:0.3498,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3768,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3491,  }]\n",
      "Training on Total Epoch: 555, Round: 555\n",
      "Evalset: [Train : Metrics { logloss:0.3488,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3759,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3481,  }]\n",
      "Training on Total Epoch: 556, Round: 556\n",
      "Evalset: [Train : Metrics { logloss:0.3477,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3748,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.347,  }]\n",
      "Training on Total Epoch: 557, Round: 557\n",
      "Evalset: [Train : Metrics { logloss:0.3466,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3738,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3459,  }]\n",
      "Training on Total Epoch: 558, Round: 558\n",
      "Evalset: [Train : Metrics { logloss:0.3455,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3727,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3448,  }]\n",
      "Training on Total Epoch: 559, Round: 559\n",
      "Evalset: [Train : Metrics { logloss:0.3445,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3437,  }]\n",
      "Training on Total Epoch: 560, Round: 560\n",
      "Evalset: [Train : Metrics { logloss:0.3434,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3704,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3427,  }]\n",
      "Training on Total Epoch: 561, Round: 561\n",
      "Evalset: [Train : Metrics { logloss:0.3424,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3693,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3419,  }]\n",
      "Training on Total Epoch: 562, Round: 562\n",
      "Evalset: [Train : Metrics { logloss:0.3414,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3682,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.341,  }]\n",
      "Training on Total Epoch: 563, Round: 563\n",
      "Evalset: [Train : Metrics { logloss:0.3403,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3671,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3401,  }]\n",
      "Training on Total Epoch: 564, Round: 564\n",
      "Evalset: [Train : Metrics { logloss:0.3393,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3659,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3391,  }]\n",
      "Training on Total Epoch: 565, Round: 565\n",
      "Evalset: [Train : Metrics { logloss:0.3382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3649,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3381,  }]\n",
      "Training on Total Epoch: 566, Round: 566\n",
      "Evalset: [Train : Metrics { logloss:0.3371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3638,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3372,  }]\n",
      "Training on Total Epoch: 567, Round: 567\n",
      "Evalset: [Train : Metrics { logloss:0.3361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3629,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3362,  }]\n",
      "Training on Total Epoch: 568, Round: 568\n",
      "Evalset: [Train : Metrics { logloss:0.335,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.362,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3353,  }]\n",
      "Training on Total Epoch: 569, Round: 569\n",
      "Evalset: [Train : Metrics { logloss:0.334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.361,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3343,  }]\n",
      "Training on Total Epoch: 570, Round: 570\n",
      "Evalset: [Train : Metrics { logloss:0.3329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.36,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3333,  }]\n",
      "Training on Total Epoch: 571, Round: 571\n",
      "Evalset: [Train : Metrics { logloss:0.3319,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3323,  }]\n",
      "Training on Total Epoch: 572, Round: 572\n",
      "Evalset: [Train : Metrics { logloss:0.3309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3582,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3312,  }]\n",
      "Training on Total Epoch: 573, Round: 573\n",
      "Evalset: [Train : Metrics { logloss:0.3299,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3573,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3302,  }]\n",
      "Training on Total Epoch: 574, Round: 574\n",
      "Evalset: [Train : Metrics { logloss:0.3289,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3564,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3293,  }]\n",
      "Training on Total Epoch: 575, Round: 575\n",
      "Evalset: [Train : Metrics { logloss:0.3279,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3556,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3284,  }]\n",
      "Training on Total Epoch: 576, Round: 576\n",
      "Evalset: [Train : Metrics { logloss:0.327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3547,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3275,  }]\n",
      "Training on Total Epoch: 577, Round: 577\n",
      "Evalset: [Train : Metrics { logloss:0.326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3539,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3267,  }]\n",
      "Training on Total Epoch: 578, Round: 578\n",
      "Evalset: [Train : Metrics { logloss:0.3251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3259,  }]\n",
      "Training on Total Epoch: 579, Round: 579\n",
      "Evalset: [Train : Metrics { logloss:0.3242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3521,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3251,  }]\n",
      "Training on Total Epoch: 580, Round: 580\n",
      "Evalset: [Train : Metrics { logloss:0.3232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3512,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3243,  }]\n",
      "Training on Total Epoch: 581, Round: 581\n",
      "Evalset: [Train : Metrics { logloss:0.3223,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3504,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3234,  }]\n",
      "Training on Total Epoch: 582, Round: 582\n",
      "Evalset: [Train : Metrics { logloss:0.3213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3495,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3226,  }]\n",
      "Training on Total Epoch: 583, Round: 583\n",
      "Evalset: [Train : Metrics { logloss:0.3203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3487,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3218,  }]\n",
      "Training on Total Epoch: 584, Round: 584\n",
      "Evalset: [Train : Metrics { logloss:0.3193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3478,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.321,  }]\n",
      "Training on Total Epoch: 585, Round: 585\n",
      "Evalset: [Train : Metrics { logloss:0.3183,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3201,  }]\n",
      "Training on Total Epoch: 586, Round: 586\n",
      "Evalset: [Train : Metrics { logloss:0.3173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3462,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3193,  }]\n",
      "Training on Total Epoch: 587, Round: 587\n",
      "Evalset: [Train : Metrics { logloss:0.3164,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3184,  }]\n",
      "Training on Total Epoch: 588, Round: 588\n",
      "Evalset: [Train : Metrics { logloss:0.3154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3445,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3176,  }]\n",
      "Training on Total Epoch: 589, Round: 589\n",
      "Evalset: [Train : Metrics { logloss:0.3145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3434,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3166,  }]\n",
      "Training on Total Epoch: 590, Round: 590\n",
      "Evalset: [Train : Metrics { logloss:0.3136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3424,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3157,  }]\n",
      "Training on Total Epoch: 591, Round: 591\n",
      "Evalset: [Train : Metrics { logloss:0.3126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3415,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3148,  }]\n",
      "Training on Total Epoch: 592, Round: 592\n",
      "Evalset: [Train : Metrics { logloss:0.3117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3406,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3138,  }]\n",
      "Training on Total Epoch: 593, Round: 593\n",
      "Evalset: [Train : Metrics { logloss:0.3108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3398,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.313,  }]\n",
      "Training on Total Epoch: 594, Round: 594\n",
      "Evalset: [Train : Metrics { logloss:0.3099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3388,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3121,  }]\n",
      "Training on Total Epoch: 595, Round: 595\n",
      "Evalset: [Train : Metrics { logloss:0.3089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3113,  }]\n",
      "Training on Total Epoch: 596, Round: 596\n",
      "Evalset: [Train : Metrics { logloss:0.3081,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3372,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3104,  }]\n",
      "Training on Total Epoch: 597, Round: 597\n",
      "Evalset: [Train : Metrics { logloss:0.3072,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3363,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3096,  }]\n",
      "Training on Total Epoch: 598, Round: 598\n",
      "Evalset: [Train : Metrics { logloss:0.3063,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3087,  }]\n",
      "Training on Total Epoch: 599, Round: 599\n",
      "Evalset: [Train : Metrics { logloss:0.3054,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3077,  }]\n",
      "Training on Total Epoch: 600, Round: 600\n",
      "Evalset: [Train : Metrics { logloss:0.3044,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3068,  }]\n",
      "Training on Total Epoch: 601, Round: 601\n",
      "Evalset: [Train : Metrics { logloss:0.3035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3059,  }]\n",
      "Training on Total Epoch: 602, Round: 602\n",
      "Evalset: [Train : Metrics { logloss:0.3026,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.305,  }]\n",
      "Training on Total Epoch: 603, Round: 603\n",
      "Evalset: [Train : Metrics { logloss:0.3017,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3319,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3042,  }]\n",
      "Training on Total Epoch: 604, Round: 604\n",
      "Evalset: [Train : Metrics { logloss:0.3008,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3034,  }]\n",
      "Training on Total Epoch: 605, Round: 605\n",
      "Evalset: [Train : Metrics { logloss:0.2999,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3303,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3025,  }]\n",
      "Training on Total Epoch: 606, Round: 606\n",
      "Evalset: [Train : Metrics { logloss:0.299,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3018,  }]\n",
      "Training on Total Epoch: 607, Round: 607\n",
      "Evalset: [Train : Metrics { logloss:0.2981,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.301,  }]\n",
      "Training on Total Epoch: 608, Round: 608\n",
      "Evalset: [Train : Metrics { logloss:0.2973,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.3001,  }]\n",
      "Training on Total Epoch: 609, Round: 609\n",
      "Evalset: [Train : Metrics { logloss:0.2965,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2993,  }]\n",
      "Training on Total Epoch: 610, Round: 610\n",
      "Evalset: [Train : Metrics { logloss:0.2956,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2986,  }]\n",
      "Training on Total Epoch: 611, Round: 611\n",
      "Evalset: [Train : Metrics { logloss:0.2948,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2979,  }]\n",
      "Training on Total Epoch: 612, Round: 612\n",
      "Evalset: [Train : Metrics { logloss:0.2939,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2972,  }]\n",
      "Training on Total Epoch: 613, Round: 613\n",
      "Evalset: [Train : Metrics { logloss:0.293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2965,  }]\n",
      "Training on Total Epoch: 614, Round: 614\n",
      "Evalset: [Train : Metrics { logloss:0.2922,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2958,  }]\n",
      "Training on Total Epoch: 615, Round: 615\n",
      "Evalset: [Train : Metrics { logloss:0.2914,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2951,  }]\n",
      "Training on Total Epoch: 616, Round: 616\n",
      "Evalset: [Train : Metrics { logloss:0.2905,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2942,  }]\n",
      "Training on Total Epoch: 617, Round: 617\n",
      "Evalset: [Train : Metrics { logloss:0.2897,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2933,  }]\n",
      "Training on Total Epoch: 618, Round: 618\n",
      "Evalset: [Train : Metrics { logloss:0.2889,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.32,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2925,  }]\n",
      "Training on Total Epoch: 619, Round: 619\n",
      "Evalset: [Train : Metrics { logloss:0.2881,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2917,  }]\n",
      "Training on Total Epoch: 620, Round: 620\n",
      "Evalset: [Train : Metrics { logloss:0.2873,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3187,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.291,  }]\n",
      "Training on Total Epoch: 621, Round: 621\n",
      "Evalset: [Train : Metrics { logloss:0.2865,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2902,  }]\n",
      "Training on Total Epoch: 622, Round: 622\n",
      "Evalset: [Train : Metrics { logloss:0.2856,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3173,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2894,  }]\n",
      "Training on Total Epoch: 623, Round: 623\n",
      "Evalset: [Train : Metrics { logloss:0.2848,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2886,  }]\n",
      "Training on Total Epoch: 624, Round: 624\n",
      "Evalset: [Train : Metrics { logloss:0.284,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3155,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2878,  }]\n",
      "Training on Total Epoch: 625, Round: 625\n",
      "Evalset: [Train : Metrics { logloss:0.2831,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3147,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2869,  }]\n",
      "Training on Total Epoch: 626, Round: 626\n",
      "Evalset: [Train : Metrics { logloss:0.2823,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3139,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.286,  }]\n",
      "Training on Total Epoch: 627, Round: 627\n",
      "Evalset: [Train : Metrics { logloss:0.2815,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2853,  }]\n",
      "Training on Total Epoch: 628, Round: 628\n",
      "Evalset: [Train : Metrics { logloss:0.2807,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2846,  }]\n",
      "Training on Total Epoch: 629, Round: 629\n",
      "Evalset: [Train : Metrics { logloss:0.2799,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3117,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.284,  }]\n",
      "Training on Total Epoch: 630, Round: 630\n",
      "Evalset: [Train : Metrics { logloss:0.2791,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2832,  }]\n",
      "Training on Total Epoch: 631, Round: 631\n",
      "Evalset: [Train : Metrics { logloss:0.2783,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3104,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2824,  }]\n",
      "Training on Total Epoch: 632, Round: 632\n",
      "Evalset: [Train : Metrics { logloss:0.2775,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3099,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2817,  }]\n",
      "Training on Total Epoch: 633, Round: 633\n",
      "Evalset: [Train : Metrics { logloss:0.2767,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3094,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.281,  }]\n",
      "Training on Total Epoch: 634, Round: 634\n",
      "Evalset: [Train : Metrics { logloss:0.2759,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2802,  }]\n",
      "Training on Total Epoch: 635, Round: 635\n",
      "Evalset: [Train : Metrics { logloss:0.2751,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2794,  }]\n",
      "Training on Total Epoch: 636, Round: 636\n",
      "Evalset: [Train : Metrics { logloss:0.2744,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3071,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2786,  }]\n",
      "Training on Total Epoch: 637, Round: 637\n",
      "Evalset: [Train : Metrics { logloss:0.2736,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3063,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.278,  }]\n",
      "Training on Total Epoch: 638, Round: 638\n",
      "Evalset: [Train : Metrics { logloss:0.2729,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3057,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2774,  }]\n",
      "Training on Total Epoch: 639, Round: 639\n",
      "Evalset: [Train : Metrics { logloss:0.2721,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3051,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2769,  }]\n",
      "Training on Total Epoch: 640, Round: 640\n",
      "Evalset: [Train : Metrics { logloss:0.2714,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3045,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2764,  }]\n",
      "Training on Total Epoch: 641, Round: 641\n",
      "Evalset: [Train : Metrics { logloss:0.2707,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2759,  }]\n",
      "Training on Total Epoch: 642, Round: 642\n",
      "Evalset: [Train : Metrics { logloss:0.27,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3033,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2753,  }]\n",
      "Training on Total Epoch: 643, Round: 643\n",
      "Evalset: [Train : Metrics { logloss:0.2693,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3025,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2748,  }]\n",
      "Training on Total Epoch: 644, Round: 644\n",
      "Evalset: [Train : Metrics { logloss:0.2686,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3019,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2741,  }]\n",
      "Training on Total Epoch: 645, Round: 645\n",
      "Evalset: [Train : Metrics { logloss:0.2678,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3011,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2733,  }]\n",
      "Training on Total Epoch: 646, Round: 646\n",
      "Evalset: [Train : Metrics { logloss:0.2671,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.3004,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2726,  }]\n",
      "Training on Total Epoch: 647, Round: 647\n",
      "Evalset: [Train : Metrics { logloss:0.2664,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2998,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.272,  }]\n",
      "Training on Total Epoch: 648, Round: 648\n",
      "Evalset: [Train : Metrics { logloss:0.2656,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2992,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2713,  }]\n",
      "Training on Total Epoch: 649, Round: 649\n",
      "Evalset: [Train : Metrics { logloss:0.2649,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2985,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2707,  }]\n",
      "Training on Total Epoch: 650, Round: 650\n",
      "Evalset: [Train : Metrics { logloss:0.2641,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2979,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2699,  }]\n",
      "Training on Total Epoch: 651, Round: 651\n",
      "Evalset: [Train : Metrics { logloss:0.2634,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2973,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2691,  }]\n",
      "Training on Total Epoch: 652, Round: 652\n",
      "Evalset: [Train : Metrics { logloss:0.2626,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2967,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2684,  }]\n",
      "Training on Total Epoch: 653, Round: 653\n",
      "Evalset: [Train : Metrics { logloss:0.2619,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2962,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2677,  }]\n",
      "Training on Total Epoch: 654, Round: 654\n",
      "Evalset: [Train : Metrics { logloss:0.2612,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2956,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2671,  }]\n",
      "Training on Total Epoch: 655, Round: 655\n",
      "Evalset: [Train : Metrics { logloss:0.2605,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.295,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2665,  }]\n",
      "Training on Total Epoch: 656, Round: 656\n",
      "Evalset: [Train : Metrics { logloss:0.2598,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2945,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.266,  }]\n",
      "Training on Total Epoch: 657, Round: 657\n",
      "Evalset: [Train : Metrics { logloss:0.2591,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2938,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2653,  }]\n",
      "Training on Total Epoch: 658, Round: 658\n",
      "Evalset: [Train : Metrics { logloss:0.2584,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2647,  }]\n",
      "Training on Total Epoch: 659, Round: 659\n",
      "Evalset: [Train : Metrics { logloss:0.2577,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2923,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2642,  }]\n",
      "Training on Total Epoch: 660, Round: 660\n",
      "Evalset: [Train : Metrics { logloss:0.2571,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2638,  }]\n",
      "Training on Total Epoch: 661, Round: 661\n",
      "Evalset: [Train : Metrics { logloss:0.2564,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2631,  }]\n",
      "Training on Total Epoch: 662, Round: 662\n",
      "Evalset: [Train : Metrics { logloss:0.2558,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2902,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2624,  }]\n",
      "Training on Total Epoch: 663, Round: 663\n",
      "Evalset: [Train : Metrics { logloss:0.2551,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2618,  }]\n",
      "Training on Total Epoch: 664, Round: 664\n",
      "Evalset: [Train : Metrics { logloss:0.2545,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2612,  }]\n",
      "Training on Total Epoch: 665, Round: 665\n",
      "Evalset: [Train : Metrics { logloss:0.2538,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2606,  }]\n",
      "Training on Total Epoch: 666, Round: 666\n",
      "Evalset: [Train : Metrics { logloss:0.2532,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.26,  }]\n",
      "Training on Total Epoch: 667, Round: 667\n",
      "Evalset: [Train : Metrics { logloss:0.2525,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2872,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2593,  }]\n",
      "Training on Total Epoch: 668, Round: 668\n",
      "Evalset: [Train : Metrics { logloss:0.2519,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2865,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2585,  }]\n",
      "Training on Total Epoch: 669, Round: 669\n",
      "Evalset: [Train : Metrics { logloss:0.2512,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2858,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2577,  }]\n",
      "Training on Total Epoch: 670, Round: 670\n",
      "Evalset: [Train : Metrics { logloss:0.2506,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2852,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.257,  }]\n",
      "Training on Total Epoch: 671, Round: 671\n",
      "Evalset: [Train : Metrics { logloss:0.2499,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2847,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2564,  }]\n",
      "Training on Total Epoch: 672, Round: 672\n",
      "Evalset: [Train : Metrics { logloss:0.2493,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2842,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2558,  }]\n",
      "Training on Total Epoch: 673, Round: 673\n",
      "Evalset: [Train : Metrics { logloss:0.2486,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2837,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2553,  }]\n",
      "Training on Total Epoch: 674, Round: 674\n",
      "Evalset: [Train : Metrics { logloss:0.2479,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2831,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2548,  }]\n",
      "Training on Total Epoch: 675, Round: 675\n",
      "Evalset: [Train : Metrics { logloss:0.2473,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2826,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2543,  }]\n",
      "Training on Total Epoch: 676, Round: 676\n",
      "Evalset: [Train : Metrics { logloss:0.2467,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2823,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.254,  }]\n",
      "Training on Total Epoch: 677, Round: 677\n",
      "Evalset: [Train : Metrics { logloss:0.246,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2535,  }]\n",
      "Training on Total Epoch: 678, Round: 678\n",
      "Evalset: [Train : Metrics { logloss:0.2454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2814,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2529,  }]\n",
      "Training on Total Epoch: 679, Round: 679\n",
      "Evalset: [Train : Metrics { logloss:0.2447,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2808,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2523,  }]\n",
      "Training on Total Epoch: 680, Round: 680\n",
      "Evalset: [Train : Metrics { logloss:0.2441,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2802,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2516,  }]\n",
      "Training on Total Epoch: 681, Round: 681\n",
      "Evalset: [Train : Metrics { logloss:0.2435,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2796,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.251,  }]\n",
      "Training on Total Epoch: 682, Round: 682\n",
      "Evalset: [Train : Metrics { logloss:0.2428,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2789,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2503,  }]\n",
      "Training on Total Epoch: 683, Round: 683\n",
      "Evalset: [Train : Metrics { logloss:0.2422,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2782,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2496,  }]\n",
      "Training on Total Epoch: 684, Round: 684\n",
      "Evalset: [Train : Metrics { logloss:0.2416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2775,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2489,  }]\n",
      "Training on Total Epoch: 685, Round: 685\n",
      "Evalset: [Train : Metrics { logloss:0.241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2771,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2482,  }]\n",
      "Training on Total Epoch: 686, Round: 686\n",
      "Evalset: [Train : Metrics { logloss:0.2404,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2766,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2477,  }]\n",
      "Training on Total Epoch: 687, Round: 687\n",
      "Evalset: [Train : Metrics { logloss:0.2398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2761,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2472,  }]\n",
      "Training on Total Epoch: 688, Round: 688\n",
      "Evalset: [Train : Metrics { logloss:0.2392,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2755,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2467,  }]\n",
      "Training on Total Epoch: 689, Round: 689\n",
      "Evalset: [Train : Metrics { logloss:0.2386,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2749,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2462,  }]\n",
      "Training on Total Epoch: 690, Round: 690\n",
      "Evalset: [Train : Metrics { logloss:0.238,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2744,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2456,  }]\n",
      "Training on Total Epoch: 691, Round: 691\n",
      "Evalset: [Train : Metrics { logloss:0.2374,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2738,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.245,  }]\n",
      "Training on Total Epoch: 692, Round: 692\n",
      "Evalset: [Train : Metrics { logloss:0.2368,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2733,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2445,  }]\n",
      "Training on Total Epoch: 693, Round: 693\n",
      "Evalset: [Train : Metrics { logloss:0.2362,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2728,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.244,  }]\n",
      "Training on Total Epoch: 694, Round: 694\n",
      "Evalset: [Train : Metrics { logloss:0.2356,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2723,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2435,  }]\n",
      "Training on Total Epoch: 695, Round: 695\n",
      "Evalset: [Train : Metrics { logloss:0.235,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2718,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2428,  }]\n",
      "Training on Total Epoch: 696, Round: 696\n",
      "Evalset: [Train : Metrics { logloss:0.2344,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2712,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2423,  }]\n",
      "Training on Total Epoch: 697, Round: 697\n",
      "Evalset: [Train : Metrics { logloss:0.2338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2707,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2417,  }]\n",
      "Training on Total Epoch: 698, Round: 698\n",
      "Evalset: [Train : Metrics { logloss:0.2333,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2703,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2412,  }]\n",
      "Training on Total Epoch: 699, Round: 699\n",
      "Evalset: [Train : Metrics { logloss:0.2327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2697,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2407,  }]\n",
      "Training on Total Epoch: 700, Round: 700\n",
      "Evalset: [Train : Metrics { logloss:0.2321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2691,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2403,  }]\n",
      "Training on Total Epoch: 701, Round: 701\n",
      "Evalset: [Train : Metrics { logloss:0.2315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2685,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2397,  }]\n",
      "Training on Total Epoch: 702, Round: 702\n",
      "Evalset: [Train : Metrics { logloss:0.231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2679,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2391,  }]\n",
      "Training on Total Epoch: 703, Round: 703\n",
      "Evalset: [Train : Metrics { logloss:0.2304,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2674,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2386,  }]\n",
      "Training on Total Epoch: 704, Round: 704\n",
      "Evalset: [Train : Metrics { logloss:0.2299,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2667,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.238,  }]\n",
      "Training on Total Epoch: 705, Round: 705\n",
      "Evalset: [Train : Metrics { logloss:0.2293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2663,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2375,  }]\n",
      "Training on Total Epoch: 706, Round: 706\n",
      "Evalset: [Train : Metrics { logloss:0.2287,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2659,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2372,  }]\n",
      "Training on Total Epoch: 707, Round: 707\n",
      "Evalset: [Train : Metrics { logloss:0.2281,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2656,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2369,  }]\n",
      "Training on Total Epoch: 708, Round: 708\n",
      "Evalset: [Train : Metrics { logloss:0.2276,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2654,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2365,  }]\n",
      "Training on Total Epoch: 709, Round: 709\n",
      "Evalset: [Train : Metrics { logloss:0.227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2651,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2361,  }]\n",
      "Training on Total Epoch: 710, Round: 710\n",
      "Evalset: [Train : Metrics { logloss:0.2265,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2648,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2357,  }]\n",
      "Training on Total Epoch: 711, Round: 711\n",
      "Evalset: [Train : Metrics { logloss:0.2259,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2644,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2351,  }]\n",
      "Training on Total Epoch: 712, Round: 712\n",
      "Evalset: [Train : Metrics { logloss:0.2253,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2638,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2345,  }]\n",
      "Training on Total Epoch: 713, Round: 713\n",
      "Evalset: [Train : Metrics { logloss:0.2248,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2632,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2339,  }]\n",
      "Training on Total Epoch: 714, Round: 714\n",
      "Evalset: [Train : Metrics { logloss:0.2242,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2626,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2332,  }]\n",
      "Training on Total Epoch: 715, Round: 715\n",
      "Evalset: [Train : Metrics { logloss:0.2237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2621,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2326,  }]\n",
      "Training on Total Epoch: 716, Round: 716\n",
      "Evalset: [Train : Metrics { logloss:0.2231,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2616,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.232,  }]\n",
      "Training on Total Epoch: 717, Round: 717\n",
      "Evalset: [Train : Metrics { logloss:0.2226,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2315,  }]\n",
      "Training on Total Epoch: 718, Round: 718\n",
      "Evalset: [Train : Metrics { logloss:0.222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2604,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2308,  }]\n",
      "Training on Total Epoch: 719, Round: 719\n",
      "Evalset: [Train : Metrics { logloss:0.2215,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2599,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2303,  }]\n",
      "Training on Total Epoch: 720, Round: 720\n",
      "Evalset: [Train : Metrics { logloss:0.221,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2594,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2299,  }]\n",
      "Training on Total Epoch: 721, Round: 721\n",
      "Evalset: [Train : Metrics { logloss:0.2205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2294,  }]\n",
      "Training on Total Epoch: 722, Round: 722\n",
      "Evalset: [Train : Metrics { logloss:0.22,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2585,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.229,  }]\n",
      "Training on Total Epoch: 723, Round: 723\n",
      "Evalset: [Train : Metrics { logloss:0.2195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2285,  }]\n",
      "Training on Total Epoch: 724, Round: 724\n",
      "Evalset: [Train : Metrics { logloss:0.2189,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2577,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2281,  }]\n",
      "Training on Total Epoch: 725, Round: 725\n",
      "Evalset: [Train : Metrics { logloss:0.2184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2574,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2277,  }]\n",
      "Training on Total Epoch: 726, Round: 726\n",
      "Evalset: [Train : Metrics { logloss:0.2178,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2568,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2273,  }]\n",
      "Training on Total Epoch: 727, Round: 727\n",
      "Evalset: [Train : Metrics { logloss:0.2173,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2563,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2268,  }]\n",
      "Training on Total Epoch: 728, Round: 728\n",
      "Evalset: [Train : Metrics { logloss:0.2168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2556,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2262,  }]\n",
      "Training on Total Epoch: 729, Round: 729\n",
      "Evalset: [Train : Metrics { logloss:0.2163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2551,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2257,  }]\n",
      "Training on Total Epoch: 730, Round: 730\n",
      "Evalset: [Train : Metrics { logloss:0.2158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2546,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2253,  }]\n",
      "Training on Total Epoch: 731, Round: 731\n",
      "Evalset: [Train : Metrics { logloss:0.2152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2541,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2248,  }]\n",
      "Training on Total Epoch: 732, Round: 732\n",
      "Evalset: [Train : Metrics { logloss:0.2147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2535,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2243,  }]\n",
      "Training on Total Epoch: 733, Round: 733\n",
      "Evalset: [Train : Metrics { logloss:0.2142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.253,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2239,  }]\n",
      "Training on Total Epoch: 734, Round: 734\n",
      "Evalset: [Train : Metrics { logloss:0.2137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2525,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2235,  }]\n",
      "Training on Total Epoch: 735, Round: 735\n",
      "Evalset: [Train : Metrics { logloss:0.2132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2519,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.223,  }]\n",
      "Training on Total Epoch: 736, Round: 736\n",
      "Evalset: [Train : Metrics { logloss:0.2126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2514,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2224,  }]\n",
      "Training on Total Epoch: 737, Round: 737\n",
      "Evalset: [Train : Metrics { logloss:0.2121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2509,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2219,  }]\n",
      "Training on Total Epoch: 738, Round: 738\n",
      "Evalset: [Train : Metrics { logloss:0.2116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2505,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2215,  }]\n",
      "Training on Total Epoch: 739, Round: 739\n",
      "Evalset: [Train : Metrics { logloss:0.2111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2501,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.221,  }]\n",
      "Training on Total Epoch: 740, Round: 740\n",
      "Evalset: [Train : Metrics { logloss:0.2106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2206,  }]\n",
      "Training on Total Epoch: 741, Round: 741\n",
      "Evalset: [Train : Metrics { logloss:0.21,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2496,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2202,  }]\n",
      "Training on Total Epoch: 742, Round: 742\n",
      "Evalset: [Train : Metrics { logloss:0.2095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2493,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2198,  }]\n",
      "Training on Total Epoch: 743, Round: 743\n",
      "Evalset: [Train : Metrics { logloss:0.209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2491,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2194,  }]\n",
      "Training on Total Epoch: 744, Round: 744\n",
      "Evalset: [Train : Metrics { logloss:0.2085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2488,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.219,  }]\n",
      "Training on Total Epoch: 745, Round: 745\n",
      "Evalset: [Train : Metrics { logloss:0.208,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2484,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2186,  }]\n",
      "Training on Total Epoch: 746, Round: 746\n",
      "Evalset: [Train : Metrics { logloss:0.2075,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2182,  }]\n",
      "Training on Total Epoch: 747, Round: 747\n",
      "Evalset: [Train : Metrics { logloss:0.207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2474,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2177,  }]\n",
      "Training on Total Epoch: 748, Round: 748\n",
      "Evalset: [Train : Metrics { logloss:0.2065,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2468,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2172,  }]\n",
      "Training on Total Epoch: 749, Round: 749\n",
      "Evalset: [Train : Metrics { logloss:0.206,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2463,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2167,  }]\n",
      "Training on Total Epoch: 750, Round: 750\n",
      "Evalset: [Train : Metrics { logloss:0.2055,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2458,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2163,  }]\n",
      "Training on Total Epoch: 751, Round: 751\n",
      "Evalset: [Train : Metrics { logloss:0.205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2453,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2158,  }]\n",
      "Training on Total Epoch: 752, Round: 752\n",
      "Evalset: [Train : Metrics { logloss:0.2045,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2449,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2152,  }]\n",
      "Training on Total Epoch: 753, Round: 753\n",
      "Evalset: [Train : Metrics { logloss:0.2039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2444,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2145,  }]\n",
      "Training on Total Epoch: 754, Round: 754\n",
      "Evalset: [Train : Metrics { logloss:0.2035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2439,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2139,  }]\n",
      "Training on Total Epoch: 755, Round: 755\n",
      "Evalset: [Train : Metrics { logloss:0.203,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2133,  }]\n",
      "Training on Total Epoch: 756, Round: 756\n",
      "Evalset: [Train : Metrics { logloss:0.2025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2127,  }]\n",
      "Training on Total Epoch: 757, Round: 757\n",
      "Evalset: [Train : Metrics { logloss:0.202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2426,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2122,  }]\n",
      "Training on Total Epoch: 758, Round: 758\n",
      "Evalset: [Train : Metrics { logloss:0.2015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2422,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2119,  }]\n",
      "Training on Total Epoch: 759, Round: 759\n",
      "Evalset: [Train : Metrics { logloss:0.201,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2417,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2116,  }]\n",
      "Training on Total Epoch: 760, Round: 760\n",
      "Evalset: [Train : Metrics { logloss:0.2005,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2411,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2113,  }]\n",
      "Training on Total Epoch: 761, Round: 761\n",
      "Evalset: [Train : Metrics { logloss:0.2001,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2406,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2109,  }]\n",
      "Training on Total Epoch: 762, Round: 762\n",
      "Evalset: [Train : Metrics { logloss:0.1996,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2402,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2104,  }]\n",
      "Training on Total Epoch: 763, Round: 763\n",
      "Evalset: [Train : Metrics { logloss:0.1991,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2399,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.21,  }]\n",
      "Training on Total Epoch: 764, Round: 764\n",
      "Evalset: [Train : Metrics { logloss:0.1985,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2396,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2097,  }]\n",
      "Training on Total Epoch: 765, Round: 765\n",
      "Evalset: [Train : Metrics { logloss:0.1981,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2393,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2093,  }]\n",
      "Training on Total Epoch: 766, Round: 766\n",
      "Evalset: [Train : Metrics { logloss:0.1976,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2389,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2089,  }]\n",
      "Training on Total Epoch: 767, Round: 767\n",
      "Evalset: [Train : Metrics { logloss:0.1971,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2386,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2084,  }]\n",
      "Training on Total Epoch: 768, Round: 768\n",
      "Evalset: [Train : Metrics { logloss:0.1967,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2383,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2079,  }]\n",
      "Training on Total Epoch: 769, Round: 769\n",
      "Evalset: [Train : Metrics { logloss:0.1962,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2378,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2073,  }]\n",
      "Training on Total Epoch: 770, Round: 770\n",
      "Evalset: [Train : Metrics { logloss:0.1958,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2373,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2068,  }]\n",
      "Training on Total Epoch: 771, Round: 771\n",
      "Evalset: [Train : Metrics { logloss:0.1953,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2064,  }]\n",
      "Training on Total Epoch: 772, Round: 772\n",
      "Evalset: [Train : Metrics { logloss:0.1949,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2368,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.206,  }]\n",
      "Training on Total Epoch: 773, Round: 773\n",
      "Evalset: [Train : Metrics { logloss:0.1945,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2364,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2055,  }]\n",
      "Training on Total Epoch: 774, Round: 774\n",
      "Evalset: [Train : Metrics { logloss:0.1941,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2051,  }]\n",
      "Training on Total Epoch: 775, Round: 775\n",
      "Evalset: [Train : Metrics { logloss:0.1936,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2047,  }]\n",
      "Training on Total Epoch: 776, Round: 776\n",
      "Evalset: [Train : Metrics { logloss:0.1932,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2044,  }]\n",
      "Training on Total Epoch: 777, Round: 777\n",
      "Evalset: [Train : Metrics { logloss:0.1927,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.204,  }]\n",
      "Training on Total Epoch: 778, Round: 778\n",
      "Evalset: [Train : Metrics { logloss:0.1923,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2038,  }]\n",
      "Training on Total Epoch: 779, Round: 779\n",
      "Evalset: [Train : Metrics { logloss:0.1918,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2036,  }]\n",
      "Training on Total Epoch: 780, Round: 780\n",
      "Evalset: [Train : Metrics { logloss:0.1914,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2342,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2034,  }]\n",
      "Training on Total Epoch: 781, Round: 781\n",
      "Evalset: [Train : Metrics { logloss:0.1909,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2032,  }]\n",
      "Training on Total Epoch: 782, Round: 782\n",
      "Evalset: [Train : Metrics { logloss:0.1905,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.203,  }]\n",
      "Training on Total Epoch: 783, Round: 783\n",
      "Evalset: [Train : Metrics { logloss:0.1901,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2028,  }]\n",
      "Training on Total Epoch: 784, Round: 784\n",
      "Evalset: [Train : Metrics { logloss:0.1897,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2024,  }]\n",
      "Training on Total Epoch: 785, Round: 785\n",
      "Evalset: [Train : Metrics { logloss:0.1892,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2019,  }]\n",
      "Training on Total Epoch: 786, Round: 786\n",
      "Evalset: [Train : Metrics { logloss:0.1888,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2012,  }]\n",
      "Training on Total Epoch: 787, Round: 787\n",
      "Evalset: [Train : Metrics { logloss:0.1884,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2316,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2007,  }]\n",
      "Training on Total Epoch: 788, Round: 788\n",
      "Evalset: [Train : Metrics { logloss:0.1879,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.2003,  }]\n",
      "Training on Total Epoch: 789, Round: 789\n",
      "Evalset: [Train : Metrics { logloss:0.1875,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1999,  }]\n",
      "Training on Total Epoch: 790, Round: 790\n",
      "Evalset: [Train : Metrics { logloss:0.1871,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2301,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1994,  }]\n",
      "Training on Total Epoch: 791, Round: 791\n",
      "Evalset: [Train : Metrics { logloss:0.1867,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2296,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.199,  }]\n",
      "Training on Total Epoch: 792, Round: 792\n",
      "Evalset: [Train : Metrics { logloss:0.1863,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1987,  }]\n",
      "Training on Total Epoch: 793, Round: 793\n",
      "Evalset: [Train : Metrics { logloss:0.1859,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1985,  }]\n",
      "Training on Total Epoch: 794, Round: 794\n",
      "Evalset: [Train : Metrics { logloss:0.1855,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2287,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1981,  }]\n",
      "Training on Total Epoch: 795, Round: 795\n",
      "Evalset: [Train : Metrics { logloss:0.185,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2284,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1977,  }]\n",
      "Training on Total Epoch: 796, Round: 796\n",
      "Evalset: [Train : Metrics { logloss:0.1846,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1973,  }]\n",
      "Training on Total Epoch: 797, Round: 797\n",
      "Evalset: [Train : Metrics { logloss:0.1841,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.197,  }]\n",
      "Training on Total Epoch: 798, Round: 798\n",
      "Evalset: [Train : Metrics { logloss:0.1837,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1967,  }]\n",
      "Training on Total Epoch: 799, Round: 799\n",
      "Evalset: [Train : Metrics { logloss:0.1833,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1964,  }]\n",
      "Training on Total Epoch: 800, Round: 800\n",
      "Evalset: [Train : Metrics { logloss:0.1829,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2268,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1961,  }]\n",
      "Training on Total Epoch: 801, Round: 801\n",
      "Evalset: [Train : Metrics { logloss:0.1826,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1959,  }]\n",
      "Training on Total Epoch: 802, Round: 802\n",
      "Evalset: [Train : Metrics { logloss:0.1822,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1956,  }]\n",
      "Training on Total Epoch: 803, Round: 803\n",
      "Evalset: [Train : Metrics { logloss:0.1818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1952,  }]\n",
      "Training on Total Epoch: 804, Round: 804\n",
      "Evalset: [Train : Metrics { logloss:0.1814,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1947,  }]\n",
      "Training on Total Epoch: 805, Round: 805\n",
      "Evalset: [Train : Metrics { logloss:0.181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1942,  }]\n",
      "Training on Total Epoch: 806, Round: 806\n",
      "Evalset: [Train : Metrics { logloss:0.1806,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1936,  }]\n",
      "Training on Total Epoch: 807, Round: 807\n",
      "Evalset: [Train : Metrics { logloss:0.1802,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.193,  }]\n",
      "Training on Total Epoch: 808, Round: 808\n",
      "Evalset: [Train : Metrics { logloss:0.1797,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1925,  }]\n",
      "Training on Total Epoch: 809, Round: 809\n",
      "Evalset: [Train : Metrics { logloss:0.1793,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1922,  }]\n",
      "Training on Total Epoch: 810, Round: 810\n",
      "Evalset: [Train : Metrics { logloss:0.1789,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1918,  }]\n",
      "Training on Total Epoch: 811, Round: 811\n",
      "Evalset: [Train : Metrics { logloss:0.1785,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1915,  }]\n",
      "Training on Total Epoch: 812, Round: 812\n",
      "Evalset: [Train : Metrics { logloss:0.1781,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1912,  }]\n",
      "Training on Total Epoch: 813, Round: 813\n",
      "Evalset: [Train : Metrics { logloss:0.1777,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1908,  }]\n",
      "Training on Total Epoch: 814, Round: 814\n",
      "Evalset: [Train : Metrics { logloss:0.1773,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1905,  }]\n",
      "Training on Total Epoch: 815, Round: 815\n",
      "Evalset: [Train : Metrics { logloss:0.177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1902,  }]\n",
      "Training on Total Epoch: 816, Round: 816\n",
      "Evalset: [Train : Metrics { logloss:0.1766,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2206,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1898,  }]\n",
      "Training on Total Epoch: 817, Round: 817\n",
      "Evalset: [Train : Metrics { logloss:0.1763,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2202,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1895,  }]\n",
      "Training on Total Epoch: 818, Round: 818\n",
      "Evalset: [Train : Metrics { logloss:0.1759,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.22,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1892,  }]\n",
      "Training on Total Epoch: 819, Round: 819\n",
      "Evalset: [Train : Metrics { logloss:0.1755,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2197,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1889,  }]\n",
      "Training on Total Epoch: 820, Round: 820\n",
      "Evalset: [Train : Metrics { logloss:0.1751,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2194,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1886,  }]\n",
      "Training on Total Epoch: 821, Round: 821\n",
      "Evalset: [Train : Metrics { logloss:0.1747,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1884,  }]\n",
      "Training on Total Epoch: 822, Round: 822\n",
      "Evalset: [Train : Metrics { logloss:0.1744,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2188,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1882,  }]\n",
      "Training on Total Epoch: 823, Round: 823\n",
      "Evalset: [Train : Metrics { logloss:0.174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2187,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.188,  }]\n",
      "Training on Total Epoch: 824, Round: 824\n",
      "Evalset: [Train : Metrics { logloss:0.1736,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1877,  }]\n",
      "Training on Total Epoch: 825, Round: 825\n",
      "Evalset: [Train : Metrics { logloss:0.1733,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1873,  }]\n",
      "Training on Total Epoch: 826, Round: 826\n",
      "Evalset: [Train : Metrics { logloss:0.1729,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1871,  }]\n",
      "Training on Total Epoch: 827, Round: 827\n",
      "Evalset: [Train : Metrics { logloss:0.1725,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1868,  }]\n",
      "Training on Total Epoch: 828, Round: 828\n",
      "Evalset: [Train : Metrics { logloss:0.1722,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2172,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1865,  }]\n",
      "Training on Total Epoch: 829, Round: 829\n",
      "Evalset: [Train : Metrics { logloss:0.1718,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2169,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1862,  }]\n",
      "Training on Total Epoch: 830, Round: 830\n",
      "Evalset: [Train : Metrics { logloss:0.1715,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1859,  }]\n",
      "Training on Total Epoch: 831, Round: 831\n",
      "Evalset: [Train : Metrics { logloss:0.1711,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1857,  }]\n",
      "Training on Total Epoch: 832, Round: 832\n",
      "Evalset: [Train : Metrics { logloss:0.1708,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2159,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1853,  }]\n",
      "Training on Total Epoch: 833, Round: 833\n",
      "Evalset: [Train : Metrics { logloss:0.1704,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2156,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1849,  }]\n",
      "Training on Total Epoch: 834, Round: 834\n",
      "Evalset: [Train : Metrics { logloss:0.1701,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2153,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1845,  }]\n",
      "Training on Total Epoch: 835, Round: 835\n",
      "Evalset: [Train : Metrics { logloss:0.1697,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.184,  }]\n",
      "Training on Total Epoch: 836, Round: 836\n",
      "Evalset: [Train : Metrics { logloss:0.1693,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2146,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1835,  }]\n",
      "Training on Total Epoch: 837, Round: 837\n",
      "Evalset: [Train : Metrics { logloss:0.169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2142,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1831,  }]\n",
      "Training on Total Epoch: 838, Round: 838\n",
      "Evalset: [Train : Metrics { logloss:0.1686,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2139,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1828,  }]\n",
      "Training on Total Epoch: 839, Round: 839\n",
      "Evalset: [Train : Metrics { logloss:0.1683,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1825,  }]\n",
      "Training on Total Epoch: 840, Round: 840\n",
      "Evalset: [Train : Metrics { logloss:0.168,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1821,  }]\n",
      "Training on Total Epoch: 841, Round: 841\n",
      "Evalset: [Train : Metrics { logloss:0.1676,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2127,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1818,  }]\n",
      "Training on Total Epoch: 842, Round: 842\n",
      "Evalset: [Train : Metrics { logloss:0.1672,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1815,  }]\n",
      "Training on Total Epoch: 843, Round: 843\n",
      "Evalset: [Train : Metrics { logloss:0.1669,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1811,  }]\n",
      "Training on Total Epoch: 844, Round: 844\n",
      "Evalset: [Train : Metrics { logloss:0.1665,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2119,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1807,  }]\n",
      "Training on Total Epoch: 845, Round: 845\n",
      "Evalset: [Train : Metrics { logloss:0.1661,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2116,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1803,  }]\n",
      "Training on Total Epoch: 846, Round: 846\n",
      "Evalset: [Train : Metrics { logloss:0.1657,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2113,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1799,  }]\n",
      "Training on Total Epoch: 847, Round: 847\n",
      "Evalset: [Train : Metrics { logloss:0.1654,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1796,  }]\n",
      "Training on Total Epoch: 848, Round: 848\n",
      "Evalset: [Train : Metrics { logloss:0.165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2108,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1794,  }]\n",
      "Training on Total Epoch: 849, Round: 849\n",
      "Evalset: [Train : Metrics { logloss:0.1647,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2106,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1792,  }]\n",
      "Training on Total Epoch: 850, Round: 850\n",
      "Evalset: [Train : Metrics { logloss:0.1644,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2102,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1789,  }]\n",
      "Training on Total Epoch: 851, Round: 851\n",
      "Evalset: [Train : Metrics { logloss:0.1641,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2099,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1787,  }]\n",
      "Training on Total Epoch: 852, Round: 852\n",
      "Evalset: [Train : Metrics { logloss:0.1638,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2096,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1784,  }]\n",
      "Training on Total Epoch: 853, Round: 853\n",
      "Evalset: [Train : Metrics { logloss:0.1635,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2091,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1781,  }]\n",
      "Training on Total Epoch: 854, Round: 854\n",
      "Evalset: [Train : Metrics { logloss:0.1632,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2087,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1778,  }]\n",
      "Training on Total Epoch: 855, Round: 855\n",
      "Evalset: [Train : Metrics { logloss:0.163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2083,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1777,  }]\n",
      "Training on Total Epoch: 856, Round: 856\n",
      "Evalset: [Train : Metrics { logloss:0.1627,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1775,  }]\n",
      "Training on Total Epoch: 857, Round: 857\n",
      "Evalset: [Train : Metrics { logloss:0.1623,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2077,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1772,  }]\n",
      "Training on Total Epoch: 858, Round: 858\n",
      "Evalset: [Train : Metrics { logloss:0.162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2074,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1769,  }]\n",
      "Training on Total Epoch: 859, Round: 859\n",
      "Evalset: [Train : Metrics { logloss:0.1616,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2073,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1765,  }]\n",
      "Training on Total Epoch: 860, Round: 860\n",
      "Evalset: [Train : Metrics { logloss:0.1612,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2071,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1761,  }]\n",
      "Training on Total Epoch: 861, Round: 861\n",
      "Evalset: [Train : Metrics { logloss:0.1609,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1758,  }]\n",
      "Training on Total Epoch: 862, Round: 862\n",
      "Evalset: [Train : Metrics { logloss:0.1605,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2069,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1755,  }]\n",
      "Training on Total Epoch: 863, Round: 863\n",
      "Evalset: [Train : Metrics { logloss:0.1602,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2067,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1752,  }]\n",
      "Training on Total Epoch: 864, Round: 864\n",
      "Evalset: [Train : Metrics { logloss:0.1598,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2065,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1749,  }]\n",
      "Training on Total Epoch: 865, Round: 865\n",
      "Evalset: [Train : Metrics { logloss:0.1595,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2063,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1745,  }]\n",
      "Training on Total Epoch: 866, Round: 866\n",
      "Evalset: [Train : Metrics { logloss:0.1592,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2061,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1742,  }]\n",
      "Training on Total Epoch: 867, Round: 867\n",
      "Evalset: [Train : Metrics { logloss:0.1588,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2057,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1739,  }]\n",
      "Training on Total Epoch: 868, Round: 868\n",
      "Evalset: [Train : Metrics { logloss:0.1585,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2053,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1736,  }]\n",
      "Training on Total Epoch: 869, Round: 869\n",
      "Evalset: [Train : Metrics { logloss:0.1582,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2049,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1733,  }]\n",
      "Training on Total Epoch: 870, Round: 870\n",
      "Evalset: [Train : Metrics { logloss:0.1579,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2045,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1731,  }]\n",
      "Training on Total Epoch: 871, Round: 871\n",
      "Evalset: [Train : Metrics { logloss:0.1577,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2041,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1728,  }]\n",
      "Training on Total Epoch: 872, Round: 872\n",
      "Evalset: [Train : Metrics { logloss:0.1574,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2037,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1726,  }]\n",
      "Training on Total Epoch: 873, Round: 873\n",
      "Evalset: [Train : Metrics { logloss:0.1571,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2034,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1723,  }]\n",
      "Training on Total Epoch: 874, Round: 874\n",
      "Evalset: [Train : Metrics { logloss:0.1568,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2031,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.172,  }]\n",
      "Training on Total Epoch: 875, Round: 875\n",
      "Evalset: [Train : Metrics { logloss:0.1564,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2028,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1717,  }]\n",
      "Training on Total Epoch: 876, Round: 876\n",
      "Evalset: [Train : Metrics { logloss:0.1561,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2026,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1715,  }]\n",
      "Training on Total Epoch: 877, Round: 877\n",
      "Evalset: [Train : Metrics { logloss:0.1558,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2025,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1713,  }]\n",
      "Training on Total Epoch: 878, Round: 878\n",
      "Evalset: [Train : Metrics { logloss:0.1554,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2025,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.171,  }]\n",
      "Training on Total Epoch: 879, Round: 879\n",
      "Evalset: [Train : Metrics { logloss:0.1551,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2023,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1707,  }]\n",
      "Training on Total Epoch: 880, Round: 880\n",
      "Evalset: [Train : Metrics { logloss:0.1547,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2022,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1704,  }]\n",
      "Training on Total Epoch: 881, Round: 881\n",
      "Evalset: [Train : Metrics { logloss:0.1544,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2019,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1701,  }]\n",
      "Training on Total Epoch: 882, Round: 882\n",
      "Evalset: [Train : Metrics { logloss:0.1541,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2016,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1699,  }]\n",
      "Training on Total Epoch: 883, Round: 883\n",
      "Evalset: [Train : Metrics { logloss:0.1538,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2014,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1697,  }]\n",
      "Training on Total Epoch: 884, Round: 884\n",
      "Evalset: [Train : Metrics { logloss:0.1535,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2012,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1695,  }]\n",
      "Training on Total Epoch: 885, Round: 885\n",
      "Evalset: [Train : Metrics { logloss:0.1532,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2009,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1691,  }]\n",
      "Training on Total Epoch: 886, Round: 886\n",
      "Evalset: [Train : Metrics { logloss:0.1529,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2005,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1688,  }]\n",
      "Training on Total Epoch: 887, Round: 887\n",
      "Evalset: [Train : Metrics { logloss:0.1526,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.2002,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1684,  }]\n",
      "Training on Total Epoch: 888, Round: 888\n",
      "Evalset: [Train : Metrics { logloss:0.1523,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1999,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1682,  }]\n",
      "Training on Total Epoch: 889, Round: 889\n",
      "Evalset: [Train : Metrics { logloss:0.1521,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1996,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.168,  }]\n",
      "Training on Total Epoch: 890, Round: 890\n",
      "Evalset: [Train : Metrics { logloss:0.1518,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1994,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1678,  }]\n",
      "Training on Total Epoch: 891, Round: 891\n",
      "Evalset: [Train : Metrics { logloss:0.1515,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1992,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1677,  }]\n",
      "Training on Total Epoch: 892, Round: 892\n",
      "Evalset: [Train : Metrics { logloss:0.1512,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.199,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1675,  }]\n",
      "Training on Total Epoch: 893, Round: 893\n",
      "Evalset: [Train : Metrics { logloss:0.1509,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1988,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1672,  }]\n",
      "Training on Total Epoch: 894, Round: 894\n",
      "Evalset: [Train : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1986,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1669,  }]\n",
      "Training on Total Epoch: 895, Round: 895\n",
      "Evalset: [Train : Metrics { logloss:0.1502,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1984,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1665,  }]\n",
      "Training on Total Epoch: 896, Round: 896\n",
      "Evalset: [Train : Metrics { logloss:0.1499,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1981,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1659,  }]\n",
      "Training on Total Epoch: 897, Round: 897\n",
      "Evalset: [Train : Metrics { logloss:0.1495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1978,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1655,  }]\n",
      "Training on Total Epoch: 898, Round: 898\n",
      "Evalset: [Train : Metrics { logloss:0.1492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1975,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1652,  }]\n",
      "Training on Total Epoch: 899, Round: 899\n",
      "Evalset: [Train : Metrics { logloss:0.149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1973,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1649,  }]\n",
      "Training on Total Epoch: 900, Round: 900\n",
      "Evalset: [Train : Metrics { logloss:0.1487,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1969,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1647,  }]\n",
      "Training on Total Epoch: 901, Round: 901\n",
      "Evalset: [Train : Metrics { logloss:0.1485,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1966,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1647,  }]\n",
      "Training on Total Epoch: 902, Round: 902\n",
      "Evalset: [Train : Metrics { logloss:0.1482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1963,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1646,  }]\n",
      "Training on Total Epoch: 903, Round: 903\n",
      "Evalset: [Train : Metrics { logloss:0.148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1645,  }]\n",
      "Training on Total Epoch: 904, Round: 904\n",
      "Evalset: [Train : Metrics { logloss:0.1477,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1957,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1643,  }]\n",
      "Training on Total Epoch: 905, Round: 905\n",
      "Evalset: [Train : Metrics { logloss:0.1474,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1954,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1641,  }]\n",
      "Training on Total Epoch: 906, Round: 906\n",
      "Evalset: [Train : Metrics { logloss:0.1471,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1952,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1638,  }]\n",
      "Training on Total Epoch: 907, Round: 907\n",
      "Evalset: [Train : Metrics { logloss:0.1468,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1949,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1635,  }]\n",
      "Training on Total Epoch: 908, Round: 908\n",
      "Evalset: [Train : Metrics { logloss:0.1465,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1947,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1632,  }]\n",
      "Training on Total Epoch: 909, Round: 909\n",
      "Evalset: [Train : Metrics { logloss:0.1462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1944,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.163,  }]\n",
      "Training on Total Epoch: 910, Round: 910\n",
      "Evalset: [Train : Metrics { logloss:0.146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1942,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1627,  }]\n",
      "Training on Total Epoch: 911, Round: 911\n",
      "Evalset: [Train : Metrics { logloss:0.1457,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.194,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1624,  }]\n",
      "Training on Total Epoch: 912, Round: 912\n",
      "Evalset: [Train : Metrics { logloss:0.1454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1938,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1621,  }]\n",
      "Training on Total Epoch: 913, Round: 913\n",
      "Evalset: [Train : Metrics { logloss:0.1451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1936,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.162,  }]\n",
      "Training on Total Epoch: 914, Round: 914\n",
      "Evalset: [Train : Metrics { logloss:0.1448,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1934,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1617,  }]\n",
      "Training on Total Epoch: 915, Round: 915\n",
      "Evalset: [Train : Metrics { logloss:0.1446,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1933,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1616,  }]\n",
      "Training on Total Epoch: 916, Round: 916\n",
      "Evalset: [Train : Metrics { logloss:0.1443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1931,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1613,  }]\n",
      "Training on Total Epoch: 917, Round: 917\n",
      "Evalset: [Train : Metrics { logloss:0.144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1931,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1611,  }]\n",
      "Training on Total Epoch: 918, Round: 918\n",
      "Evalset: [Train : Metrics { logloss:0.1437,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1929,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1608,  }]\n",
      "Training on Total Epoch: 919, Round: 919\n",
      "Evalset: [Train : Metrics { logloss:0.1434,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1926,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1604,  }]\n",
      "Training on Total Epoch: 920, Round: 920\n",
      "Evalset: [Train : Metrics { logloss:0.1431,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1923,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1599,  }]\n",
      "Training on Total Epoch: 921, Round: 921\n",
      "Evalset: [Train : Metrics { logloss:0.1428,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1922,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1596,  }]\n",
      "Training on Total Epoch: 922, Round: 922\n",
      "Evalset: [Train : Metrics { logloss:0.1425,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1921,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1594,  }]\n",
      "Training on Total Epoch: 923, Round: 923\n",
      "Evalset: [Train : Metrics { logloss:0.1422,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1591,  }]\n",
      "Training on Total Epoch: 924, Round: 924\n",
      "Evalset: [Train : Metrics { logloss:0.1419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1589,  }]\n",
      "Training on Total Epoch: 925, Round: 925\n",
      "Evalset: [Train : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1912,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1586,  }]\n",
      "Training on Total Epoch: 926, Round: 926\n",
      "Evalset: [Train : Metrics { logloss:0.1413,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1908,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1582,  }]\n",
      "Training on Total Epoch: 927, Round: 927\n",
      "Evalset: [Train : Metrics { logloss:0.141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1903,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1577,  }]\n",
      "Training on Total Epoch: 928, Round: 928\n",
      "Evalset: [Train : Metrics { logloss:0.1407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1574,  }]\n",
      "Training on Total Epoch: 929, Round: 929\n",
      "Evalset: [Train : Metrics { logloss:0.1405,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.157,  }]\n",
      "Training on Total Epoch: 930, Round: 930\n",
      "Evalset: [Train : Metrics { logloss:0.1402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1567,  }]\n",
      "Training on Total Epoch: 931, Round: 931\n",
      "Evalset: [Train : Metrics { logloss:0.1399,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1565,  }]\n",
      "Training on Total Epoch: 932, Round: 932\n",
      "Evalset: [Train : Metrics { logloss:0.1396,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1564,  }]\n",
      "Training on Total Epoch: 933, Round: 933\n",
      "Evalset: [Train : Metrics { logloss:0.1394,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1564,  }]\n",
      "Training on Total Epoch: 934, Round: 934\n",
      "Evalset: [Train : Metrics { logloss:0.1391,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1563,  }]\n",
      "Training on Total Epoch: 935, Round: 935\n",
      "Evalset: [Train : Metrics { logloss:0.1388,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1562,  }]\n",
      "Training on Total Epoch: 936, Round: 936\n",
      "Evalset: [Train : Metrics { logloss:0.1385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1559,  }]\n",
      "Training on Total Epoch: 937, Round: 937\n",
      "Evalset: [Train : Metrics { logloss:0.1382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1556,  }]\n",
      "Training on Total Epoch: 938, Round: 938\n",
      "Evalset: [Train : Metrics { logloss:0.1379,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1552,  }]\n",
      "Training on Total Epoch: 939, Round: 939\n",
      "Evalset: [Train : Metrics { logloss:0.1376,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1549,  }]\n",
      "Training on Total Epoch: 940, Round: 940\n",
      "Evalset: [Train : Metrics { logloss:0.1373,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1872,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1545,  }]\n",
      "Training on Total Epoch: 941, Round: 941\n",
      "Evalset: [Train : Metrics { logloss:0.1371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.187,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1541,  }]\n",
      "Training on Total Epoch: 942, Round: 942\n",
      "Evalset: [Train : Metrics { logloss:0.1368,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1868,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1539,  }]\n",
      "Training on Total Epoch: 943, Round: 943\n",
      "Evalset: [Train : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1867,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1537,  }]\n",
      "Training on Total Epoch: 944, Round: 944\n",
      "Evalset: [Train : Metrics { logloss:0.1362,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1866,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1536,  }]\n",
      "Training on Total Epoch: 945, Round: 945\n",
      "Evalset: [Train : Metrics { logloss:0.136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1865,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1535,  }]\n",
      "Training on Total Epoch: 946, Round: 946\n",
      "Evalset: [Train : Metrics { logloss:0.1357,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1864,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1532,  }]\n",
      "Training on Total Epoch: 947, Round: 947\n",
      "Evalset: [Train : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1862,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.153,  }]\n",
      "Training on Total Epoch: 948, Round: 948\n",
      "Evalset: [Train : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.186,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1528,  }]\n",
      "Training on Total Epoch: 949, Round: 949\n",
      "Evalset: [Train : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1858,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1527,  }]\n",
      "Training on Total Epoch: 950, Round: 950\n",
      "Evalset: [Train : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1857,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1525,  }]\n",
      "Training on Total Epoch: 951, Round: 951\n",
      "Evalset: [Train : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1855,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1524,  }]\n",
      "Training on Total Epoch: 952, Round: 952\n",
      "Evalset: [Train : Metrics { logloss:0.1342,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1852,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1522,  }]\n",
      "Training on Total Epoch: 953, Round: 953\n",
      "Evalset: [Train : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1849,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1518,  }]\n",
      "Training on Total Epoch: 954, Round: 954\n",
      "Evalset: [Train : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1847,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1516,  }]\n",
      "Training on Total Epoch: 955, Round: 955\n",
      "Evalset: [Train : Metrics { logloss:0.1334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1844,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1514,  }]\n",
      "Training on Total Epoch: 956, Round: 956\n",
      "Evalset: [Train : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1842,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1512,  }]\n",
      "Training on Total Epoch: 957, Round: 957\n",
      "Evalset: [Train : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1841,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1511,  }]\n",
      "Training on Total Epoch: 958, Round: 958\n",
      "Evalset: [Train : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1839,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1508,  }]\n",
      "Training on Total Epoch: 959, Round: 959\n",
      "Evalset: [Train : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1837,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1506,  }]\n",
      "Training on Total Epoch: 960, Round: 960\n",
      "Evalset: [Train : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1834,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1502,  }]\n",
      "Training on Total Epoch: 961, Round: 961\n",
      "Evalset: [Train : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1831,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1499,  }]\n",
      "Training on Total Epoch: 962, Round: 962\n",
      "Evalset: [Train : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1828,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1495,  }]\n",
      "Training on Total Epoch: 963, Round: 963\n",
      "Evalset: [Train : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1825,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1493,  }]\n",
      "Training on Total Epoch: 964, Round: 964\n",
      "Evalset: [Train : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1822,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1491,  }]\n",
      "Training on Total Epoch: 965, Round: 965\n",
      "Evalset: [Train : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.182,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.149,  }]\n",
      "Training on Total Epoch: 966, Round: 966\n",
      "Evalset: [Train : Metrics { logloss:0.1305,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1819,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1488,  }]\n",
      "Training on Total Epoch: 967, Round: 967\n",
      "Evalset: [Train : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1817,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1488,  }]\n",
      "Training on Total Epoch: 968, Round: 968\n",
      "Evalset: [Train : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1816,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1488,  }]\n",
      "Training on Total Epoch: 969, Round: 969\n",
      "Evalset: [Train : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1816,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1489,  }]\n",
      "Training on Total Epoch: 970, Round: 970\n",
      "Evalset: [Train : Metrics { logloss:0.1296,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1815,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1487,  }]\n",
      "Training on Total Epoch: 971, Round: 971\n",
      "Evalset: [Train : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1813,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1484,  }]\n",
      "Training on Total Epoch: 972, Round: 972\n",
      "Evalset: [Train : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1811,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.148,  }]\n",
      "Training on Total Epoch: 973, Round: 973\n",
      "Evalset: [Train : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1808,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1475,  }]\n",
      "Training on Total Epoch: 974, Round: 974\n",
      "Evalset: [Train : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1805,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1472,  }]\n",
      "Training on Total Epoch: 975, Round: 975\n",
      "Evalset: [Train : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1803,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1468,  }]\n",
      "Training on Total Epoch: 976, Round: 976\n",
      "Evalset: [Train : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.18,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1463,  }]\n",
      "Training on Total Epoch: 977, Round: 977\n",
      "Evalset: [Train : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1798,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1459,  }]\n",
      "Training on Total Epoch: 978, Round: 978\n",
      "Evalset: [Train : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1798,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1457,  }]\n",
      "Training on Total Epoch: 979, Round: 979\n",
      "Evalset: [Train : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1796,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1456,  }]\n",
      "Training on Total Epoch: 980, Round: 980\n",
      "Evalset: [Train : Metrics { logloss:0.127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1794,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1454,  }]\n",
      "Training on Total Epoch: 981, Round: 981\n",
      "Evalset: [Train : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1793,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1453,  }]\n",
      "Training on Total Epoch: 982, Round: 982\n",
      "Evalset: [Train : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1792,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1451,  }]\n",
      "Training on Total Epoch: 983, Round: 983\n",
      "Evalset: [Train : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.179,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1449,  }]\n",
      "Training on Total Epoch: 984, Round: 984\n",
      "Evalset: [Train : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1788,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1447,  }]\n",
      "Training on Total Epoch: 985, Round: 985\n",
      "Evalset: [Train : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1785,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1445,  }]\n",
      "Training on Total Epoch: 986, Round: 986\n",
      "Evalset: [Train : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1781,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1443,  }]\n",
      "Training on Total Epoch: 987, Round: 987\n",
      "Evalset: [Train : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1779,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.144,  }]\n",
      "Training on Total Epoch: 988, Round: 988\n",
      "Evalset: [Train : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1776,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1438,  }]\n",
      "Training on Total Epoch: 989, Round: 989\n",
      "Evalset: [Train : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1776,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1437,  }]\n",
      "Training on Total Epoch: 990, Round: 990\n",
      "Evalset: [Train : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1775,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1435,  }]\n",
      "Training on Total Epoch: 991, Round: 991\n",
      "Evalset: [Train : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1773,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1434,  }]\n",
      "Training on Total Epoch: 992, Round: 992\n",
      "Evalset: [Train : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1772,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1435,  }]\n",
      "Training on Total Epoch: 993, Round: 993\n",
      "Evalset: [Train : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1435,  }]\n",
      "Training on Total Epoch: 994, Round: 994\n",
      "Evalset: [Train : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1767,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1433,  }]\n",
      "Training on Total Epoch: 995, Round: 995\n",
      "Evalset: [Train : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1763,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.143,  }]\n",
      "Training on Total Epoch: 996, Round: 996\n",
      "Evalset: [Train : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1427,  }]\n",
      "Training on Total Epoch: 997, Round: 997\n",
      "Evalset: [Train : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1758,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1424,  }]\n",
      "Training on Total Epoch: 998, Round: 998\n",
      "Evalset: [Train : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1756,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1421,  }]\n",
      "Training on Total Epoch: 999, Round: 999\n",
      "Evalset: [Train : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1754,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1418,  }]\n",
      "Training on Total Epoch: 1000, Round: 1000\n",
      "Evalset: [Train : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1752,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1415,  }]\n",
      "Training on Total Epoch: 1001, Round: 1001\n",
      "Evalset: [Train : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1749,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1412,  }]\n",
      "Training on Total Epoch: 1002, Round: 1002\n",
      "Evalset: [Train : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1746,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1409,  }]\n",
      "Training on Total Epoch: 1003, Round: 1003\n",
      "Evalset: [Train : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1744,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1407,  }]\n",
      "Training on Total Epoch: 1004, Round: 1004\n",
      "Evalset: [Train : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1743,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1406,  }]\n",
      "Training on Total Epoch: 1005, Round: 1005\n",
      "Evalset: [Train : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1742,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1404,  }]\n",
      "Training on Total Epoch: 1006, Round: 1006\n",
      "Evalset: [Train : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1741,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1404,  }]\n",
      "Training on Total Epoch: 1007, Round: 1007\n",
      "Evalset: [Train : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1739,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1403,  }]\n",
      "Training on Total Epoch: 1008, Round: 1008\n",
      "Evalset: [Train : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1737,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1402,  }]\n",
      "Training on Total Epoch: 1009, Round: 1009\n",
      "Evalset: [Train : Metrics { logloss:0.1205,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1736,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1401,  }]\n",
      "Training on Total Epoch: 1010, Round: 1010\n",
      "Evalset: [Train : Metrics { logloss:0.1202,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1736,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1401,  }]\n",
      "Training on Total Epoch: 1011, Round: 1011\n",
      "Evalset: [Train : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1735,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1399,  }]\n",
      "Training on Total Epoch: 1012, Round: 1012\n",
      "Evalset: [Train : Metrics { logloss:0.1197,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1733,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1395,  }]\n",
      "Training on Total Epoch: 1013, Round: 1013\n",
      "Evalset: [Train : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1732,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1392,  }]\n",
      "Training on Total Epoch: 1014, Round: 1014\n",
      "Evalset: [Train : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.173,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.139,  }]\n",
      "Training on Total Epoch: 1015, Round: 1015\n",
      "Evalset: [Train : Metrics { logloss:0.119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1728,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1388,  }]\n",
      "Training on Total Epoch: 1016, Round: 1016\n",
      "Evalset: [Train : Metrics { logloss:0.1188,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1726,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1387,  }]\n",
      "Training on Total Epoch: 1017, Round: 1017\n",
      "Evalset: [Train : Metrics { logloss:0.1186,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1724,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1386,  }]\n",
      "Training on Total Epoch: 1018, Round: 1018\n",
      "Evalset: [Train : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1722,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1383,  }]\n",
      "Training on Total Epoch: 1019, Round: 1019\n",
      "Evalset: [Train : Metrics { logloss:0.1181,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1719,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1381,  }]\n",
      "Training on Total Epoch: 1020, Round: 1020\n",
      "Evalset: [Train : Metrics { logloss:0.1179,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1716,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1378,  }]\n",
      "Training on Total Epoch: 1021, Round: 1021\n",
      "Evalset: [Train : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1714,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1376,  }]\n",
      "Training on Total Epoch: 1022, Round: 1022\n",
      "Evalset: [Train : Metrics { logloss:0.1174,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1713,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1372,  }]\n",
      "Training on Total Epoch: 1023, Round: 1023\n",
      "Evalset: [Train : Metrics { logloss:0.1171,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1711,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1368,  }]\n",
      "Training on Total Epoch: 1024, Round: 1024\n",
      "Evalset: [Train : Metrics { logloss:0.1169,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.171,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1366,  }]\n",
      "Training on Total Epoch: 1025, Round: 1025\n",
      "Evalset: [Train : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1707,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1364,  }]\n",
      "Training on Total Epoch: 1026, Round: 1026\n",
      "Evalset: [Train : Metrics { logloss:0.1165,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1705,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1362,  }]\n",
      "Training on Total Epoch: 1027, Round: 1027\n",
      "Evalset: [Train : Metrics { logloss:0.1162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1702,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.136,  }]\n",
      "Training on Total Epoch: 1028, Round: 1028\n",
      "Evalset: [Train : Metrics { logloss:0.116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1701,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1357,  }]\n",
      "Training on Total Epoch: 1029, Round: 1029\n",
      "Evalset: [Train : Metrics { logloss:0.1158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1699,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1355,  }]\n",
      "Training on Total Epoch: 1030, Round: 1030\n",
      "Evalset: [Train : Metrics { logloss:0.1156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1698,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1355,  }]\n",
      "Training on Total Epoch: 1031, Round: 1031\n",
      "Evalset: [Train : Metrics { logloss:0.1154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1695,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1354,  }]\n",
      "Training on Total Epoch: 1032, Round: 1032\n",
      "Evalset: [Train : Metrics { logloss:0.1152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1693,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1352,  }]\n",
      "Training on Total Epoch: 1033, Round: 1033\n",
      "Evalset: [Train : Metrics { logloss:0.1151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1691,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1351,  }]\n",
      "Training on Total Epoch: 1034, Round: 1034\n",
      "Evalset: [Train : Metrics { logloss:0.1149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1689,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1349,  }]\n",
      "Training on Total Epoch: 1035, Round: 1035\n",
      "Evalset: [Train : Metrics { logloss:0.1147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1686,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1347,  }]\n",
      "Training on Total Epoch: 1036, Round: 1036\n",
      "Evalset: [Train : Metrics { logloss:0.1145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1684,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1344,  }]\n",
      "Training on Total Epoch: 1037, Round: 1037\n",
      "Evalset: [Train : Metrics { logloss:0.1142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1683,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.134,  }]\n",
      "Training on Total Epoch: 1038, Round: 1038\n",
      "Evalset: [Train : Metrics { logloss:0.114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1682,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1337,  }]\n",
      "Training on Total Epoch: 1039, Round: 1039\n",
      "Evalset: [Train : Metrics { logloss:0.1138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1682,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1336,  }]\n",
      "Training on Total Epoch: 1040, Round: 1040\n",
      "Evalset: [Train : Metrics { logloss:0.1136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1681,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1334,  }]\n",
      "Training on Total Epoch: 1041, Round: 1041\n",
      "Evalset: [Train : Metrics { logloss:0.1134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1333,  }]\n",
      "Training on Total Epoch: 1042, Round: 1042\n",
      "Evalset: [Train : Metrics { logloss:0.1132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1331,  }]\n",
      "Training on Total Epoch: 1043, Round: 1043\n",
      "Evalset: [Train : Metrics { logloss:0.113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1679,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1329,  }]\n",
      "Training on Total Epoch: 1044, Round: 1044\n",
      "Evalset: [Train : Metrics { logloss:0.1128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1677,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1327,  }]\n",
      "Training on Total Epoch: 1045, Round: 1045\n",
      "Evalset: [Train : Metrics { logloss:0.1125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1676,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1325,  }]\n",
      "Training on Total Epoch: 1046, Round: 1046\n",
      "Evalset: [Train : Metrics { logloss:0.1123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1674,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1323,  }]\n",
      "Training on Total Epoch: 1047, Round: 1047\n",
      "Evalset: [Train : Metrics { logloss:0.1121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1672,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1321,  }]\n",
      "Training on Total Epoch: 1048, Round: 1048\n",
      "Evalset: [Train : Metrics { logloss:0.1119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.132,  }]\n",
      "Training on Total Epoch: 1049, Round: 1049\n",
      "Evalset: [Train : Metrics { logloss:0.1117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1668,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1319,  }]\n",
      "Training on Total Epoch: 1050, Round: 1050\n",
      "Evalset: [Train : Metrics { logloss:0.1116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1666,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1318,  }]\n",
      "Training on Total Epoch: 1051, Round: 1051\n",
      "Evalset: [Train : Metrics { logloss:0.1114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1665,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1318,  }]\n",
      "Training on Total Epoch: 1052, Round: 1052\n",
      "Evalset: [Train : Metrics { logloss:0.1112,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1664,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1317,  }]\n",
      "Training on Total Epoch: 1053, Round: 1053\n",
      "Evalset: [Train : Metrics { logloss:0.111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1662,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1317,  }]\n",
      "Training on Total Epoch: 1054, Round: 1054\n",
      "Evalset: [Train : Metrics { logloss:0.1109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1316,  }]\n",
      "Training on Total Epoch: 1055, Round: 1055\n",
      "Evalset: [Train : Metrics { logloss:0.1107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1659,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1315,  }]\n",
      "Training on Total Epoch: 1056, Round: 1056\n",
      "Evalset: [Train : Metrics { logloss:0.1105,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1657,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1313,  }]\n",
      "Training on Total Epoch: 1057, Round: 1057\n",
      "Evalset: [Train : Metrics { logloss:0.1103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1656,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1312,  }]\n",
      "Training on Total Epoch: 1058, Round: 1058\n",
      "Evalset: [Train : Metrics { logloss:0.1102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1655,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1312,  }]\n",
      "Training on Total Epoch: 1059, Round: 1059\n",
      "Evalset: [Train : Metrics { logloss:0.1101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1654,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1313,  }]\n",
      "Training on Total Epoch: 1060, Round: 1060\n",
      "Evalset: [Train : Metrics { logloss:0.1099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1652,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1311,  }]\n",
      "Training on Total Epoch: 1061, Round: 1061\n",
      "Evalset: [Train : Metrics { logloss:0.1097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.165,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1309,  }]\n",
      "Training on Total Epoch: 1062, Round: 1062\n",
      "Evalset: [Train : Metrics { logloss:0.1095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1649,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1306,  }]\n",
      "Training on Total Epoch: 1063, Round: 1063\n",
      "Evalset: [Train : Metrics { logloss:0.1092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1647,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1304,  }]\n",
      "Training on Total Epoch: 1064, Round: 1064\n",
      "Evalset: [Train : Metrics { logloss:0.109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1646,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1301,  }]\n",
      "Training on Total Epoch: 1065, Round: 1065\n",
      "Evalset: [Train : Metrics { logloss:0.1087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1645,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1298,  }]\n",
      "Training on Total Epoch: 1066, Round: 1066\n",
      "Evalset: [Train : Metrics { logloss:0.1085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1645,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1295,  }]\n",
      "Training on Total Epoch: 1067, Round: 1067\n",
      "Evalset: [Train : Metrics { logloss:0.1082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1644,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1292,  }]\n",
      "Training on Total Epoch: 1068, Round: 1068\n",
      "Evalset: [Train : Metrics { logloss:0.1079,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1643,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1288,  }]\n",
      "Training on Total Epoch: 1069, Round: 1069\n",
      "Evalset: [Train : Metrics { logloss:0.1077,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1642,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1286,  }]\n",
      "Training on Total Epoch: 1070, Round: 1070\n",
      "Evalset: [Train : Metrics { logloss:0.1075,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1284,  }]\n",
      "Training on Total Epoch: 1071, Round: 1071\n",
      "Evalset: [Train : Metrics { logloss:0.1073,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1638,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1283,  }]\n",
      "Training on Total Epoch: 1072, Round: 1072\n",
      "Evalset: [Train : Metrics { logloss:0.1071,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1636,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1282,  }]\n",
      "Training on Total Epoch: 1073, Round: 1073\n",
      "Evalset: [Train : Metrics { logloss:0.1069,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1634,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1281,  }]\n",
      "Training on Total Epoch: 1074, Round: 1074\n",
      "Evalset: [Train : Metrics { logloss:0.1067,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1632,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1281,  }]\n",
      "Training on Total Epoch: 1075, Round: 1075\n",
      "Evalset: [Train : Metrics { logloss:0.1066,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1282,  }]\n",
      "Training on Total Epoch: 1076, Round: 1076\n",
      "Evalset: [Train : Metrics { logloss:0.1065,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1282,  }]\n",
      "Training on Total Epoch: 1077, Round: 1077\n",
      "Evalset: [Train : Metrics { logloss:0.1063,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1629,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1282,  }]\n",
      "Training on Total Epoch: 1078, Round: 1078\n",
      "Evalset: [Train : Metrics { logloss:0.1062,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1628,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1281,  }]\n",
      "Training on Total Epoch: 1079, Round: 1079\n",
      "Evalset: [Train : Metrics { logloss:0.106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1626,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.128,  }]\n",
      "Training on Total Epoch: 1080, Round: 1080\n",
      "Evalset: [Train : Metrics { logloss:0.1058,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1624,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1277,  }]\n",
      "Training on Total Epoch: 1081, Round: 1081\n",
      "Evalset: [Train : Metrics { logloss:0.1056,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1622,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1275,  }]\n",
      "Training on Total Epoch: 1082, Round: 1082\n",
      "Evalset: [Train : Metrics { logloss:0.1054,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1621,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1271,  }]\n",
      "Training on Total Epoch: 1083, Round: 1083\n",
      "Evalset: [Train : Metrics { logloss:0.1052,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.162,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1269,  }]\n",
      "Training on Total Epoch: 1084, Round: 1084\n",
      "Evalset: [Train : Metrics { logloss:0.105,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1619,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1266,  }]\n",
      "Training on Total Epoch: 1085, Round: 1085\n",
      "Evalset: [Train : Metrics { logloss:0.1048,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1618,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1265,  }]\n",
      "Training on Total Epoch: 1086, Round: 1086\n",
      "Evalset: [Train : Metrics { logloss:0.1046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1617,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1264,  }]\n",
      "Training on Total Epoch: 1087, Round: 1087\n",
      "Evalset: [Train : Metrics { logloss:0.1045,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1615,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1262,  }]\n",
      "Training on Total Epoch: 1088, Round: 1088\n",
      "Evalset: [Train : Metrics { logloss:0.1043,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1613,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.126,  }]\n",
      "Training on Total Epoch: 1089, Round: 1089\n",
      "Evalset: [Train : Metrics { logloss:0.1041,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1612,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1258,  }]\n",
      "Training on Total Epoch: 1090, Round: 1090\n",
      "Evalset: [Train : Metrics { logloss:0.1039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1611,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1256,  }]\n",
      "Training on Total Epoch: 1091, Round: 1091\n",
      "Evalset: [Train : Metrics { logloss:0.1037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1611,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1254,  }]\n",
      "Training on Total Epoch: 1092, Round: 1092\n",
      "Evalset: [Train : Metrics { logloss:0.1036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1611,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1253,  }]\n",
      "Training on Total Epoch: 1093, Round: 1093\n",
      "Evalset: [Train : Metrics { logloss:0.1034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1611,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1253,  }]\n",
      "Training on Total Epoch: 1094, Round: 1094\n",
      "Evalset: [Train : Metrics { logloss:0.1033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.161,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1253,  }]\n",
      "Training on Total Epoch: 1095, Round: 1095\n",
      "Evalset: [Train : Metrics { logloss:0.103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1609,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1251,  }]\n",
      "Training on Total Epoch: 1096, Round: 1096\n",
      "Evalset: [Train : Metrics { logloss:0.1028,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1608,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1249,  }]\n",
      "Training on Total Epoch: 1097, Round: 1097\n",
      "Evalset: [Train : Metrics { logloss:0.1027,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1608,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1249,  }]\n",
      "Training on Total Epoch: 1098, Round: 1098\n",
      "Evalset: [Train : Metrics { logloss:0.1025,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1607,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1247,  }]\n",
      "Training on Total Epoch: 1099, Round: 1099\n",
      "Evalset: [Train : Metrics { logloss:0.1023,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1605,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1246,  }]\n",
      "Training on Total Epoch: 1100, Round: 1100\n",
      "Evalset: [Train : Metrics { logloss:0.1021,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1603,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1244,  }]\n",
      "Training on Total Epoch: 1101, Round: 1101\n",
      "Evalset: [Train : Metrics { logloss:0.102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.16,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1243,  }]\n",
      "Training on Total Epoch: 1102, Round: 1102\n",
      "Evalset: [Train : Metrics { logloss:0.1018,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1596,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.124,  }]\n",
      "Training on Total Epoch: 1103, Round: 1103\n",
      "Evalset: [Train : Metrics { logloss:0.1016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1594,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1239,  }]\n",
      "Training on Total Epoch: 1104, Round: 1104\n",
      "Evalset: [Train : Metrics { logloss:0.1014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1592,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1238,  }]\n",
      "Training on Total Epoch: 1105, Round: 1105\n",
      "Evalset: [Train : Metrics { logloss:0.1013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1591,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1238,  }]\n",
      "Training on Total Epoch: 1106, Round: 1106\n",
      "Evalset: [Train : Metrics { logloss:0.1012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1589,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1237,  }]\n",
      "Training on Total Epoch: 1107, Round: 1107\n",
      "Evalset: [Train : Metrics { logloss:0.101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1588,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1236,  }]\n",
      "Training on Total Epoch: 1108, Round: 1108\n",
      "Evalset: [Train : Metrics { logloss:0.1007,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1586,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1234,  }]\n",
      "Training on Total Epoch: 1109, Round: 1109\n",
      "Evalset: [Train : Metrics { logloss:0.1005,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1584,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1231,  }]\n",
      "Training on Total Epoch: 1110, Round: 1110\n",
      "Evalset: [Train : Metrics { logloss:0.1003,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1583,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1229,  }]\n",
      "Training on Total Epoch: 1111, Round: 1111\n",
      "Evalset: [Train : Metrics { logloss:0.1001,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1581,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1226,  }]\n",
      "Training on Total Epoch: 1112, Round: 1112\n",
      "Evalset: [Train : Metrics { logloss:0.0999,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.158,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1223,  }]\n",
      "Training on Total Epoch: 1113, Round: 1113\n",
      "Evalset: [Train : Metrics { logloss:0.0997,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1578,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1221,  }]\n",
      "Training on Total Epoch: 1114, Round: 1114\n",
      "Evalset: [Train : Metrics { logloss:0.0996,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1577,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1218,  }]\n",
      "Training on Total Epoch: 1115, Round: 1115\n",
      "Evalset: [Train : Metrics { logloss:0.0994,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1575,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1217,  }]\n",
      "Training on Total Epoch: 1116, Round: 1116\n",
      "Evalset: [Train : Metrics { logloss:0.0992,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1572,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1214,  }]\n",
      "Training on Total Epoch: 1117, Round: 1117\n",
      "Evalset: [Train : Metrics { logloss:0.099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1571,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1211,  }]\n",
      "Training on Total Epoch: 1118, Round: 1118\n",
      "Evalset: [Train : Metrics { logloss:0.0989,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1568,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1208,  }]\n",
      "Training on Total Epoch: 1119, Round: 1119\n",
      "Evalset: [Train : Metrics { logloss:0.0987,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1567,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1207,  }]\n",
      "Training on Total Epoch: 1120, Round: 1120\n",
      "Evalset: [Train : Metrics { logloss:0.0986,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1566,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1207,  }]\n",
      "Training on Total Epoch: 1121, Round: 1121\n",
      "Evalset: [Train : Metrics { logloss:0.0984,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1564,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1206,  }]\n",
      "Training on Total Epoch: 1122, Round: 1122\n",
      "Evalset: [Train : Metrics { logloss:0.0983,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1564,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1205,  }]\n",
      "Training on Total Epoch: 1123, Round: 1123\n",
      "Evalset: [Train : Metrics { logloss:0.0981,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1563,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1204,  }]\n",
      "Training on Total Epoch: 1124, Round: 1124\n",
      "Evalset: [Train : Metrics { logloss:0.0979,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1562,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1203,  }]\n",
      "Training on Total Epoch: 1125, Round: 1125\n",
      "Evalset: [Train : Metrics { logloss:0.0978,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1562,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1203,  }]\n",
      "Training on Total Epoch: 1126, Round: 1126\n",
      "Evalset: [Train : Metrics { logloss:0.0976,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1562,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1202,  }]\n",
      "Training on Total Epoch: 1127, Round: 1127\n",
      "Evalset: [Train : Metrics { logloss:0.0975,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1562,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1203,  }]\n",
      "Training on Total Epoch: 1128, Round: 1128\n",
      "Evalset: [Train : Metrics { logloss:0.0973,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1562,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1203,  }]\n",
      "Training on Total Epoch: 1129, Round: 1129\n",
      "Evalset: [Train : Metrics { logloss:0.0972,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1561,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1203,  }]\n",
      "Training on Total Epoch: 1130, Round: 1130\n",
      "Evalset: [Train : Metrics { logloss:0.097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1559,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1202,  }]\n",
      "Training on Total Epoch: 1131, Round: 1131\n",
      "Evalset: [Train : Metrics { logloss:0.0969,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1558,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1201,  }]\n",
      "Training on Total Epoch: 1132, Round: 1132\n",
      "Evalset: [Train : Metrics { logloss:0.0967,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1557,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1199,  }]\n",
      "Training on Total Epoch: 1133, Round: 1133\n",
      "Evalset: [Train : Metrics { logloss:0.0965,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1555,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1195,  }]\n",
      "Training on Total Epoch: 1134, Round: 1134\n",
      "Evalset: [Train : Metrics { logloss:0.0962,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1553,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1191,  }]\n",
      "Training on Total Epoch: 1135, Round: 1135\n",
      "Evalset: [Train : Metrics { logloss:0.096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1551,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1189,  }]\n",
      "Training on Total Epoch: 1136, Round: 1136\n",
      "Evalset: [Train : Metrics { logloss:0.0958,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1549,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1187,  }]\n",
      "Training on Total Epoch: 1137, Round: 1137\n",
      "Evalset: [Train : Metrics { logloss:0.0957,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1547,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1185,  }]\n",
      "Training on Total Epoch: 1138, Round: 1138\n",
      "Evalset: [Train : Metrics { logloss:0.0955,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1545,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1184,  }]\n",
      "Training on Total Epoch: 1139, Round: 1139\n",
      "Evalset: [Train : Metrics { logloss:0.0953,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1543,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1182,  }]\n",
      "Training on Total Epoch: 1140, Round: 1140\n",
      "Evalset: [Train : Metrics { logloss:0.0952,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1541,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1181,  }]\n",
      "Training on Total Epoch: 1141, Round: 1141\n",
      "Evalset: [Train : Metrics { logloss:0.095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1539,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.118,  }]\n",
      "Training on Total Epoch: 1142, Round: 1142\n",
      "Evalset: [Train : Metrics { logloss:0.0948,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1537,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.118,  }]\n",
      "Training on Total Epoch: 1143, Round: 1143\n",
      "Evalset: [Train : Metrics { logloss:0.0947,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1537,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1179,  }]\n",
      "Training on Total Epoch: 1144, Round: 1144\n",
      "Evalset: [Train : Metrics { logloss:0.0946,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1535,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1178,  }]\n",
      "Training on Total Epoch: 1145, Round: 1145\n",
      "Evalset: [Train : Metrics { logloss:0.0944,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1533,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1176,  }]\n",
      "Training on Total Epoch: 1146, Round: 1146\n",
      "Evalset: [Train : Metrics { logloss:0.0942,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1532,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1173,  }]\n",
      "Training on Total Epoch: 1147, Round: 1147\n",
      "Evalset: [Train : Metrics { logloss:0.0939,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1532,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1171,  }]\n",
      "Training on Total Epoch: 1148, Round: 1148\n",
      "Evalset: [Train : Metrics { logloss:0.0937,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1531,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1169,  }]\n",
      "Training on Total Epoch: 1149, Round: 1149\n",
      "Evalset: [Train : Metrics { logloss:0.0935,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1529,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1166,  }]\n",
      "Training on Total Epoch: 1150, Round: 1150\n",
      "Evalset: [Train : Metrics { logloss:0.0934,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1528,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1165,  }]\n",
      "Training on Total Epoch: 1151, Round: 1151\n",
      "Evalset: [Train : Metrics { logloss:0.0932,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1526,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1164,  }]\n",
      "Training on Total Epoch: 1152, Round: 1152\n",
      "Evalset: [Train : Metrics { logloss:0.0931,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1525,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1164,  }]\n",
      "Training on Total Epoch: 1153, Round: 1153\n",
      "Evalset: [Train : Metrics { logloss:0.0929,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1524,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1164,  }]\n",
      "Training on Total Epoch: 1154, Round: 1154\n",
      "Evalset: [Train : Metrics { logloss:0.0928,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1524,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1164,  }]\n",
      "Training on Total Epoch: 1155, Round: 1155\n",
      "Evalset: [Train : Metrics { logloss:0.0927,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1523,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1165,  }]\n",
      "Training on Total Epoch: 1156, Round: 1156\n",
      "Evalset: [Train : Metrics { logloss:0.0926,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1523,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1164,  }]\n",
      "Training on Total Epoch: 1157, Round: 1157\n",
      "Evalset: [Train : Metrics { logloss:0.0924,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1523,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1163,  }]\n",
      "Training on Total Epoch: 1158, Round: 1158\n",
      "Evalset: [Train : Metrics { logloss:0.0922,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1522,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.116,  }]\n",
      "Training on Total Epoch: 1159, Round: 1159\n",
      "Evalset: [Train : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1521,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1158,  }]\n",
      "Training on Total Epoch: 1160, Round: 1160\n",
      "Evalset: [Train : Metrics { logloss:0.0919,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1521,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1156,  }]\n",
      "Training on Total Epoch: 1161, Round: 1161\n",
      "Evalset: [Train : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.152,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1155,  }]\n",
      "Training on Total Epoch: 1162, Round: 1162\n",
      "Evalset: [Train : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.152,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1154,  }]\n",
      "Training on Total Epoch: 1163, Round: 1163\n",
      "Evalset: [Train : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1519,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1154,  }]\n",
      "Training on Total Epoch: 1164, Round: 1164\n",
      "Evalset: [Train : Metrics { logloss:0.0913,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1518,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1154,  }]\n",
      "Training on Total Epoch: 1165, Round: 1165\n",
      "Evalset: [Train : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1516,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1153,  }]\n",
      "Training on Total Epoch: 1166, Round: 1166\n",
      "Evalset: [Train : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1514,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1151,  }]\n",
      "Training on Total Epoch: 1167, Round: 1167\n",
      "Evalset: [Train : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1512,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1149,  }]\n",
      "Training on Total Epoch: 1168, Round: 1168\n",
      "Evalset: [Train : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1508,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1147,  }]\n",
      "Training on Total Epoch: 1169, Round: 1169\n",
      "Evalset: [Train : Metrics { logloss:0.0903,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1144,  }]\n",
      "Training on Total Epoch: 1170, Round: 1170\n",
      "Evalset: [Train : Metrics { logloss:0.0901,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1142,  }]\n",
      "Training on Total Epoch: 1171, Round: 1171\n",
      "Evalset: [Train : Metrics { logloss:0.09,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1141,  }]\n",
      "Training on Total Epoch: 1172, Round: 1172\n",
      "Evalset: [Train : Metrics { logloss:0.0899,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1507,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1142,  }]\n",
      "Training on Total Epoch: 1173, Round: 1173\n",
      "Evalset: [Train : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1506,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1143,  }]\n",
      "Training on Total Epoch: 1174, Round: 1174\n",
      "Evalset: [Train : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1504,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1142,  }]\n",
      "Training on Total Epoch: 1175, Round: 1175\n",
      "Evalset: [Train : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1503,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1141,  }]\n",
      "Training on Total Epoch: 1176, Round: 1176\n",
      "Evalset: [Train : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1502,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.114,  }]\n",
      "Training on Total Epoch: 1177, Round: 1177\n",
      "Evalset: [Train : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.15,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1137,  }]\n",
      "Training on Total Epoch: 1178, Round: 1178\n",
      "Evalset: [Train : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1499,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1136,  }]\n",
      "Training on Total Epoch: 1179, Round: 1179\n",
      "Evalset: [Train : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1134,  }]\n",
      "Training on Total Epoch: 1180, Round: 1180\n",
      "Evalset: [Train : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1131,  }]\n",
      "Training on Total Epoch: 1181, Round: 1181\n",
      "Evalset: [Train : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1498,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1129,  }]\n",
      "Training on Total Epoch: 1182, Round: 1182\n",
      "Evalset: [Train : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1497,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1128,  }]\n",
      "Training on Total Epoch: 1183, Round: 1183\n",
      "Evalset: [Train : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1496,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1127,  }]\n",
      "Training on Total Epoch: 1184, Round: 1184\n",
      "Evalset: [Train : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1494,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1127,  }]\n",
      "Training on Total Epoch: 1185, Round: 1185\n",
      "Evalset: [Train : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1493,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1127,  }]\n",
      "Training on Total Epoch: 1186, Round: 1186\n",
      "Evalset: [Train : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1491,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1125,  }]\n",
      "Training on Total Epoch: 1187, Round: 1187\n",
      "Evalset: [Train : Metrics { logloss:0.0875,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.149,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1124,  }]\n",
      "Training on Total Epoch: 1188, Round: 1188\n",
      "Evalset: [Train : Metrics { logloss:0.0874,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1488,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1124,  }]\n",
      "Training on Total Epoch: 1189, Round: 1189\n",
      "Evalset: [Train : Metrics { logloss:0.0872,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1486,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1123,  }]\n",
      "Training on Total Epoch: 1190, Round: 1190\n",
      "Evalset: [Train : Metrics { logloss:0.0871,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1486,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1122,  }]\n",
      "Training on Total Epoch: 1191, Round: 1191\n",
      "Evalset: [Train : Metrics { logloss:0.0869,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1485,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.112,  }]\n",
      "Training on Total Epoch: 1192, Round: 1192\n",
      "Evalset: [Train : Metrics { logloss:0.0868,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1485,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1119,  }]\n",
      "Training on Total Epoch: 1193, Round: 1193\n",
      "Evalset: [Train : Metrics { logloss:0.0867,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1485,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1118,  }]\n",
      "Training on Total Epoch: 1194, Round: 1194\n",
      "Evalset: [Train : Metrics { logloss:0.0865,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1486,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1117,  }]\n",
      "Training on Total Epoch: 1195, Round: 1195\n",
      "Evalset: [Train : Metrics { logloss:0.0864,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1485,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1116,  }]\n",
      "Training on Total Epoch: 1196, Round: 1196\n",
      "Evalset: [Train : Metrics { logloss:0.0862,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1484,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1115,  }]\n",
      "Training on Total Epoch: 1197, Round: 1197\n",
      "Evalset: [Train : Metrics { logloss:0.0861,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1483,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1114,  }]\n",
      "Training on Total Epoch: 1198, Round: 1198\n",
      "Evalset: [Train : Metrics { logloss:0.0859,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1482,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1113,  }]\n",
      "Training on Total Epoch: 1199, Round: 1199\n",
      "Evalset: [Train : Metrics { logloss:0.0857,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1481,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1112,  }]\n",
      "Training on Total Epoch: 1200, Round: 1200\n",
      "Evalset: [Train : Metrics { logloss:0.0856,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1481,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1111,  }]\n",
      "Training on Total Epoch: 1201, Round: 1201\n",
      "Evalset: [Train : Metrics { logloss:0.0855,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.148,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1112,  }]\n",
      "Training on Total Epoch: 1202, Round: 1202\n",
      "Evalset: [Train : Metrics { logloss:0.0854,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1479,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1112,  }]\n",
      "Training on Total Epoch: 1203, Round: 1203\n",
      "Evalset: [Train : Metrics { logloss:0.0852,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1477,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.111,  }]\n",
      "Training on Total Epoch: 1204, Round: 1204\n",
      "Evalset: [Train : Metrics { logloss:0.0851,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1474,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1108,  }]\n",
      "Training on Total Epoch: 1205, Round: 1205\n",
      "Evalset: [Train : Metrics { logloss:0.0849,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1473,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1106,  }]\n",
      "Training on Total Epoch: 1206, Round: 1206\n",
      "Evalset: [Train : Metrics { logloss:0.0847,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1472,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1103,  }]\n",
      "Training on Total Epoch: 1207, Round: 1207\n",
      "Evalset: [Train : Metrics { logloss:0.0846,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1471,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1101,  }]\n",
      "Training on Total Epoch: 1208, Round: 1208\n",
      "Evalset: [Train : Metrics { logloss:0.0844,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.147,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1099,  }]\n",
      "Training on Total Epoch: 1209, Round: 1209\n",
      "Evalset: [Train : Metrics { logloss:0.0842,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1468,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1097,  }]\n",
      "Training on Total Epoch: 1210, Round: 1210\n",
      "Evalset: [Train : Metrics { logloss:0.0841,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1466,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1096,  }]\n",
      "Training on Total Epoch: 1211, Round: 1211\n",
      "Evalset: [Train : Metrics { logloss:0.084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1464,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1094,  }]\n",
      "Training on Total Epoch: 1212, Round: 1212\n",
      "Evalset: [Train : Metrics { logloss:0.0838,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1462,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1091,  }]\n",
      "Training on Total Epoch: 1213, Round: 1213\n",
      "Evalset: [Train : Metrics { logloss:0.0837,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1461,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1089,  }]\n",
      "Training on Total Epoch: 1214, Round: 1214\n",
      "Evalset: [Train : Metrics { logloss:0.0836,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.146,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1087,  }]\n",
      "Training on Total Epoch: 1215, Round: 1215\n",
      "Evalset: [Train : Metrics { logloss:0.0834,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1459,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1086,  }]\n",
      "Training on Total Epoch: 1216, Round: 1216\n",
      "Evalset: [Train : Metrics { logloss:0.0833,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1459,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1086,  }]\n",
      "Training on Total Epoch: 1217, Round: 1217\n",
      "Evalset: [Train : Metrics { logloss:0.0832,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1459,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1086,  }]\n",
      "Training on Total Epoch: 1218, Round: 1218\n",
      "Evalset: [Train : Metrics { logloss:0.0831,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1458,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1085,  }]\n",
      "Training on Total Epoch: 1219, Round: 1219\n",
      "Evalset: [Train : Metrics { logloss:0.0829,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1456,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1085,  }]\n",
      "Training on Total Epoch: 1220, Round: 1220\n",
      "Evalset: [Train : Metrics { logloss:0.0829,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1455,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1086,  }]\n",
      "Training on Total Epoch: 1221, Round: 1221\n",
      "Evalset: [Train : Metrics { logloss:0.0827,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1454,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1086,  }]\n",
      "Training on Total Epoch: 1222, Round: 1222\n",
      "Evalset: [Train : Metrics { logloss:0.0826,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1452,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1088,  }]\n",
      "Training on Total Epoch: 1223, Round: 1223\n",
      "Evalset: [Train : Metrics { logloss:0.0825,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1451,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1088,  }]\n",
      "Training on Total Epoch: 1224, Round: 1224\n",
      "Evalset: [Train : Metrics { logloss:0.0824,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.145,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1087,  }]\n",
      "Training on Total Epoch: 1225, Round: 1225\n",
      "Evalset: [Train : Metrics { logloss:0.0822,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1449,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1085,  }]\n",
      "Training on Total Epoch: 1226, Round: 1226\n",
      "Evalset: [Train : Metrics { logloss:0.082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1448,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1082,  }]\n",
      "Training on Total Epoch: 1227, Round: 1227\n",
      "Evalset: [Train : Metrics { logloss:0.0818,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1447,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1079,  }]\n",
      "Training on Total Epoch: 1228, Round: 1228\n",
      "Evalset: [Train : Metrics { logloss:0.0816,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1445,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1076,  }]\n",
      "Training on Total Epoch: 1229, Round: 1229\n",
      "Evalset: [Train : Metrics { logloss:0.0815,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1444,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1074,  }]\n",
      "Training on Total Epoch: 1230, Round: 1230\n",
      "Evalset: [Train : Metrics { logloss:0.0813,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1443,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1074,  }]\n",
      "Training on Total Epoch: 1231, Round: 1231\n",
      "Evalset: [Train : Metrics { logloss:0.0812,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1442,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1072,  }]\n",
      "Training on Total Epoch: 1232, Round: 1232\n",
      "Evalset: [Train : Metrics { logloss:0.0811,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1441,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1071,  }]\n",
      "Training on Total Epoch: 1233, Round: 1233\n",
      "Evalset: [Train : Metrics { logloss:0.0809,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1442,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1071,  }]\n",
      "Training on Total Epoch: 1234, Round: 1234\n",
      "Evalset: [Train : Metrics { logloss:0.0808,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1441,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1071,  }]\n",
      "Training on Total Epoch: 1235, Round: 1235\n",
      "Evalset: [Train : Metrics { logloss:0.0807,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1441,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1071,  }]\n",
      "Training on Total Epoch: 1236, Round: 1236\n",
      "Evalset: [Train : Metrics { logloss:0.0806,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.144,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1071,  }]\n",
      "Training on Total Epoch: 1237, Round: 1237\n",
      "Evalset: [Train : Metrics { logloss:0.0805,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1439,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1071,  }]\n",
      "Training on Total Epoch: 1238, Round: 1238\n",
      "Evalset: [Train : Metrics { logloss:0.0804,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1438,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1069,  }]\n",
      "Training on Total Epoch: 1239, Round: 1239\n",
      "Evalset: [Train : Metrics { logloss:0.0802,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1437,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1066,  }]\n",
      "Training on Total Epoch: 1240, Round: 1240\n",
      "Evalset: [Train : Metrics { logloss:0.0801,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1435,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1064,  }]\n",
      "Training on Total Epoch: 1241, Round: 1241\n",
      "Evalset: [Train : Metrics { logloss:0.08,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1063,  }]\n",
      "Training on Total Epoch: 1242, Round: 1242\n",
      "Evalset: [Train : Metrics { logloss:0.0798,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1432,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1061,  }]\n",
      "Training on Total Epoch: 1243, Round: 1243\n",
      "Evalset: [Train : Metrics { logloss:0.0797,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1432,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.106,  }]\n",
      "Training on Total Epoch: 1244, Round: 1244\n",
      "Evalset: [Train : Metrics { logloss:0.0796,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1059,  }]\n",
      "Training on Total Epoch: 1245, Round: 1245\n",
      "Evalset: [Train : Metrics { logloss:0.0795,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1059,  }]\n",
      "Training on Total Epoch: 1246, Round: 1246\n",
      "Evalset: [Train : Metrics { logloss:0.0794,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1433,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1058,  }]\n",
      "Training on Total Epoch: 1247, Round: 1247\n",
      "Evalset: [Train : Metrics { logloss:0.0793,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1432,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1058,  }]\n",
      "Training on Total Epoch: 1248, Round: 1248\n",
      "Evalset: [Train : Metrics { logloss:0.0792,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.143,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1058,  }]\n",
      "Training on Total Epoch: 1249, Round: 1249\n",
      "Evalset: [Train : Metrics { logloss:0.0791,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1428,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1057,  }]\n",
      "Training on Total Epoch: 1250, Round: 1250\n",
      "Evalset: [Train : Metrics { logloss:0.079,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1426,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1056,  }]\n",
      "Training on Total Epoch: 1251, Round: 1251\n",
      "Evalset: [Train : Metrics { logloss:0.0788,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1424,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1053,  }]\n",
      "Training on Total Epoch: 1252, Round: 1252\n",
      "Evalset: [Train : Metrics { logloss:0.0786,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1421,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1049,  }]\n",
      "Training on Total Epoch: 1253, Round: 1253\n",
      "Evalset: [Train : Metrics { logloss:0.0784,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1419,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1046,  }]\n",
      "Training on Total Epoch: 1254, Round: 1254\n",
      "Evalset: [Train : Metrics { logloss:0.0783,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1418,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1044,  }]\n",
      "Training on Total Epoch: 1255, Round: 1255\n",
      "Evalset: [Train : Metrics { logloss:0.0782,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1417,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1042,  }]\n",
      "Training on Total Epoch: 1256, Round: 1256\n",
      "Evalset: [Train : Metrics { logloss:0.078,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1417,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1041,  }]\n",
      "Training on Total Epoch: 1257, Round: 1257\n",
      "Evalset: [Train : Metrics { logloss:0.0779,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1416,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1041,  }]\n",
      "Training on Total Epoch: 1258, Round: 1258\n",
      "Evalset: [Train : Metrics { logloss:0.0778,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1415,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1041,  }]\n",
      "Training on Total Epoch: 1259, Round: 1259\n",
      "Evalset: [Train : Metrics { logloss:0.0777,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1414,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.104,  }]\n",
      "Training on Total Epoch: 1260, Round: 1260\n",
      "Evalset: [Train : Metrics { logloss:0.0775,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1411,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1039,  }]\n",
      "Training on Total Epoch: 1261, Round: 1261\n",
      "Evalset: [Train : Metrics { logloss:0.0774,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 1262, Round: 1262\n",
      "Evalset: [Train : Metrics { logloss:0.0773,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1408,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 1263, Round: 1263\n",
      "Evalset: [Train : Metrics { logloss:0.0771,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 1264, Round: 1264\n",
      "Evalset: [Train : Metrics { logloss:0.077,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.141,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 1265, Round: 1265\n",
      "Evalset: [Train : Metrics { logloss:0.0769,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1411,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1037,  }]\n",
      "Training on Total Epoch: 1266, Round: 1266\n",
      "Evalset: [Train : Metrics { logloss:0.0767,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1411,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1036,  }]\n",
      "Training on Total Epoch: 1267, Round: 1267\n",
      "Evalset: [Train : Metrics { logloss:0.0766,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1035,  }]\n",
      "Training on Total Epoch: 1268, Round: 1268\n",
      "Evalset: [Train : Metrics { logloss:0.0765,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1035,  }]\n",
      "Training on Total Epoch: 1269, Round: 1269\n",
      "Evalset: [Train : Metrics { logloss:0.0764,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1035,  }]\n",
      "Training on Total Epoch: 1270, Round: 1270\n",
      "Evalset: [Train : Metrics { logloss:0.0763,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.141,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1034,  }]\n",
      "Training on Total Epoch: 1271, Round: 1271\n",
      "Evalset: [Train : Metrics { logloss:0.0762,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.141,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1033,  }]\n",
      "Training on Total Epoch: 1272, Round: 1272\n",
      "Evalset: [Train : Metrics { logloss:0.076,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1409,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1032,  }]\n",
      "Training on Total Epoch: 1273, Round: 1273\n",
      "Evalset: [Train : Metrics { logloss:0.0759,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1407,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.103,  }]\n",
      "Training on Total Epoch: 1274, Round: 1274\n",
      "Evalset: [Train : Metrics { logloss:0.0757,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1406,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1028,  }]\n",
      "Training on Total Epoch: 1275, Round: 1275\n",
      "Evalset: [Train : Metrics { logloss:0.0756,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1404,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 1276, Round: 1276\n",
      "Evalset: [Train : Metrics { logloss:0.0755,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1403,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 1277, Round: 1277\n",
      "Evalset: [Train : Metrics { logloss:0.0754,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1401,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 1278, Round: 1278\n",
      "Evalset: [Train : Metrics { logloss:0.0753,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1401,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1027,  }]\n",
      "Training on Total Epoch: 1279, Round: 1279\n",
      "Evalset: [Train : Metrics { logloss:0.0752,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.14,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1026,  }]\n",
      "Training on Total Epoch: 1280, Round: 1280\n",
      "Evalset: [Train : Metrics { logloss:0.0751,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.14,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1025,  }]\n",
      "Training on Total Epoch: 1281, Round: 1281\n",
      "Evalset: [Train : Metrics { logloss:0.075,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.14,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1023,  }]\n",
      "Training on Total Epoch: 1282, Round: 1282\n",
      "Evalset: [Train : Metrics { logloss:0.0748,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.14,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1022,  }]\n",
      "Training on Total Epoch: 1283, Round: 1283\n",
      "Evalset: [Train : Metrics { logloss:0.0747,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.14,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1021,  }]\n",
      "Training on Total Epoch: 1284, Round: 1284\n",
      "Evalset: [Train : Metrics { logloss:0.0746,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1399,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.102,  }]\n",
      "Training on Total Epoch: 1285, Round: 1285\n",
      "Evalset: [Train : Metrics { logloss:0.0745,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1398,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.102,  }]\n",
      "Training on Total Epoch: 1286, Round: 1286\n",
      "Evalset: [Train : Metrics { logloss:0.0743,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1397,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1018,  }]\n",
      "Training on Total Epoch: 1287, Round: 1287\n",
      "Evalset: [Train : Metrics { logloss:0.0742,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1395,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1017,  }]\n",
      "Training on Total Epoch: 1288, Round: 1288\n",
      "Evalset: [Train : Metrics { logloss:0.0741,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1392,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1016,  }]\n",
      "Training on Total Epoch: 1289, Round: 1289\n",
      "Evalset: [Train : Metrics { logloss:0.074,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1389,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1015,  }]\n",
      "Training on Total Epoch: 1290, Round: 1290\n",
      "Evalset: [Train : Metrics { logloss:0.0739,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1387,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1013,  }]\n",
      "Training on Total Epoch: 1291, Round: 1291\n",
      "Evalset: [Train : Metrics { logloss:0.0738,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1386,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1012,  }]\n",
      "Training on Total Epoch: 1292, Round: 1292\n",
      "Evalset: [Train : Metrics { logloss:0.0736,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1386,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1011,  }]\n",
      "Training on Total Epoch: 1293, Round: 1293\n",
      "Evalset: [Train : Metrics { logloss:0.0735,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1385,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.101,  }]\n",
      "Training on Total Epoch: 1294, Round: 1294\n",
      "Evalset: [Train : Metrics { logloss:0.0734,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1385,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1009,  }]\n",
      "Training on Total Epoch: 1295, Round: 1295\n",
      "Evalset: [Train : Metrics { logloss:0.0732,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1008,  }]\n",
      "Training on Total Epoch: 1296, Round: 1296\n",
      "Evalset: [Train : Metrics { logloss:0.0731,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1008,  }]\n",
      "Training on Total Epoch: 1297, Round: 1297\n",
      "Evalset: [Train : Metrics { logloss:0.073,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1009,  }]\n",
      "Training on Total Epoch: 1298, Round: 1298\n",
      "Evalset: [Train : Metrics { logloss:0.073,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1385,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1009,  }]\n",
      "Training on Total Epoch: 1299, Round: 1299\n",
      "Evalset: [Train : Metrics { logloss:0.0729,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1386,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1009,  }]\n",
      "Training on Total Epoch: 1300, Round: 1300\n",
      "Evalset: [Train : Metrics { logloss:0.0728,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1386,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1007,  }]\n",
      "Training on Total Epoch: 1301, Round: 1301\n",
      "Evalset: [Train : Metrics { logloss:0.0727,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1385,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1005,  }]\n",
      "Training on Total Epoch: 1302, Round: 1302\n",
      "Evalset: [Train : Metrics { logloss:0.0725,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1003,  }]\n",
      "Training on Total Epoch: 1303, Round: 1303\n",
      "Evalset: [Train : Metrics { logloss:0.0724,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1384,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1002,  }]\n",
      "Training on Total Epoch: 1304, Round: 1304\n",
      "Evalset: [Train : Metrics { logloss:0.0723,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1383,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1002,  }]\n",
      "Training on Total Epoch: 1305, Round: 1305\n",
      "Evalset: [Train : Metrics { logloss:0.0722,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1381,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1001,  }]\n",
      "Training on Total Epoch: 1306, Round: 1306\n",
      "Evalset: [Train : Metrics { logloss:0.0722,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1379,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1001,  }]\n",
      "Training on Total Epoch: 1307, Round: 1307\n",
      "Evalset: [Train : Metrics { logloss:0.0721,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1379,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.1,  }]\n",
      "Training on Total Epoch: 1308, Round: 1308\n",
      "Evalset: [Train : Metrics { logloss:0.0719,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1378,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0999,  }]\n",
      "Training on Total Epoch: 1309, Round: 1309\n",
      "Evalset: [Train : Metrics { logloss:0.0718,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0997,  }]\n",
      "Training on Total Epoch: 1310, Round: 1310\n",
      "Evalset: [Train : Metrics { logloss:0.0716,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0995,  }]\n",
      "Training on Total Epoch: 1311, Round: 1311\n",
      "Evalset: [Train : Metrics { logloss:0.0715,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1378,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0993,  }]\n",
      "Training on Total Epoch: 1312, Round: 1312\n",
      "Evalset: [Train : Metrics { logloss:0.0713,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0991,  }]\n",
      "Training on Total Epoch: 1313, Round: 1313\n",
      "Evalset: [Train : Metrics { logloss:0.0712,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0989,  }]\n",
      "Training on Total Epoch: 1314, Round: 1314\n",
      "Evalset: [Train : Metrics { logloss:0.071,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1377,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0987,  }]\n",
      "Training on Total Epoch: 1315, Round: 1315\n",
      "Evalset: [Train : Metrics { logloss:0.0709,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1376,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0986,  }]\n",
      "Training on Total Epoch: 1316, Round: 1316\n",
      "Evalset: [Train : Metrics { logloss:0.0709,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1374,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0986,  }]\n",
      "Training on Total Epoch: 1317, Round: 1317\n",
      "Evalset: [Train : Metrics { logloss:0.0708,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1373,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0986,  }]\n",
      "Training on Total Epoch: 1318, Round: 1318\n",
      "Evalset: [Train : Metrics { logloss:0.0707,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1371,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0986,  }]\n",
      "Training on Total Epoch: 1319, Round: 1319\n",
      "Evalset: [Train : Metrics { logloss:0.0706,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.137,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0987,  }]\n",
      "Training on Total Epoch: 1320, Round: 1320\n",
      "Evalset: [Train : Metrics { logloss:0.0705,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1368,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0987,  }]\n",
      "Training on Total Epoch: 1321, Round: 1321\n",
      "Evalset: [Train : Metrics { logloss:0.0704,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1368,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0987,  }]\n",
      "Training on Total Epoch: 1322, Round: 1322\n",
      "Evalset: [Train : Metrics { logloss:0.0703,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1367,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0986,  }]\n",
      "Training on Total Epoch: 1323, Round: 1323\n",
      "Evalset: [Train : Metrics { logloss:0.0701,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1366,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0985,  }]\n",
      "Training on Total Epoch: 1324, Round: 1324\n",
      "Evalset: [Train : Metrics { logloss:0.07,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1366,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0984,  }]\n",
      "Training on Total Epoch: 1325, Round: 1325\n",
      "Evalset: [Train : Metrics { logloss:0.0699,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0984,  }]\n",
      "Training on Total Epoch: 1326, Round: 1326\n",
      "Evalset: [Train : Metrics { logloss:0.0698,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0983,  }]\n",
      "Training on Total Epoch: 1327, Round: 1327\n",
      "Evalset: [Train : Metrics { logloss:0.0696,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0981,  }]\n",
      "Training on Total Epoch: 1328, Round: 1328\n",
      "Evalset: [Train : Metrics { logloss:0.0695,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1365,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0979,  }]\n",
      "Training on Total Epoch: 1329, Round: 1329\n",
      "Evalset: [Train : Metrics { logloss:0.0694,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1364,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0978,  }]\n",
      "Training on Total Epoch: 1330, Round: 1330\n",
      "Evalset: [Train : Metrics { logloss:0.0693,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1364,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0976,  }]\n",
      "Training on Total Epoch: 1331, Round: 1331\n",
      "Evalset: [Train : Metrics { logloss:0.0692,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1363,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0975,  }]\n",
      "Training on Total Epoch: 1332, Round: 1332\n",
      "Evalset: [Train : Metrics { logloss:0.069,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1361,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0973,  }]\n",
      "Training on Total Epoch: 1333, Round: 1333\n",
      "Evalset: [Train : Metrics { logloss:0.0689,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.136,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0971,  }]\n",
      "Training on Total Epoch: 1334, Round: 1334\n",
      "Evalset: [Train : Metrics { logloss:0.0688,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0969,  }]\n",
      "Training on Total Epoch: 1335, Round: 1335\n",
      "Evalset: [Train : Metrics { logloss:0.0687,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1359,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0968,  }]\n",
      "Training on Total Epoch: 1336, Round: 1336\n",
      "Evalset: [Train : Metrics { logloss:0.0686,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1358,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0967,  }]\n",
      "Training on Total Epoch: 1337, Round: 1337\n",
      "Evalset: [Train : Metrics { logloss:0.0685,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1357,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1338, Round: 1338\n",
      "Evalset: [Train : Metrics { logloss:0.0684,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1355,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1339, Round: 1339\n",
      "Evalset: [Train : Metrics { logloss:0.0683,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1340, Round: 1340\n",
      "Evalset: [Train : Metrics { logloss:0.0681,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0965,  }]\n",
      "Training on Total Epoch: 1341, Round: 1341\n",
      "Evalset: [Train : Metrics { logloss:0.0681,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0964,  }]\n",
      "Training on Total Epoch: 1342, Round: 1342\n",
      "Evalset: [Train : Metrics { logloss:0.068,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0965,  }]\n",
      "Training on Total Epoch: 1343, Round: 1343\n",
      "Evalset: [Train : Metrics { logloss:0.0679,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0966,  }]\n",
      "Training on Total Epoch: 1344, Round: 1344\n",
      "Evalset: [Train : Metrics { logloss:0.0679,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0965,  }]\n",
      "Training on Total Epoch: 1345, Round: 1345\n",
      "Evalset: [Train : Metrics { logloss:0.0678,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0965,  }]\n",
      "Training on Total Epoch: 1346, Round: 1346\n",
      "Evalset: [Train : Metrics { logloss:0.0677,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0964,  }]\n",
      "Training on Total Epoch: 1347, Round: 1347\n",
      "Evalset: [Train : Metrics { logloss:0.0676,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0964,  }]\n",
      "Training on Total Epoch: 1348, Round: 1348\n",
      "Evalset: [Train : Metrics { logloss:0.0675,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1354,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0965,  }]\n",
      "Training on Total Epoch: 1349, Round: 1349\n",
      "Evalset: [Train : Metrics { logloss:0.0674,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1353,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0965,  }]\n",
      "Training on Total Epoch: 1350, Round: 1350\n",
      "Evalset: [Train : Metrics { logloss:0.0673,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0964,  }]\n",
      "Training on Total Epoch: 1351, Round: 1351\n",
      "Evalset: [Train : Metrics { logloss:0.0672,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1352,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0964,  }]\n",
      "Training on Total Epoch: 1352, Round: 1352\n",
      "Evalset: [Train : Metrics { logloss:0.0671,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1351,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0963,  }]\n",
      "Training on Total Epoch: 1353, Round: 1353\n",
      "Evalset: [Train : Metrics { logloss:0.0669,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0962,  }]\n",
      "Training on Total Epoch: 1354, Round: 1354\n",
      "Evalset: [Train : Metrics { logloss:0.0668,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.096,  }]\n",
      "Training on Total Epoch: 1355, Round: 1355\n",
      "Evalset: [Train : Metrics { logloss:0.0667,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0958,  }]\n",
      "Training on Total Epoch: 1356, Round: 1356\n",
      "Evalset: [Train : Metrics { logloss:0.0665,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0954,  }]\n",
      "Training on Total Epoch: 1357, Round: 1357\n",
      "Evalset: [Train : Metrics { logloss:0.0663,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1358, Round: 1358\n",
      "Evalset: [Train : Metrics { logloss:0.0662,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0952,  }]\n",
      "Training on Total Epoch: 1359, Round: 1359\n",
      "Evalset: [Train : Metrics { logloss:0.0661,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.135,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0951,  }]\n",
      "Training on Total Epoch: 1360, Round: 1360\n",
      "Evalset: [Train : Metrics { logloss:0.066,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1349,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1361, Round: 1361\n",
      "Evalset: [Train : Metrics { logloss:0.0659,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1348,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1362, Round: 1362\n",
      "Evalset: [Train : Metrics { logloss:0.0658,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1347,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1363, Round: 1363\n",
      "Evalset: [Train : Metrics { logloss:0.0657,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1345,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0951,  }]\n",
      "Training on Total Epoch: 1364, Round: 1364\n",
      "Evalset: [Train : Metrics { logloss:0.0656,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1343,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0951,  }]\n",
      "Training on Total Epoch: 1365, Round: 1365\n",
      "Evalset: [Train : Metrics { logloss:0.0655,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1342,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0951,  }]\n",
      "Training on Total Epoch: 1366, Round: 1366\n",
      "Evalset: [Train : Metrics { logloss:0.0654,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1367, Round: 1367\n",
      "Evalset: [Train : Metrics { logloss:0.0653,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1341,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1368, Round: 1368\n",
      "Evalset: [Train : Metrics { logloss:0.0653,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.134,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1369, Round: 1369\n",
      "Evalset: [Train : Metrics { logloss:0.0652,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.095,  }]\n",
      "Training on Total Epoch: 1370, Round: 1370\n",
      "Evalset: [Train : Metrics { logloss:0.0651,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1339,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0949,  }]\n",
      "Training on Total Epoch: 1371, Round: 1371\n",
      "Evalset: [Train : Metrics { logloss:0.0649,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1338,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0947,  }]\n",
      "Training on Total Epoch: 1372, Round: 1372\n",
      "Evalset: [Train : Metrics { logloss:0.0648,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1337,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0945,  }]\n",
      "Training on Total Epoch: 1373, Round: 1373\n",
      "Evalset: [Train : Metrics { logloss:0.0647,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1336,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0943,  }]\n",
      "Training on Total Epoch: 1374, Round: 1374\n",
      "Evalset: [Train : Metrics { logloss:0.0646,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1335,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1375, Round: 1375\n",
      "Evalset: [Train : Metrics { logloss:0.0645,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1333,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1376, Round: 1376\n",
      "Evalset: [Train : Metrics { logloss:0.0644,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1331,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.094,  }]\n",
      "Training on Total Epoch: 1377, Round: 1377\n",
      "Evalset: [Train : Metrics { logloss:0.0643,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.133,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1378, Round: 1378\n",
      "Evalset: [Train : Metrics { logloss:0.0643,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1329,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0941,  }]\n",
      "Training on Total Epoch: 1379, Round: 1379\n",
      "Evalset: [Train : Metrics { logloss:0.0642,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.094,  }]\n",
      "Training on Total Epoch: 1380, Round: 1380\n",
      "Evalset: [Train : Metrics { logloss:0.0641,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0939,  }]\n",
      "Training on Total Epoch: 1381, Round: 1381\n",
      "Evalset: [Train : Metrics { logloss:0.0639,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1328,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0938,  }]\n",
      "Training on Total Epoch: 1382, Round: 1382\n",
      "Evalset: [Train : Metrics { logloss:0.0639,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1327,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0938,  }]\n",
      "Training on Total Epoch: 1383, Round: 1383\n",
      "Evalset: [Train : Metrics { logloss:0.0638,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1327,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0937,  }]\n",
      "Training on Total Epoch: 1384, Round: 1384\n",
      "Evalset: [Train : Metrics { logloss:0.0636,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0935,  }]\n",
      "Training on Total Epoch: 1385, Round: 1385\n",
      "Evalset: [Train : Metrics { logloss:0.0635,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1326,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1386, Round: 1386\n",
      "Evalset: [Train : Metrics { logloss:0.0635,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0933,  }]\n",
      "Training on Total Epoch: 1387, Round: 1387\n",
      "Evalset: [Train : Metrics { logloss:0.0634,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1388, Round: 1388\n",
      "Evalset: [Train : Metrics { logloss:0.0633,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1389, Round: 1389\n",
      "Evalset: [Train : Metrics { logloss:0.0632,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1390, Round: 1390\n",
      "Evalset: [Train : Metrics { logloss:0.0631,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1391, Round: 1391\n",
      "Evalset: [Train : Metrics { logloss:0.063,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0934,  }]\n",
      "Training on Total Epoch: 1392, Round: 1392\n",
      "Evalset: [Train : Metrics { logloss:0.0629,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0933,  }]\n",
      "Training on Total Epoch: 1393, Round: 1393\n",
      "Evalset: [Train : Metrics { logloss:0.0628,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0932,  }]\n",
      "Training on Total Epoch: 1394, Round: 1394\n",
      "Evalset: [Train : Metrics { logloss:0.0627,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0931,  }]\n",
      "Training on Total Epoch: 1395, Round: 1395\n",
      "Evalset: [Train : Metrics { logloss:0.0626,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0931,  }]\n",
      "Training on Total Epoch: 1396, Round: 1396\n",
      "Evalset: [Train : Metrics { logloss:0.0626,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1325,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.093,  }]\n",
      "Training on Total Epoch: 1397, Round: 1397\n",
      "Evalset: [Train : Metrics { logloss:0.0625,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0929,  }]\n",
      "Training on Total Epoch: 1398, Round: 1398\n",
      "Evalset: [Train : Metrics { logloss:0.0624,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0927,  }]\n",
      "Training on Total Epoch: 1399, Round: 1399\n",
      "Evalset: [Train : Metrics { logloss:0.0622,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0925,  }]\n",
      "Training on Total Epoch: 1400, Round: 1400\n",
      "Evalset: [Train : Metrics { logloss:0.0621,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1322,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0923,  }]\n",
      "Training on Total Epoch: 1401, Round: 1401\n",
      "Evalset: [Train : Metrics { logloss:0.062,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0923,  }]\n",
      "Training on Total Epoch: 1402, Round: 1402\n",
      "Evalset: [Train : Metrics { logloss:0.062,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1324,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0923,  }]\n",
      "Training on Total Epoch: 1403, Round: 1403\n",
      "Evalset: [Train : Metrics { logloss:0.0619,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1404, Round: 1404\n",
      "Evalset: [Train : Metrics { logloss:0.0618,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1323,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1405, Round: 1405\n",
      "Evalset: [Train : Metrics { logloss:0.0617,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1321,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0923,  }]\n",
      "Training on Total Epoch: 1406, Round: 1406\n",
      "Evalset: [Train : Metrics { logloss:0.0616,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.132,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1407, Round: 1407\n",
      "Evalset: [Train : Metrics { logloss:0.0615,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1318,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1408, Round: 1408\n",
      "Evalset: [Train : Metrics { logloss:0.0615,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1409, Round: 1409\n",
      "Evalset: [Train : Metrics { logloss:0.0614,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1317,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0922,  }]\n",
      "Training on Total Epoch: 1410, Round: 1410\n",
      "Evalset: [Train : Metrics { logloss:0.0614,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1315,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0921,  }]\n",
      "Training on Total Epoch: 1411, Round: 1411\n",
      "Evalset: [Train : Metrics { logloss:0.0613,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1314,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.092,  }]\n",
      "Training on Total Epoch: 1412, Round: 1412\n",
      "Evalset: [Train : Metrics { logloss:0.0612,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1413, Round: 1413\n",
      "Evalset: [Train : Metrics { logloss:0.0611,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0917,  }]\n",
      "Training on Total Epoch: 1414, Round: 1414\n",
      "Evalset: [Train : Metrics { logloss:0.061,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0918,  }]\n",
      "Training on Total Epoch: 1415, Round: 1415\n",
      "Evalset: [Train : Metrics { logloss:0.0609,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0917,  }]\n",
      "Training on Total Epoch: 1416, Round: 1416\n",
      "Evalset: [Train : Metrics { logloss:0.0608,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1313,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0916,  }]\n",
      "Training on Total Epoch: 1417, Round: 1417\n",
      "Evalset: [Train : Metrics { logloss:0.0607,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0915,  }]\n",
      "Training on Total Epoch: 1418, Round: 1418\n",
      "Evalset: [Train : Metrics { logloss:0.0605,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0915,  }]\n",
      "Training on Total Epoch: 1419, Round: 1419\n",
      "Evalset: [Train : Metrics { logloss:0.0604,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0915,  }]\n",
      "Training on Total Epoch: 1420, Round: 1420\n",
      "Evalset: [Train : Metrics { logloss:0.0603,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0914,  }]\n",
      "Training on Total Epoch: 1421, Round: 1421\n",
      "Evalset: [Train : Metrics { logloss:0.0602,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0913,  }]\n",
      "Training on Total Epoch: 1422, Round: 1422\n",
      "Evalset: [Train : Metrics { logloss:0.0601,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0912,  }]\n",
      "Training on Total Epoch: 1423, Round: 1423\n",
      "Evalset: [Train : Metrics { logloss:0.06,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.091,  }]\n",
      "Training on Total Epoch: 1424, Round: 1424\n",
      "Evalset: [Train : Metrics { logloss:0.0599,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1425, Round: 1425\n",
      "Evalset: [Train : Metrics { logloss:0.0598,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1426, Round: 1426\n",
      "Evalset: [Train : Metrics { logloss:0.0597,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1427, Round: 1427\n",
      "Evalset: [Train : Metrics { logloss:0.0596,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1428, Round: 1428\n",
      "Evalset: [Train : Metrics { logloss:0.0596,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1429, Round: 1429\n",
      "Evalset: [Train : Metrics { logloss:0.0595,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1430, Round: 1430\n",
      "Evalset: [Train : Metrics { logloss:0.0594,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0908,  }]\n",
      "Training on Total Epoch: 1431, Round: 1431\n",
      "Evalset: [Train : Metrics { logloss:0.0593,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0907,  }]\n",
      "Training on Total Epoch: 1432, Round: 1432\n",
      "Evalset: [Train : Metrics { logloss:0.0592,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1433, Round: 1433\n",
      "Evalset: [Train : Metrics { logloss:0.0591,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1434, Round: 1434\n",
      "Evalset: [Train : Metrics { logloss:0.0591,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1435, Round: 1435\n",
      "Evalset: [Train : Metrics { logloss:0.059,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.131,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0906,  }]\n",
      "Training on Total Epoch: 1436, Round: 1436\n",
      "Evalset: [Train : Metrics { logloss:0.0589,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0905,  }]\n",
      "Training on Total Epoch: 1437, Round: 1437\n",
      "Evalset: [Train : Metrics { logloss:0.0588,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1312,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0904,  }]\n",
      "Training on Total Epoch: 1438, Round: 1438\n",
      "Evalset: [Train : Metrics { logloss:0.0587,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1311,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0902,  }]\n",
      "Training on Total Epoch: 1439, Round: 1439\n",
      "Evalset: [Train : Metrics { logloss:0.0585,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1309,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.09,  }]\n",
      "Training on Total Epoch: 1440, Round: 1440\n",
      "Evalset: [Train : Metrics { logloss:0.0584,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1308,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1441, Round: 1441\n",
      "Evalset: [Train : Metrics { logloss:0.0583,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1307,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1442, Round: 1442\n",
      "Evalset: [Train : Metrics { logloss:0.0582,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1304,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1443, Round: 1443\n",
      "Evalset: [Train : Metrics { logloss:0.0581,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1302,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1444, Round: 1444\n",
      "Evalset: [Train : Metrics { logloss:0.0581,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.13,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1445, Round: 1445\n",
      "Evalset: [Train : Metrics { logloss:0.058,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1298,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1446, Round: 1446\n",
      "Evalset: [Train : Metrics { logloss:0.058,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1447, Round: 1447\n",
      "Evalset: [Train : Metrics { logloss:0.0579,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1297,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0899,  }]\n",
      "Training on Total Epoch: 1448, Round: 1448\n",
      "Evalset: [Train : Metrics { logloss:0.0578,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1294,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0898,  }]\n",
      "Training on Total Epoch: 1449, Round: 1449\n",
      "Evalset: [Train : Metrics { logloss:0.0577,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1293,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0896,  }]\n",
      "Training on Total Epoch: 1450, Round: 1450\n",
      "Evalset: [Train : Metrics { logloss:0.0576,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0895,  }]\n",
      "Training on Total Epoch: 1451, Round: 1451\n",
      "Evalset: [Train : Metrics { logloss:0.0575,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1452, Round: 1452\n",
      "Evalset: [Train : Metrics { logloss:0.0574,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1453, Round: 1453\n",
      "Evalset: [Train : Metrics { logloss:0.0573,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1454, Round: 1454\n",
      "Evalset: [Train : Metrics { logloss:0.0573,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1455, Round: 1455\n",
      "Evalset: [Train : Metrics { logloss:0.0572,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1292,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0894,  }]\n",
      "Training on Total Epoch: 1456, Round: 1456\n",
      "Evalset: [Train : Metrics { logloss:0.0571,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0892,  }]\n",
      "Training on Total Epoch: 1457, Round: 1457\n",
      "Evalset: [Train : Metrics { logloss:0.057,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0891,  }]\n",
      "Training on Total Epoch: 1458, Round: 1458\n",
      "Evalset: [Train : Metrics { logloss:0.0569,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.089,  }]\n",
      "Training on Total Epoch: 1459, Round: 1459\n",
      "Evalset: [Train : Metrics { logloss:0.0568,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1460, Round: 1460\n",
      "Evalset: [Train : Metrics { logloss:0.0567,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1461, Round: 1461\n",
      "Evalset: [Train : Metrics { logloss:0.0566,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1462, Round: 1462\n",
      "Evalset: [Train : Metrics { logloss:0.0565,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1463, Round: 1463\n",
      "Evalset: [Train : Metrics { logloss:0.0564,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1291,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1464, Round: 1464\n",
      "Evalset: [Train : Metrics { logloss:0.0563,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1465, Round: 1465\n",
      "Evalset: [Train : Metrics { logloss:0.0562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.129,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1466, Round: 1466\n",
      "Evalset: [Train : Metrics { logloss:0.0562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1289,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1467, Round: 1467\n",
      "Evalset: [Train : Metrics { logloss:0.0562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1468, Round: 1468\n",
      "Evalset: [Train : Metrics { logloss:0.0562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1469, Round: 1469\n",
      "Evalset: [Train : Metrics { logloss:0.0562,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1288,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0889,  }]\n",
      "Training on Total Epoch: 1470, Round: 1470\n",
      "Evalset: [Train : Metrics { logloss:0.0561,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0888,  }]\n",
      "Training on Total Epoch: 1471, Round: 1471\n",
      "Evalset: [Train : Metrics { logloss:0.056,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1286,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0887,  }]\n",
      "Training on Total Epoch: 1472, Round: 1472\n",
      "Evalset: [Train : Metrics { logloss:0.0559,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1285,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0886,  }]\n",
      "Training on Total Epoch: 1473, Round: 1473\n",
      "Evalset: [Train : Metrics { logloss:0.0558,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1284,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0885,  }]\n",
      "Training on Total Epoch: 1474, Round: 1474\n",
      "Evalset: [Train : Metrics { logloss:0.0556,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0883,  }]\n",
      "Training on Total Epoch: 1475, Round: 1475\n",
      "Evalset: [Train : Metrics { logloss:0.0555,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0882,  }]\n",
      "Training on Total Epoch: 1476, Round: 1476\n",
      "Evalset: [Train : Metrics { logloss:0.0554,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1283,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.088,  }]\n",
      "Training on Total Epoch: 1477, Round: 1477\n",
      "Evalset: [Train : Metrics { logloss:0.0553,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1282,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0879,  }]\n",
      "Training on Total Epoch: 1478, Round: 1478\n",
      "Evalset: [Train : Metrics { logloss:0.0553,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.128,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0879,  }]\n",
      "Training on Total Epoch: 1479, Round: 1479\n",
      "Evalset: [Train : Metrics { logloss:0.0552,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1279,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0878,  }]\n",
      "Training on Total Epoch: 1480, Round: 1480\n",
      "Evalset: [Train : Metrics { logloss:0.055,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0876,  }]\n",
      "Training on Total Epoch: 1481, Round: 1481\n",
      "Evalset: [Train : Metrics { logloss:0.0549,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0873,  }]\n",
      "Training on Total Epoch: 1482, Round: 1482\n",
      "Evalset: [Train : Metrics { logloss:0.0548,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1483, Round: 1483\n",
      "Evalset: [Train : Metrics { logloss:0.0547,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.087,  }]\n",
      "Training on Total Epoch: 1484, Round: 1484\n",
      "Evalset: [Train : Metrics { logloss:0.0546,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1278,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 1485, Round: 1485\n",
      "Evalset: [Train : Metrics { logloss:0.0545,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1277,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0867,  }]\n",
      "Training on Total Epoch: 1486, Round: 1486\n",
      "Evalset: [Train : Metrics { logloss:0.0544,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1487, Round: 1487\n",
      "Evalset: [Train : Metrics { logloss:0.0543,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1276,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1488, Round: 1488\n",
      "Evalset: [Train : Metrics { logloss:0.0543,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0865,  }]\n",
      "Training on Total Epoch: 1489, Round: 1489\n",
      "Evalset: [Train : Metrics { logloss:0.0542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1275,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1490, Round: 1490\n",
      "Evalset: [Train : Metrics { logloss:0.0542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 1491, Round: 1491\n",
      "Evalset: [Train : Metrics { logloss:0.0542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0869,  }]\n",
      "Training on Total Epoch: 1492, Round: 1492\n",
      "Evalset: [Train : Metrics { logloss:0.0542,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1493, Round: 1493\n",
      "Evalset: [Train : Metrics { logloss:0.0541,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1274,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0872,  }]\n",
      "Training on Total Epoch: 1494, Round: 1494\n",
      "Evalset: [Train : Metrics { logloss:0.0541,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1273,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0871,  }]\n",
      "Training on Total Epoch: 1495, Round: 1495\n",
      "Evalset: [Train : Metrics { logloss:0.0539,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1272,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0868,  }]\n",
      "Training on Total Epoch: 1496, Round: 1496\n",
      "Evalset: [Train : Metrics { logloss:0.0538,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1271,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0866,  }]\n",
      "Training on Total Epoch: 1497, Round: 1497\n",
      "Evalset: [Train : Metrics { logloss:0.0537,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.127,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0864,  }]\n",
      "Training on Total Epoch: 1498, Round: 1498\n",
      "Evalset: [Train : Metrics { logloss:0.0535,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1269,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0862,  }]\n",
      "Training on Total Epoch: 1499, Round: 1499\n",
      "Evalset: [Train : Metrics { logloss:0.0534,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1267,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0861,  }]\n",
      "Training on Total Epoch: 1500, Round: 1500\n",
      "Evalset: [Train : Metrics { logloss:0.0533,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1266,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1501, Round: 1501\n",
      "Evalset: [Train : Metrics { logloss:0.0533,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1266,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.086,  }]\n",
      "Training on Total Epoch: 1502, Round: 1502\n",
      "Evalset: [Train : Metrics { logloss:0.0532,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1503, Round: 1503\n",
      "Evalset: [Train : Metrics { logloss:0.0531,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1504, Round: 1504\n",
      "Evalset: [Train : Metrics { logloss:0.0531,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1505, Round: 1505\n",
      "Evalset: [Train : Metrics { logloss:0.053,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0859,  }]\n",
      "Training on Total Epoch: 1506, Round: 1506\n",
      "Evalset: [Train : Metrics { logloss:0.0529,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1507, Round: 1507\n",
      "Evalset: [Train : Metrics { logloss:0.0528,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0858,  }]\n",
      "Training on Total Epoch: 1508, Round: 1508\n",
      "Evalset: [Train : Metrics { logloss:0.0527,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1265,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0857,  }]\n",
      "Training on Total Epoch: 1509, Round: 1509\n",
      "Evalset: [Train : Metrics { logloss:0.0527,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1264,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1510, Round: 1510\n",
      "Evalset: [Train : Metrics { logloss:0.0525,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1511, Round: 1511\n",
      "Evalset: [Train : Metrics { logloss:0.0525,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0853,  }]\n",
      "Training on Total Epoch: 1512, Round: 1512\n",
      "Evalset: [Train : Metrics { logloss:0.0523,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1263,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1513, Round: 1513\n",
      "Evalset: [Train : Metrics { logloss:0.0523,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1514, Round: 1514\n",
      "Evalset: [Train : Metrics { logloss:0.0522,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1262,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1515, Round: 1515\n",
      "Evalset: [Train : Metrics { logloss:0.0521,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1516, Round: 1516\n",
      "Evalset: [Train : Metrics { logloss:0.052,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1517, Round: 1517\n",
      "Evalset: [Train : Metrics { logloss:0.0519,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1518, Round: 1518\n",
      "Evalset: [Train : Metrics { logloss:0.0519,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1519, Round: 1519\n",
      "Evalset: [Train : Metrics { logloss:0.0518,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1520, Round: 1520\n",
      "Evalset: [Train : Metrics { logloss:0.0518,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1521, Round: 1521\n",
      "Evalset: [Train : Metrics { logloss:0.0517,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1522, Round: 1522\n",
      "Evalset: [Train : Metrics { logloss:0.0517,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1261,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1523, Round: 1523\n",
      "Evalset: [Train : Metrics { logloss:0.0516,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.126,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0851,  }]\n",
      "Training on Total Epoch: 1524, Round: 1524\n",
      "Evalset: [Train : Metrics { logloss:0.0516,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1259,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1525, Round: 1525\n",
      "Evalset: [Train : Metrics { logloss:0.0515,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1258,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1526, Round: 1526\n",
      "Evalset: [Train : Metrics { logloss:0.0514,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1257,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1527, Round: 1527\n",
      "Evalset: [Train : Metrics { logloss:0.0514,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1528, Round: 1528\n",
      "Evalset: [Train : Metrics { logloss:0.0514,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1256,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1529, Round: 1529\n",
      "Evalset: [Train : Metrics { logloss:0.0513,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1530, Round: 1530\n",
      "Evalset: [Train : Metrics { logloss:0.0513,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1255,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0856,  }]\n",
      "Training on Total Epoch: 1531, Round: 1531\n",
      "Evalset: [Train : Metrics { logloss:0.0512,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1254,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0855,  }]\n",
      "Training on Total Epoch: 1532, Round: 1532\n",
      "Evalset: [Train : Metrics { logloss:0.0511,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0854,  }]\n",
      "Training on Total Epoch: 1533, Round: 1533\n",
      "Evalset: [Train : Metrics { logloss:0.051,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0852,  }]\n",
      "Training on Total Epoch: 1534, Round: 1534\n",
      "Evalset: [Train : Metrics { logloss:0.0508,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.085,  }]\n",
      "Training on Total Epoch: 1535, Round: 1535\n",
      "Evalset: [Train : Metrics { logloss:0.0508,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1252,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0849,  }]\n",
      "Training on Total Epoch: 1536, Round: 1536\n",
      "Evalset: [Train : Metrics { logloss:0.0507,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0848,  }]\n",
      "Training on Total Epoch: 1537, Round: 1537\n",
      "Evalset: [Train : Metrics { logloss:0.0506,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0847,  }]\n",
      "Training on Total Epoch: 1538, Round: 1538\n",
      "Evalset: [Train : Metrics { logloss:0.0505,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1251,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1539, Round: 1539\n",
      "Evalset: [Train : Metrics { logloss:0.0505,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.125,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1540, Round: 1540\n",
      "Evalset: [Train : Metrics { logloss:0.0504,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1249,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0846,  }]\n",
      "Training on Total Epoch: 1541, Round: 1541\n",
      "Evalset: [Train : Metrics { logloss:0.0503,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1248,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0845,  }]\n",
      "Training on Total Epoch: 1542, Round: 1542\n",
      "Evalset: [Train : Metrics { logloss:0.0502,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1543, Round: 1543\n",
      "Evalset: [Train : Metrics { logloss:0.0501,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1544, Round: 1544\n",
      "Evalset: [Train : Metrics { logloss:0.05,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1545, Round: 1545\n",
      "Evalset: [Train : Metrics { logloss:0.0499,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0844,  }]\n",
      "Training on Total Epoch: 1546, Round: 1546\n",
      "Evalset: [Train : Metrics { logloss:0.0498,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1547, Round: 1547\n",
      "Evalset: [Train : Metrics { logloss:0.0497,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0843,  }]\n",
      "Training on Total Epoch: 1548, Round: 1548\n",
      "Evalset: [Train : Metrics { logloss:0.0496,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0841,  }]\n",
      "Training on Total Epoch: 1549, Round: 1549\n",
      "Evalset: [Train : Metrics { logloss:0.0495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1550, Round: 1550\n",
      "Evalset: [Train : Metrics { logloss:0.0495,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1247,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1551, Round: 1551\n",
      "Evalset: [Train : Metrics { logloss:0.0494,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1552, Round: 1552\n",
      "Evalset: [Train : Metrics { logloss:0.0493,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1553, Round: 1553\n",
      "Evalset: [Train : Metrics { logloss:0.0492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1246,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1554, Round: 1554\n",
      "Evalset: [Train : Metrics { logloss:0.0492,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1555, Round: 1555\n",
      "Evalset: [Train : Metrics { logloss:0.0491,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1245,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1556, Round: 1556\n",
      "Evalset: [Train : Metrics { logloss:0.0491,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1557, Round: 1557\n",
      "Evalset: [Train : Metrics { logloss:0.049,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1558, Round: 1558\n",
      "Evalset: [Train : Metrics { logloss:0.049,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1559, Round: 1559\n",
      "Evalset: [Train : Metrics { logloss:0.049,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1560, Round: 1560\n",
      "Evalset: [Train : Metrics { logloss:0.0489,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1561, Round: 1561\n",
      "Evalset: [Train : Metrics { logloss:0.0488,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.084,  }]\n",
      "Training on Total Epoch: 1562, Round: 1562\n",
      "Evalset: [Train : Metrics { logloss:0.0487,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0839,  }]\n",
      "Training on Total Epoch: 1563, Round: 1563\n",
      "Evalset: [Train : Metrics { logloss:0.0486,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1244,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0838,  }]\n",
      "Training on Total Epoch: 1564, Round: 1564\n",
      "Evalset: [Train : Metrics { logloss:0.0486,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1565, Round: 1565\n",
      "Evalset: [Train : Metrics { logloss:0.0485,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1566, Round: 1566\n",
      "Evalset: [Train : Metrics { logloss:0.0484,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1243,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1567, Round: 1567\n",
      "Evalset: [Train : Metrics { logloss:0.0483,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1568, Round: 1568\n",
      "Evalset: [Train : Metrics { logloss:0.0483,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1242,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1569, Round: 1569\n",
      "Evalset: [Train : Metrics { logloss:0.0483,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1241,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1570, Round: 1570\n",
      "Evalset: [Train : Metrics { logloss:0.0482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.124,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0834,  }]\n",
      "Training on Total Epoch: 1571, Round: 1571\n",
      "Evalset: [Train : Metrics { logloss:0.0482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1239,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1572, Round: 1572\n",
      "Evalset: [Train : Metrics { logloss:0.0482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0835,  }]\n",
      "Training on Total Epoch: 1573, Round: 1573\n",
      "Evalset: [Train : Metrics { logloss:0.0482,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1574, Round: 1574\n",
      "Evalset: [Train : Metrics { logloss:0.0481,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1575, Round: 1575\n",
      "Evalset: [Train : Metrics { logloss:0.0481,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1576, Round: 1576\n",
      "Evalset: [Train : Metrics { logloss:0.048,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0837,  }]\n",
      "Training on Total Epoch: 1577, Round: 1577\n",
      "Evalset: [Train : Metrics { logloss:0.0479,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1238,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0836,  }]\n",
      "Training on Total Epoch: 1578, Round: 1578\n",
      "Evalset: [Train : Metrics { logloss:0.0478,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0833,  }]\n",
      "Training on Total Epoch: 1579, Round: 1579\n",
      "Evalset: [Train : Metrics { logloss:0.0476,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1237,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0831,  }]\n",
      "Training on Total Epoch: 1580, Round: 1580\n",
      "Evalset: [Train : Metrics { logloss:0.0475,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1236,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0829,  }]\n",
      "Training on Total Epoch: 1581, Round: 1581\n",
      "Evalset: [Train : Metrics { logloss:0.0474,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1235,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0827,  }]\n",
      "Training on Total Epoch: 1582, Round: 1582\n",
      "Evalset: [Train : Metrics { logloss:0.0473,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1234,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0827,  }]\n",
      "Training on Total Epoch: 1583, Round: 1583\n",
      "Evalset: [Train : Metrics { logloss:0.0473,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0826,  }]\n",
      "Training on Total Epoch: 1584, Round: 1584\n",
      "Evalset: [Train : Metrics { logloss:0.0472,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1233,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0826,  }]\n",
      "Training on Total Epoch: 1585, Round: 1585\n",
      "Evalset: [Train : Metrics { logloss:0.0471,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0826,  }]\n",
      "Training on Total Epoch: 1586, Round: 1586\n",
      "Evalset: [Train : Metrics { logloss:0.0471,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1232,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0826,  }]\n",
      "Training on Total Epoch: 1587, Round: 1587\n",
      "Evalset: [Train : Metrics { logloss:0.047,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0825,  }]\n",
      "Training on Total Epoch: 1588, Round: 1588\n",
      "Evalset: [Train : Metrics { logloss:0.0469,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0825,  }]\n",
      "Training on Total Epoch: 1589, Round: 1589\n",
      "Evalset: [Train : Metrics { logloss:0.0468,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0825,  }]\n",
      "Training on Total Epoch: 1590, Round: 1590\n",
      "Evalset: [Train : Metrics { logloss:0.0467,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0824,  }]\n",
      "Training on Total Epoch: 1591, Round: 1591\n",
      "Evalset: [Train : Metrics { logloss:0.0467,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0824,  }]\n",
      "Training on Total Epoch: 1592, Round: 1592\n",
      "Evalset: [Train : Metrics { logloss:0.0466,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0823,  }]\n",
      "Training on Total Epoch: 1593, Round: 1593\n",
      "Evalset: [Train : Metrics { logloss:0.0466,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0823,  }]\n",
      "Training on Total Epoch: 1594, Round: 1594\n",
      "Evalset: [Train : Metrics { logloss:0.0465,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0822,  }]\n",
      "Training on Total Epoch: 1595, Round: 1595\n",
      "Evalset: [Train : Metrics { logloss:0.0464,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0821,  }]\n",
      "Training on Total Epoch: 1596, Round: 1596\n",
      "Evalset: [Train : Metrics { logloss:0.0464,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0821,  }]\n",
      "Training on Total Epoch: 1597, Round: 1597\n",
      "Evalset: [Train : Metrics { logloss:0.0463,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.082,  }]\n",
      "Training on Total Epoch: 1598, Round: 1598\n",
      "Evalset: [Train : Metrics { logloss:0.0462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1231,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.082,  }]\n",
      "Training on Total Epoch: 1599, Round: 1599\n",
      "Evalset: [Train : Metrics { logloss:0.0462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.082,  }]\n",
      "Training on Total Epoch: 1600, Round: 1600\n",
      "Evalset: [Train : Metrics { logloss:0.0462,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.123,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.082,  }]\n",
      "Training on Total Epoch: 1601, Round: 1601\n",
      "Evalset: [Train : Metrics { logloss:0.0461,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1229,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.082,  }]\n",
      "Training on Total Epoch: 1602, Round: 1602\n",
      "Evalset: [Train : Metrics { logloss:0.0461,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1228,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.082,  }]\n",
      "Training on Total Epoch: 1603, Round: 1603\n",
      "Evalset: [Train : Metrics { logloss:0.0461,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1227,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0821,  }]\n",
      "Training on Total Epoch: 1604, Round: 1604\n",
      "Evalset: [Train : Metrics { logloss:0.046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0821,  }]\n",
      "Training on Total Epoch: 1605, Round: 1605\n",
      "Evalset: [Train : Metrics { logloss:0.046,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0819,  }]\n",
      "Training on Total Epoch: 1606, Round: 1606\n",
      "Evalset: [Train : Metrics { logloss:0.0459,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0818,  }]\n",
      "Training on Total Epoch: 1607, Round: 1607\n",
      "Evalset: [Train : Metrics { logloss:0.0458,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0817,  }]\n",
      "Training on Total Epoch: 1608, Round: 1608\n",
      "Evalset: [Train : Metrics { logloss:0.0457,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1226,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0818,  }]\n",
      "Training on Total Epoch: 1609, Round: 1609\n",
      "Evalset: [Train : Metrics { logloss:0.0457,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0817,  }]\n",
      "Training on Total Epoch: 1610, Round: 1610\n",
      "Evalset: [Train : Metrics { logloss:0.0456,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0817,  }]\n",
      "Training on Total Epoch: 1611, Round: 1611\n",
      "Evalset: [Train : Metrics { logloss:0.0455,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0816,  }]\n",
      "Training on Total Epoch: 1612, Round: 1612\n",
      "Evalset: [Train : Metrics { logloss:0.0454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0815,  }]\n",
      "Training on Total Epoch: 1613, Round: 1613\n",
      "Evalset: [Train : Metrics { logloss:0.0454,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1225,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0815,  }]\n",
      "Training on Total Epoch: 1614, Round: 1614\n",
      "Evalset: [Train : Metrics { logloss:0.0453,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0816,  }]\n",
      "Training on Total Epoch: 1615, Round: 1615\n",
      "Evalset: [Train : Metrics { logloss:0.0453,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0815,  }]\n",
      "Training on Total Epoch: 1616, Round: 1616\n",
      "Evalset: [Train : Metrics { logloss:0.0452,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1224,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0815,  }]\n",
      "Training on Total Epoch: 1617, Round: 1617\n",
      "Evalset: [Train : Metrics { logloss:0.0452,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1223,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0814,  }]\n",
      "Training on Total Epoch: 1618, Round: 1618\n",
      "Evalset: [Train : Metrics { logloss:0.0451,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1222,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0813,  }]\n",
      "Training on Total Epoch: 1619, Round: 1619\n",
      "Evalset: [Train : Metrics { logloss:0.045,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1221,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0812,  }]\n",
      "Training on Total Epoch: 1620, Round: 1620\n",
      "Evalset: [Train : Metrics { logloss:0.045,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0812,  }]\n",
      "Training on Total Epoch: 1621, Round: 1621\n",
      "Evalset: [Train : Metrics { logloss:0.0449,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0812,  }]\n",
      "Training on Total Epoch: 1622, Round: 1622\n",
      "Evalset: [Train : Metrics { logloss:0.0448,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.081,  }]\n",
      "Training on Total Epoch: 1623, Round: 1623\n",
      "Evalset: [Train : Metrics { logloss:0.0447,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0808,  }]\n",
      "Training on Total Epoch: 1624, Round: 1624\n",
      "Evalset: [Train : Metrics { logloss:0.0446,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0807,  }]\n",
      "Training on Total Epoch: 1625, Round: 1625\n",
      "Evalset: [Train : Metrics { logloss:0.0445,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0806,  }]\n",
      "Training on Total Epoch: 1626, Round: 1626\n",
      "Evalset: [Train : Metrics { logloss:0.0445,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0805,  }]\n",
      "Training on Total Epoch: 1627, Round: 1627\n",
      "Evalset: [Train : Metrics { logloss:0.0444,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0805,  }]\n",
      "Training on Total Epoch: 1628, Round: 1628\n",
      "Evalset: [Train : Metrics { logloss:0.0443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0806,  }]\n",
      "Training on Total Epoch: 1629, Round: 1629\n",
      "Evalset: [Train : Metrics { logloss:0.0443,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0807,  }]\n",
      "Training on Total Epoch: 1630, Round: 1630\n",
      "Evalset: [Train : Metrics { logloss:0.0442,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0808,  }]\n",
      "Training on Total Epoch: 1631, Round: 1631\n",
      "Evalset: [Train : Metrics { logloss:0.0442,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0808,  }]\n",
      "Training on Total Epoch: 1632, Round: 1632\n",
      "Evalset: [Train : Metrics { logloss:0.0441,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.122,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0807,  }]\n",
      "Training on Total Epoch: 1633, Round: 1633\n",
      "Evalset: [Train : Metrics { logloss:0.044,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0805,  }]\n",
      "Training on Total Epoch: 1634, Round: 1634\n",
      "Evalset: [Train : Metrics { logloss:0.0439,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1219,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0805,  }]\n",
      "Training on Total Epoch: 1635, Round: 1635\n",
      "Evalset: [Train : Metrics { logloss:0.0439,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0805,  }]\n",
      "Training on Total Epoch: 1636, Round: 1636\n",
      "Evalset: [Train : Metrics { logloss:0.0438,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0806,  }]\n",
      "Training on Total Epoch: 1637, Round: 1637\n",
      "Evalset: [Train : Metrics { logloss:0.0438,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0806,  }]\n",
      "Training on Total Epoch: 1638, Round: 1638\n",
      "Evalset: [Train : Metrics { logloss:0.0438,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1218,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0807,  }]\n",
      "Training on Total Epoch: 1639, Round: 1639\n",
      "Evalset: [Train : Metrics { logloss:0.0437,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1217,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0804,  }]\n",
      "Training on Total Epoch: 1640, Round: 1640\n",
      "Evalset: [Train : Metrics { logloss:0.0435,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1216,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0802,  }]\n",
      "Training on Total Epoch: 1641, Round: 1641\n",
      "Evalset: [Train : Metrics { logloss:0.0435,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0801,  }]\n",
      "Training on Total Epoch: 1642, Round: 1642\n",
      "Evalset: [Train : Metrics { logloss:0.0434,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0799,  }]\n",
      "Training on Total Epoch: 1643, Round: 1643\n",
      "Evalset: [Train : Metrics { logloss:0.0433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0797,  }]\n",
      "Training on Total Epoch: 1644, Round: 1644\n",
      "Evalset: [Train : Metrics { logloss:0.0433,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0797,  }]\n",
      "Training on Total Epoch: 1645, Round: 1645\n",
      "Evalset: [Train : Metrics { logloss:0.0432,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0797,  }]\n",
      "Training on Total Epoch: 1646, Round: 1646\n",
      "Evalset: [Train : Metrics { logloss:0.0432,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0797,  }]\n",
      "Training on Total Epoch: 1647, Round: 1647\n",
      "Evalset: [Train : Metrics { logloss:0.0431,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0798,  }]\n",
      "Training on Total Epoch: 1648, Round: 1648\n",
      "Evalset: [Train : Metrics { logloss:0.0431,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.08,  }]\n",
      "Training on Total Epoch: 1649, Round: 1649\n",
      "Evalset: [Train : Metrics { logloss:0.0431,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.121,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0801,  }]\n",
      "Training on Total Epoch: 1650, Round: 1650\n",
      "Evalset: [Train : Metrics { logloss:0.043,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0801,  }]\n",
      "Training on Total Epoch: 1651, Round: 1651\n",
      "Evalset: [Train : Metrics { logloss:0.043,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.08,  }]\n",
      "Training on Total Epoch: 1652, Round: 1652\n",
      "Evalset: [Train : Metrics { logloss:0.0429,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.08,  }]\n",
      "Training on Total Epoch: 1653, Round: 1653\n",
      "Evalset: [Train : Metrics { logloss:0.0429,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.08,  }]\n",
      "Training on Total Epoch: 1654, Round: 1654\n",
      "Evalset: [Train : Metrics { logloss:0.0429,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0801,  }]\n",
      "Training on Total Epoch: 1655, Round: 1655\n",
      "Evalset: [Train : Metrics { logloss:0.0428,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0802,  }]\n",
      "Training on Total Epoch: 1656, Round: 1656\n",
      "Evalset: [Train : Metrics { logloss:0.0428,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0801,  }]\n",
      "Training on Total Epoch: 1657, Round: 1657\n",
      "Evalset: [Train : Metrics { logloss:0.0427,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.08,  }]\n",
      "Training on Total Epoch: 1658, Round: 1658\n",
      "Evalset: [Train : Metrics { logloss:0.0426,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1215,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0799,  }]\n",
      "Training on Total Epoch: 1659, Round: 1659\n",
      "Evalset: [Train : Metrics { logloss:0.0425,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0797,  }]\n",
      "Training on Total Epoch: 1660, Round: 1660\n",
      "Evalset: [Train : Metrics { logloss:0.0424,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1214,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0794,  }]\n",
      "Training on Total Epoch: 1661, Round: 1661\n",
      "Evalset: [Train : Metrics { logloss:0.0423,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1213,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0793,  }]\n",
      "Training on Total Epoch: 1662, Round: 1662\n",
      "Evalset: [Train : Metrics { logloss:0.0423,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0794,  }]\n",
      "Training on Total Epoch: 1663, Round: 1663\n",
      "Evalset: [Train : Metrics { logloss:0.0422,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1212,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0795,  }]\n",
      "Training on Total Epoch: 1664, Round: 1664\n",
      "Evalset: [Train : Metrics { logloss:0.0421,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1211,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0795,  }]\n",
      "Training on Total Epoch: 1665, Round: 1665\n",
      "Evalset: [Train : Metrics { logloss:0.0421,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0794,  }]\n",
      "Training on Total Epoch: 1666, Round: 1666\n",
      "Evalset: [Train : Metrics { logloss:0.042,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0795,  }]\n",
      "Training on Total Epoch: 1667, Round: 1667\n",
      "Evalset: [Train : Metrics { logloss:0.042,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0796,  }]\n",
      "Training on Total Epoch: 1668, Round: 1668\n",
      "Evalset: [Train : Metrics { logloss:0.0419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1209,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0797,  }]\n",
      "Training on Total Epoch: 1669, Round: 1669\n",
      "Evalset: [Train : Metrics { logloss:0.0419,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1208,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0796,  }]\n",
      "Training on Total Epoch: 1670, Round: 1670\n",
      "Evalset: [Train : Metrics { logloss:0.0418,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0796,  }]\n",
      "Training on Total Epoch: 1671, Round: 1671\n",
      "Evalset: [Train : Metrics { logloss:0.0418,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0796,  }]\n",
      "Training on Total Epoch: 1672, Round: 1672\n",
      "Evalset: [Train : Metrics { logloss:0.0418,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0795,  }]\n",
      "Training on Total Epoch: 1673, Round: 1673\n",
      "Evalset: [Train : Metrics { logloss:0.0417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0794,  }]\n",
      "Training on Total Epoch: 1674, Round: 1674\n",
      "Evalset: [Train : Metrics { logloss:0.0417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1207,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0793,  }]\n",
      "Training on Total Epoch: 1675, Round: 1675\n",
      "Evalset: [Train : Metrics { logloss:0.0417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1206,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0793,  }]\n",
      "Training on Total Epoch: 1676, Round: 1676\n",
      "Evalset: [Train : Metrics { logloss:0.0417,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1204,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0793,  }]\n",
      "Training on Total Epoch: 1677, Round: 1677\n",
      "Evalset: [Train : Metrics { logloss:0.0416,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1203,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0792,  }]\n",
      "Training on Total Epoch: 1678, Round: 1678\n",
      "Evalset: [Train : Metrics { logloss:0.0415,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1202,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.079,  }]\n",
      "Training on Total Epoch: 1679, Round: 1679\n",
      "Evalset: [Train : Metrics { logloss:0.0414,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0788,  }]\n",
      "Training on Total Epoch: 1680, Round: 1680\n",
      "Evalset: [Train : Metrics { logloss:0.0413,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0786,  }]\n",
      "Training on Total Epoch: 1681, Round: 1681\n",
      "Evalset: [Train : Metrics { logloss:0.0413,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1199,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0785,  }]\n",
      "Training on Total Epoch: 1682, Round: 1682\n",
      "Evalset: [Train : Metrics { logloss:0.0412,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1199,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0785,  }]\n",
      "Training on Total Epoch: 1683, Round: 1683\n",
      "Evalset: [Train : Metrics { logloss:0.0411,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0784,  }]\n",
      "Training on Total Epoch: 1684, Round: 1684\n",
      "Evalset: [Train : Metrics { logloss:0.041,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0784,  }]\n",
      "Training on Total Epoch: 1685, Round: 1685\n",
      "Evalset: [Train : Metrics { logloss:0.041,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0784,  }]\n",
      "Training on Total Epoch: 1686, Round: 1686\n",
      "Evalset: [Train : Metrics { logloss:0.0409,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1202,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0785,  }]\n",
      "Training on Total Epoch: 1687, Round: 1687\n",
      "Evalset: [Train : Metrics { logloss:0.0408,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1202,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0785,  }]\n",
      "Training on Total Epoch: 1688, Round: 1688\n",
      "Evalset: [Train : Metrics { logloss:0.0408,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1202,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0785,  }]\n",
      "Training on Total Epoch: 1689, Round: 1689\n",
      "Evalset: [Train : Metrics { logloss:0.0408,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0785,  }]\n",
      "Training on Total Epoch: 1690, Round: 1690\n",
      "Evalset: [Train : Metrics { logloss:0.0407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0785,  }]\n",
      "Training on Total Epoch: 1691, Round: 1691\n",
      "Evalset: [Train : Metrics { logloss:0.0407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1199,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0786,  }]\n",
      "Training on Total Epoch: 1692, Round: 1692\n",
      "Evalset: [Train : Metrics { logloss:0.0407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1198,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0786,  }]\n",
      "Training on Total Epoch: 1693, Round: 1693\n",
      "Evalset: [Train : Metrics { logloss:0.0407,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0788,  }]\n",
      "Training on Total Epoch: 1694, Round: 1694\n",
      "Evalset: [Train : Metrics { logloss:0.0406,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0787,  }]\n",
      "Training on Total Epoch: 1695, Round: 1695\n",
      "Evalset: [Train : Metrics { logloss:0.0405,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0786,  }]\n",
      "Training on Total Epoch: 1696, Round: 1696\n",
      "Evalset: [Train : Metrics { logloss:0.0405,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0784,  }]\n",
      "Training on Total Epoch: 1697, Round: 1697\n",
      "Evalset: [Train : Metrics { logloss:0.0404,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0783,  }]\n",
      "Training on Total Epoch: 1698, Round: 1698\n",
      "Evalset: [Train : Metrics { logloss:0.0404,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0781,  }]\n",
      "Training on Total Epoch: 1699, Round: 1699\n",
      "Evalset: [Train : Metrics { logloss:0.0403,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.078,  }]\n",
      "Training on Total Epoch: 1700, Round: 1700\n",
      "Evalset: [Train : Metrics { logloss:0.0402,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.078,  }]\n",
      "Training on Total Epoch: 1701, Round: 1701\n",
      "Evalset: [Train : Metrics { logloss:0.0401,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1198,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.078,  }]\n",
      "Training on Total Epoch: 1702, Round: 1702\n",
      "Evalset: [Train : Metrics { logloss:0.0401,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0779,  }]\n",
      "Training on Total Epoch: 1703, Round: 1703\n",
      "Evalset: [Train : Metrics { logloss:0.04,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0777,  }]\n",
      "Training on Total Epoch: 1704, Round: 1704\n",
      "Evalset: [Train : Metrics { logloss:0.0399,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0775,  }]\n",
      "Training on Total Epoch: 1705, Round: 1705\n",
      "Evalset: [Train : Metrics { logloss:0.0399,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1201,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0773,  }]\n",
      "Training on Total Epoch: 1706, Round: 1706\n",
      "Evalset: [Train : Metrics { logloss:0.0398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0774,  }]\n",
      "Training on Total Epoch: 1707, Round: 1707\n",
      "Evalset: [Train : Metrics { logloss:0.0398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0776,  }]\n",
      "Training on Total Epoch: 1708, Round: 1708\n",
      "Evalset: [Train : Metrics { logloss:0.0398,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.12,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0777,  }]\n",
      "Training on Total Epoch: 1709, Round: 1709\n",
      "Evalset: [Train : Metrics { logloss:0.0397,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1199,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0776,  }]\n",
      "Training on Total Epoch: 1710, Round: 1710\n",
      "Evalset: [Train : Metrics { logloss:0.0396,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1198,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0776,  }]\n",
      "Training on Total Epoch: 1711, Round: 1711\n",
      "Evalset: [Train : Metrics { logloss:0.0395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1198,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0776,  }]\n",
      "Training on Total Epoch: 1712, Round: 1712\n",
      "Evalset: [Train : Metrics { logloss:0.0395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1197,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0777,  }]\n",
      "Training on Total Epoch: 1713, Round: 1713\n",
      "Evalset: [Train : Metrics { logloss:0.0395,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0778,  }]\n",
      "Training on Total Epoch: 1714, Round: 1714\n",
      "Evalset: [Train : Metrics { logloss:0.0394,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1194,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0779,  }]\n",
      "Training on Total Epoch: 1715, Round: 1715\n",
      "Evalset: [Train : Metrics { logloss:0.0394,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.078,  }]\n",
      "Training on Total Epoch: 1716, Round: 1716\n",
      "Evalset: [Train : Metrics { logloss:0.0393,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1192,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0779,  }]\n",
      "Training on Total Epoch: 1717, Round: 1717\n",
      "Evalset: [Train : Metrics { logloss:0.0392,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0778,  }]\n",
      "Training on Total Epoch: 1718, Round: 1718\n",
      "Evalset: [Train : Metrics { logloss:0.0392,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0778,  }]\n",
      "Training on Total Epoch: 1719, Round: 1719\n",
      "Evalset: [Train : Metrics { logloss:0.0391,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0777,  }]\n",
      "Training on Total Epoch: 1720, Round: 1720\n",
      "Evalset: [Train : Metrics { logloss:0.0391,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0778,  }]\n",
      "Training on Total Epoch: 1721, Round: 1721\n",
      "Evalset: [Train : Metrics { logloss:0.039,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0778,  }]\n",
      "Training on Total Epoch: 1722, Round: 1722\n",
      "Evalset: [Train : Metrics { logloss:0.0389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0777,  }]\n",
      "Training on Total Epoch: 1723, Round: 1723\n",
      "Evalset: [Train : Metrics { logloss:0.0389,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0776,  }]\n",
      "Training on Total Epoch: 1724, Round: 1724\n",
      "Evalset: [Train : Metrics { logloss:0.0388,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0775,  }]\n",
      "Training on Total Epoch: 1725, Round: 1725\n",
      "Evalset: [Train : Metrics { logloss:0.0387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0774,  }]\n",
      "Training on Total Epoch: 1726, Round: 1726\n",
      "Evalset: [Train : Metrics { logloss:0.0387,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0774,  }]\n",
      "Training on Total Epoch: 1727, Round: 1727\n",
      "Evalset: [Train : Metrics { logloss:0.0386,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1194,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0774,  }]\n",
      "Training on Total Epoch: 1728, Round: 1728\n",
      "Evalset: [Train : Metrics { logloss:0.0385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0773,  }]\n",
      "Training on Total Epoch: 1729, Round: 1729\n",
      "Evalset: [Train : Metrics { logloss:0.0385,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0772,  }]\n",
      "Training on Total Epoch: 1730, Round: 1730\n",
      "Evalset: [Train : Metrics { logloss:0.0384,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1197,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0771,  }]\n",
      "Training on Total Epoch: 1731, Round: 1731\n",
      "Evalset: [Train : Metrics { logloss:0.0384,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1197,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0769,  }]\n",
      "Training on Total Epoch: 1732, Round: 1732\n",
      "Evalset: [Train : Metrics { logloss:0.0383,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1197,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0767,  }]\n",
      "Training on Total Epoch: 1733, Round: 1733\n",
      "Evalset: [Train : Metrics { logloss:0.0383,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0766,  }]\n",
      "Training on Total Epoch: 1734, Round: 1734\n",
      "Evalset: [Train : Metrics { logloss:0.0382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1196,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0765,  }]\n",
      "Training on Total Epoch: 1735, Round: 1735\n",
      "Evalset: [Train : Metrics { logloss:0.0382,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0765,  }]\n",
      "Training on Total Epoch: 1736, Round: 1736\n",
      "Evalset: [Train : Metrics { logloss:0.0381,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1195,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0764,  }]\n",
      "Training on Total Epoch: 1737, Round: 1737\n",
      "Evalset: [Train : Metrics { logloss:0.038,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1738, Round: 1738\n",
      "Evalset: [Train : Metrics { logloss:0.038,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1739, Round: 1739\n",
      "Evalset: [Train : Metrics { logloss:0.0379,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1193,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0762,  }]\n",
      "Training on Total Epoch: 1740, Round: 1740\n",
      "Evalset: [Train : Metrics { logloss:0.0378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1192,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0761,  }]\n",
      "Training on Total Epoch: 1741, Round: 1741\n",
      "Evalset: [Train : Metrics { logloss:0.0378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1191,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0762,  }]\n",
      "Training on Total Epoch: 1742, Round: 1742\n",
      "Evalset: [Train : Metrics { logloss:0.0378,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1189,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1743, Round: 1743\n",
      "Evalset: [Train : Metrics { logloss:0.0377,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1188,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1744, Round: 1744\n",
      "Evalset: [Train : Metrics { logloss:0.0377,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1188,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1745, Round: 1745\n",
      "Evalset: [Train : Metrics { logloss:0.0376,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1188,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1746, Round: 1746\n",
      "Evalset: [Train : Metrics { logloss:0.0376,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1188,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0764,  }]\n",
      "Training on Total Epoch: 1747, Round: 1747\n",
      "Evalset: [Train : Metrics { logloss:0.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1187,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1748, Round: 1748\n",
      "Evalset: [Train : Metrics { logloss:0.0375,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1186,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0762,  }]\n",
      "Training on Total Epoch: 1749, Round: 1749\n",
      "Evalset: [Train : Metrics { logloss:0.0374,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0762,  }]\n",
      "Training on Total Epoch: 1750, Round: 1750\n",
      "Evalset: [Train : Metrics { logloss:0.0373,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0762,  }]\n",
      "Training on Total Epoch: 1751, Round: 1751\n",
      "Evalset: [Train : Metrics { logloss:0.0373,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1752, Round: 1752\n",
      "Evalset: [Train : Metrics { logloss:0.0373,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0763,  }]\n",
      "Training on Total Epoch: 1753, Round: 1753\n",
      "Evalset: [Train : Metrics { logloss:0.0372,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0762,  }]\n",
      "Training on Total Epoch: 1754, Round: 1754\n",
      "Evalset: [Train : Metrics { logloss:0.0371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0761,  }]\n",
      "Training on Total Epoch: 1755, Round: 1755\n",
      "Evalset: [Train : Metrics { logloss:0.0371,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0759,  }]\n",
      "Training on Total Epoch: 1756, Round: 1756\n",
      "Evalset: [Train : Metrics { logloss:0.037,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0759,  }]\n",
      "Training on Total Epoch: 1757, Round: 1757\n",
      "Evalset: [Train : Metrics { logloss:0.0369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0759,  }]\n",
      "Training on Total Epoch: 1758, Round: 1758\n",
      "Evalset: [Train : Metrics { logloss:0.0369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0758,  }]\n",
      "Training on Total Epoch: 1759, Round: 1759\n",
      "Evalset: [Train : Metrics { logloss:0.0369,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0758,  }]\n",
      "Training on Total Epoch: 1760, Round: 1760\n",
      "Evalset: [Train : Metrics { logloss:0.0368,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0758,  }]\n",
      "Training on Total Epoch: 1761, Round: 1761\n",
      "Evalset: [Train : Metrics { logloss:0.0368,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0758,  }]\n",
      "Training on Total Epoch: 1762, Round: 1762\n",
      "Evalset: [Train : Metrics { logloss:0.0367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0758,  }]\n",
      "Training on Total Epoch: 1763, Round: 1763\n",
      "Evalset: [Train : Metrics { logloss:0.0367,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0757,  }]\n",
      "Training on Total Epoch: 1764, Round: 1764\n",
      "Evalset: [Train : Metrics { logloss:0.0366,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0757,  }]\n",
      "Training on Total Epoch: 1765, Round: 1765\n",
      "Evalset: [Train : Metrics { logloss:0.0365,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0757,  }]\n",
      "Training on Total Epoch: 1766, Round: 1766\n",
      "Evalset: [Train : Metrics { logloss:0.0365,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0757,  }]\n",
      "Training on Total Epoch: 1767, Round: 1767\n",
      "Evalset: [Train : Metrics { logloss:0.0364,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0758,  }]\n",
      "Training on Total Epoch: 1768, Round: 1768\n",
      "Evalset: [Train : Metrics { logloss:0.0364,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0758,  }]\n",
      "Training on Total Epoch: 1769, Round: 1769\n",
      "Evalset: [Train : Metrics { logloss:0.0363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0757,  }]\n",
      "Training on Total Epoch: 1770, Round: 1770\n",
      "Evalset: [Train : Metrics { logloss:0.0363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0757,  }]\n",
      "Training on Total Epoch: 1771, Round: 1771\n",
      "Evalset: [Train : Metrics { logloss:0.0363,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0756,  }]\n",
      "Training on Total Epoch: 1772, Round: 1772\n",
      "Evalset: [Train : Metrics { logloss:0.0362,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1186,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0756,  }]\n",
      "Training on Total Epoch: 1773, Round: 1773\n",
      "Evalset: [Train : Metrics { logloss:0.0362,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0755,  }]\n",
      "Training on Total Epoch: 1774, Round: 1774\n",
      "Evalset: [Train : Metrics { logloss:0.0361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1186,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0754,  }]\n",
      "Training on Total Epoch: 1775, Round: 1775\n",
      "Evalset: [Train : Metrics { logloss:0.0361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1186,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0754,  }]\n",
      "Training on Total Epoch: 1776, Round: 1776\n",
      "Evalset: [Train : Metrics { logloss:0.0361,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1187,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0755,  }]\n",
      "Training on Total Epoch: 1777, Round: 1777\n",
      "Evalset: [Train : Metrics { logloss:0.036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1187,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0756,  }]\n",
      "Training on Total Epoch: 1778, Round: 1778\n",
      "Evalset: [Train : Metrics { logloss:0.036,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1186,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0756,  }]\n",
      "Training on Total Epoch: 1779, Round: 1779\n",
      "Evalset: [Train : Metrics { logloss:0.0359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1185,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0757,  }]\n",
      "Training on Total Epoch: 1780, Round: 1780\n",
      "Evalset: [Train : Metrics { logloss:0.0359,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0756,  }]\n",
      "Training on Total Epoch: 1781, Round: 1781\n",
      "Evalset: [Train : Metrics { logloss:0.0358,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0756,  }]\n",
      "Training on Total Epoch: 1782, Round: 1782\n",
      "Evalset: [Train : Metrics { logloss:0.0357,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1182,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0754,  }]\n",
      "Training on Total Epoch: 1783, Round: 1783\n",
      "Evalset: [Train : Metrics { logloss:0.0356,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1181,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0752,  }]\n",
      "Training on Total Epoch: 1784, Round: 1784\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.118,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1785, Round: 1785\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1179,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0748,  }]\n",
      "Training on Total Epoch: 1786, Round: 1786\n",
      "Evalset: [Train : Metrics { logloss:0.0355,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.118,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0748,  }]\n",
      "Training on Total Epoch: 1787, Round: 1787\n",
      "Evalset: [Train : Metrics { logloss:0.0354,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1181,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0748,  }]\n",
      "Training on Total Epoch: 1788, Round: 1788\n",
      "Evalset: [Train : Metrics { logloss:0.0354,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1181,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1789, Round: 1789\n",
      "Evalset: [Train : Metrics { logloss:0.0354,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1182,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1790, Round: 1790\n",
      "Evalset: [Train : Metrics { logloss:0.0353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0748,  }]\n",
      "Training on Total Epoch: 1791, Round: 1791\n",
      "Evalset: [Train : Metrics { logloss:0.0353,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1792, Round: 1792\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.075,  }]\n",
      "Training on Total Epoch: 1793, Round: 1793\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1184,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0751,  }]\n",
      "Training on Total Epoch: 1794, Round: 1794\n",
      "Evalset: [Train : Metrics { logloss:0.0352,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0752,  }]\n",
      "Training on Total Epoch: 1795, Round: 1795\n",
      "Evalset: [Train : Metrics { logloss:0.0351,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0752,  }]\n",
      "Training on Total Epoch: 1796, Round: 1796\n",
      "Evalset: [Train : Metrics { logloss:0.0351,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.075,  }]\n",
      "Training on Total Epoch: 1797, Round: 1797\n",
      "Evalset: [Train : Metrics { logloss:0.035,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1798, Round: 1798\n",
      "Evalset: [Train : Metrics { logloss:0.0349,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0748,  }]\n",
      "Training on Total Epoch: 1799, Round: 1799\n",
      "Evalset: [Train : Metrics { logloss:0.0349,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1183,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0747,  }]\n",
      "Training on Total Epoch: 1800, Round: 1800\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1181,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0746,  }]\n",
      "Training on Total Epoch: 1801, Round: 1801\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.118,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0744,  }]\n",
      "Training on Total Epoch: 1802, Round: 1802\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1178,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0745,  }]\n",
      "Training on Total Epoch: 1803, Round: 1803\n",
      "Evalset: [Train : Metrics { logloss:0.0348,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1178,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0745,  }]\n",
      "Training on Total Epoch: 1804, Round: 1804\n",
      "Evalset: [Train : Metrics { logloss:0.0347,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0745,  }]\n",
      "Training on Total Epoch: 1805, Round: 1805\n",
      "Evalset: [Train : Metrics { logloss:0.0347,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0744,  }]\n",
      "Training on Total Epoch: 1806, Round: 1806\n",
      "Evalset: [Train : Metrics { logloss:0.0346,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1807, Round: 1807\n",
      "Evalset: [Train : Metrics { logloss:0.0346,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0744,  }]\n",
      "Training on Total Epoch: 1808, Round: 1808\n",
      "Evalset: [Train : Metrics { logloss:0.0345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0745,  }]\n",
      "Training on Total Epoch: 1809, Round: 1809\n",
      "Evalset: [Train : Metrics { logloss:0.0345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0747,  }]\n",
      "Training on Total Epoch: 1810, Round: 1810\n",
      "Evalset: [Train : Metrics { logloss:0.0345,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0748,  }]\n",
      "Training on Total Epoch: 1811, Round: 1811\n",
      "Evalset: [Train : Metrics { logloss:0.0344,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1812, Round: 1812\n",
      "Evalset: [Train : Metrics { logloss:0.0343,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.075,  }]\n",
      "Training on Total Epoch: 1813, Round: 1813\n",
      "Evalset: [Train : Metrics { logloss:0.0343,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1814, Round: 1814\n",
      "Evalset: [Train : Metrics { logloss:0.0342,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1815, Round: 1815\n",
      "Evalset: [Train : Metrics { logloss:0.0341,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0748,  }]\n",
      "Training on Total Epoch: 1816, Round: 1816\n",
      "Evalset: [Train : Metrics { logloss:0.0341,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1173,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0749,  }]\n",
      "Training on Total Epoch: 1817, Round: 1817\n",
      "Evalset: [Train : Metrics { logloss:0.034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1172,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0747,  }]\n",
      "Training on Total Epoch: 1818, Round: 1818\n",
      "Evalset: [Train : Metrics { logloss:0.034,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1172,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0746,  }]\n",
      "Training on Total Epoch: 1819, Round: 1819\n",
      "Evalset: [Train : Metrics { logloss:0.0339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1173,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0745,  }]\n",
      "Training on Total Epoch: 1820, Round: 1820\n",
      "Evalset: [Train : Metrics { logloss:0.0339,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1173,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0744,  }]\n",
      "Training on Total Epoch: 1821, Round: 1821\n",
      "Evalset: [Train : Metrics { logloss:0.0338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1822, Round: 1822\n",
      "Evalset: [Train : Metrics { logloss:0.0338,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1823, Round: 1823\n",
      "Evalset: [Train : Metrics { logloss:0.0337,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1824, Round: 1824\n",
      "Evalset: [Train : Metrics { logloss:0.0337,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1825, Round: 1825\n",
      "Evalset: [Train : Metrics { logloss:0.0336,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1826, Round: 1826\n",
      "Evalset: [Train : Metrics { logloss:0.0335,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1827, Round: 1827\n",
      "Evalset: [Train : Metrics { logloss:0.0335,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0744,  }]\n",
      "Training on Total Epoch: 1828, Round: 1828\n",
      "Evalset: [Train : Metrics { logloss:0.0335,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0744,  }]\n",
      "Training on Total Epoch: 1829, Round: 1829\n",
      "Evalset: [Train : Metrics { logloss:0.0334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0744,  }]\n",
      "Training on Total Epoch: 1830, Round: 1830\n",
      "Evalset: [Train : Metrics { logloss:0.0334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0743,  }]\n",
      "Training on Total Epoch: 1831, Round: 1831\n",
      "Evalset: [Train : Metrics { logloss:0.0334,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0742,  }]\n",
      "Training on Total Epoch: 1832, Round: 1832\n",
      "Evalset: [Train : Metrics { logloss:0.0333,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.074,  }]\n",
      "Training on Total Epoch: 1833, Round: 1833\n",
      "Evalset: [Train : Metrics { logloss:0.0332,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0739,  }]\n",
      "Training on Total Epoch: 1834, Round: 1834\n",
      "Evalset: [Train : Metrics { logloss:0.0332,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0739,  }]\n",
      "Training on Total Epoch: 1835, Round: 1835\n",
      "Evalset: [Train : Metrics { logloss:0.0331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0738,  }]\n",
      "Training on Total Epoch: 1836, Round: 1836\n",
      "Evalset: [Train : Metrics { logloss:0.0331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0737,  }]\n",
      "Training on Total Epoch: 1837, Round: 1837\n",
      "Evalset: [Train : Metrics { logloss:0.0331,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1176,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0736,  }]\n",
      "Training on Total Epoch: 1838, Round: 1838\n",
      "Evalset: [Train : Metrics { logloss:0.033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0736,  }]\n",
      "Training on Total Epoch: 1839, Round: 1839\n",
      "Evalset: [Train : Metrics { logloss:0.033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0735,  }]\n",
      "Training on Total Epoch: 1840, Round: 1840\n",
      "Evalset: [Train : Metrics { logloss:0.033,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1178,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0733,  }]\n",
      "Training on Total Epoch: 1841, Round: 1841\n",
      "Evalset: [Train : Metrics { logloss:0.0329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1179,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0733,  }]\n",
      "Training on Total Epoch: 1842, Round: 1842\n",
      "Evalset: [Train : Metrics { logloss:0.0329,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1179,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0733,  }]\n",
      "Training on Total Epoch: 1843, Round: 1843\n",
      "Evalset: [Train : Metrics { logloss:0.0328,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.118,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0732,  }]\n",
      "Training on Total Epoch: 1844, Round: 1844\n",
      "Evalset: [Train : Metrics { logloss:0.0327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.118,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0731,  }]\n",
      "Training on Total Epoch: 1845, Round: 1845\n",
      "Evalset: [Train : Metrics { logloss:0.0327,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1179,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.073,  }]\n",
      "Training on Total Epoch: 1846, Round: 1846\n",
      "Evalset: [Train : Metrics { logloss:0.0326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1177,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.073,  }]\n",
      "Training on Total Epoch: 1847, Round: 1847\n",
      "Evalset: [Train : Metrics { logloss:0.0326,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0732,  }]\n",
      "Training on Total Epoch: 1848, Round: 1848\n",
      "Evalset: [Train : Metrics { logloss:0.0325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1175,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0734,  }]\n",
      "Training on Total Epoch: 1849, Round: 1849\n",
      "Evalset: [Train : Metrics { logloss:0.0325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1174,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0737,  }]\n",
      "Training on Total Epoch: 1850, Round: 1850\n",
      "Evalset: [Train : Metrics { logloss:0.0325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1173,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0738,  }]\n",
      "Training on Total Epoch: 1851, Round: 1851\n",
      "Evalset: [Train : Metrics { logloss:0.0325,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1171,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0739,  }]\n",
      "Training on Total Epoch: 1852, Round: 1852\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.117,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0739,  }]\n",
      "Training on Total Epoch: 1853, Round: 1853\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1169,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.074,  }]\n",
      "Training on Total Epoch: 1854, Round: 1854\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.074,  }]\n",
      "Training on Total Epoch: 1855, Round: 1855\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0741,  }]\n",
      "Training on Total Epoch: 1856, Round: 1856\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0742,  }]\n",
      "Training on Total Epoch: 1857, Round: 1857\n",
      "Evalset: [Train : Metrics { logloss:0.0324,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0742,  }]\n",
      "Training on Total Epoch: 1858, Round: 1858\n",
      "Evalset: [Train : Metrics { logloss:0.0323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0741,  }]\n",
      "Training on Total Epoch: 1859, Round: 1859\n",
      "Evalset: [Train : Metrics { logloss:0.0323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0741,  }]\n",
      "Training on Total Epoch: 1860, Round: 1860\n",
      "Evalset: [Train : Metrics { logloss:0.0323,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.074,  }]\n",
      "Training on Total Epoch: 1861, Round: 1861\n",
      "Evalset: [Train : Metrics { logloss:0.0322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0739,  }]\n",
      "Training on Total Epoch: 1862, Round: 1862\n",
      "Evalset: [Train : Metrics { logloss:0.0322,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0737,  }]\n",
      "Training on Total Epoch: 1863, Round: 1863\n",
      "Evalset: [Train : Metrics { logloss:0.0321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0738,  }]\n",
      "Training on Total Epoch: 1864, Round: 1864\n",
      "Evalset: [Train : Metrics { logloss:0.0321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1169,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0738,  }]\n",
      "Training on Total Epoch: 1865, Round: 1865\n",
      "Evalset: [Train : Metrics { logloss:0.0321,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1169,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0739,  }]\n",
      "Training on Total Epoch: 1866, Round: 1866\n",
      "Evalset: [Train : Metrics { logloss:0.032,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1168,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0738,  }]\n",
      "Training on Total Epoch: 1867, Round: 1867\n",
      "Evalset: [Train : Metrics { logloss:0.0319,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0735,  }]\n",
      "Training on Total Epoch: 1868, Round: 1868\n",
      "Evalset: [Train : Metrics { logloss:0.0318,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0735,  }]\n",
      "Training on Total Epoch: 1869, Round: 1869\n",
      "Evalset: [Train : Metrics { logloss:0.0318,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1165,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0735,  }]\n",
      "Training on Total Epoch: 1870, Round: 1870\n",
      "Evalset: [Train : Metrics { logloss:0.0318,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1165,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0735,  }]\n",
      "Training on Total Epoch: 1871, Round: 1871\n",
      "Evalset: [Train : Metrics { logloss:0.0317,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0734,  }]\n",
      "Training on Total Epoch: 1872, Round: 1872\n",
      "Evalset: [Train : Metrics { logloss:0.0316,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0734,  }]\n",
      "Training on Total Epoch: 1873, Round: 1873\n",
      "Evalset: [Train : Metrics { logloss:0.0316,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0733,  }]\n",
      "Training on Total Epoch: 1874, Round: 1874\n",
      "Evalset: [Train : Metrics { logloss:0.0315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0733,  }]\n",
      "Training on Total Epoch: 1875, Round: 1875\n",
      "Evalset: [Train : Metrics { logloss:0.0315,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1167,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0732,  }]\n",
      "Training on Total Epoch: 1876, Round: 1876\n",
      "Evalset: [Train : Metrics { logloss:0.0314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0732,  }]\n",
      "Training on Total Epoch: 1877, Round: 1877\n",
      "Evalset: [Train : Metrics { logloss:0.0314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0731,  }]\n",
      "Training on Total Epoch: 1878, Round: 1878\n",
      "Evalset: [Train : Metrics { logloss:0.0314,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0731,  }]\n",
      "Training on Total Epoch: 1879, Round: 1879\n",
      "Evalset: [Train : Metrics { logloss:0.0313,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0731,  }]\n",
      "Training on Total Epoch: 1880, Round: 1880\n",
      "Evalset: [Train : Metrics { logloss:0.0312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1165,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.073,  }]\n",
      "Training on Total Epoch: 1881, Round: 1881\n",
      "Evalset: [Train : Metrics { logloss:0.0312,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0729,  }]\n",
      "Training on Total Epoch: 1882, Round: 1882\n",
      "Evalset: [Train : Metrics { logloss:0.0311,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0729,  }]\n",
      "Training on Total Epoch: 1883, Round: 1883\n",
      "Evalset: [Train : Metrics { logloss:0.0311,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0728,  }]\n",
      "Training on Total Epoch: 1884, Round: 1884\n",
      "Evalset: [Train : Metrics { logloss:0.0311,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0727,  }]\n",
      "Training on Total Epoch: 1885, Round: 1885\n",
      "Evalset: [Train : Metrics { logloss:0.031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0726,  }]\n",
      "Training on Total Epoch: 1886, Round: 1886\n",
      "Evalset: [Train : Metrics { logloss:0.031,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0723,  }]\n",
      "Training on Total Epoch: 1887, Round: 1887\n",
      "Evalset: [Train : Metrics { logloss:0.0309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0721,  }]\n",
      "Training on Total Epoch: 1888, Round: 1888\n",
      "Evalset: [Train : Metrics { logloss:0.0309,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.072,  }]\n",
      "Training on Total Epoch: 1889, Round: 1889\n",
      "Evalset: [Train : Metrics { logloss:0.0308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.072,  }]\n",
      "Training on Total Epoch: 1890, Round: 1890\n",
      "Evalset: [Train : Metrics { logloss:0.0308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1162,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0721,  }]\n",
      "Training on Total Epoch: 1891, Round: 1891\n",
      "Evalset: [Train : Metrics { logloss:0.0308,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0723,  }]\n",
      "Training on Total Epoch: 1892, Round: 1892\n",
      "Evalset: [Train : Metrics { logloss:0.0307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1163,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0724,  }]\n",
      "Training on Total Epoch: 1893, Round: 1893\n",
      "Evalset: [Train : Metrics { logloss:0.0307,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1164,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0724,  }]\n",
      "Training on Total Epoch: 1894, Round: 1894\n",
      "Evalset: [Train : Metrics { logloss:0.0306,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1165,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0725,  }]\n",
      "Training on Total Epoch: 1895, Round: 1895\n",
      "Evalset: [Train : Metrics { logloss:0.0306,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.1166,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0725,  }]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN Simple Interf Evaluator(name = Eval_2, task = classification, has trained n_epoch = 1896, n_step = 7584)."
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Evaluate the model - Benchmark Model 2 - 3 Layers, Meidum Sized Model with Dropout\n",
    "# \n",
    "model2 = Model_2(backend=backend, device=device, autograd=False)\n",
    "crit2 = MultiCrossEntropy(eps = 1e-10, raw_logits=False, backend=backend, device=device, autograd=False)\n",
    "optm2 = AdamW(model2.parameters(), lr = 1e-4, eps = 1e-10, backend=backend, device=device, autograd=False)\n",
    "eval2 = Evaluator(\"Eval_2\", task = \"classification\", module=model2, criterion=crit2, optimizer=optm2)\n",
    "\n",
    "# Start to train the model\n",
    "eval2.fit(\n",
    "    X = train_feature, y = train_target,\n",
    "    epoches = 5000,\n",
    "    batch_size = 1024,\n",
    "    shuffle = True,\n",
    "    random_state = None,\n",
    "    one_hot = True,\n",
    "    verbosity = 1,\n",
    "    evalper = 1,\n",
    "    evalset = {\n",
    "        \"Train\": (train_feature, train_target),\n",
    "        \"Valid\": (valid_feature, valid_target),\n",
    "        \"Test\":  (test_feature, test_target)\n",
    "    },\n",
    "    evalmetrics = [\"logloss\"],\n",
    "    early_stop = 5,\n",
    "    early_stop_logic = \"most\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Config: {Benchmark Evaluation: Model2, (64, 128, Dropout, 32, 10)}\n",
      "ACC    : 0.980427\n",
      "PREC   : 0.980974\n",
      "RECALL : 0.980187\n",
      "F1     : 0.980424\n",
      "CONFUSION MATRIX:\n",
      "         0       1    2       3       4       5       6    7       8       9\n",
      "0  0.9918  0.0000  0.0  0.0000  0.0000  0.0000  0.0000  0.0  0.0000  0.0000\n",
      "1  0.0000  0.9583  0.0  0.0000  0.0000  0.0000  0.0000  0.0  0.0000  0.0000\n",
      "2  0.0000  0.0090  1.0  0.0000  0.0000  0.0000  0.0000  0.0  0.0000  0.0000\n",
      "3  0.0000  0.0000  0.0  0.9677  0.0000  0.0323  0.0000  0.0  0.0000  0.0081\n",
      "4  0.0000  0.0000  0.0  0.0000  0.9829  0.0000  0.0256  0.0  0.0000  0.0000\n",
      "5  0.0000  0.0000  0.0  0.0000  0.0082  0.9672  0.0000  0.0  0.0082  0.0000\n",
      "6  0.0000  0.0000  0.0  0.0000  0.0000  0.0000  0.9725  0.0  0.0000  0.0000\n",
      "7  0.0000  0.0000  0.0  0.0000  0.0000  0.0000  0.0000  1.0  0.0000  0.0000\n",
      "8  0.0000  0.0312  0.0  0.0208  0.0000  0.0000  0.0000  0.0  0.9792  0.0000\n",
      "9  0.0099  0.0099  0.0  0.0198  0.0099  0.0000  0.0000  0.0  0.0099  0.9901\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the model - Benchmark Model 2 - 3 Layers, Meidum Sized Model with Dropout\n",
    "# \n",
    "\n",
    "# Print the results for the test-set\n",
    "eval2.eval()\n",
    "pred, acc, prec, recall, f1, cfm = eval_pipeline(eval2, test_feature, test_target)\n",
    "print(\"Model Config: {Benchmark Evaluation: Model2, (64, 128, Dropout, 32, 10)}\")\n",
    "print(\"ACC    :\", round(acc, 6))\n",
    "print(\"PREC   :\", round(prec, 6))\n",
    "print(\"RECALL :\", round(recall, 6))\n",
    "print(\"F1     :\", round(f1, 6))\n",
    "print(\"CONFUSION MATRIX:\\n\", pd.DataFrame(cfm.to_numpy_array().round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1.3 Results from the 3rd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Total Epoch: 1938, Round: 0\n",
      "Training on Total Epoch: 1939, Round: 1\n",
      "Training on Total Epoch: 1940, Round: 2\n",
      "Evalset: [Train : Metrics { logloss:0.0163,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0591,  }]\n",
      "Training on Total Epoch: 1941, Round: 3\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.059,  }]\n",
      "Training on Total Epoch: 1942, Round: 4\n",
      "Evalset: [Train : Metrics { logloss:0.0162,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0589,  }]\n",
      "Training on Total Epoch: 1943, Round: 5\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0587,  }]\n",
      "Training on Total Epoch: 1944, Round: 6\n",
      "Evalset: [Train : Metrics { logloss:0.0161,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0586,  }]\n",
      "Training on Total Epoch: 1945, Round: 7\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0585,  }]\n",
      "Training on Total Epoch: 1946, Round: 8\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0583,  }]\n",
      "Training on Total Epoch: 1947, Round: 9\n",
      "Evalset: [Train : Metrics { logloss:0.016,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0582,  }]\n",
      "Training on Total Epoch: 1948, Round: 10\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0582,  }]\n",
      "Training on Total Epoch: 1949, Round: 11\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1950, Round: 12\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1951, Round: 13\n",
      "Evalset: [Train : Metrics { logloss:0.0159,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1952, Round: 14\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1953, Round: 15\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1954, Round: 16\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0582,  }]\n",
      "Training on Total Epoch: 1955, Round: 17\n",
      "Evalset: [Train : Metrics { logloss:0.0158,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0583,  }]\n",
      "Training on Total Epoch: 1956, Round: 18\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0584,  }]\n",
      "Training on Total Epoch: 1957, Round: 19\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0584,  }]\n",
      "Training on Total Epoch: 1958, Round: 20\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0585,  }]\n",
      "Training on Total Epoch: 1959, Round: 21\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0585,  }]\n",
      "Training on Total Epoch: 1960, Round: 22\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0585,  }]\n",
      "Training on Total Epoch: 1961, Round: 23\n",
      "Evalset: [Train : Metrics { logloss:0.0157,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0585,  }]\n",
      "Training on Total Epoch: 1962, Round: 24\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0584,  }]\n",
      "Training on Total Epoch: 1963, Round: 25\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0583,  }]\n",
      "Training on Total Epoch: 1964, Round: 26\n",
      "Evalset: [Train : Metrics { logloss:0.0156,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0582,  }]\n",
      "Training on Total Epoch: 1965, Round: 27\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0912,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1966, Round: 28\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1967, Round: 29\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1968, Round: 30\n",
      "Evalset: [Train : Metrics { logloss:0.0155,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1969, Round: 31\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0912,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1970, Round: 32\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0913,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1971, Round: 33\n",
      "Evalset: [Train : Metrics { logloss:0.0154,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1972, Round: 34\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1973, Round: 35\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1974, Round: 36\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1975, Round: 37\n",
      "Evalset: [Train : Metrics { logloss:0.0153,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1976, Round: 38\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 1977, Round: 39\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0578,  }]\n",
      "Training on Total Epoch: 1978, Round: 40\n",
      "Evalset: [Train : Metrics { logloss:0.0152,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0921,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0578,  }]\n",
      "Training on Total Epoch: 1979, Round: 41\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0921,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0578,  }]\n",
      "Training on Total Epoch: 1980, Round: 42\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.092,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0578,  }]\n",
      "Training on Total Epoch: 1981, Round: 43\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 1982, Round: 44\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1983, Round: 45\n",
      "Evalset: [Train : Metrics { logloss:0.0151,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1984, Round: 46\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0582,  }]\n",
      "Training on Total Epoch: 1985, Round: 47\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0583,  }]\n",
      "Training on Total Epoch: 1986, Round: 48\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0919,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0583,  }]\n",
      "Training on Total Epoch: 1987, Round: 49\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0584,  }]\n",
      "Training on Total Epoch: 1988, Round: 50\n",
      "Evalset: [Train : Metrics { logloss:0.015,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0584,  }]\n",
      "Training on Total Epoch: 1989, Round: 51\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0918,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0583,  }]\n",
      "Training on Total Epoch: 1990, Round: 52\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0583,  }]\n",
      "Training on Total Epoch: 1991, Round: 53\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0917,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0582,  }]\n",
      "Training on Total Epoch: 1992, Round: 54\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0581,  }]\n",
      "Training on Total Epoch: 1993, Round: 55\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 1994, Round: 56\n",
      "Evalset: [Train : Metrics { logloss:0.0149,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 1995, Round: 57\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0578,  }]\n",
      "Training on Total Epoch: 1996, Round: 58\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0913,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 1997, Round: 59\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0913,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0576,  }]\n",
      "Training on Total Epoch: 1998, Round: 60\n",
      "Evalset: [Train : Metrics { logloss:0.0148,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0912,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0576,  }]\n",
      "Training on Total Epoch: 1999, Round: 61\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2000, Round: 62\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.091,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2001, Round: 63\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0576,  }]\n",
      "Training on Total Epoch: 2002, Round: 64\n",
      "Evalset: [Train : Metrics { logloss:0.0147,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0908,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0576,  }]\n",
      "Training on Total Epoch: 2003, Round: 65\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2004, Round: 66\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2005, Round: 67\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2006, Round: 68\n",
      "Evalset: [Train : Metrics { logloss:0.0146,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0908,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2007, Round: 69\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0908,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2008, Round: 70\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0908,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0578,  }]\n",
      "Training on Total Epoch: 2009, Round: 71\n",
      "Evalset: [Train : Metrics { logloss:0.0145,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0908,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2010, Round: 72\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 2011, Round: 73\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2012, Round: 74\n",
      "Evalset: [Train : Metrics { logloss:0.0144,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0913,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2013, Round: 75\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2014, Round: 76\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2015, Round: 77\n",
      "Evalset: [Train : Metrics { logloss:0.0143,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2016, Round: 78\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2017, Round: 79\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 2018, Round: 80\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 2019, Round: 81\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.058,  }]\n",
      "Training on Total Epoch: 2020, Round: 82\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2021, Round: 83\n",
      "Evalset: [Train : Metrics { logloss:0.0142,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2022, Round: 84\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2023, Round: 85\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2024, Round: 86\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2025, Round: 87\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0579,  }]\n",
      "Training on Total Epoch: 2026, Round: 88\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0578,  }]\n",
      "Training on Total Epoch: 2027, Round: 89\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0577,  }]\n",
      "Training on Total Epoch: 2028, Round: 90\n",
      "Evalset: [Train : Metrics { logloss:0.0141,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0576,  }]\n",
      "Training on Total Epoch: 2029, Round: 91\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0575,  }]\n",
      "Training on Total Epoch: 2030, Round: 92\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0913,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0574,  }]\n",
      "Training on Total Epoch: 2031, Round: 93\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0912,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2032, Round: 94\n",
      "Evalset: [Train : Metrics { logloss:0.014,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0572,  }]\n",
      "Training on Total Epoch: 2033, Round: 95\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.091,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0572,  }]\n",
      "Training on Total Epoch: 2034, Round: 96\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0571,  }]\n",
      "Training on Total Epoch: 2035, Round: 97\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0571,  }]\n",
      "Training on Total Epoch: 2036, Round: 98\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2037, Round: 99\n",
      "Evalset: [Train : Metrics { logloss:0.0139,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2038, Round: 100\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.091,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2039, Round: 101\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0911,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2040, Round: 102\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0913,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2041, Round: 103\n",
      "Evalset: [Train : Metrics { logloss:0.0138,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2042, Round: 104\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2043, Round: 105\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0916,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2044, Round: 106\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2045, Round: 107\n",
      "Evalset: [Train : Metrics { logloss:0.0137,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2046, Round: 108\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0915,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2047, Round: 109\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0914,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2048, Round: 110\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0912,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2049, Round: 111\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.091,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2050, Round: 112\n",
      "Evalset: [Train : Metrics { logloss:0.0136,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0909,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2051, Round: 113\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2052, Round: 114\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0906,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2053, Round: 115\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0571,  }]\n",
      "Training on Total Epoch: 2054, Round: 116\n",
      "Evalset: [Train : Metrics { logloss:0.0135,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0572,  }]\n",
      "Training on Total Epoch: 2055, Round: 117\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2056, Round: 118\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0906,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2057, Round: 119\n",
      "Evalset: [Train : Metrics { logloss:0.0134,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0906,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2058, Round: 120\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2059, Round: 121\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2060, Round: 122\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2061, Round: 123\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0906,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0572,  }]\n",
      "Training on Total Epoch: 2062, Round: 124\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0571,  }]\n",
      "Training on Total Epoch: 2063, Round: 125\n",
      "Evalset: [Train : Metrics { logloss:0.0133,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0904,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2064, Round: 126\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0904,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2065, Round: 127\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0904,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2066, Round: 128\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2067, Round: 129\n",
      "Evalset: [Train : Metrics { logloss:0.0132,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2068, Round: 130\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0906,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2069, Round: 131\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2070, Round: 132\n",
      "Evalset: [Train : Metrics { logloss:0.0131,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0907,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2071, Round: 133\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0906,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2072, Round: 134\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0905,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2073, Round: 135\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0904,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2074, Round: 136\n",
      "Evalset: [Train : Metrics { logloss:0.013,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0903,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2075, Round: 137\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0901,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2076, Round: 138\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0899,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2077, Round: 139\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2078, Round: 140\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2079, Round: 141\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2080, Round: 142\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0571,  }]\n",
      "Training on Total Epoch: 2081, Round: 143\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0572,  }]\n",
      "Training on Total Epoch: 2082, Round: 144\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2083, Round: 145\n",
      "Evalset: [Train : Metrics { logloss:0.0129,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0574,  }]\n",
      "Training on Total Epoch: 2084, Round: 146\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0574,  }]\n",
      "Training on Total Epoch: 2085, Round: 147\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0574,  }]\n",
      "Training on Total Epoch: 2086, Round: 148\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2087, Round: 149\n",
      "Evalset: [Train : Metrics { logloss:0.0128,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0572,  }]\n",
      "Training on Total Epoch: 2088, Round: 150\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2089, Round: 151\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2090, Round: 152\n",
      "Evalset: [Train : Metrics { logloss:0.0127,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2091, Round: 153\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2092, Round: 154\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2093, Round: 155\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2094, Round: 156\n",
      "Evalset: [Train : Metrics { logloss:0.0126,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2095, Round: 157\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2096, Round: 158\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2097, Round: 159\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2098, Round: 160\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2099, Round: 161\n",
      "Evalset: [Train : Metrics { logloss:0.0125,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2100, Round: 162\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2101, Round: 163\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2102, Round: 164\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0899,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2103, Round: 165\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.09,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2104, Round: 166\n",
      "Evalset: [Train : Metrics { logloss:0.0124,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0901,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2105, Round: 167\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0902,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2106, Round: 168\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0902,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2107, Round: 169\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0902,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2108, Round: 170\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0902,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2109, Round: 171\n",
      "Evalset: [Train : Metrics { logloss:0.0123,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0901,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2110, Round: 172\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0899,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2111, Round: 173\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0899,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2112, Round: 174\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0899,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2113, Round: 175\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2114, Round: 176\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2115, Round: 177\n",
      "Evalset: [Train : Metrics { logloss:0.0122,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2116, Round: 178\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2117, Round: 179\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2118, Round: 180\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0898,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2119, Round: 181\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2120, Round: 182\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2121, Round: 183\n",
      "Evalset: [Train : Metrics { logloss:0.0121,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2122, Round: 184\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2123, Round: 185\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2124, Round: 186\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2125, Round: 187\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2126, Round: 188\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2127, Round: 189\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0571,  }]\n",
      "Training on Total Epoch: 2128, Round: 190\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2129, Round: 191\n",
      "Evalset: [Train : Metrics { logloss:0.012,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0574,  }]\n",
      "Training on Total Epoch: 2130, Round: 192\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0574,  }]\n",
      "Training on Total Epoch: 2131, Round: 193\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0575,  }]\n",
      "Training on Total Epoch: 2132, Round: 194\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0574,  }]\n",
      "Training on Total Epoch: 2133, Round: 195\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2134, Round: 196\n",
      "Evalset: [Train : Metrics { logloss:0.0119,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0573,  }]\n",
      "Training on Total Epoch: 2135, Round: 197\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0572,  }]\n",
      "Training on Total Epoch: 2136, Round: 198\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0571,  }]\n",
      "Training on Total Epoch: 2137, Round: 199\n",
      "Evalset: [Train : Metrics { logloss:0.0118,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.057,  }]\n",
      "Training on Total Epoch: 2138, Round: 200\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0569,  }]\n",
      "Training on Total Epoch: 2139, Round: 201\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0568,  }]\n",
      "Training on Total Epoch: 2140, Round: 202\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2141, Round: 203\n",
      "Evalset: [Train : Metrics { logloss:0.0117,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2142, Round: 204\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2143, Round: 205\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2144, Round: 206\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2145, Round: 207\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2146, Round: 208\n",
      "Evalset: [Train : Metrics { logloss:0.0116,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2147, Round: 209\n",
      "Evalset: [Train : Metrics { logloss:0.0115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2148, Round: 210\n",
      "Evalset: [Train : Metrics { logloss:0.0115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2149, Round: 211\n",
      "Evalset: [Train : Metrics { logloss:0.0115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2150, Round: 212\n",
      "Evalset: [Train : Metrics { logloss:0.0115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2151, Round: 213\n",
      "Evalset: [Train : Metrics { logloss:0.0115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2152, Round: 214\n",
      "Evalset: [Train : Metrics { logloss:0.0115,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2153, Round: 215\n",
      "Evalset: [Train : Metrics { logloss:0.0114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2154, Round: 216\n",
      "Evalset: [Train : Metrics { logloss:0.0114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2155, Round: 217\n",
      "Evalset: [Train : Metrics { logloss:0.0114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0897,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2156, Round: 218\n",
      "Evalset: [Train : Metrics { logloss:0.0114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2157, Round: 219\n",
      "Evalset: [Train : Metrics { logloss:0.0114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2158, Round: 220\n",
      "Evalset: [Train : Metrics { logloss:0.0114,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2159, Round: 221\n",
      "Evalset: [Train : Metrics { logloss:0.0113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2160, Round: 222\n",
      "Evalset: [Train : Metrics { logloss:0.0113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2161, Round: 223\n",
      "Evalset: [Train : Metrics { logloss:0.0113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2162, Round: 224\n",
      "Evalset: [Train : Metrics { logloss:0.0113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2163, Round: 225\n",
      "Evalset: [Train : Metrics { logloss:0.0113,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2164, Round: 226\n",
      "Evalset: [Train : Metrics { logloss:0.0112,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2165, Round: 227\n",
      "Evalset: [Train : Metrics { logloss:0.0112,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2166, Round: 228\n",
      "Evalset: [Train : Metrics { logloss:0.0112,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2167, Round: 229\n",
      "Evalset: [Train : Metrics { logloss:0.0112,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2168, Round: 230\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2169, Round: 231\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2170, Round: 232\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2171, Round: 233\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2172, Round: 234\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2173, Round: 235\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2174, Round: 236\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2175, Round: 237\n",
      "Evalset: [Train : Metrics { logloss:0.0111,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2176, Round: 238\n",
      "Evalset: [Train : Metrics { logloss:0.011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2177, Round: 239\n",
      "Evalset: [Train : Metrics { logloss:0.011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2178, Round: 240\n",
      "Evalset: [Train : Metrics { logloss:0.011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2179, Round: 241\n",
      "Evalset: [Train : Metrics { logloss:0.011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2180, Round: 242\n",
      "Evalset: [Train : Metrics { logloss:0.011,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2181, Round: 243\n",
      "Evalset: [Train : Metrics { logloss:0.0109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2182, Round: 244\n",
      "Evalset: [Train : Metrics { logloss:0.0109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0566,  }]\n",
      "Training on Total Epoch: 2183, Round: 245\n",
      "Evalset: [Train : Metrics { logloss:0.0109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2184, Round: 246\n",
      "Evalset: [Train : Metrics { logloss:0.0109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0567,  }]\n",
      "Training on Total Epoch: 2185, Round: 247\n",
      "Evalset: [Train : Metrics { logloss:0.0109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2186, Round: 248\n",
      "Evalset: [Train : Metrics { logloss:0.0109,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2187, Round: 249\n",
      "Evalset: [Train : Metrics { logloss:0.0108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2188, Round: 250\n",
      "Evalset: [Train : Metrics { logloss:0.0108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2189, Round: 251\n",
      "Evalset: [Train : Metrics { logloss:0.0108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2190, Round: 252\n",
      "Evalset: [Train : Metrics { logloss:0.0108,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2191, Round: 253\n",
      "Evalset: [Train : Metrics { logloss:0.0107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2192, Round: 254\n",
      "Evalset: [Train : Metrics { logloss:0.0107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2193, Round: 255\n",
      "Evalset: [Train : Metrics { logloss:0.0107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2194, Round: 256\n",
      "Evalset: [Train : Metrics { logloss:0.0107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2195, Round: 257\n",
      "Evalset: [Train : Metrics { logloss:0.0107,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2196, Round: 258\n",
      "Evalset: [Train : Metrics { logloss:0.0106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2197, Round: 259\n",
      "Evalset: [Train : Metrics { logloss:0.0106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2198, Round: 260\n",
      "Evalset: [Train : Metrics { logloss:0.0106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2199, Round: 261\n",
      "Evalset: [Train : Metrics { logloss:0.0106,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2200, Round: 262\n",
      "Evalset: [Train : Metrics { logloss:0.0105,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2201, Round: 263\n",
      "Evalset: [Train : Metrics { logloss:0.0105,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2202, Round: 264\n",
      "Evalset: [Train : Metrics { logloss:0.0105,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2203, Round: 265\n",
      "Evalset: [Train : Metrics { logloss:0.0105,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2204, Round: 266\n",
      "Evalset: [Train : Metrics { logloss:0.0104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2205, Round: 267\n",
      "Evalset: [Train : Metrics { logloss:0.0104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2206, Round: 268\n",
      "Evalset: [Train : Metrics { logloss:0.0104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2207, Round: 269\n",
      "Evalset: [Train : Metrics { logloss:0.0104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2208, Round: 270\n",
      "Evalset: [Train : Metrics { logloss:0.0104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2209, Round: 271\n",
      "Evalset: [Train : Metrics { logloss:0.0104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2210, Round: 272\n",
      "Evalset: [Train : Metrics { logloss:0.0104,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2211, Round: 273\n",
      "Evalset: [Train : Metrics { logloss:0.0103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2212, Round: 274\n",
      "Evalset: [Train : Metrics { logloss:0.0103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2213, Round: 275\n",
      "Evalset: [Train : Metrics { logloss:0.0103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2214, Round: 276\n",
      "Evalset: [Train : Metrics { logloss:0.0103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2215, Round: 277\n",
      "Evalset: [Train : Metrics { logloss:0.0103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2216, Round: 278\n",
      "Evalset: [Train : Metrics { logloss:0.0103,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2217, Round: 279\n",
      "Evalset: [Train : Metrics { logloss:0.0102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2218, Round: 280\n",
      "Evalset: [Train : Metrics { logloss:0.0102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2219, Round: 281\n",
      "Evalset: [Train : Metrics { logloss:0.0102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2220, Round: 282\n",
      "Evalset: [Train : Metrics { logloss:0.0102,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2221, Round: 283\n",
      "Evalset: [Train : Metrics { logloss:0.0101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2222, Round: 284\n",
      "Evalset: [Train : Metrics { logloss:0.0101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2223, Round: 285\n",
      "Evalset: [Train : Metrics { logloss:0.0101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2224, Round: 286\n",
      "Evalset: [Train : Metrics { logloss:0.0101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2225, Round: 287\n",
      "Evalset: [Train : Metrics { logloss:0.0101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2226, Round: 288\n",
      "Evalset: [Train : Metrics { logloss:0.0101,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2227, Round: 289\n",
      "Evalset: [Train : Metrics { logloss:0.01,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2228, Round: 290\n",
      "Evalset: [Train : Metrics { logloss:0.01,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2229, Round: 291\n",
      "Evalset: [Train : Metrics { logloss:0.01,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2230, Round: 292\n",
      "Evalset: [Train : Metrics { logloss:0.01,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0892,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2231, Round: 293\n",
      "Evalset: [Train : Metrics { logloss:0.01,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2232, Round: 294\n",
      "Evalset: [Train : Metrics { logloss:0.01,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2233, Round: 295\n",
      "Evalset: [Train : Metrics { logloss:0.0099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2234, Round: 296\n",
      "Evalset: [Train : Metrics { logloss:0.0099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2235, Round: 297\n",
      "Evalset: [Train : Metrics { logloss:0.0099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2236, Round: 298\n",
      "Evalset: [Train : Metrics { logloss:0.0099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2237, Round: 299\n",
      "Evalset: [Train : Metrics { logloss:0.0099,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2238, Round: 300\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2239, Round: 301\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2240, Round: 302\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2241, Round: 303\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0896,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2242, Round: 304\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0895,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2243, Round: 305\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0894,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2244, Round: 306\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0893,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2245, Round: 307\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0891,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2246, Round: 308\n",
      "Evalset: [Train : Metrics { logloss:0.0097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.089,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2247, Round: 309\n",
      "Evalset: [Train : Metrics { logloss:0.0097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2248, Round: 310\n",
      "Evalset: [Train : Metrics { logloss:0.0097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2249, Round: 311\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2250, Round: 312\n",
      "Evalset: [Train : Metrics { logloss:0.0098,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0565,  }]\n",
      "Training on Total Epoch: 2251, Round: 313\n",
      "Evalset: [Train : Metrics { logloss:0.0097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2252, Round: 314\n",
      "Evalset: [Train : Metrics { logloss:0.0097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2253, Round: 315\n",
      "Evalset: [Train : Metrics { logloss:0.0097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2254, Round: 316\n",
      "Evalset: [Train : Metrics { logloss:0.0097,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2255, Round: 317\n",
      "Evalset: [Train : Metrics { logloss:0.0096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2256, Round: 318\n",
      "Evalset: [Train : Metrics { logloss:0.0096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2257, Round: 319\n",
      "Evalset: [Train : Metrics { logloss:0.0096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2258, Round: 320\n",
      "Evalset: [Train : Metrics { logloss:0.0096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2259, Round: 321\n",
      "Evalset: [Train : Metrics { logloss:0.0096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2260, Round: 322\n",
      "Evalset: [Train : Metrics { logloss:0.0096,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2261, Round: 323\n",
      "Evalset: [Train : Metrics { logloss:0.0095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2262, Round: 324\n",
      "Evalset: [Train : Metrics { logloss:0.0095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2263, Round: 325\n",
      "Evalset: [Train : Metrics { logloss:0.0095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2264, Round: 326\n",
      "Evalset: [Train : Metrics { logloss:0.0095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2265, Round: 327\n",
      "Evalset: [Train : Metrics { logloss:0.0095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2266, Round: 328\n",
      "Evalset: [Train : Metrics { logloss:0.0095,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2267, Round: 329\n",
      "Evalset: [Train : Metrics { logloss:0.0094,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2268, Round: 330\n",
      "Evalset: [Train : Metrics { logloss:0.0094,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2269, Round: 331\n",
      "Evalset: [Train : Metrics { logloss:0.0094,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2270, Round: 332\n",
      "Evalset: [Train : Metrics { logloss:0.0094,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2271, Round: 333\n",
      "Evalset: [Train : Metrics { logloss:0.0094,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2272, Round: 334\n",
      "Evalset: [Train : Metrics { logloss:0.0093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0564,  }]\n",
      "Training on Total Epoch: 2273, Round: 335\n",
      "Evalset: [Train : Metrics { logloss:0.0093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0563,  }]\n",
      "Training on Total Epoch: 2274, Round: 336\n",
      "Evalset: [Train : Metrics { logloss:0.0093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2275, Round: 337\n",
      "Evalset: [Train : Metrics { logloss:0.0093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2276, Round: 338\n",
      "Evalset: [Train : Metrics { logloss:0.0093,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2277, Round: 339\n",
      "Evalset: [Train : Metrics { logloss:0.0092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2278, Round: 340\n",
      "Evalset: [Train : Metrics { logloss:0.0092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2279, Round: 341\n",
      "Evalset: [Train : Metrics { logloss:0.0092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0554,  }]\n",
      "Training on Total Epoch: 2280, Round: 342\n",
      "Evalset: [Train : Metrics { logloss:0.0092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0553,  }]\n",
      "Training on Total Epoch: 2281, Round: 343\n",
      "Evalset: [Train : Metrics { logloss:0.0092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0553,  }]\n",
      "Training on Total Epoch: 2282, Round: 344\n",
      "Evalset: [Train : Metrics { logloss:0.0092,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0553,  }]\n",
      "Training on Total Epoch: 2283, Round: 345\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0554,  }]\n",
      "Training on Total Epoch: 2284, Round: 346\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0889,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0554,  }]\n",
      "Training on Total Epoch: 2285, Round: 347\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0888,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2286, Round: 348\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0887,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2287, Round: 349\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0886,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2288, Round: 350\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2289, Round: 351\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2290, Round: 352\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2291, Round: 353\n",
      "Evalset: [Train : Metrics { logloss:0.0091,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2292, Round: 354\n",
      "Evalset: [Train : Metrics { logloss:0.009,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2293, Round: 355\n",
      "Evalset: [Train : Metrics { logloss:0.009,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2294, Round: 356\n",
      "Evalset: [Train : Metrics { logloss:0.009,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2295, Round: 357\n",
      "Evalset: [Train : Metrics { logloss:0.009,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2296, Round: 358\n",
      "Evalset: [Train : Metrics { logloss:0.009,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2297, Round: 359\n",
      "Evalset: [Train : Metrics { logloss:0.0089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2298, Round: 360\n",
      "Evalset: [Train : Metrics { logloss:0.0089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2299, Round: 361\n",
      "Evalset: [Train : Metrics { logloss:0.0089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2300, Round: 362\n",
      "Evalset: [Train : Metrics { logloss:0.0089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2301, Round: 363\n",
      "Evalset: [Train : Metrics { logloss:0.0089,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2302, Round: 364\n",
      "Evalset: [Train : Metrics { logloss:0.0088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2303, Round: 365\n",
      "Evalset: [Train : Metrics { logloss:0.0088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2304, Round: 366\n",
      "Evalset: [Train : Metrics { logloss:0.0088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2305, Round: 367\n",
      "Evalset: [Train : Metrics { logloss:0.0088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2306, Round: 368\n",
      "Evalset: [Train : Metrics { logloss:0.0088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2307, Round: 369\n",
      "Evalset: [Train : Metrics { logloss:0.0088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2308, Round: 370\n",
      "Evalset: [Train : Metrics { logloss:0.0088,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2309, Round: 371\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2310, Round: 372\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0885,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2311, Round: 373\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2312, Round: 374\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2313, Round: 375\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0561,  }]\n",
      "Training on Total Epoch: 2314, Round: 376\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0884,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2315, Round: 377\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2316, Round: 378\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0883,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0562,  }]\n",
      "Training on Total Epoch: 2317, Round: 379\n",
      "Evalset: [Train : Metrics { logloss:0.0087,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2318, Round: 380\n",
      "Evalset: [Train : Metrics { logloss:0.0086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2319, Round: 381\n",
      "Evalset: [Train : Metrics { logloss:0.0086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2320, Round: 382\n",
      "Evalset: [Train : Metrics { logloss:0.0086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2321, Round: 383\n",
      "Evalset: [Train : Metrics { logloss:0.0086,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0882,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2322, Round: 384\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0553,  }]\n",
      "Training on Total Epoch: 2323, Round: 385\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0552,  }]\n",
      "Training on Total Epoch: 2324, Round: 386\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0551,  }]\n",
      "Training on Total Epoch: 2325, Round: 387\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0551,  }]\n",
      "Training on Total Epoch: 2326, Round: 388\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0551,  }]\n",
      "Training on Total Epoch: 2327, Round: 389\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0552,  }]\n",
      "Training on Total Epoch: 2328, Round: 390\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0553,  }]\n",
      "Training on Total Epoch: 2329, Round: 391\n",
      "Evalset: [Train : Metrics { logloss:0.0085,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0554,  }]\n",
      "Training on Total Epoch: 2330, Round: 392\n",
      "Evalset: [Train : Metrics { logloss:0.0084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2331, Round: 393\n",
      "Evalset: [Train : Metrics { logloss:0.0084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0877,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2332, Round: 394\n",
      "Evalset: [Train : Metrics { logloss:0.0084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2333, Round: 395\n",
      "Evalset: [Train : Metrics { logloss:0.0084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0874,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2334, Round: 396\n",
      "Evalset: [Train : Metrics { logloss:0.0084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0874,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.056,  }]\n",
      "Training on Total Epoch: 2335, Round: 397\n",
      "Evalset: [Train : Metrics { logloss:0.0084,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0874,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0559,  }]\n",
      "Training on Total Epoch: 2336, Round: 398\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0874,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2337, Round: 399\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0874,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0558,  }]\n",
      "Training on Total Epoch: 2338, Round: 400\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0875,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2339, Round: 401\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0875,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0557,  }]\n",
      "Training on Total Epoch: 2340, Round: 402\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0875,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2341, Round: 403\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0875,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0556,  }]\n",
      "Training on Total Epoch: 2342, Round: 404\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0555,  }]\n",
      "Training on Total Epoch: 2343, Round: 405\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0554,  }]\n",
      "Training on Total Epoch: 2344, Round: 406\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0554,  }]\n",
      "Training on Total Epoch: 2345, Round: 407\n",
      "Evalset: [Train : Metrics { logloss:0.0083,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0553,  }]\n",
      "Training on Total Epoch: 2346, Round: 408\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0551,  }]\n",
      "Training on Total Epoch: 2347, Round: 409\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0876,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0549,  }]\n",
      "Training on Total Epoch: 2348, Round: 410\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0548,  }]\n",
      "Training on Total Epoch: 2349, Round: 411\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0878,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0548,  }]\n",
      "Training on Total Epoch: 2350, Round: 412\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0548,  }]\n",
      "Training on Total Epoch: 2351, Round: 413\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0879,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0548,  }]\n",
      "Training on Total Epoch: 2352, Round: 414\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0548,  }]\n",
      "Training on Total Epoch: 2353, Round: 415\n",
      "Evalset: [Train : Metrics { logloss:0.0082,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0548,  }]\n",
      "Training on Total Epoch: 2354, Round: 416\n",
      "Evalset: [Train : Metrics { logloss:0.0081,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.088,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0549,  }]\n",
      "Training on Total Epoch: 2355, Round: 417\n",
      "Evalset: [Train : Metrics { logloss:0.0081,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.055,  }]\n",
      "Training on Total Epoch: 2356, Round: 418\n",
      "Evalset: [Train : Metrics { logloss:0.0081,  }]\n",
      "Evalset: [Valid : Metrics { logloss:0.0881,  }]\n",
      "Evalset: [Test : Metrics { logloss:0.0551,  }]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN Simple Interf Evaluator(name = Eval_3, task = classification, has trained n_epoch = 2357, n_step = 4714)."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Evaluate the model - Benchmark Model 3 - 3 Layers, Large Sized Model with Higher Rate Dropout\n",
    "#\n",
    "\n",
    "model3 = Model_3(backend=backend, device=device, autograd=False)\n",
    "crit3 = MultiCrossEntropy(eps = 1e-10, raw_logits=False, backend=backend, device=device, autograd=False)\n",
    "optm3 = AdamW(model3.parameters(), lr = 1e-4, eps = 1e-10, backend=backend, device=device, autograd=False)\n",
    "eval3 = Evaluator(\"Eval_3\", task = \"classification\", module=model3, criterion=crit3, optimizer=optm3)\n",
    "\n",
    "# Start to train the model\n",
    "eval3.fit(\n",
    "    X = train_feature, y = train_target,\n",
    "    epoches = 5000,\n",
    "    batch_size = 2048,\n",
    "    shuffle = True,\n",
    "    random_state = None,\n",
    "    one_hot = True,\n",
    "    verbosity = 1,\n",
    "    evalper = 1,\n",
    "    evalset = {\n",
    "        \"Train\": (train_feature, train_target),\n",
    "        \"Valid\": (valid_feature, valid_target),\n",
    "        \"Test\":  (test_feature, test_target)\n",
    "    },\n",
    "    evalmetrics = [\"logloss\"],\n",
    "    early_stop = 5,\n",
    "    early_stop_logic = \"most\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Config: {Benchmark Evaluation: Model3, (64, 256, Dropout, 128, Dropout, 10)}\n",
      "ACC    : 0.983096\n",
      "PREC   : 0.983669\n",
      "RECALL : 0.983208\n",
      "F1     : 0.983318\n",
      "CONFUSION MATRIX:\n",
      "         0       1    2       3       4       5       6       7       8       9\n",
      "0  0.9918  0.0000  0.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "1  0.0000  0.9664  0.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "2  0.0000  0.0090  1.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "3  0.0000  0.0000  0.0  0.9752  0.0000  0.0413  0.0000  0.0083  0.0000  0.0083\n",
      "4  0.0085  0.0000  0.0  0.0000  0.9831  0.0000  0.0085  0.0000  0.0000  0.0000\n",
      "5  0.0000  0.0000  0.0  0.0081  0.0081  0.9593  0.0000  0.0000  0.0000  0.0000\n",
      "6  0.0000  0.0000  0.0  0.0000  0.0000  0.0000  0.9907  0.0000  0.0000  0.0000\n",
      "7  0.0000  0.0000  0.0  0.0000  0.0000  0.0000  0.0000  0.9903  0.0000  0.0000\n",
      "8  0.0000  0.0316  0.0  0.0211  0.0000  0.0000  0.0000  0.0000  0.9895  0.0000\n",
      "9  0.0000  0.0000  0.0  0.0000  0.0095  0.0000  0.0000  0.0000  0.0095  0.9905\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the model - Benchmark Model 3 - 3 Layers, Large Sized Model with Higher Rate Dropout\n",
    "# \n",
    "\n",
    "# Print the results for the test-set\n",
    "eval3.eval()\n",
    "pred, acc, prec, recall, f1, cfm = eval_pipeline(eval3, test_feature, test_target)\n",
    "print(\"Model Config: {Benchmark Evaluation: Model3, (64, 256, Dropout, 128, Dropout, 10)}\")\n",
    "print(\"ACC    :\", round(acc, 6))\n",
    "print(\"PREC   :\", round(prec, 6))\n",
    "print(\"RECALL :\", round(recall, 6))\n",
    "print(\"F1     :\", round(f1, 6))\n",
    "print(\"CONFUSION MATRIX:\\n\", pd.DataFrame(cfm.to_numpy_array().round(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of saving the Gradient Boosting model to disk.\n",
    "#\n",
    "\n",
    "# |\n",
    "# V De-comment this line to save the model.\n",
    "# model2.save(model2, \"./models/MLP.ID02.bin\")\n",
    "\n",
    "# |\n",
    "# V De-comment this line to save the evaluator.\n",
    "# eval3.save(eval3, \"./models/MLP.EVAL03.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.3.2 Visualization of the predictions and training process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training/validation loss over epochs\n",
    "\n",
    "# Collect train-valid losses\n",
    "def collect_losses(evaluator: nn_SInterf_Evaluator, \n",
    "                   metric = \"logloss\",\n",
    "                   collect = [\"Train\", \"Valid\"]) -> Tuple[dict, pd.DataFrame]:\n",
    "\n",
    "    evalhist = deepcopy(evaluator.evalhist_)\n",
    "    evaldict = {}\n",
    "    evaldict[\"No\"] = []\n",
    "    for c in collect:\n",
    "        evaldict[c] = []\n",
    "\n",
    "    # For each, extract data as float types\n",
    "    for k in evalhist.keys():\n",
    "        obj = evalhist[k]\n",
    "        # No self-increment\n",
    "        evaldict[\"No\"].append(k)\n",
    "        for c in collect:\n",
    "            data = obj[c][metric].to_list()\n",
    "            evaldict[c].append(data)\n",
    "\n",
    "    return evaldict, pd.DataFrame(evaldict)\n",
    "\n",
    "# Plot train/train-valid losses\n",
    "def plot_loss(df, xlabel_: str | None = None):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.collections import LineCollection\n",
    "    from matplotlib.colors import Normalize\n",
    "\n",
    "    if 'No' in df.columns:\n",
    "        x = df['No'].values\n",
    "        xlabel = 'Epoch'\n",
    "    else:\n",
    "        x = np.arange(len(df))\n",
    "        xlabel = 'Index' if xlabel_ is None else xlabel_\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "    # Plot training loss with gradient color\n",
    "    y_train = df['Train'].values\n",
    "    pts_train = np.array([x, y_train]).T.reshape(-1, 1, 2)\n",
    "    segs_train = np.concatenate([pts_train[:-1], pts_train[1:]], axis=1)\n",
    "    norm_train = Normalize(vmin=y_train.min(), vmax=y_train.max())\n",
    "    lc_train = LineCollection(segs_train, cmap='viridis', norm=norm_train)\n",
    "    lc_train.set_array(y_train)\n",
    "    lc_train.set_linewidth(2)\n",
    "    ax.add_collection(lc_train)\n",
    "    cbar_train = fig.colorbar(lc_train, ax=ax, pad=0.02)\n",
    "    cbar_train.set_label('Loss')\n",
    "\n",
    "    # Plot validation loss if available\n",
    "    if 'Valid' in df.columns:\n",
    "        y_valid = df['Valid'].values\n",
    "        pts_valid = np.array([x, y_valid]).T.reshape(-1, 1, 2)\n",
    "        segs_valid = np.concatenate([pts_valid[:-1], pts_valid[1:]], axis=1)\n",
    "        norm_valid = Normalize(vmin=y_valid.min(), vmax=y_valid.max())\n",
    "        lc_valid = LineCollection(segs_valid, cmap='plasma', norm=norm_valid)\n",
    "        lc_valid.set_array(y_valid)\n",
    "        lc_valid.set_linewidth(2)\n",
    "        ax.add_collection(lc_valid)\n",
    "\n",
    "    ax.set_xlim(x.min(), x.max())\n",
    "    y_min = y_train.min()\n",
    "    y_max = y_train.max()\n",
    "    if 'Valid' in df.columns:\n",
    "        y_min = min(y_min, y_valid.min())\n",
    "        y_max = max(y_max, y_valid.max())\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Loss Over {}s'.format(xlabel))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses across steps\n",
    "\n",
    "step_losses = pd.DataFrame({\"Train\": eval3.losses_.values()}, index=list(eval3.losses_.keys()))\n",
    "plot_loss(step_losses, xlabel_=\"Steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the epoch-wise Train/Validation change\n",
    "\n",
    "evaldict, losses = collect_losses(eval3)\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze overfitting vs underfitting and architectural choices\n",
    "\n",
    "# My models demonstrate progressively improving performance (ACC: 97.6% to 98.3%)\n",
    "#   with increasing architectural complexity and dropout/L2 regularization.\n",
    "# Underfitting: Not evident, as all models achieve strong test metrics (>97.5% ACC) on MNIST, \n",
    "#   indicating sufficient capacity to learn the dataset's patterns.\n",
    "# Overfitting: Mitigated by dropout layers (Model2/3), which regularize training and reduce co-adaptation \n",
    "#   of neurons. The consistent improvement in test performance with added complexity suggests effective generalization.\n",
    "# Note, albeit you have dropout and L2 regularization, if training for a prolonged steps, overfitting may happen.\n",
    "# An example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here is an example of overfitted model\n",
    "\n",
    "# BAD EXAMPLE: with overfitting\n",
    "modelx = Model_3(backend=backend, device=device, autograd=False)\n",
    "critx = MultiCrossEntropy(eps = 1e-10, raw_logits=False, backend=backend, device=device, autograd=False)\n",
    "optmx = AdamW(modelx.parameters(), lr = 1e-4, eps = 1e-10, backend=backend, device=device, autograd=False)\n",
    "evalx = Evaluator(\"Eval_x\", task = \"classification\", module=modelx, criterion=critx, optimizer=optmx)\n",
    "\n",
    "# Start to train the model\n",
    "evalx.fit(\n",
    "    X = train_feature, y = train_target,\n",
    "    epoches = 5000,\n",
    "    batch_size = 2048,\n",
    "    shuffle = True,\n",
    "    random_state = None,\n",
    "    one_hot = True,\n",
    "    verbosity = 1,\n",
    "    evalper = 10,\n",
    "    evalset = {\n",
    "        \"Train\": (train_feature, train_target),\n",
    "        \"Valid\": (valid_feature, valid_target),\n",
    "        \"Test\":  (test_feature, test_target)\n",
    "    },\n",
    "    evalmetrics = [\"logloss\"],\n",
    ")\n",
    "\n",
    "evaldict, losses = collect_losses(evalx)\n",
    "plot_loss(losses.iloc[100:-1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significant overfitting detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`End of Homework 3 Q3 by Nathmath Huang (bh2821)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
